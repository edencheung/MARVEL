================================ System Message ================================


    You are a supervisor agent in a multi-agent system focused on identifying hardware security vulnerabilities in RTL code. 
    Your objective is to analyze the given SoC and generate a detailed security report.

    You have access to the following tools: ['run_anomaly_detector_agent', 'run_llm_cwe_checker_agent', 'run_similar_bug_agent', 'list_dir', 'read_file', 'read_file_with_line_numbers']. Each tool specializes in a specific task:

    - CWE Agent: Given a Verilog file, a top module, and a security aspect, this agent maps the RTL code to relevant CWEs and detects CWE-related vulnerabilities.
    - Similar Bug Agent: Accepts a file path and a line number (where a bug was found) to locate similar patterns or recurring bugs throughout the RTL code.

    Instructions for analysis:

    - Read the documentataion to identify security features and register interfaces policies.
    - Read through the different systemverilog files to probe for issues and use the anomaly agent
    - If a bug is detected but not localized, use the CWE Agent to further inspect the related security aspect in the surrounding RTL.
    - After detecting any bugs, use the Similar Bug Agent to scan similar files (of the same or of different IPs) for similar vulnerabilities.

    Output Format:

    - For each identified issue, report:
    - File name
    - Line number(s)
    - Brief description of the issue
    - Security aspect affected
    - Tools used to identify the issue

    When your analysis is complete, end your response with "END".
    
================================ Human Message =================================

Identify security issues in the otbn IP of the OpenTitan SoC, located at /home/eden/Desktop/Code/HACK@CHES/p2/opentitan.

    - All IPs are located in the 'hw/ip' directory.
    - RTL code for each IP is located in its 'rtl' subdirectory, with source files having the '.sv' extension.
        - reg_top files contain the register interface for the IP.
        - control/fsm files contain the control logic for the IP.
        - core files contain the core logic for the IP.
    - Documentation files (.md) are located in the 'doc' directories of each IP.
        - theory_of_operation explains the properties of the IP and its security features.
        - registers.md files contain the register interface and its read/write access policies.
    - Ignore '.core' files; they are used by build tools and are not relevant for security analysis.

    Focus on the otbn IP and make sure to analyze it thoroughly.

    First, identify the relevant security properties and read/write policies of the register interfaces from the documentation. 
    Then, use all available tools to perform a comprehensive security analysis on the RTL code.
    
================================== Ai Message ==================================
Tool Calls:
  list_dir (call_dMLjQTNZ4lwIK5m9EEeUNRuD)
 Call ID: call_dMLjQTNZ4lwIK5m9EEeUNRuD
  Args:
    dir_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn
================================= Tool Message =================================
Name: list_dir

Files in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn:
.flake8 otbn_pkg.core README.md BUILD defs.bzl otbn.core

Directories in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn:
data pre_syn syn dv util rtl lint doc pre_sca
================================== Ai Message ==================================
Tool Calls:
  list_dir (call_L4famYRZY4xhzKEZPkWNSFX6)
 Call ID: call_L4famYRZY4xhzKEZPkWNSFX6
  Args:
    dir_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/doc
================================= Tool Message =================================
Name: list_dir

Files in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/doc:
registers.md interfaces.md otbn_intro.md otbn_blockarch.svg checklist.md otbn_development_process.svg programmers_guide.md otbn_operational_states.svg otbn_operation.svg rshi.svg isa.md developing_otbn.md theory_of_operation.md

Directories in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/doc:

================================== Ai Message ==================================
Tool Calls:
  read_file (call_njugBy5StcXLKN4FBmPhHari)
 Call ID: call_njugBy5StcXLKN4FBmPhHari
  Args:
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/doc/theory_of_operation.md
================================= Tool Message =================================
Name: read_file

# Theory of Operation

## Block Diagram

![OTBN architecture block diagram](./otbn_blockarch.svg)

## Design Details

### Memories

The OTBN processor core has access to two dedicated memories: an instruction memory (IMEM), and a data memory (DMEM).
The IMEM is 8 KiB, the DMEM is 4 KiB.

The memory layout follows the Harvard architecture.
Both memories are byte-addressed, with addresses starting at 0.

The instruction memory (IMEM) is 32b wide and provides the instruction stream to the OTBN processor.
It cannot be read from or written to by user code through load or store instructions.

The data memory (DMEM) is 256b wide and read-write accessible from the base and big number instruction subsets of the OTBN processor core.
There are four instructions that can access data memory.
In the base instruction subset, there are {{#otbn-insn-ref LW}} (load word) and {{#otbn-insn-ref SW}} (store word).
These access 32b-aligned 32b words.
In the big number instruction subset, there are {{#otbn-insn-ref BN.LID}} (load indirect) and {{#otbn-insn-ref BN.SID}} (store indirect).
These access 256b-aligned 256b words.

Both memories can be accessed through OTBN's register interface ([`DMEM`](registers.md#dmem) and [`IMEM`](registers.md#imem)).
All memory accesses through the register interface must be word-aligned 32b word accesses.

When OTBN is in any state other than [idle](#operational-states), reads return zero and writes have no effect.
Furthermore, a memory access when OTBN is neither idle nor locked will cause OTBN to generate a fatal error with code `ILLEGAL_BUS_ACCESS`.
A host processor can check whether OTBN is busy by reading the [`STATUS`](registers.md#status) register.

The underlying memories used to implement the IMEM and DMEM may not grant all access requests (see [Memory Scrambling](#memory-scrambling) for details).
A request won't be granted if new scrambling keys have been requested for the memory that aren't yet available.
Functionally it should be impossible for either OTBN or a host processor to make a memory request whilst new scrambling keys are unavailable.
OTBN is in the busy state whilst keys are requested so OTBN will not execute any programs and a host processor access will generated an `ILLEGAL_BUS_ACCESS` fatal error.
Should a request not be granted due to a fault, a `BAD_INTERNAL_STATE` fatal error will be raised.

While DMEM is 4kiB, only the first 3kiB (at addresses `0x0` to `0xbff`) is visible through the register interface.
This is to allow OTBN applications to store sensitive information in the other 1kiB, making it harder for that information to leak back to Ibex.

Each memory write through the register interface updates a checksum.
See the [Memory Load Integrity](#memory-load-integrity) section for more details.

### Instruction Prefetch

OTBN employs an instruction prefetch stage to enable pre-decoding of instructions to enable the [blanking SCA hardening measure](#blanking).
Its operation is entirely transparent to software.
It does not speculate and will only prefetch where the next instruction address can be known.
This results in a stall cycle for all conditional branches and jumps as the result is neither predicted nor known ahead of time.
Instruction bits held in the prefetch buffer are unscrambled but use the integrity protection described in [Data Integrity Protection](#data-integrity-protection).

### Random Numbers

OTBN is connected to the [Entropy Distribution Network (EDN)](../../edn/README.md) which can provide random numbers via the `RND` and `URND` CSRs and WSRs.

`RND` provides bits taken directly from the EDN connected via `edn_rnd`.
The EDN interface provides 32b of entropy per transaction and comes from a different clock domain to the OTBN core.
A FIFO is used to synchronize the incoming package to the OTBN clock domain.
Synchronized packages are then set starting from bottom up to a single `WLEN` value of 256b.
In order to service a single EDN request, a total of 8 transactions are required from EDN interface.

The `RND` CSR and WSR take their bits from the same source.
A read from the `RND` CSR returns the bottom 32b; the other 192b are discarded.
On a read from the `RND` CSR or WSR, OTBN will stall while it waits for data.
It will resume execution on the cycle after it receives the final word of data from the EDN.

As an EDN request can take time, `RND` is backed by a single-entry cache containing the result of the most recent EDN request in OTBN core level.
Writing any value to the `RND_PREFETCH` CSR initiates a prefetch.
This requests data from the EDN, storing it in the cache, and can hide the EDN latency.
Writes to `RND_PREFETCH` will be ignored whilst a prefetch is in progress or when the cache is already full.
If the cache is full, a read from `RND` returns immediately with the contents of the cache, which is then emptied.
If the cache is not full, a read from `RND` will block as described above until OTBN receives the final word of data from the EDN.

OTBN discards any data that is in the cache at the start of an operation.
If there is still a pending prefetch when an OTBN operation starts, the results of the prefetch will also discarded.

`URND` provides bits from a local XoShiRo256++ PRNG within OTBN; reads from it never stall.
This PRNG is seeded once from the EDN connected via `edn_urnd` when OTBN starts execution.
Each new execution of OTBN will reseed the `URND` PRNG.
The PRNG state is advanced every cycle when OTBN is running.

The PRNG has a long cycle length but has a fixed point: the sequence of numbers will get stuck if the state ever happens to become zero.
This will never happen in normal operation.
If a fault causes the state to become zero, OTBN raises a `BAD_INTERNAL_STATE` fatal error.

### Operational States

<!--
Source: https://docs.google.com/drawings/d/1C0D4UriRk5pKGFoFtAXYLcJ1oBG1BCDd2omCLPYHtr0/edit

Download the SVG from Google Draw, open it in Inkscape once and save it without changes to add width/height information to the image.
-->
![OTBN operational states](./otbn_operational_states.svg)

OTBN can be in different operational states.
After reset (*init*), OTBN performs a secure wipe of the internal state and then becomes *idle*.
OTBN is *busy* for as long it is performing an operation.
OTBN is *locked* if a fatal error was observed or after handling an RMA request.

The current operational state is reflected in the [`STATUS`](registers.md#status) register.
- After reset, OTBN is busy with the internal secure wipe and the [`STATUS`](registers.md#status) register is set to `BUSY_SEC_WIPE_INT`.
- If OTBN is idle, the [`STATUS`](registers.md#status) register is set to `IDLE`.
- If OTBN is busy, the [`STATUS`](registers.md#status) register is set to one of the values starting with `BUSY_`.
- If OTBN is locked, the [`STATUS`](registers.md#status) register is set to `LOCKED`.

OTBN transitions into the busy state as result of host software [issuing a command](#operations-and-commands); OTBN is then said to perform an operation.
OTBN transitions out of the busy state whenever the operation has completed.
In the [`STATUS`](registers.md#status) register the different `BUSY_*` values represent the operation that is currently being performed.

A transition out of the busy state is signaled by the `done` interrupt ([`INTR_STATE.done`](registers.md#intr_state)).

The locked state is a terminal state; transitioning out of it requires an OTBN reset.

### Operations and Commands

OTBN understands a set of commands to perform certain operations.
Commands are issued by writing to the [`CMD`](registers.md#cmd) register.

The `EXECUTE` command starts the [execution of the application](#software-execution) contained in OTBN's instruction memory.

The `SEC_WIPE_DMEM` command [securely wipes the data memory](#secure-wipe).

The `SEC_WIPE_IMEM` command [securely wipes the instruction memory](#secure-wipe).

### Software Execution

Software execution on OTBN is triggered by host software by [issuing the `EXECUTE` command](#operations-and-commands).
The software then runs to completion, without the ability for host software to interrupt or inspect the execution.

- OTBN transitions into the busy state, and reflects this by setting [`STATUS`](registers.md#status) to `BUSY_EXECUTE`.
- The internal randomness source, which provides random numbers to the `URND` CSR and WSR, is re-seeded from the EDN.
- The instruction at address zero is fetched and executed.
- From this point on, all subsequent instructions are executed according to their semantics until either an {{#otbn-insn-ref ECALL}} instruction is executed, or an error is detected.
- A [secure wipe of internal state](#internal-state-secure-wipe) is performed.
- The [`ERR_BITS`](registers.md#err_bits) register is set to indicate either a successful execution (value `0`), or to indicate the error that was observed (a non-zero value).
- OTBN transitions into the [idle state](#operational-states) (in case of a successful execution, or a recoverable error) or the locked state (in case of a fatal error).
  This transition is signaled by raising the `done` interrupt ([`INTR_STATE.done`](registers.md#intr_state)), and reflected in the [`STATUS`](registers.md#status) register.

### Errors

OTBN is able to detect a range of errors, which are classified as *software errors* or *fatal errors*.
A software error is an error in the code that OTBN executes.
In the absence of an attacker, these errors are due to a programmer's mistake.
A fatal error is typically the violation of a security property.
All errors and their classification are listed in the [List of Errors](#list-of-errors).

Whenever an error is detected, OTBN reacts locally, and informs the OpenTitan system about it by raising an alert.
OTBN generally does not try to recover from errors itself, and provides no error handling support to code that runs on it.

OTBN gives host software the option to recover from some errors by restarting the operation.
All software errors are treated as recoverable, unless [`CTRL.software_errs_fatal`](registers.md#ctrl) is set, and are handled as described in the section [Reaction to Recoverable Errors](#reaction-to-recoverable-errors).
When [`CTRL.software_errs_fatal`](registers.md#ctrl) is set, software errors become fatal errors.

Fatal errors are treated as described in the section [Reaction to Fatal Errors](#reaction-to-fatal-errors).

### Reaction to Recoverable Errors

Recoverable errors can be the result of a programming error in OTBN software.
Recoverable errors can only occur during the execution of software on OTBN, and not in other situations in which OTBN might be busy.

The following actions are taken when OTBN detects a recoverable error:

1. The currently running operation is terminated, similar to the way an {{#otbn-insn-ref ECALL}} instruction [is executed](#returning-from-an-application):
   - No more instructions are fetched or executed.
   - A [secure wipe of internal state](#internal-state-secure-wipe) is performed.
   - The [`ERR_BITS`](registers.md#err_bits) register is set to a non-zero value that describes the error.
   - The current operation is marked as complete by setting [`INTR_STATE.done`](registers.md#intr_state).
   - The [`STATUS`](registers.md#status) register is set to `IDLE`.
2. A [recoverable alert](#alerts) is raised.

The host software can start another operation on OTBN after a recoverable error was detected.

### Reaction to Fatal Errors

Fatal errors are generally seen as a sign of an intrusion, resulting in more drastic measures to protect the secrets stored within OTBN.
Fatal errors can occur at any time, even when an OTBN operation isn't in progress.

The following actions are taken when OTBN detects a fatal error:

1. A [secure wipe of the data memory](#data-memory-dmem-secure-wipe) and a [secure wipe of the instruction memory](#instruction-memory-imem-secure-wipe) is initiated.
2. If OTBN [is not idle](#operational-states), then the currently running operation is terminated, similarly to how an operation ends after an {{#otbn-insn-ref ECALL}} instruction [is executed](#returning-from-an-application):
   - No more instructions are fetched or executed.
   - A [secure wipe of internal state](#internal-state-secure-wipe) is performed.
   - The [`ERR_BITS`](registers.md#err_bits) register is set to a non-zero value that describes the error.
   - The current operation is marked as complete by setting [`INTR_STATE.done`](registers.md#intr_state).
3. The [`STATUS`](registers.md#status) register is set to `LOCKED`.
4. A [fatal alert](#alerts) is raised.

Note that OTBN can detect some errors even when it isn't running.
One example of this is an error caused by an integrity error when reading or writing OTBN's memories over the bus.
In this case, the [`ERR_BITS`](registers.md#err_bits) register will not change.
This avoids race conditions with the host processor's error handling software.
However, every error that OTBN detects when it isn't running is fatal.
This means that the cause will be reflected in [`FATAL_ALERT_CAUSE`](registers.md#fatal_alert_cause), as described below in [Alerts](#alerts).
This way, no alert is generated without setting an error code somewhere.

### List of Errors

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Class</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>BAD_DATA_ADDR</code></td>
      <td>software</td>
      <td>A data memory access occurred with an out of bounds or unaligned access.</td>
    </tr>
    <tr>
      <td><code>BAD_INSN_ADDR</code></td>
      <td>software</td>
      <td>An instruction memory access occurred with an out of bounds or unaligned access.</td>
    </tr>
    <tr>
      <td><code>CALL_STACK</code></td>
      <td>software</td>
      <td>An instruction tried to pop from an empty call stack or push to a full call stack.</td>
    </tr>
    <tr>
      <td><code>ILLEGAL_INSN</code></td>
      <td>software</td>
      <td>
        An illegal instruction was about to be executed.
      </td>
    <tr>
      <td><code>LOOP</code></td>
      <td>software</td>
      <td>
        A loop stack-related error was detected.
      </td>
    </tr>
    <tr>
      <td><code>KEY_INVALID</code></td>
      <td>software</td>
      <td>
        An attempt to read a `KEY_*` WSR was detected, but no key was provided by the key manager.
      </td>
    </tr>
    <tr>
      <td><code>RND_REP_CHK_FAIL</code></td>
      <td>recoverable</td>
      <td>
        The random number obtained from the last read of the RND register failed the repetition check.
        The RND EDN interface returned identical random numbers on two subsequent entropy requests.
      </td>
    </tr>
    <tr>
      <td><code>RND_FIPS_CHK_FAIL</code></td>
      <td>recoverable</td>
      <td>
        The random number obtained from the last read of the RND register has been generated from entropy that at least partially failed the FIPS health checks in the entropy source.
      </td>
    </tr>
    <tr>
      <td><code>IMEM_INTG_VIOLATION</code></td>
      <td>fatal</td>
      <td>Data read from the instruction memory failed the integrity checks.</td>
    </tr>
    <tr>
      <td><code>DMEM_INTG_VIOLATION</code></td>
      <td>fatal</td>
      <td>Data read from the data memory failed the integrity checks.</td>
    </tr>
    <tr>
      <td><code>REG_INTG_VIOLATION</code></td>
      <td>fatal</td>
      <td>Data read from a GPR or WDR failed the integrity checks.</td>
    </tr>
    <tr>
      <td><code>BUS_INTG_VIOLATION</code></td>
      <td>fatal</td>
      <td>An incoming bus transaction failed the integrity checks.</td>
    </tr>
    <tr>
      <td><code>BAD_INTERNAL_STATE</code></td>
      <td>fatal</td>
      <td>The internal state of OTBN has become corrupt.</td>
    </tr>
    <tr>
      <td><code>ILLEGAL_BUS_ACCESS</code></td>
      <td>fatal</td>
      <td>A bus-accessible register or memory was accessed when not allowed.</td>
    </tr>
    <tr>
      <td><code>LIFECYCLE_ESCALATION</code></td>
      <td>fatal</td>
      <td>A life cycle escalation request was received.</td>
    </tr>
    <tr>
      <td><code>FATAL_SOFTWARE</code></td>
      <td>fatal</td>
      <td>A software error was seen and [`CTRL.software_errs_fatal`](registers.md#ctrl) was set.</td>
    </tr>
  </tbody>
</table>

### Alerts

An alert is a reaction to an error that OTBN detected.
OTBN has two alerts, one recoverable and one fatal.

A **recoverable alert** is a one-time triggered alert caused by [recoverable errors](#reaction-to-recoverable-errors).
The error that caused the alert can be determined by reading the [`ERR_BITS`](registers.md#err_bits) register.

A **fatal alert** is a continuously triggered alert caused by [fatal errors](#reaction-to-fatal-errors).
The error that caused the alert can be determined by reading the [`FATAL_ALERT_CAUSE`](registers.md#fatal_alert_cause) register.
If OTBN was running, this value will also be reflected in the [`ERR_BITS`](registers.md#err_bits) register.
A fatal alert can only be cleared by resetting OTBN through the `rst_ni` line.

The host CPU can clear the [`ERR_BITS`](registers.md#err_bits) when OTBN is not running.
Writing any value to [`ERR_BITS`](registers.md#err_bits) clears this register to zero.
Write attempts while OTBN is running are ignored.

### Reaction to Life Cycle Escalation Requests

OTBN receives and reacts to escalation signals from the [life cycle controller](../../lc_ctrl/README.md#security-escalation).
An incoming life cycle escalation is a fatal error of type `lifecycle_escalation` and treated as described in the section [Fatal Errors](#reaction-to-fatal-errors).

### Idle

OTBN exposes a single-bit `idle_o` signal, intended to be used by the clock manager to clock-gate the block when it is not in use.
This signal is in the same clock domain as `clk_i`.
The `idle_o` signal is high when OTBN [is idle](#operational-states), and low otherwise.

OTBN also exposes another version of the idle signal as `idle_otp_o`.
This works analogously, but is in the same clock domain as `clk_otp_i`.

TODO: Specify interactions between `idle_o`, `idle_otp_o` and the clock manager fully.

### Data Integrity Protection

OTBN stores and operates on data (state) in its dedicated memories, register files, and internal registers.
OTBN's data integrity protection is designed to protect all data stored and transmitted within OTBN from modifications through physical attacks.

During transmission, the integrity of data is protected with an integrity protection code.
Data at rest in the instruction and data memories is additionally scrambled.

In the following, the Integrity Protection Code and the scrambling algorithm are discussed, followed by their application to individual storage elements.

#### Integrity Protection Code

OTBN uses the same integrity protection code everywhere to provide overarching data protection without regular re-encoding.
The code is applied to 32b data words, and produces 39b of encoded data.

The code used is an (39,32) Hsiao "single error correction, double error detection" (SECDED) error correction code (ECC) [[CHEN08](#ref-chen08)].
It has a minimum Hamming distance of four, resulting in the ability to detect at least three errors in a 32 bit word.
The code is used for error detection only; no error correction is performed.

#### Memory Scrambling

Contents of OTBN's instruction and data memories are scrambled while at rest.
The data is bound to the address and scrambled before being stored in memory.
The addresses are randomly remapped.

Note that data stored in other temporary memories within OTBN, including the register files, is not scrambled.

Scrambling is used to obfuscate the memory contents and to diffuse the data.
Obfuscation makes passive probing more difficult, while diffusion makes active fault injection attacks more difficult.

The scrambling mechanism is described in detail in the [section "Scrambling Primitive" of the SRAM Controller Technical Specification](../../sram_ctrl/README.md#scrambling-primitive).

When OTBN comes out of reset, its memories have default scrambling keys.
The host processor can request new keys for each memory by issuing a [secure wipe of DMEM](#data-memory-dmem-secure-wipe) and a [secure wipe of IMEM](#instruction-memory-imem-secure-wipe).

#### Actions on Integrity Errors

A fatal error is raised whenever a data integrity violation is detected, which results in an immediate stop of all processing and the issuing of a fatal alert.
The section [Error Handling and Reporting](#design-details-error-handling-and-reporting) describes the error handling in more detail.

#### Register File Integrity Protection

OTBN contains two register files: the 32b GPRs and the 256b WDRs.
The data stored in both register files is protected with the [Integrity Protection Code](#integrity-protection-code).
Neither the register file contents nor register addresses are scrambled.

The GPRs `x2` to `x31` store a 32b data word together with the Integrity Protection Code, resulting in 39b of stored data.
(`x0`, the zero register, and `x1`, the call stack, require special treatment.)

Each 256b Wide Data Register (WDR) stores a 256b data word together with the Integrity Protection Code, resulting in 312b of stored data.
The integrity protection is done separately for each of the eight 32b sub-words within a 256b word.

The register files can consume data protected with the Integrity Protection Code, or add it on demand.
Whenever possible the Integrity Protection Code is preserved from its source and written directly to the register files without recalculation, in particular in the following cases:

* Data coming from the data memory (DMEM) through the load-store unit to a GPR or WDR.
* Data copied between WDRs using the {{#otbn-insn-ref BN.MOV}} or {{#otbn-insn-ref BN.MOVR}} instructions.
* Data conditionally copied between WDRs using the {{#otbn-insn-ref BN.SEL}} instruction.
* Data copied between the `ACC` and `MOD` WSRs and a WDR.
* Data copied between any of the `MOD0` to `MOD7` CSRs and a GPR.
  (TODO: Not yet implemented.)

In all other cases the register files add the Integrity Protection Code to the incoming data before storing the data word.

The integrity protection bits are checked on every read from the register files, even if the integrity protection is not removed from the data.

Detected integrity violations in a register file raise a fatal `reg_error`.

#### Data Memory (DMEM) Integrity Protection

OTBN's data memory is 256b wide, but allows for 32b word accesses.
To facilitate such accesses, all integrity protection in the data memory is done on a 32b word granularity.

All data entering or leaving the data memory block is protected with the [Integrity Protection Code](#integrity-protection-code);
this code is not re-computed within the memory block.

Before being stored in SRAM, the data word with the attached Integrity Protection Code, as well as the address are scrambled according to the [memory scrambling algorithm](#memory-scrambling).
The scrambling is reversed on a read.

The ephemeral memory scrambling key and the nonce are provided by the OTP block.
They are set once when OTBN block is reset, and changed whenever a [secure wipe](#data-memory-dmem-secure-wipe) of the data memory is performed.
For example, see earlgrey's [OTP block](../../../top_earlgrey/ip_autogen/otp_ctrl/doc/theory_of_operation.md#scrambling-key-derivation).

The Integrity Protection Code is checked on every memory read, even though the code remains attached to the data.
A further check must be performed when the data is consumed.
Detected integrity violations in the data memory raise a fatal `dmem_error`.

#### Instruction Memory (IMEM) Integrity Protection

All data entering or leaving the instruction memory block is protected with the [Integrity Protection Code](#integrity-protection-code);
this code is not re-computed within the memory block.

Before being stored in SRAM, the instruction word with the attached Integrity Protection Code, as well as the address are scrambled according to the [memory scrambling algorithm](#memory-scrambling).
The scrambling is reversed on a read.

The ephemeral memory scrambling key and the nonce are provided by the OTP block (for example, see earlgrey's [scrambling specification](../../../top_earlgrey/ip_autogen/otp_ctrl/doc/theory_of_operation.md#scrambling-key-derivation)).
They are set once when OTBN block is reset, and changed whenever a [secure wipe](#instruction-memory-imem-secure-wipe) of the instruction memory is performed.

The Integrity Protection Code is checked on every memory read, even though the code remains attached to the data.
A further check must be performed when the data is consumed.
Detected integrity violations in the data memory raise a fatal `imem_error`.

### Memory Load Integrity

As well as the integrity protection discussed above for the memories and bus interface, OTBN has a second layer of integrity checking to allow a host processor to ensure that a program has been loaded correctly.
This is visible through the [`LOAD_CHECKSUM`](registers.md#load_checksum) register.
The register exposes a cumulative CRC checksum which is updated on every write to either memory.

This is intended as a light-weight way to implement a more efficient "write and read back" check.
It isn't a cryptographically secure MAC, so cannot spot an attacker who can completely control the bus.
However, in this case the attacker would be equally able to control responses from OTBN, so any such check could be subverted.

The CRC used is the 32-bit CRC-32-IEEE checksum.
This standard choice of generating polynomial makes it compatible with other tooling and libraries, such as the [crc32 function](https://docs.python.org/3/library/binascii.html#binascii.crc32) in the python 'binascii' module and the crc instructions in the RISC-V bitmanip specification [[SYMBIOTIC21]](#ref-symbiotic21).
The stream over which the checksum is computed is the stream of writes that have been seen since the last write to [`LOAD_CHECKSUM`](registers.md#load_checksum).
Each write is treated as a 48b value, `{imem, idx, wdata}`.
Here, `imem` is a single bit flag which is one for writes to IMEM and zero for writes to DMEM.
The `idx` value is the index of the word within the memory, zero extended from 10b to 15b.
Finally, `wdata` is the 32b word that was written.
Writes that are less than 32b or not aligned on a 32b boundary are ignored and not factored into the CRC calculation.

The host processor can also write to the register.
Typically, this will be to clear the value to `32'h00000000`, the traditional starting value for a 32-bit CRC.
Note the internal representation of the CRC is inverted from the register visible version.
This is done to maintain compatibility with existing CRC-32-IEEE tooling and libraries.

To use this functionality, the host processor should set [`LOAD_CHECKSUM`](registers.md#load_checksum) to a known value (traditionally, `32'h00000000`).
Next, it should write the program to be loaded to OTBN's IMEM and DMEM over the bus.
Finally, it should read back the value of [`LOAD_CHECKSUM`](registers.md#load_checksum) and compare it with an expected value.

### Secure Wipe

Applications running on OTBN may store sensitive data in the internal registers or the memory.
In order to prevent an untrusted application from reading any leftover data, OTBN provides the secure wipe operation.
This operation can be applied to:
- [Data memory](#data-memory-dmem-secure-wipe)
- [Instruction memory](#instruction-memory-imem-secure-wipe)
- [Internal state](#internal-state-secure-wipe)

The three forms of secure wipe can be triggered in different ways.

A secure wipe of either the instruction or the data memory can be triggered from host software by issuing a `SEC_WIPE_DMEM` or `SEC_WIPE_IMEM` [command](#design-details-command).

A secure wipe of instruction memory, data memory, and all internal state is performed automatically when handling a [fatal error](#reaction-to-fatal-errors).
In addition, it can be triggered by the [Life Cycle Controller](../../lc_ctrl/README.md) before RMA entry using the `lc_rma_req/ack` interface.
In both cases OTBN enters the locked state afterwards and needs to be reset.

A secure wipe of the internal state only is triggered automatically after reset and when OTBN [ends the software execution](#software-execution), either successfully, or unsuccessfully due to a [recoverable error](#reaction-to-recoverable-errors).

If OTBN cannot complete a secure wipe of the internal state (e.g., due to failing to obtain the required randomness), it immediately becomes locked.
In this case, OTBN must be reset and will then retry the secure wipe.
The secure wipe after reset must succeed before OTBN can be used.

#### Data Memory (DMEM) Secure Wipe

The wiping is performed by securely replacing the memory scrambling key, making all data stored in the memory unusable.
The key replacement is a two-step process:

* Overwrite the 128b key of the memory scrambling primitive with randomness from URND.
  This action takes a single cycle.
* Request new scrambling parameters from OTP.
  The request takes multiple cycles to complete.

Host software can initiate a data memory secure wipe by [issuing the `SEC_WIPE_DMEM` command](#operations-and-commands).

#### Instruction Memory (IMEM) Secure Wipe

The wiping is performed by securely replacing the memory scrambling key, making all instructions stored in the memory unusable.
The key replacement is a two-step process:

* Overwrite the 128b key of the memory scrambling primitive with randomness from URND.
  This action takes a single cycle.
* Request new scrambling parameters from OTP.
  The request takes multiple cycles to complete.

Host software can initiate a data memory secure wipe by [issuing the `SEC_WIPE_IMEM` command](#operations-and-commands).

#### Internal State Secure Wipe

OTBN provides a mechanism to securely wipe all internal state, excluding the instruction and data memories.

The following state is wiped:
* Register files: GPRs and WDRs
* The accumulator register (also accessible through the ACC WSR)
* Flags (accessible through the FG0, FG1, and FLAGS CSRs)
* The modulus (accessible through the MOD0 to MOD7 CSRs and the MOD WSR)

The wiping procedure is a two-step process:
* Overwrite the state with randomness from URND and request a reseed of URND.
* Overwrite the state with randomness from reseeded URND.

Note that after internal secure wipe, the state of registers is undefined.
In order to prevent mismatches between ISS and RTL, software needs to initialise a register with a full-word write before using its value.

Loop and call stack pointers are reset.

Host software cannot explicitly trigger an internal secure wipe; it is performed automatically after reset and at the end of an `EXECUTE` operation.

================================== Ai Message ==================================
Tool Calls:
  read_file (call_PXmRRdcsCXzpOVS6GsL8Xpmd)
 Call ID: call_PXmRRdcsCXzpOVS6GsL8Xpmd
  Args:
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/doc/registers.md
================================= Tool Message =================================
Name: read_file

# Registers

<!-- BEGIN CMDGEN util/regtool.py -d ./hw/ip/otbn/data/otbn.hjson -->
## Summary

| Name                                           | Offset   |   Length | Description                                     |
|:-----------------------------------------------|:---------|---------:|:------------------------------------------------|
| otbn.[`INTR_STATE`](#intr_state)               | 0x0      |        4 | Interrupt State Register                        |
| otbn.[`INTR_ENABLE`](#intr_enable)             | 0x4      |        4 | Interrupt Enable Register                       |
| otbn.[`INTR_TEST`](#intr_test)                 | 0x8      |        4 | Interrupt Test Register                         |
| otbn.[`ALERT_TEST`](#alert_test)               | 0xc      |        4 | Alert Test Register                             |
| otbn.[`CMD`](#cmd)                             | 0x10     |        4 | Command Register                                |
| otbn.[`CTRL`](#ctrl)                           | 0x14     |        4 | Control Register                                |
| otbn.[`STATUS`](#status)                       | 0x18     |        4 | Status Register                                 |
| otbn.[`ERR_BITS`](#err_bits)                   | 0x1c     |        4 | Operation Result Register                       |
| otbn.[`FATAL_ALERT_CAUSE`](#fatal_alert_cause) | 0x20     |        4 | Fatal Alert Cause Register                      |
| otbn.[`INSN_CNT`](#insn_cnt)                   | 0x24     |        4 | Instruction Count Register                      |
| otbn.[`LOAD_CHECKSUM`](#load_checksum)         | 0x28     |        4 | A 32-bit CRC checksum of data written to memory |
| otbn.[`IMEM`](#imem)                           | 0x4000   |     8192 | Instruction Memory Access                       |
| otbn.[`DMEM`](#dmem)                           | 0x8000   |     3072 | Data Memory Access                              |

## INTR_STATE
Interrupt State Register
- Offset: `0x0`
- Reset default: `0x0`
- Reset mask: `0x1`

### Fields

```wavejson
{"reg": [{"name": "done", "bits": 1, "attr": ["rw1c"], "rotate": -90}, {"bits": 31}], "config": {"lanes": 1, "fontsize": 10, "vspace": 80}}
```

|  Bits  |  Type  |  Reset  | Name   | Description                       |
|:------:|:------:|:-------:|:-------|:----------------------------------|
|  31:1  |        |         |        | Reserved                          |
|   0    |  rw1c  |   0x0   | done   | OTBN has completed the operation. |

## INTR_ENABLE
Interrupt Enable Register
- Offset: `0x4`
- Reset default: `0x0`
- Reset mask: `0x1`

### Fields

```wavejson
{"reg": [{"name": "done", "bits": 1, "attr": ["rw"], "rotate": -90}, {"bits": 31}], "config": {"lanes": 1, "fontsize": 10, "vspace": 80}}
```

|  Bits  |  Type  |  Reset  | Name   | Description                                                    |
|:------:|:------:|:-------:|:-------|:---------------------------------------------------------------|
|  31:1  |        |         |        | Reserved                                                       |
|   0    |   rw   |   0x0   | done   | Enable interrupt when [`INTR_STATE.done`](#intr_state) is set. |

## INTR_TEST
Interrupt Test Register
- Offset: `0x8`
- Reset default: `0x0`
- Reset mask: `0x1`

### Fields

```wavejson
{"reg": [{"name": "done", "bits": 1, "attr": ["wo"], "rotate": -90}, {"bits": 31}], "config": {"lanes": 1, "fontsize": 10, "vspace": 80}}
```

|  Bits  |  Type  |  Reset  | Name   | Description                                             |
|:------:|:------:|:-------:|:-------|:--------------------------------------------------------|
|  31:1  |        |         |        | Reserved                                                |
|   0    |   wo   |   0x0   | done   | Write 1 to force [`INTR_STATE.done`](#intr_state) to 1. |

## ALERT_TEST
Alert Test Register
- Offset: `0xc`
- Reset default: `0x0`
- Reset mask: `0x3`

### Fields

```wavejson
{"reg": [{"name": "fatal", "bits": 1, "attr": ["wo"], "rotate": -90}, {"name": "recov", "bits": 1, "attr": ["wo"], "rotate": -90}, {"bits": 30}], "config": {"lanes": 1, "fontsize": 10, "vspace": 80}}
```

|  Bits  |  Type  |  Reset  | Name   | Description                                      |
|:------:|:------:|:-------:|:-------|:-------------------------------------------------|
|  31:2  |        |         |        | Reserved                                         |
|   1    |   wo   |   0x0   | recov  | Write 1 to trigger one alert event of this kind. |
|   0    |   wo   |   0x0   | fatal  | Write 1 to trigger one alert event of this kind. |

## CMD
Command Register

A command initiates an OTBN operation. While performing the operation,
OTBN is busy; the [`STATUS`](#status) register reflects that.

All operations signal their completion by raising the done
interrupt; alternatively, software may poll the [`STATUS`](#status) register.

Writes are ignored if OTBN is not idle.
Unrecognized commands are ignored.
- Offset: `0x10`
- Reset default: `0x0`
- Reset mask: `0xff`

### Fields

```wavejson
{"reg": [{"name": "cmd", "bits": 8, "attr": ["wo"], "rotate": 0}, {"bits": 24}], "config": {"lanes": 1, "fontsize": 10, "vspace": 80}}
```

|  Bits  |  Type  |  Reset  | Name             |
|:------:|:------:|:-------:|:-----------------|
|  31:8  |        |         | Reserved         |
|  7:0   |   wo   |   0x0   | [cmd](#cmd--cmd) |

### CMD . cmd
The operation to perform.

| Value | Name          | Description |
|:------|:--------------|:------------|
| 0xd8  | EXECUTE       | Starts the execution of the program stored in the instruction memory, starting at address zero. |
| 0xc3  | SEC_WIPE_DMEM | Securely removes all contents from the data memory. |
| 0x1e  | SEC_WIPE_IMEM | Securely removes all contents from the instruction  memory. |

## CTRL
Control Register
- Offset: `0x14`
- Reset default: `0x0`
- Reset mask: `0x1`

### Fields

```wavejson
{"reg": [{"name": "software_errs_fatal", "bits": 1, "attr": ["rw"], "rotate": -90}, {"bits": 31}], "config": {"lanes": 1, "fontsize": 10, "vspace": 210}}
```

|  Bits  |  Type  |  Reset  | Name                | Description                                                                                                                                                      |
|:------:|:------:|:-------:|:--------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  31:1  |        |         |                     | Reserved                                                                                                                                                         |
|   0    |   rw   |   0x0   | software_errs_fatal | Controls the reaction to software errors. When set software errors produce fatal errors, rather than recoverable errors. Writes are ignored if OTBN is not idle. |

## STATUS
Status Register
- Offset: `0x18`
- Reset default: `0x4`
- Reset mask: `0xff`

### Fields

```wavejson
{"reg": [{"name": "status", "bits": 8, "attr": ["ro"], "rotate": 0}, {"bits": 24}], "config": {"lanes": 1, "fontsize": 10, "vspace": 80}}
```

|  Bits  |  Type  |  Reset  | Name                      |
|:------:|:------:|:-------:|:--------------------------|
|  31:8  |        |         | Reserved                  |
|  7:0   |   ro   |   0x4   | [status](#status--status) |

### STATUS . status
Indicates the current operational state OTBN is in.

All BUSY values represent an operation started by a write to the
[`CMD`](#cmd) register.

| Value | Name               | Description                                           |
|:------|:-------------------|:------------------------------------------------------|
| 0x00  | IDLE               | OTBN is idle: it is not performing any action.        |
| 0x01  | BUSY_EXECUTE       | OTBN is busy executing software.                      |
| 0x02  | BUSY_SEC_WIPE_DMEM | OTBN is busy securely wiping the data memory.         |
| 0x03  | BUSY_SEC_WIPE_IMEM | OTBN is busy securely wiping the instruction memory.  |
| 0x04  | BUSY_SEC_WIPE_INT  | OTBN is busy securely wiping the internal state.      |
| 0xFF  | LOCKED             | OTBN is locked as reaction to a fatal error, and must be reset to unlock it again. See also the section "Reaction to Fatal Errors". |


## ERR_BITS
Operation Result Register

Describes the errors detected during an operation.

Refer to the "List of Errors" section for a detailed description of the
errors.

The host CPU can clear this register when OTBN is not running,
by writing any value. Write attempts while OTBN is running are ignored.
- Offset: `0x1c`
- Reset default: `0x0`
- Reset mask: `0xff00ff`

### Fields

```wavejson
{"reg": [{"name": "bad_data_addr", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "bad_insn_addr", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "call_stack", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "illegal_insn", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "loop", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "key_invalid", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "rnd_rep_chk_fail", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "rnd_fips_chk_fail", "bits": 1, "attr": ["rw"], "rotate": -90}, {"bits": 8}, {"name": "imem_intg_violation", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "dmem_intg_violation", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "reg_intg_violation", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "bus_intg_violation", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "bad_internal_state", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "illegal_bus_access", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "lifecycle_escalation", "bits": 1, "attr": ["rw"], "rotate": -90}, {"name": "fatal_software", "bits": 1, "attr": ["rw"], "rotate": -90}, {"bits": 8}], "config": {"lanes": 1, "fontsize": 10, "vspace": 220}}
```

|  Bits  |  Type  |  Reset  | Name                 | Description                                  |
|:------:|:------:|:-------:|:---------------------|:---------------------------------------------|
| 31:24  |        |         |                      | Reserved                                     |
|   23   |   rw   |   0x0   | fatal_software       | A `FATAL_SOFTWARE` error was observed.       |
|   22   |   rw   |   0x0   | lifecycle_escalation | A `LIFECYCLE_ESCALATION` error was observed. |
|   21   |   rw   |   0x0   | illegal_bus_access   | An `ILLEGAL_BUS_ACCESS` error was observed.  |
|   20   |   rw   |   0x0   | bad_internal_state   | A `BAD_INTERNAL_STATE` error was observed.   |
|   19   |   rw   |   0x0   | bus_intg_violation   | A `BUS_INTG_VIOLATION` error was observed.   |
|   18   |   rw   |   0x0   | reg_intg_violation   | A `REG_INTG_VIOLATION` error was observed.   |
|   17   |   rw   |   0x0   | dmem_intg_violation  | A `DMEM_INTG_VIOLATION` error was observed.  |
|   16   |   rw   |   0x0   | imem_intg_violation  | A `IMEM_INTG_VIOLATION` error was observed.  |
|  15:8  |        |         |                      | Reserved                                     |
|   7    |   rw   |   0x0   | rnd_fips_chk_fail    | An `RND_FIPS_CHK_FAIL` error was observed.   |
|   6    |   rw   |   0x0   | rnd_rep_chk_fail     | An `RND_REP_CHK_FAIL` error was observed.    |
|   5    |   rw   |   0x0   | key_invalid          | A `KEY_INVALID` error was observed.          |
|   4    |   rw   |   0x0   | loop                 | A `LOOP` error was observed.                 |
|   3    |   rw   |   0x0   | illegal_insn         | An `ILLEGAL_INSN` error was observed.        |
|   2    |   rw   |   0x0   | call_stack           | A `CALL_STACK` error was observed.           |
|   1    |   rw   |   0x0   | bad_insn_addr        | A `BAD_INSN_ADDR` error was observed.        |
|   0    |   rw   |   0x0   | bad_data_addr        | A `BAD_DATA_ADDR` error was observed.        |

## FATAL_ALERT_CAUSE
Fatal Alert Cause Register

Describes any errors that led to a fatal alert.
A fatal error puts OTBN in locked state; the value of this register
does not change until OTBN is reset.

Refer to the "List of Errors" section for a detailed description of the
errors.
- Offset: `0x20`
- Reset default: `0x0`
- Reset mask: `0xff`

### Fields

```wavejson
{"reg": [{"name": "imem_intg_violation", "bits": 1, "attr": ["ro"], "rotate": -90}, {"name": "dmem_intg_violation", "bits": 1, "attr": ["ro"], "rotate": -90}, {"name": "reg_intg_violation", "bits": 1, "attr": ["ro"], "rotate": -90}, {"name": "bus_intg_violation", "bits": 1, "attr": ["ro"], "rotate": -90}, {"name": "bad_internal_state", "bits": 1, "attr": ["ro"], "rotate": -90}, {"name": "illegal_bus_access", "bits": 1, "attr": ["ro"], "rotate": -90}, {"name": "lifecycle_escalation", "bits": 1, "attr": ["ro"], "rotate": -90}, {"name": "fatal_software", "bits": 1, "attr": ["ro"], "rotate": -90}, {"bits": 24}], "config": {"lanes": 1, "fontsize": 10, "vspace": 220}}
```

|  Bits  |  Type  |  Reset  | Name                 | Description                                  |
|:------:|:------:|:-------:|:---------------------|:---------------------------------------------|
|  31:8  |        |         |                      | Reserved                                     |
|   7    |   ro   |   0x0   | fatal_software       | A `FATAL_SOFTWARE` error was observed.       |
|   6    |   ro   |   0x0   | lifecycle_escalation | A `LIFECYCLE_ESCALATION` error was observed. |
|   5    |   ro   |   0x0   | illegal_bus_access   | A `ILLEGAL_BUS_ACCESS` error was observed.   |
|   4    |   ro   |   0x0   | bad_internal_state   | A `BAD_INTERNAL_STATE` error was observed.   |
|   3    |   ro   |   0x0   | bus_intg_violation   | A `BUS_INTG_VIOLATION` error was observed.   |
|   2    |   ro   |   0x0   | reg_intg_violation   | A `REG_INTG_VIOLATION` error was observed.   |
|   1    |   ro   |   0x0   | dmem_intg_violation  | A `DMEM_INTG_VIOLATION` error was observed.  |
|   0    |   ro   |   0x0   | imem_intg_violation  | A `IMEM_INTG_VIOLATION` error was observed.  |

## INSN_CNT
Instruction Count Register

Returns the number of instructions executed in the current or last
operation. The counter saturates at 2^32-1 and is reset to 0 at the
start of a new operation.

Only the EXECUTE operation counts instructions; for all other operations
this register remains at 0. Instructions triggering an error do not
count towards the total.

Always reads as 0 if OTBN is locked.

The host CPU can clear this register when OTBN is not running,
by writing any value. Write attempts while OTBN is running are ignored.
- Offset: `0x24`
- Reset default: `0x0`
- Reset mask: `0xffffffff`

### Fields

```wavejson
{"reg": [{"name": "insn_cnt", "bits": 32, "attr": ["rw"], "rotate": 0}], "config": {"lanes": 1, "fontsize": 10, "vspace": 80}}
```

|  Bits  |  Type  |  Reset  | Name     | Description                          |
|:------:|:------:|:-------:|:---------|:-------------------------------------|
|  31:0  |   rw   |   0x0   | insn_cnt | The number of executed instructions. |

## LOAD_CHECKSUM
A 32-bit CRC checksum of data written to memory

See the "Memory Load Integrity" section of the manual for full details.
- Offset: `0x28`
- Reset default: `0x0`
- Reset mask: `0xffffffff`

### Fields

```wavejson
{"reg": [{"name": "checksum", "bits": 32, "attr": ["rw"], "rotate": 0}], "config": {"lanes": 1, "fontsize": 10, "vspace": 80}}
```

|  Bits  |  Type  |  Reset  | Name     | Description          |
|:------:|:------:|:-------:|:---------|:---------------------|
|  31:0  |   rw   |   0x0   | checksum | Checksum accumulator |

## IMEM
Instruction Memory Access

The instruction memory may only be accessed through this window
while OTBN is idle.

If OTBN is busy or locked, read accesses return 0 and write accesses
are ignored.
If OTBN is busy, any access additionally triggers an
ILLEGAL_BUS_ACCESS fatal error.

- Word Aligned Offset Range: `0x4000`to`0x5ffc`
- Size (words): `2048`
- Access: `rw`
- Byte writes are *not* supported.

## DMEM
Data Memory Access

The data memory may only be accessed through this window while OTBN
is idle.

If OTBN is busy or locked, read accesses return 0 and write accesses
are ignored.
If OTBN is busy, any access additionally triggers an
ILLEGAL_BUS_ACCESS fatal error.

Note that DMEM is actually 4kiB in size, but only the first 3kiB of
the memory is visible through this register interface.

- Word Aligned Offset Range: `0x8000`to`0x8bfc`
- Size (words): `768`
- Access: `rw`
- Byte writes are *not* supported.


<!-- END CMDGEN -->

================================== Ai Message ==================================
Tool Calls:
  list_dir (call_k38fB19tU1U8VgGoCdStquOr)
 Call ID: call_k38fB19tU1U8VgGoCdStquOr
  Args:
    dir_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl
================================= Tool Message =================================
Name: list_dir

Files in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl:
otbn_predecode.sv otbn_controller.sv otbn_mac_bignum.sv otbn_reg_top.sv otbn_rf_base.sv otbn_rf_bignum_ff.sv otbn_rf_bignum_fpga.sv otbn_instruction_fetch.sv otbn_decoder.sv otbn_rf_bignum.sv otbn.sv otbn_rf_base_fpga.sv otbn_rf_base_ff.sv otbn_alu_bignum.sv otbn_rnd.sv otbn_reg_pkg.sv otbn_pkg.sv otbn_loop_controller.sv otbn_stack.sv otbn_scramble_ctrl.sv otbn_start_stop_control.sv otbn_alu_base.sv otbn_lsu.sv otbn_core.sv

Directories in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl:

================================== Ai Message ==================================
Tool Calls:
  read_file_with_line_numbers (call_ZX0luHI9iPAwxR0reIcJCH0N)
 Call ID: call_ZX0luHI9iPAwxR0reIcJCH0N
  Args:
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn_reg_top.sv
================================= Tool Message =================================
Name: read_file_with_line_numbers

1: // Copyright lowRISC contributors (OpenTitan project).
2: // Licensed under the Apache License, Version 2.0, see LICENSE for details.
3: // SPDX-License-Identifier: Apache-2.0
4: //
5: // Register Top module auto-generated by `reggen`
6: 
7: `include "prim_assert.sv"
8: 
9: module otbn_reg_top (
10:   input clk_i,
11:   input rst_ni,
12:   input  tlul_pkg::tl_h2d_t tl_i,
13:   output tlul_pkg::tl_d2h_t tl_o,
14: 
15:   // Output port for window
16:   output tlul_pkg::tl_h2d_t tl_win_o  [2],
17:   input  tlul_pkg::tl_d2h_t tl_win_i  [2],
18: 
19:   // To HW
20:   output otbn_reg_pkg::otbn_reg2hw_t reg2hw, // Write
21:   input  otbn_reg_pkg::otbn_hw2reg_t hw2reg, // Read
22: 
23:   // Integrity check errors
24:   output logic intg_err_o
25: );
26: 
27:   import otbn_reg_pkg::* ;
28: 
29:   localparam int AW = 16;
30:   localparam int DW = 32;
31:   localparam int DBW = DW/8;                    // Byte Width
32: 
33:   // register signals
34:   logic           reg_we;
35:   logic           reg_re;
36:   logic [AW-1:0]  reg_addr;
37:   logic [DW-1:0]  reg_wdata;
38:   logic [DBW-1:0] reg_be;
39:   logic [DW-1:0]  reg_rdata;
40:   logic           reg_error;
41: 
42:   logic          addrmiss, wr_err;
43: 
44:   logic [DW-1:0] reg_rdata_next;
45:   logic reg_busy;
46: 
47:   tlul_pkg::tl_h2d_t tl_reg_h2d;
48:   tlul_pkg::tl_d2h_t tl_reg_d2h;
49: 
50: 
51:   // incoming payload check
52:   logic intg_err;
53:   tlul_cmd_intg_chk u_chk (
54:     .tl_i(tl_i),
55:     .err_o(intg_err)
56:   );
57: 
58:   // also check for spurious write enables
59:   logic reg_we_err;
60:   logic [10:0] reg_we_check;
61:   prim_reg_we_check #(
62:     .OneHotWidth(11)
63:   ) u_prim_reg_we_check (
64:     .clk_i(clk_i),
65:     .rst_ni(rst_ni),
66:     .oh_i  (reg_we_check),
67:     .en_i  (reg_we && !addrmiss),
68:     .err_o (reg_we_err)
69:   );
70: 
71:   logic err_q;
72:   always_ff @(posedge clk_i or negedge rst_ni) begin
73:     if (!rst_ni) begin
74:       err_q <= '0;
75:     end else if (intg_err || reg_we_err) begin
76:       err_q <= 1'b1;
77:     end
78:   end
79: 
80:   // integrity error output is permanent and should be used for alert generation
81:   // register errors are transactional
82:   assign intg_err_o = err_q | intg_err | reg_we_err;
83: 
84:   // outgoing integrity generation
85:   tlul_pkg::tl_d2h_t tl_o_pre;
86:   tlul_rsp_intg_gen #(
87:     .EnableRspIntgGen(1),
88:     .EnableDataIntgGen(0)
89:   ) u_rsp_intg_gen (
90:     .tl_i(tl_o_pre),
91:     .tl_o(tl_o)
92:   );
93: 
94:   tlul_pkg::tl_h2d_t tl_socket_h2d [3];
95:   tlul_pkg::tl_d2h_t tl_socket_d2h [3];
96: 
97:   logic [1:0] reg_steer;
98: 
99:   // socket_1n connection
100:   assign tl_reg_h2d = tl_socket_h2d[2];
101:   assign tl_socket_d2h[2] = tl_reg_d2h;
102: 
103:   assign tl_win_o[0] = tl_socket_h2d[0];
104:   assign tl_socket_d2h[0] = tl_win_i[0];
105:   assign tl_win_o[1] = tl_socket_h2d[1];
106:   assign tl_socket_d2h[1] = tl_win_i[1];
107: 
108:   // Create Socket_1n
109:   tlul_socket_1n #(
110:     .N            (3),
111:     .HReqPass     (1'b1),
112:     .HRspPass     (1'b1),
113:     .DReqPass     ({3{1'b1}}),
114:     .DRspPass     ({3{1'b1}}),
115:     .HReqDepth    (4'h0),
116:     .HRspDepth    (4'h0),
117:     .DReqDepth    ({3{4'h0}}),
118:     .DRspDepth    ({3{4'h0}}),
119:     .ExplicitErrs (1'b0)
120:   ) u_socket (
121:     .clk_i  (clk_i),
122:     .rst_ni (rst_ni),
123:     .tl_h_i (tl_i),
124:     .tl_h_o (tl_o_pre),
125:     .tl_d_o (tl_socket_h2d),
126:     .tl_d_i (tl_socket_d2h),
127:     .dev_select_i (reg_steer)
128:   );
129: 
130:   // Create steering logic
131:   always_comb begin
132:     reg_steer =
133:         tl_i.a_address[AW-1:0] inside {[16384:24575]} ? 2'd0 :
134:         tl_i.a_address[AW-1:0] inside {[32768:35839]} ? 2'd1 :
135:         // Default set to register
136:         2'd2;
137: 
138:     // Override this in case of an integrity error
139:     if (intg_err) begin
140:       reg_steer = 2'd2;
141:     end
142:   end
143: 
144:   tlul_adapter_reg #(
145:     .RegAw(AW),
146:     .RegDw(DW),
147:     .EnableDataIntgGen(1)
148:   ) u_reg_if (
149:     .clk_i  (clk_i),
150:     .rst_ni (rst_ni),
151: 
152:     .tl_i (tl_reg_h2d),
153:     .tl_o (tl_reg_d2h),
154: 
155:     .en_ifetch_i(prim_mubi_pkg::MuBi4False),
156:     .intg_error_o(),
157: 
158:     .we_o    (reg_we),
159:     .re_o    (reg_re),
160:     .addr_o  (reg_addr),
161:     .wdata_o (reg_wdata),
162:     .be_o    (reg_be),
163:     .busy_i  (reg_busy),
164:     .rdata_i (reg_rdata),
165:     .error_i (reg_error)
166:   );
167: 
168:   // cdc oversampling signals
169: 
170:   assign reg_rdata = reg_rdata_next ;
171:   assign reg_error = addrmiss | wr_err | intg_err;
172: 
173:   // Define SW related signals
174:   // Format: <reg>_<field>_{wd|we|qs}
175:   //        or <reg>_{wd|we|qs} if field == 1 or 0
176:   logic intr_state_we;
177:   logic intr_state_qs;
178:   logic intr_state_wd;
179:   logic intr_enable_we;
180:   logic intr_enable_qs;
181:   logic intr_enable_wd;
182:   logic intr_test_we;
183:   logic intr_test_wd;
184:   logic alert_test_we;
185:   logic alert_test_fatal_wd;
186:   logic alert_test_recov_wd;
187:   logic cmd_we;
188:   logic [7:0] cmd_wd;
189:   logic ctrl_re;
190:   logic ctrl_we;
191:   logic ctrl_qs;
192:   logic ctrl_wd;
193:   logic [7:0] status_qs;
194:   logic err_bits_re;
195:   logic err_bits_we;
196:   logic err_bits_bad_data_addr_qs;
197:   logic err_bits_bad_data_addr_wd;
198:   logic err_bits_bad_insn_addr_qs;
199:   logic err_bits_bad_insn_addr_wd;
200:   logic err_bits_call_stack_qs;
201:   logic err_bits_call_stack_wd;
202:   logic err_bits_illegal_insn_qs;
203:   logic err_bits_illegal_insn_wd;
204:   logic err_bits_loop_qs;
205:   logic err_bits_loop_wd;
206:   logic err_bits_key_invalid_qs;
207:   logic err_bits_key_invalid_wd;
208:   logic err_bits_rnd_rep_chk_fail_qs;
209:   logic err_bits_rnd_rep_chk_fail_wd;
210:   logic err_bits_rnd_fips_chk_fail_qs;
211:   logic err_bits_rnd_fips_chk_fail_wd;
212:   logic err_bits_imem_intg_violation_qs;
213:   logic err_bits_imem_intg_violation_wd;
214:   logic err_bits_dmem_intg_violation_qs;
215:   logic err_bits_dmem_intg_violation_wd;
216:   logic err_bits_reg_intg_violation_qs;
217:   logic err_bits_reg_intg_violation_wd;
218:   logic err_bits_bus_intg_violation_qs;
219:   logic err_bits_bus_intg_violation_wd;
220:   logic err_bits_bad_internal_state_qs;
221:   logic err_bits_bad_internal_state_wd;
222:   logic err_bits_illegal_bus_access_qs;
223:   logic err_bits_illegal_bus_access_wd;
224:   logic err_bits_lifecycle_escalation_qs;
225:   logic err_bits_lifecycle_escalation_wd;
226:   logic err_bits_fatal_software_qs;
227:   logic err_bits_fatal_software_wd;
228:   logic fatal_alert_cause_imem_intg_violation_qs;
229:   logic fatal_alert_cause_dmem_intg_violation_qs;
230:   logic fatal_alert_cause_reg_intg_violation_qs;
231:   logic fatal_alert_cause_bus_intg_violation_qs;
232:   logic fatal_alert_cause_bad_internal_state_qs;
233:   logic fatal_alert_cause_illegal_bus_access_qs;
234:   logic fatal_alert_cause_lifecycle_escalation_qs;
235:   logic fatal_alert_cause_fatal_software_qs;
236:   logic insn_cnt_re;
237:   logic insn_cnt_we;
238:   logic [31:0] insn_cnt_qs;
239:   logic [31:0] insn_cnt_wd;
240:   logic load_checksum_re;
241:   logic load_checksum_we;
242:   logic [31:0] load_checksum_qs;
243:   logic [31:0] load_checksum_wd;
244: 
245:   // Register instances
246:   // R[intr_state]: V(False)
247:   prim_subreg #(
248:     .DW      (1),
249:     .SwAccess(prim_subreg_pkg::SwAccessW1C),
250:     .RESVAL  (1'h0),
251:     .Mubi    (1'b0)
252:   ) u_intr_state (
253:     .clk_i   (clk_i),
254:     .rst_ni  (rst_ni),
255: 
256:     // from register interface
257:     .we     (intr_state_we),
258:     .wd     (intr_state_wd),
259: 
260:     // from internal hardware
261:     .de     (hw2reg.intr_state.de),
262:     .d      (hw2reg.intr_state.d),
263: 
264:     // to internal hardware
265:     .qe     (),
266:     .q      (reg2hw.intr_state.q),
267:     .ds     (),
268: 
269:     // to register interface (read)
270:     .qs     (intr_state_qs)
271:   );
272: 
273: 
274:   // R[intr_enable]: V(False)
275:   prim_subreg #(
276:     .DW      (1),
277:     .SwAccess(prim_subreg_pkg::SwAccessRW),
278:     .RESVAL  (1'h0),
279:     .Mubi    (1'b0)
280:   ) u_intr_enable (
281:     .clk_i   (clk_i),
282:     .rst_ni  (rst_ni),
283: 
284:     // from register interface
285:     .we     (intr_enable_we),
286:     .wd     (intr_enable_wd),
287: 
288:     // from internal hardware
289:     .de     (1'b0),
290:     .d      ('0),
291: 
292:     // to internal hardware
293:     .qe     (),
294:     .q      (reg2hw.intr_enable.q),
295:     .ds     (),
296: 
297:     // to register interface (read)
298:     .qs     (intr_enable_qs)
299:   );
300: 
301: 
302:   // R[intr_test]: V(True)
303:   logic intr_test_qe;
304:   logic [0:0] intr_test_flds_we;
305:   assign intr_test_qe = &intr_test_flds_we;
306:   prim_subreg_ext #(
307:     .DW    (1)
308:   ) u_intr_test (
309:     .re     (1'b0),
310:     .we     (intr_test_we),
311:     .wd     (intr_test_wd),
312:     .d      ('0),
313:     .qre    (),
314:     .qe     (intr_test_flds_we[0]),
315:     .q      (reg2hw.intr_test.q),
316:     .ds     (),
317:     .qs     ()
318:   );
319:   assign reg2hw.intr_test.qe = intr_test_qe;
320: 
321: 
322:   // R[alert_test]: V(True)
323:   logic alert_test_qe;
324:   logic [1:0] alert_test_flds_we;
325:   assign alert_test_qe = &alert_test_flds_we;
326:   //   F[fatal]: 0:0
327:   prim_subreg_ext #(
328:     .DW    (1)
329:   ) u_alert_test_fatal (
330:     .re     (1'b0),
331:     .we     (alert_test_we),
332:     .wd     (alert_test_fatal_wd),
333:     .d      ('0),
334:     .qre    (),
335:     .qe     (alert_test_flds_we[0]),
336:     .q      (reg2hw.alert_test.fatal.q),
337:     .ds     (),
338:     .qs     ()
339:   );
340:   assign reg2hw.alert_test.fatal.qe = alert_test_qe;
341: 
342:   //   F[recov]: 1:1
343:   prim_subreg_ext #(
344:     .DW    (1)
345:   ) u_alert_test_recov (
346:     .re     (1'b0),
347:     .we     (alert_test_we),
348:     .wd     (alert_test_recov_wd),
349:     .d      ('0),
350:     .qre    (),
351:     .qe     (alert_test_flds_we[1]),
352:     .q      (reg2hw.alert_test.recov.q),
353:     .ds     (),
354:     .qs     ()
355:   );
356:   assign reg2hw.alert_test.recov.qe = alert_test_qe;
357: 
358: 
359:   // R[cmd]: V(True)
360:   logic cmd_qe;
361:   logic [0:0] cmd_flds_we;
362:   assign cmd_qe = &cmd_flds_we;
363:   prim_subreg_ext #(
364:     .DW    (8)
365:   ) u_cmd (
366:     .re     (1'b0),
367:     .we     (cmd_we),
368:     .wd     (cmd_wd),
369:     .d      ('0),
370:     .qre    (),
371:     .qe     (cmd_flds_we[0]),
372:     .q      (reg2hw.cmd.q),
373:     .ds     (),
374:     .qs     ()
375:   );
376:   assign reg2hw.cmd.qe = cmd_qe;
377: 
378: 
379:   // R[ctrl]: V(True)
380:   logic ctrl_qe;
381:   logic [0:0] ctrl_flds_we;
382:   assign ctrl_qe = &ctrl_flds_we;
383:   prim_subreg_ext #(
384:     .DW    (1)
385:   ) u_ctrl (
386:     .re     (ctrl_re),
387:     .we     (ctrl_we),
388:     .wd     (ctrl_wd),
389:     .d      (hw2reg.ctrl.d),
390:     .qre    (),
391:     .qe     (ctrl_flds_we[0]),
392:     .q      (reg2hw.ctrl.q),
393:     .ds     (),
394:     .qs     (ctrl_qs)
395:   );
396:   assign reg2hw.ctrl.qe = ctrl_qe;
397: 
398: 
399:   // R[status]: V(False)
400:   prim_subreg #(
401:     .DW      (8),
402:     .SwAccess(prim_subreg_pkg::SwAccessRO),
403:     .RESVAL  (8'h4),
404:     .Mubi    (1'b0)
405:   ) u_status (
406:     .clk_i   (clk_i),
407:     .rst_ni  (rst_ni),
408: 
409:     // from register interface
410:     .we     (1'b0),
411:     .wd     ('0),
412: 
413:     // from internal hardware
414:     .de     (hw2reg.status.de),
415:     .d      (hw2reg.status.d),
416: 
417:     // to internal hardware
418:     .qe     (),
419:     .q      (),
420:     .ds     (),
421: 
422:     // to register interface (read)
423:     .qs     (status_qs)
424:   );
425: 
426: 
427:   // R[err_bits]: V(True)
428:   logic err_bits_qe;
429:   logic [15:0] err_bits_flds_we;
430:   assign err_bits_qe = &err_bits_flds_we;
431:   //   F[bad_data_addr]: 0:0
432:   prim_subreg_ext #(
433:     .DW    (1)
434:   ) u_err_bits_bad_data_addr (
435:     .re     (err_bits_re),
436:     .we     (err_bits_we),
437:     .wd     (err_bits_bad_data_addr_wd),
438:     .d      (hw2reg.err_bits.bad_data_addr.d),
439:     .qre    (),
440:     .qe     (err_bits_flds_we[0]),
441:     .q      (reg2hw.err_bits.bad_data_addr.q),
442:     .ds     (),
443:     .qs     (err_bits_bad_data_addr_qs)
444:   );
445:   assign reg2hw.err_bits.bad_data_addr.qe = err_bits_qe;
446: 
447:   //   F[bad_insn_addr]: 1:1
448:   prim_subreg_ext #(
449:     .DW    (1)
450:   ) u_err_bits_bad_insn_addr (
451:     .re     (err_bits_re),
452:     .we     (err_bits_we),
453:     .wd     (err_bits_bad_insn_addr_wd),
454:     .d      (hw2reg.err_bits.bad_insn_addr.d),
455:     .qre    (),
456:     .qe     (err_bits_flds_we[1]),
457:     .q      (reg2hw.err_bits.bad_insn_addr.q),
458:     .ds     (),
459:     .qs     (err_bits_bad_insn_addr_qs)
460:   );
461:   assign reg2hw.err_bits.bad_insn_addr.qe = err_bits_qe;
462: 
463:   //   F[call_stack]: 2:2
464:   prim_subreg_ext #(
465:     .DW    (1)
466:   ) u_err_bits_call_stack (
467:     .re     (err_bits_re),
468:     .we     (err_bits_we),
469:     .wd     (err_bits_call_stack_wd),
470:     .d      (hw2reg.err_bits.call_stack.d),
471:     .qre    (),
472:     .qe     (err_bits_flds_we[2]),
473:     .q      (reg2hw.err_bits.call_stack.q),
474:     .ds     (),
475:     .qs     (err_bits_call_stack_qs)
476:   );
477:   assign reg2hw.err_bits.call_stack.qe = err_bits_qe;
478: 
479:   //   F[illegal_insn]: 3:3
480:   prim_subreg_ext #(
481:     .DW    (1)
482:   ) u_err_bits_illegal_insn (
483:     .re     (err_bits_re),
484:     .we     (err_bits_we),
485:     .wd     (err_bits_illegal_insn_wd),
486:     .d      (hw2reg.err_bits.illegal_insn.d),
487:     .qre    (),
488:     .qe     (err_bits_flds_we[3]),
489:     .q      (reg2hw.err_bits.illegal_insn.q),
490:     .ds     (),
491:     .qs     (err_bits_illegal_insn_qs)
492:   );
493:   assign reg2hw.err_bits.illegal_insn.qe = err_bits_qe;
494: 
495:   //   F[loop]: 4:4
496:   prim_subreg_ext #(
497:     .DW    (1)
498:   ) u_err_bits_loop (
499:     .re     (err_bits_re),
500:     .we     (err_bits_we),
501:     .wd     (err_bits_loop_wd),
502:     .d      (hw2reg.err_bits.loop.d),
503:     .qre    (),
504:     .qe     (err_bits_flds_we[4]),
505:     .q      (reg2hw.err_bits.loop.q),
506:     .ds     (),
507:     .qs     (err_bits_loop_qs)
508:   );
509:   assign reg2hw.err_bits.loop.qe = err_bits_qe;
510: 
511:   //   F[key_invalid]: 5:5
512:   prim_subreg_ext #(
513:     .DW    (1)
514:   ) u_err_bits_key_invalid (
515:     .re     (err_bits_re),
516:     .we     (err_bits_we),
517:     .wd     (err_bits_key_invalid_wd),
518:     .d      (hw2reg.err_bits.key_invalid.d),
519:     .qre    (),
520:     .qe     (err_bits_flds_we[5]),
521:     .q      (reg2hw.err_bits.key_invalid.q),
522:     .ds     (),
523:     .qs     (err_bits_key_invalid_qs)
524:   );
525:   assign reg2hw.err_bits.key_invalid.qe = err_bits_qe;
526: 
527:   //   F[rnd_rep_chk_fail]: 6:6
528:   prim_subreg_ext #(
529:     .DW    (1)
530:   ) u_err_bits_rnd_rep_chk_fail (
531:     .re     (err_bits_re),
532:     .we     (err_bits_we),
533:     .wd     (err_bits_rnd_rep_chk_fail_wd),
534:     .d      (hw2reg.err_bits.rnd_rep_chk_fail.d),
535:     .qre    (),
536:     .qe     (err_bits_flds_we[6]),
537:     .q      (reg2hw.err_bits.rnd_rep_chk_fail.q),
538:     .ds     (),
539:     .qs     (err_bits_rnd_rep_chk_fail_qs)
540:   );
541:   assign reg2hw.err_bits.rnd_rep_chk_fail.qe = err_bits_qe;
542: 
543:   //   F[rnd_fips_chk_fail]: 7:7
544:   prim_subreg_ext #(
545:     .DW    (1)
546:   ) u_err_bits_rnd_fips_chk_fail (
547:     .re     (err_bits_re),
548:     .we     (err_bits_we),
549:     .wd     (err_bits_rnd_fips_chk_fail_wd),
550:     .d      (hw2reg.err_bits.rnd_fips_chk_fail.d),
551:     .qre    (),
552:     .qe     (err_bits_flds_we[7]),
553:     .q      (reg2hw.err_bits.rnd_fips_chk_fail.q),
554:     .ds     (),
555:     .qs     (err_bits_rnd_fips_chk_fail_qs)
556:   );
557:   assign reg2hw.err_bits.rnd_fips_chk_fail.qe = err_bits_qe;
558: 
559:   //   F[imem_intg_violation]: 16:16
560:   prim_subreg_ext #(
561:     .DW    (1)
562:   ) u_err_bits_imem_intg_violation (
563:     .re     (err_bits_re),
564:     .we     (err_bits_we),
565:     .wd     (err_bits_imem_intg_violation_wd),
566:     .d      (hw2reg.err_bits.imem_intg_violation.d),
567:     .qre    (),
568:     .qe     (err_bits_flds_we[8]),
569:     .q      (reg2hw.err_bits.imem_intg_violation.q),
570:     .ds     (),
571:     .qs     (err_bits_imem_intg_violation_qs)
572:   );
573:   assign reg2hw.err_bits.imem_intg_violation.qe = err_bits_qe;
574: 
575:   //   F[dmem_intg_violation]: 17:17
576:   prim_subreg_ext #(
577:     .DW    (1)
578:   ) u_err_bits_dmem_intg_violation (
579:     .re     (err_bits_re),
580:     .we     (err_bits_we),
581:     .wd     (err_bits_dmem_intg_violation_wd),
582:     .d      (hw2reg.err_bits.dmem_intg_violation.d),
583:     .qre    (),
584:     .qe     (err_bits_flds_we[9]),
585:     .q      (reg2hw.err_bits.dmem_intg_violation.q),
586:     .ds     (),
587:     .qs     (err_bits_dmem_intg_violation_qs)
588:   );
589:   assign reg2hw.err_bits.dmem_intg_violation.qe = err_bits_qe;
590: 
591:   //   F[reg_intg_violation]: 18:18
592:   prim_subreg_ext #(
593:     .DW    (1)
594:   ) u_err_bits_reg_intg_violation (
595:     .re     (err_bits_re),
596:     .we     (err_bits_we),
597:     .wd     (err_bits_reg_intg_violation_wd),
598:     .d      (hw2reg.err_bits.reg_intg_violation.d),
599:     .qre    (),
600:     .qe     (err_bits_flds_we[10]),
601:     .q      (reg2hw.err_bits.reg_intg_violation.q),
602:     .ds     (),
603:     .qs     (err_bits_reg_intg_violation_qs)
604:   );
605:   assign reg2hw.err_bits.reg_intg_violation.qe = err_bits_qe;
606: 
607:   //   F[bus_intg_violation]: 19:19
608:   prim_subreg_ext #(
609:     .DW    (1)
610:   ) u_err_bits_bus_intg_violation (
611:     .re     (err_bits_re),
612:     .we     (err_bits_we),
613:     .wd     (err_bits_bus_intg_violation_wd),
614:     .d      (hw2reg.err_bits.bus_intg_violation.d),
615:     .qre    (),
616:     .qe     (err_bits_flds_we[11]),
617:     .q      (reg2hw.err_bits.bus_intg_violation.q),
618:     .ds     (),
619:     .qs     (err_bits_bus_intg_violation_qs)
620:   );
621:   assign reg2hw.err_bits.bus_intg_violation.qe = err_bits_qe;
622: 
623:   //   F[bad_internal_state]: 20:20
624:   prim_subreg_ext #(
625:     .DW    (1)
626:   ) u_err_bits_bad_internal_state (
627:     .re     (err_bits_re),
628:     .we     (err_bits_we),
629:     .wd     (err_bits_bad_internal_state_wd),
630:     .d      (hw2reg.err_bits.bad_internal_state.d),
631:     .qre    (),
632:     .qe     (err_bits_flds_we[12]),
633:     .q      (reg2hw.err_bits.bad_internal_state.q),
634:     .ds     (),
635:     .qs     (err_bits_bad_internal_state_qs)
636:   );
637:   assign reg2hw.err_bits.bad_internal_state.qe = err_bits_qe;
638: 
639:   //   F[illegal_bus_access]: 21:21
640:   prim_subreg_ext #(
641:     .DW    (1)
642:   ) u_err_bits_illegal_bus_access (
643:     .re     (err_bits_re),
644:     .we     (err_bits_we),
645:     .wd     (err_bits_illegal_bus_access_wd),
646:     .d      (hw2reg.err_bits.illegal_bus_access.d),
647:     .qre    (),
648:     .qe     (err_bits_flds_we[13]),
649:     .q      (reg2hw.err_bits.illegal_bus_access.q),
650:     .ds     (),
651:     .qs     (err_bits_illegal_bus_access_qs)
652:   );
653:   assign reg2hw.err_bits.illegal_bus_access.qe = err_bits_qe;
654: 
655:   //   F[lifecycle_escalation]: 22:22
656:   prim_subreg_ext #(
657:     .DW    (1)
658:   ) u_err_bits_lifecycle_escalation (
659:     .re     (err_bits_re),
660:     .we     (err_bits_we),
661:     .wd     (err_bits_lifecycle_escalation_wd),
662:     .d      (hw2reg.err_bits.lifecycle_escalation.d),
663:     .qre    (),
664:     .qe     (err_bits_flds_we[14]),
665:     .q      (reg2hw.err_bits.lifecycle_escalation.q),
666:     .ds     (),
667:     .qs     (err_bits_lifecycle_escalation_qs)
668:   );
669:   assign reg2hw.err_bits.lifecycle_escalation.qe = err_bits_qe;
670: 
671:   //   F[fatal_software]: 23:23
672:   prim_subreg_ext #(
673:     .DW    (1)
674:   ) u_err_bits_fatal_software (
675:     .re     (err_bits_re),
676:     .we     (err_bits_we),
677:     .wd     (err_bits_fatal_software_wd),
678:     .d      (hw2reg.err_bits.fatal_software.d),
679:     .qre    (),
680:     .qe     (err_bits_flds_we[15]),
681:     .q      (reg2hw.err_bits.fatal_software.q),
682:     .ds     (),
683:     .qs     (err_bits_fatal_software_qs)
684:   );
685:   assign reg2hw.err_bits.fatal_software.qe = err_bits_qe;
686: 
687: 
688:   // R[fatal_alert_cause]: V(False)
689:   //   F[imem_intg_violation]: 0:0
690:   prim_subreg #(
691:     .DW      (1),
692:     .SwAccess(prim_subreg_pkg::SwAccessRO),
693:     .RESVAL  (1'h0),
694:     .Mubi    (1'b0)
695:   ) u_fatal_alert_cause_imem_intg_violation (
696:     .clk_i   (clk_i),
697:     .rst_ni  (rst_ni),
698: 
699:     // from register interface
700:     .we     (1'b0),
701:     .wd     ('0),
702: 
703:     // from internal hardware
704:     .de     (hw2reg.fatal_alert_cause.imem_intg_violation.de),
705:     .d      (hw2reg.fatal_alert_cause.imem_intg_violation.d),
706: 
707:     // to internal hardware
708:     .qe     (),
709:     .q      (),
710:     .ds     (),
711: 
712:     // to register interface (read)
713:     .qs     (fatal_alert_cause_imem_intg_violation_qs)
714:   );
715: 
716:   //   F[dmem_intg_violation]: 1:1
717:   prim_subreg #(
718:     .DW      (1),
719:     .SwAccess(prim_subreg_pkg::SwAccessRO),
720:     .RESVAL  (1'h0),
721:     .Mubi    (1'b0)
722:   ) u_fatal_alert_cause_dmem_intg_violation (
723:     .clk_i   (clk_i),
724:     .rst_ni  (rst_ni),
725: 
726:     // from register interface
727:     .we     (1'b0),
728:     .wd     ('0),
729: 
730:     // from internal hardware
731:     .de     (hw2reg.fatal_alert_cause.dmem_intg_violation.de),
732:     .d      (hw2reg.fatal_alert_cause.dmem_intg_violation.d),
733: 
734:     // to internal hardware
735:     .qe     (),
736:     .q      (),
737:     .ds     (),
738: 
739:     // to register interface (read)
740:     .qs     (fatal_alert_cause_dmem_intg_violation_qs)
741:   );
742: 
743:   //   F[reg_intg_violation]: 2:2
744:   prim_subreg #(
745:     .DW      (1),
746:     .SwAccess(prim_subreg_pkg::SwAccessRO),
747:     .RESVAL  (1'h0),
748:     .Mubi    (1'b0)
749:   ) u_fatal_alert_cause_reg_intg_violation (
750:     .clk_i   (clk_i),
751:     .rst_ni  (rst_ni),
752: 
753:     // from register interface
754:     .we     (1'b0),
755:     .wd     ('0),
756: 
757:     // from internal hardware
758:     .de     (hw2reg.fatal_alert_cause.reg_intg_violation.de),
759:     .d      (hw2reg.fatal_alert_cause.reg_intg_violation.d),
760: 
761:     // to internal hardware
762:     .qe     (),
763:     .q      (),
764:     .ds     (),
765: 
766:     // to register interface (read)
767:     .qs     (fatal_alert_cause_reg_intg_violation_qs)
768:   );
769: 
770:   //   F[bus_intg_violation]: 3:3
771:   prim_subreg #(
772:     .DW      (1),
773:     .SwAccess(prim_subreg_pkg::SwAccessRO),
774:     .RESVAL  (1'h0),
775:     .Mubi    (1'b0)
776:   ) u_fatal_alert_cause_bus_intg_violation (
777:     .clk_i   (clk_i),
778:     .rst_ni  (rst_ni),
779: 
780:     // from register interface
781:     .we     (1'b0),
782:     .wd     ('0),
783: 
784:     // from internal hardware
785:     .de     (hw2reg.fatal_alert_cause.bus_intg_violation.de),
786:     .d      (hw2reg.fatal_alert_cause.bus_intg_violation.d),
787: 
788:     // to internal hardware
789:     .qe     (),
790:     .q      (),
791:     .ds     (),
792: 
793:     // to register interface (read)
794:     .qs     (fatal_alert_cause_bus_intg_violation_qs)
795:   );
796: 
797:   //   F[bad_internal_state]: 4:4
798:   prim_subreg #(
799:     .DW      (1),
800:     .SwAccess(prim_subreg_pkg::SwAccessRO),
801:     .RESVAL  (1'h0),
802:     .Mubi    (1'b0)
803:   ) u_fatal_alert_cause_bad_internal_state (
804:     .clk_i   (clk_i),
805:     .rst_ni  (rst_ni),
806: 
807:     // from register interface
808:     .we     (1'b0),
809:     .wd     ('0),
810: 
811:     // from internal hardware
812:     .de     (hw2reg.fatal_alert_cause.bad_internal_state.de),
813:     .d      (hw2reg.fatal_alert_cause.bad_internal_state.d),
814: 
815:     // to internal hardware
816:     .qe     (),
817:     .q      (),
818:     .ds     (),
819: 
820:     // to register interface (read)
821:     .qs     (fatal_alert_cause_bad_internal_state_qs)
822:   );
823: 
824:   //   F[illegal_bus_access]: 5:5
825:   prim_subreg #(
826:     .DW      (1),
827:     .SwAccess(prim_subreg_pkg::SwAccessRO),
828:     .RESVAL  (1'h0),
829:     .Mubi    (1'b0)
830:   ) u_fatal_alert_cause_illegal_bus_access (
831:     .clk_i   (clk_i),
832:     .rst_ni  (rst_ni),
833: 
834:     // from register interface
835:     .we     (1'b0),
836:     .wd     ('0),
837: 
838:     // from internal hardware
839:     .de     (hw2reg.fatal_alert_cause.illegal_bus_access.de),
840:     .d      (hw2reg.fatal_alert_cause.illegal_bus_access.d),
841: 
842:     // to internal hardware
843:     .qe     (),
844:     .q      (),
845:     .ds     (),
846: 
847:     // to register interface (read)
848:     .qs     (fatal_alert_cause_illegal_bus_access_qs)
849:   );
850: 
851:   //   F[lifecycle_escalation]: 6:6
852:   prim_subreg #(
853:     .DW      (1),
854:     .SwAccess(prim_subreg_pkg::SwAccessRO),
855:     .RESVAL  (1'h0),
856:     .Mubi    (1'b0)
857:   ) u_fatal_alert_cause_lifecycle_escalation (
858:     .clk_i   (clk_i),
859:     .rst_ni  (rst_ni),
860: 
861:     // from register interface
862:     .we     (1'b0),
863:     .wd     ('0),
864: 
865:     // from internal hardware
866:     .de     (hw2reg.fatal_alert_cause.lifecycle_escalation.de),
867:     .d      (hw2reg.fatal_alert_cause.lifecycle_escalation.d),
868: 
869:     // to internal hardware
870:     .qe     (),
871:     .q      (),
872:     .ds     (),
873: 
874:     // to register interface (read)
875:     .qs     (fatal_alert_cause_lifecycle_escalation_qs)
876:   );
877: 
878:   //   F[fatal_software]: 7:7
879:   prim_subreg #(
880:     .DW      (1),
881:     .SwAccess(prim_subreg_pkg::SwAccessRO),
882:     .RESVAL  (1'h0),
883:     .Mubi    (1'b0)
884:   ) u_fatal_alert_cause_fatal_software (
885:     .clk_i   (clk_i),
886:     .rst_ni  (rst_ni),
887: 
888:     // from register interface
889:     .we     (1'b0),
890:     .wd     ('0),
891: 
892:     // from internal hardware
893:     .de     (hw2reg.fatal_alert_cause.fatal_software.de),
894:     .d      (hw2reg.fatal_alert_cause.fatal_software.d),
895: 
896:     // to internal hardware
897:     .qe     (),
898:     .q      (),
899:     .ds     (),
900: 
901:     // to register interface (read)
902:     .qs     (fatal_alert_cause_fatal_software_qs)
903:   );
904: 
905: 
906:   // R[insn_cnt]: V(True)
907:   logic insn_cnt_qe;
908:   logic [0:0] insn_cnt_flds_we;
909:   assign insn_cnt_qe = &insn_cnt_flds_we;
910:   prim_subreg_ext #(
911:     .DW    (32)
912:   ) u_insn_cnt (
913:     .re     (insn_cnt_re),
914:     .we     (insn_cnt_we),
915:     .wd     (insn_cnt_wd),
916:     .d      (hw2reg.insn_cnt.d),
917:     .qre    (),
918:     .qe     (insn_cnt_flds_we[0]),
919:     .q      (reg2hw.insn_cnt.q),
920:     .ds     (),
921:     .qs     (insn_cnt_qs)
922:   );
923:   assign reg2hw.insn_cnt.qe = insn_cnt_qe;
924: 
925: 
926:   // R[load_checksum]: V(True)
927:   logic load_checksum_qe;
928:   logic [0:0] load_checksum_flds_we;
929:   assign load_checksum_qe = &load_checksum_flds_we;
930:   prim_subreg_ext #(
931:     .DW    (32)
932:   ) u_load_checksum (
933:     .re     (load_checksum_re),
934:     .we     (load_checksum_we),
935:     .wd     (load_checksum_wd),
936:     .d      (hw2reg.load_checksum.d),
937:     .qre    (),
938:     .qe     (load_checksum_flds_we[0]),
939:     .q      (reg2hw.load_checksum.q),
940:     .ds     (),
941:     .qs     (load_checksum_qs)
942:   );
943:   assign reg2hw.load_checksum.qe = load_checksum_qe;
944: 
945: 
946: 
947:   logic [10:0] addr_hit;
948:   always_comb begin
949:     addr_hit[ 0] = (reg_addr == OTBN_INTR_STATE_OFFSET);
950:     addr_hit[ 1] = (reg_addr == OTBN_INTR_ENABLE_OFFSET);
951:     addr_hit[ 2] = (reg_addr == OTBN_INTR_TEST_OFFSET);
952:     addr_hit[ 3] = (reg_addr == OTBN_ALERT_TEST_OFFSET);
953:     addr_hit[ 4] = (reg_addr == OTBN_CMD_OFFSET);
954:     addr_hit[ 5] = (reg_addr == OTBN_CTRL_OFFSET);
955:     addr_hit[ 6] = (reg_addr == OTBN_STATUS_OFFSET);
956:     addr_hit[ 7] = (reg_addr == OTBN_ERR_BITS_OFFSET);
957:     addr_hit[ 8] = (reg_addr == OTBN_FATAL_ALERT_CAUSE_OFFSET);
958:     addr_hit[ 9] = (reg_addr == OTBN_INSN_CNT_OFFSET);
959:     addr_hit[10] = (reg_addr == OTBN_LOAD_CHECKSUM_OFFSET);
960:   end
961: 
962:   assign addrmiss = (reg_re || reg_we) ? ~|addr_hit : 1'b0 ;
963: 
964:   // Check sub-word write is permitted
965:   always_comb begin
966:     wr_err = (reg_we &
967:               ((addr_hit[ 0] & (|(OTBN_PERMIT[ 0] & ~reg_be))) |
968:                (addr_hit[ 1] & (|(OTBN_PERMIT[ 1] & ~reg_be))) |
969:                (addr_hit[ 2] & (|(OTBN_PERMIT[ 2] & ~reg_be))) |
970:                (addr_hit[ 3] & (|(OTBN_PERMIT[ 3] & ~reg_be))) |
971:                (addr_hit[ 4] & (|(OTBN_PERMIT[ 4] & ~reg_be))) |
972:                (addr_hit[ 5] & (|(OTBN_PERMIT[ 5] & ~reg_be))) |
973:                (addr_hit[ 6] & (|(OTBN_PERMIT[ 6] & ~reg_be))) |
974:                (addr_hit[ 7] & (|(OTBN_PERMIT[ 7] & ~reg_be))) |
975:                (addr_hit[ 8] & (|(OTBN_PERMIT[ 8] & ~reg_be))) |
976:                (addr_hit[ 9] & (|(OTBN_PERMIT[ 9] & ~reg_be))) |
977:                (addr_hit[10] & (|(OTBN_PERMIT[10] & ~reg_be)))));
978:   end
979: 
980:   // Generate write-enables
981:   assign intr_state_we = addr_hit[0] & reg_we & !reg_error;
982: 
983:   assign intr_state_wd = reg_wdata[0];
984:   assign intr_enable_we = addr_hit[1] & reg_we & !reg_error;
985: 
986:   assign intr_enable_wd = reg_wdata[0];
987:   assign intr_test_we = addr_hit[2] & reg_we & !reg_error;
988: 
989:   assign intr_test_wd = reg_wdata[0];
990:   assign alert_test_we = addr_hit[3] & reg_we & !reg_error;
991: 
992:   assign alert_test_fatal_wd = reg_wdata[0];
993: 
994:   assign alert_test_recov_wd = reg_wdata[1];
995:   assign cmd_we = addr_hit[4] & reg_we & !reg_error;
996: 
997:   assign cmd_wd = reg_wdata[7:0];
998:   assign ctrl_re = addr_hit[5] & reg_re & !reg_error;
999:   assign ctrl_we = addr_hit[5] & reg_we & !reg_error;
1000: 
1001:   assign ctrl_wd = reg_wdata[0];
1002:   assign err_bits_re = addr_hit[7] & reg_re & !reg_error;
1003:   assign err_bits_we = addr_hit[7] & reg_we & !reg_error;
1004: 
1005:   assign err_bits_bad_data_addr_wd = reg_wdata[0];
1006: 
1007:   assign err_bits_bad_insn_addr_wd = reg_wdata[1];
1008: 
1009:   assign err_bits_call_stack_wd = reg_wdata[2];
1010: 
1011:   assign err_bits_illegal_insn_wd = reg_wdata[3];
1012: 
1013:   assign err_bits_loop_wd = reg_wdata[4];
1014: 
1015:   assign err_bits_key_invalid_wd = reg_wdata[5];
1016: 
1017:   assign err_bits_rnd_rep_chk_fail_wd = reg_wdata[6];
1018: 
1019:   assign err_bits_rnd_fips_chk_fail_wd = reg_wdata[7];
1020: 
1021:   assign err_bits_imem_intg_violation_wd = reg_wdata[16];
1022: 
1023:   assign err_bits_dmem_intg_violation_wd = reg_wdata[17];
1024: 
1025:   assign err_bits_reg_intg_violation_wd = reg_wdata[18];
1026: 
1027:   assign err_bits_bus_intg_violation_wd = reg_wdata[19];
1028: 
1029:   assign err_bits_bad_internal_state_wd = reg_wdata[20];
1030: 
1031:   assign err_bits_illegal_bus_access_wd = reg_wdata[21];
1032: 
1033:   assign err_bits_lifecycle_escalation_wd = reg_wdata[22];
1034: 
1035:   assign err_bits_fatal_software_wd = reg_wdata[23];
1036:   assign insn_cnt_re = addr_hit[9] & reg_re & !reg_error;
1037:   assign insn_cnt_we = addr_hit[9] & reg_we & !reg_error;
1038: 
1039:   assign insn_cnt_wd = reg_wdata[31:0];
1040:   assign load_checksum_re = addr_hit[10] & reg_re & !reg_error;
1041:   assign load_checksum_we = addr_hit[10] & reg_we & !reg_error;
1042: 
1043:   assign load_checksum_wd = reg_wdata[31:0];
1044: 
1045:   // Assign write-enables to checker logic vector.
1046:   always_comb begin
1047:     reg_we_check[0] = intr_state_we;
1048:     reg_we_check[1] = intr_enable_we;
1049:     reg_we_check[2] = intr_test_we;
1050:     reg_we_check[3] = alert_test_we;
1051:     reg_we_check[4] = cmd_we;
1052:     reg_we_check[5] = ctrl_we;
1053:     reg_we_check[6] = 1'b0;
1054:     reg_we_check[7] = err_bits_we;
1055:     reg_we_check[8] = 1'b0;
1056:     reg_we_check[9] = insn_cnt_we;
1057:     reg_we_check[10] = load_checksum_we;
1058:   end
1059: 
1060:   // Read data return
1061:   always_comb begin
1062:     reg_rdata_next = '0;
1063:     unique case (1'b1)
1064:       addr_hit[0]: begin
1065:         reg_rdata_next[0] = intr_state_qs;
1066:       end
1067: 
1068:       addr_hit[1]: begin
1069:         reg_rdata_next[0] = intr_enable_qs;
1070:       end
1071: 
1072:       addr_hit[2]: begin
1073:         reg_rdata_next[0] = '0;
1074:       end
1075: 
1076:       addr_hit[3]: begin
1077:         reg_rdata_next[0] = '0;
1078:         reg_rdata_next[1] = '0;
1079:       end
1080: 
1081:       addr_hit[4]: begin
1082:         reg_rdata_next[7:0] = '0;
1083:       end
1084: 
1085:       addr_hit[5]: begin
1086:         reg_rdata_next[0] = ctrl_qs;
1087:       end
1088: 
1089:       addr_hit[6]: begin
1090:         reg_rdata_next[7:0] = status_qs;
1091:       end
1092: 
1093:       addr_hit[7]: begin
1094:         reg_rdata_next[0] = err_bits_bad_data_addr_qs;
1095:         reg_rdata_next[1] = err_bits_bad_insn_addr_qs;
1096:         reg_rdata_next[2] = err_bits_call_stack_qs;
1097:         reg_rdata_next[3] = err_bits_illegal_insn_qs;
1098:         reg_rdata_next[4] = err_bits_loop_qs;
1099:         reg_rdata_next[5] = err_bits_key_invalid_qs;
1100:         reg_rdata_next[6] = err_bits_rnd_rep_chk_fail_qs;
1101:         reg_rdata_next[7] = err_bits_rnd_fips_chk_fail_qs;
1102:         reg_rdata_next[16] = err_bits_imem_intg_violation_qs;
1103:         reg_rdata_next[17] = err_bits_dmem_intg_violation_qs;
1104:         reg_rdata_next[18] = err_bits_reg_intg_violation_qs;
1105:         reg_rdata_next[19] = err_bits_bus_intg_violation_qs;
1106:         reg_rdata_next[20] = err_bits_bad_internal_state_qs;
1107:         reg_rdata_next[21] = err_bits_illegal_bus_access_qs;
1108:         reg_rdata_next[22] = err_bits_lifecycle_escalation_qs;
1109:         reg_rdata_next[23] = err_bits_fatal_software_qs;
1110:       end
1111: 
1112:       addr_hit[8]: begin
1113:         reg_rdata_next[0] = fatal_alert_cause_imem_intg_violation_qs;
1114:         reg_rdata_next[1] = fatal_alert_cause_dmem_intg_violation_qs;
1115:         reg_rdata_next[2] = fatal_alert_cause_reg_intg_violation_qs;
1116:         reg_rdata_next[3] = fatal_alert_cause_bus_intg_violation_qs;
1117:         reg_rdata_next[4] = fatal_alert_cause_bad_internal_state_qs;
1118:         reg_rdata_next[5] = fatal_alert_cause_illegal_bus_access_qs;
1119:         reg_rdata_next[6] = fatal_alert_cause_lifecycle_escalation_qs;
1120:         reg_rdata_next[7] = fatal_alert_cause_fatal_software_qs;
1121:       end
1122: 
1123:       addr_hit[9]: begin
1124:         reg_rdata_next[31:0] = insn_cnt_qs;
1125:       end
1126: 
1127:       addr_hit[10]: begin
1128:         reg_rdata_next[31:0] = load_checksum_qs;
1129:       end
1130: 
1131:       default: begin
1132:         reg_rdata_next = '1;
1133:       end
1134:     endcase
1135:   end
1136: 
1137:   // shadow busy
1138:   logic shadow_busy;
1139:   assign shadow_busy = 1'b0;
1140: 
1141:   // register busy
1142:   assign reg_busy = shadow_busy;
1143: 
1144:   // Unused signal tieoff
1145: 
1146:   // wdata / byte enable are not always fully used
1147:   // add a blanket unused statement to handle lint waivers
1148:   logic unused_wdata;
1149:   logic unused_be;
1150:   assign unused_wdata = ^reg_wdata;
1151:   assign unused_be = ^reg_be;
1152: 
1153:   // Assertions for Register Interface
1154:   `ASSERT_PULSE(wePulse, reg_we, clk_i, !rst_ni)
1155:   `ASSERT_PULSE(rePulse, reg_re, clk_i, !rst_ni)
1156: 
1157:   `ASSERT(reAfterRv, $rose(reg_re || reg_we) |=> tl_o_pre.d_valid, clk_i, !rst_ni)
1158: 
1159:   `ASSERT(en2addrHit, (reg_we || reg_re) |-> $onehot0(addr_hit), clk_i, !rst_ni)
1160: 
1161:   // this is formulated as an assumption such that the FPV testbenches do disprove this
1162:   // property by mistake
1163:   //`ASSUME(reqParity, tl_reg_h2d.a_valid |-> tl_reg_h2d.a_user.chk_en == tlul_pkg::CheckDis)
1164: 
1165: endmodule

================================== Ai Message ==================================
Tool Calls:
  read_file_with_line_numbers (call_VzNFVgxkdfmibJwHaWLwJOeU)
 Call ID: call_VzNFVgxkdfmibJwHaWLwJOeU
  Args:
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv
================================= Tool Message =================================
Name: read_file_with_line_numbers

1: // Copyright lowRISC contributors (OpenTitan project).
2: // Licensed under the Apache License, Version 2.0, see LICENSE for details.
3: // SPDX-License-Identifier: Apache-2.0
4: 
5: `include "prim_assert.sv"
6: `include "prim_fifo_assert.svh"
7: 
8: /**
9:  * OpenTitan Big Number Accelerator (OTBN)
10:  */
11: module otbn
12:   import prim_alert_pkg::*;
13:   import otbn_pkg::*;
14:   import otbn_reg_pkg::*;
15: #(
16:   parameter bit                   Stub         = 1'b0,
17:   parameter regfile_e             RegFile      = RegFileFF,
18:   parameter logic [NumAlerts-1:0] AlertAsyncOn = {NumAlerts{1'b1}},
19: 
20:   // Default seed for URND PRNG
21:   parameter urnd_prng_seed_t RndCnstUrndPrngSeed = RndCnstUrndPrngSeedDefault,
22: 
23:   // Disable URND advance when not in use. Useful for SCA only.
24:   parameter bit SecMuteUrnd = 1'b0,
25:   // Skip URND re-seed at the start of an operation. Useful for SCA only.
26:   parameter bit SecSkipUrndReseedAtStart = 1'b0,
27: 
28:   // Default seed and nonce for scrambling
29:   parameter otp_ctrl_pkg::otbn_key_t   RndCnstOtbnKey   = RndCnstOtbnKeyDefault,
30:   parameter otp_ctrl_pkg::otbn_nonce_t RndCnstOtbnNonce = RndCnstOtbnNonceDefault
31: ) (
32:   input clk_i,
33:   input rst_ni,
34: 
35:   input  tlul_pkg::tl_h2d_t tl_i,
36:   output tlul_pkg::tl_d2h_t tl_o,
37: 
38:   // Inter-module signals
39:   output prim_mubi_pkg::mubi4_t idle_o,
40: 
41:   // Interrupts
42:   output logic intr_done_o,
43: 
44:   // Alerts
45:   input  prim_alert_pkg::alert_rx_t [NumAlerts-1:0] alert_rx_i,
46:   output prim_alert_pkg::alert_tx_t [NumAlerts-1:0] alert_tx_o,
47: 
48:   // Lifecycle interfaces
49:   input  lc_ctrl_pkg::lc_tx_t lc_escalate_en_i,
50: 
51:   input  lc_ctrl_pkg::lc_tx_t lc_rma_req_i,
52:   output lc_ctrl_pkg::lc_tx_t lc_rma_ack_o,
53: 
54:   // Memory configuration
55:   input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_imem_i,
56:   input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_dmem_i,
57:   output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_imem_o,
58:   output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_dmem_o,
59: 
60:   // EDN clock and interface
61:   input                     clk_edn_i,
62:   input                     rst_edn_ni,
63:   output edn_pkg::edn_req_t edn_rnd_o,
64:   input  edn_pkg::edn_rsp_t edn_rnd_i,
65: 
66:   output edn_pkg::edn_req_t edn_urnd_o,
67:   input  edn_pkg::edn_rsp_t edn_urnd_i,
68: 
69:   // Key request to OTP (running on clk_fixed)
70:   input                                   clk_otp_i,
71:   input                                   rst_otp_ni,
72:   output otp_ctrl_pkg::otbn_otp_key_req_t otbn_otp_key_o,
73:   input  otp_ctrl_pkg::otbn_otp_key_rsp_t otbn_otp_key_i,
74: 
75:   input keymgr_pkg::otbn_key_req_t keymgr_key_i
76: );
77: 
78:   import prim_mubi_pkg::*;
79:   import prim_util_pkg::vbits;
80: 
81:   logic rst_n;
82: 
83:   // hold module in reset permanently when stubbing
84:   if (Stub) begin : gen_stub_otbn
85:     assign rst_n = 1'b0;
86:   end else begin : gen_real_otbn
87:     assign rst_n = rst_ni;
88:   end
89: 
90:   // The OTBN_*_SIZE parameters are auto-generated by regtool and come from the bus window sizes;
91:   // they are given in bytes and must be powers of two.
92:   //
93:   // DMEM is actually a bit bigger than OTBN_DMEM_SIZE: there are an extra DmemScratchSizeByte bytes
94:   // that aren't accessible over the bus.
95:   localparam int ImemSizeByte = int'(otbn_reg_pkg::OTBN_IMEM_SIZE);
96:   localparam int DmemSizeByte = int'(otbn_reg_pkg::OTBN_DMEM_SIZE + DmemScratchSizeByte);
97: 
98:   localparam int ImemAddrWidth = vbits(ImemSizeByte);
99:   localparam int DmemAddrWidth = vbits(DmemSizeByte);
100: 
101:   `ASSERT_INIT(ImemSizePowerOfTwo, 2 ** ImemAddrWidth == ImemSizeByte)
102:   `ASSERT_INIT(DmemSizePowerOfTwo, 2 ** DmemAddrWidth == DmemSizeByte)
103: 
104:   logic start_d, start_q;
105:   logic busy_execute_d, busy_execute_q;
106:   logic done, done_core, locking, locking_q;
107:   logic busy_secure_wipe;
108:   logic init_sec_wipe_done_d, init_sec_wipe_done_q;
109:   logic illegal_bus_access_d, illegal_bus_access_q;
110:   logic missed_gnt_error_d, missed_gnt_error_q;
111:   logic dmem_sec_wipe;
112:   logic imem_sec_wipe;
113:   logic mems_sec_wipe;
114:   logic req_sec_wipe_urnd_keys;
115:   logic [127:0] dmem_sec_wipe_urnd_key, imem_sec_wipe_urnd_key;
116: 
117:   logic core_recoverable_err, recoverable_err_d, recoverable_err_q;
118:   mubi4_t core_escalate_en;
119: 
120:   core_err_bits_t     core_err_bits;
121:   non_core_err_bits_t non_core_err_bits, non_core_err_bits_d, non_core_err_bits_q;
122:   err_bits_t          err_bits, err_bits_d, err_bits_q;
123:   logic               err_bits_en;
124: 
125:   // ERR_BITS register should be cleared due to a write request from the host processor
126:   // when OTBN is not running.
127:   logic err_bits_clear;
128: 
129:   logic software_errs_fatal_q, software_errs_fatal_d;
130: 
131:   otbn_reg2hw_t reg2hw;
132:   otbn_hw2reg_t hw2reg;
133:   status_e      status_d, status_q;
134: 
135:   // Bus device windows, as specified in otbn.hjson
136:   typedef enum logic {
137:     TlWinImem = 1'b0,
138:     TlWinDmem = 1'b1
139:   } tl_win_e;
140: 
141:   tlul_pkg::tl_h2d_t tl_win_h2d[2];
142:   tlul_pkg::tl_d2h_t tl_win_d2h[2];
143: 
144:   // The clock can be gated and some registers can be updated as long as OTBN isn't currently
145:   // running. Other registers can only be updated when OTBN is in the Idle state (which also implies
146:   // we are not locked).
147:   logic is_not_running_d, is_not_running_q;
148:   logic otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy;
149: 
150:   assign is_not_running_d = ~|{busy_execute_d,
151:                                otbn_dmem_scramble_key_req_busy,
152:                                otbn_imem_scramble_key_req_busy,
153:                                busy_secure_wipe};
154: 
155:   always_ff @(posedge clk_i or negedge rst_ni) begin
156:     if(!rst_ni) begin
157:       // OTBN starts busy, performing the initial secure wipe.
158:       is_not_running_q  <= 1'b0;
159:     end else begin
160:       is_not_running_q  <= is_not_running_d;
161:     end
162:   end
163: 
164:   // Inter-module signals ======================================================
165: 
166:   // Note: This is not the same thing as STATUS == IDLE. For example, we want to allow clock gating
167:   // when locked.
168:   prim_mubi4_sender #(
169:     .ResetValue(prim_mubi_pkg::MuBi4True)
170:   ) u_prim_mubi4_sender (
171:     .clk_i,
172:     .rst_ni,
173:     .mubi_i(mubi4_bool_to_mubi(is_not_running_q)),
174:     .mubi_o(idle_o)
175:   );
176: 
177:   // Lifecycle ==================================================================
178: 
179:   localparam int unsigned LcEscalateCopies = 2;
180:   lc_ctrl_pkg::lc_tx_t [LcEscalateCopies-1:0] lc_escalate_en;
181:   prim_lc_sync #(
182:     .NumCopies(LcEscalateCopies)
183:   ) u_lc_escalate_en_sync (
184:     .clk_i,
185:     .rst_ni,
186:     .lc_en_i(lc_escalate_en_i),
187:     .lc_en_o(lc_escalate_en)
188:   );
189: 
190:   lc_ctrl_pkg::lc_tx_t lc_rma_req;
191:   prim_lc_sync #(
192:     .NumCopies(1)
193:   ) u_lc_rma_req_sync (
194:     .clk_i,
195:     .rst_ni,
196:     .lc_en_i(lc_rma_req_i),
197:     .lc_en_o({lc_rma_req})
198:   );
199: 
200:   // Internally, OTBN uses MUBI types.
201:   mubi4_t mubi_rma_req, mubi_rma_ack;
202:   assign mubi_rma_req = lc_ctrl_pkg::lc_to_mubi4(lc_rma_req);
203: 
204:   // When stubbing, forward req to ack.
205:   if (Stub) begin : gen_stub_rma_ack
206:     assign lc_rma_ack_o = lc_rma_req;
207:   end else begin : gen_real_rma_ack
208:     assign lc_rma_ack_o = lc_ctrl_pkg::mubi4_to_lc(mubi_rma_ack);
209:   end
210: 
211:   // Interrupts ================================================================
212: 
213:   assign done = is_busy_status(status_q) & ~is_busy_status(status_d) & init_sec_wipe_done_q;
214: 
215:   prim_intr_hw #(
216:     .Width(1)
217:   ) u_intr_hw_done (
218:     .clk_i,
219:     .rst_ni                (rst_n),
220:     .event_intr_i          (done),
221:     .reg2hw_intr_enable_q_i(reg2hw.intr_enable.q),
222:     .reg2hw_intr_test_q_i  (reg2hw.intr_test.q),
223:     .reg2hw_intr_test_qe_i (reg2hw.intr_test.qe),
224:     .reg2hw_intr_state_q_i (reg2hw.intr_state.q),
225:     .hw2reg_intr_state_de_o(hw2reg.intr_state.de),
226:     .hw2reg_intr_state_d_o (hw2reg.intr_state.d),
227:     .intr_o                (intr_done_o)
228:   );
229: 
230:   // Instruction Memory (IMEM) =================================================
231: 
232:   localparam int ImemSizeWords = ImemSizeByte / 4;
233:   localparam int ImemIndexWidth = vbits(ImemSizeWords);
234: 
235:   // Access select to IMEM: core (1), or bus (0)
236:   logic imem_access_core;
237: 
238:   logic imem_req;
239:   logic imem_gnt;
240:   logic imem_write;
241:   logic imem_wr_collision;
242:   logic imem_wpending;
243:   logic [ImemIndexWidth-1:0] imem_index;
244:   logic [38:0] imem_wdata;
245:   logic [38:0] imem_wmask;
246:   logic [38:0] imem_rdata;
247:   logic imem_rvalid;
248:   logic imem_illegal_bus_access;
249:   logic imem_missed_gnt;
250: 
251:   logic imem_req_core;
252:   logic imem_write_core;
253:   logic [ImemIndexWidth-1:0] imem_index_core;
254:   logic [38:0] imem_rdata_core;
255:   logic imem_rvalid_core;
256: 
257:   logic imem_req_bus;
258:   logic imem_dummy_response_q, imem_dummy_response_d;
259:   logic imem_write_bus;
260:   logic [ImemIndexWidth-1:0] imem_index_bus;
261:   logic [38:0] imem_wdata_bus;
262:   logic [38:0] imem_wmask_bus;
263:   logic [38:0] imem_rdata_bus, imem_rdata_bus_raw;
264:   logic imem_rdata_bus_en_q, imem_rdata_bus_en_d;
265:   logic [top_pkg::TL_DBW-1:0] imem_byte_mask_bus;
266:   logic imem_rvalid_bus;
267:   logic [1:0] imem_rerror_bus;
268: 
269:   logic imem_bus_intg_violation;
270: 
271:   typedef struct packed {
272:     logic        imem;
273:     logic [14:0] index;
274:     logic [31:0] wr_data;
275:   } mem_crc_data_in_t;
276: 
277:   logic             mem_crc_data_in_valid;
278:   mem_crc_data_in_t mem_crc_data_in;
279:   logic             set_crc;
280:   logic [31:0]      crc_in, crc_out;
281: 
282:   logic [ImemAddrWidth-1:0] imem_addr_core;
283:   assign imem_index_core = imem_addr_core[ImemAddrWidth-1:2];
284: 
285:   logic [1:0] unused_imem_addr_core_wordbits;
286:   assign unused_imem_addr_core_wordbits = imem_addr_core[1:0];
287: 
288:   otp_ctrl_pkg::otbn_key_t otbn_imem_scramble_key;
289:   otbn_imem_nonce_t        otbn_imem_scramble_nonce;
290:   logic                    otbn_imem_scramble_valid;
291:   logic                    unused_otbn_imem_scramble_key_seed_valid;
292: 
293:   otp_ctrl_pkg::otbn_key_t otbn_dmem_scramble_key;
294:   otbn_dmem_nonce_t        otbn_dmem_scramble_nonce;
295:   logic                    otbn_dmem_scramble_valid;
296:   logic                    unused_otbn_dmem_scramble_key_seed_valid;
297: 
298: 
299:   logic otbn_scramble_state_error;
300: 
301:   // SEC_CM: SCRAMBLE.KEY.SIDELOAD
302:   otbn_scramble_ctrl #(
303:     .RndCnstOtbnKey  (RndCnstOtbnKey),
304:     .RndCnstOtbnNonce(RndCnstOtbnNonce)
305:   ) u_otbn_scramble_ctrl (
306:     .clk_i,
307:     .rst_ni,
308: 
309:     .clk_otp_i,
310:     .rst_otp_ni,
311: 
312:     .otbn_otp_key_o,
313:     .otbn_otp_key_i,
314: 
315:     .otbn_dmem_scramble_key_o           (otbn_dmem_scramble_key),
316:     .otbn_dmem_scramble_nonce_o         (otbn_dmem_scramble_nonce),
317:     .otbn_dmem_scramble_valid_o         (otbn_dmem_scramble_valid),
318:     .otbn_dmem_scramble_key_seed_valid_o(unused_otbn_dmem_scramble_key_seed_valid),
319: 
320:     .otbn_imem_scramble_key_o           (otbn_imem_scramble_key),
321:     .otbn_imem_scramble_nonce_o         (otbn_imem_scramble_nonce),
322:     .otbn_imem_scramble_valid_o         (otbn_imem_scramble_valid),
323:     .otbn_imem_scramble_key_seed_valid_o(unused_otbn_imem_scramble_key_seed_valid),
324: 
325:     .otbn_dmem_scramble_sec_wipe_i    (dmem_sec_wipe),
326:     .otbn_dmem_scramble_sec_wipe_key_i(dmem_sec_wipe_urnd_key),
327:     .otbn_imem_scramble_sec_wipe_i    (imem_sec_wipe),
328:     .otbn_imem_scramble_sec_wipe_key_i(imem_sec_wipe_urnd_key),
329: 
330:     .otbn_dmem_scramble_key_req_busy_o(otbn_dmem_scramble_key_req_busy),
331:     .otbn_imem_scramble_key_req_busy_o(otbn_imem_scramble_key_req_busy),
332: 
333:     .state_error_o(otbn_scramble_state_error)
334:   );
335: 
336:   // SEC_CM: MEM.SCRAMBLE
337:   prim_ram_1p_scr #(
338:     .Width          (39),
339:     .Depth          (ImemSizeWords),
340:     .InstDepth      (ImemSizeWords),
341:     .DataBitsPerMask(39),
342:     .EnableParity   (0)
343:   ) u_imem (
344:     .clk_i,
345:     .rst_ni(rst_n),
346: 
347:     .key_valid_i(otbn_imem_scramble_valid),
348:     .key_i      (otbn_imem_scramble_key),
349:     .nonce_i    (otbn_imem_scramble_nonce),
350: 
351:     .req_i       (imem_req),
352:     .gnt_o       (imem_gnt),
353:     .write_i     (imem_write),
354:     .addr_i      (imem_index),
355:     .wdata_i     (imem_wdata),
356:     .wmask_i     (imem_wmask),
357:     .intg_error_i(locking),
358: 
359:     .rdata_o  (imem_rdata),
360:     .rvalid_o (imem_rvalid),
361:     .raddr_o  (),
362:     .rerror_o (),
363:     .cfg_i    (ram_cfg_imem_i),
364:     .cfg_rsp_o(ram_cfg_rsp_imem_o),
365: 
366:     .wr_collision_o   (imem_wr_collision),
367:     .write_pending_o  (imem_wpending),
368: 
369:     .alert_o ()
370:   );
371: 
372:   // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
373:   assign imem_missed_gnt = imem_req & ~imem_gnt;
374: 
375:   // IMEM access from main TL-UL bus
376:   logic imem_gnt_bus;
377:   // Always grant to bus accesses, when OTBN is running a dummy response is returned
378:   assign imem_gnt_bus = imem_req_bus;
379: 
380:   tlul_adapter_sram #(
381:     .SramAw          (ImemIndexWidth),
382:     .SramDw          (32),
383:     .Outstanding     (1),
384:     .ByteAccess      (0),
385:     .ErrOnRead       (0),
386:     .EnableDataIntgPt(1),
387:     .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
388:   ) u_tlul_adapter_sram_imem (
389:     .clk_i,
390:     .rst_ni                     (rst_n),
391:     .tl_i                       (tl_win_h2d[TlWinImem]),
392:     .tl_o                       (tl_win_d2h[TlWinImem]),
393:     .en_ifetch_i                (MuBi4False),
394:     .req_o                      (imem_req_bus),
395:     .req_type_o                 (),
396:     .gnt_i                      (imem_gnt_bus),
397:     .we_o                       (imem_write_bus),
398:     .addr_o                     (imem_index_bus),
399:     .wdata_o                    (imem_wdata_bus),
400:     .wmask_o                    (imem_wmask_bus),
401:     .intg_error_o               (imem_bus_intg_violation),
402:     .user_rsvd_o                (),
403:     .rdata_i                    (imem_rdata_bus),
404:     .rvalid_i                   (imem_rvalid_bus),
405:     .rerror_i                   (imem_rerror_bus),
406:     .compound_txn_in_progress_o (),
407:     .readback_en_i              (prim_mubi_pkg::MuBi4False),
408:     .readback_error_o           (),
409:     .wr_collision_i             (imem_wr_collision),
410:     .write_pending_i            (imem_wpending)
411:   );
412: 
413: 
414:   // Mux core and bus access into IMEM
415:   assign imem_access_core = busy_execute_q | start_q;
416: 
417:   assign imem_req   = imem_access_core ? imem_req_core        : imem_req_bus;
418:   assign imem_write = imem_access_core ? imem_write_core      : imem_write_bus;
419:   assign imem_index = imem_access_core ? imem_index_core      : imem_index_bus;
420:   assign imem_wdata = imem_access_core ? '0                   : imem_wdata_bus;
421: 
422:   assign imem_illegal_bus_access = imem_req_bus & imem_access_core;
423: 
424:   assign imem_dummy_response_d = imem_illegal_bus_access;
425:   always_ff @(posedge clk_i or negedge rst_ni) begin
426:     if (!rst_ni) begin
427:       imem_dummy_response_q <= 1'b0;
428:     end else begin
429:       imem_dummy_response_q <= imem_dummy_response_d;
430:     end
431:   end
432: 
433:   // The instruction memory only supports 32b word writes, so we hardcode its
434:   // wmask here.
435:   //
436:   // Since this could cause confusion if the bus tried to do a partial write
437:   // (which wasn't caught in the TLUL adapter for some reason), we assert that
438:   // the wmask signal from the bus is indeed '1 when it requests a write. We
439:   // don't have the corresponding check for writes from the core because the
440:   // core cannot perform writes (and has no imem_wmask_o port).
441:   assign imem_wmask = imem_access_core ? '1 : imem_wmask_bus;
442:   `ASSERT(ImemWmaskBusIsFullWord_A, imem_req_bus && imem_write_bus |-> imem_wmask_bus == '1)
443: 
444:   // SEC_CM: DATA_REG_SW.SCA
445:   // Blank bus read data interface during core operation to avoid leaking the currently executed
446:   // instruction from IMEM through the bus unintentionally. Also blank when OTBN is returning
447:   // a dummy response (responding to an illegal bus access) and when OTBN is locked.
448:   assign imem_rdata_bus_en_d = 1'b1;
449: 
450:   always_ff @(posedge clk_i or negedge rst_ni) begin
451:     if (!rst_ni) begin
452:         imem_rdata_bus_en_q <= 1'b1;
453:     end else begin
454:         imem_rdata_bus_en_q <= imem_rdata_bus_en_d;
455:     end
456:   end
457: 
458:   prim_blanker #(.Width(39)) u_imem_rdata_bus_blanker (
459:     .in_i (imem_rdata),
460:     .en_i (imem_rdata_bus_en_q),
461:     .out_o(imem_rdata_bus_raw)
462:   );
463: 
464:   // When OTBN is locked all imem bus reads should return 0. The blanker produces the 0s, this adds
465:   // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
466:   // through. Data bits are always left un-modified. A registered version of `locking` is used for
467:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
468:   // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
469:   // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
470:   // in so it is reasonable to proceed with returning the supplied integrity.
471:   assign imem_rdata_bus =
472:     {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : imem_rdata_bus_raw[38:32],
473:      imem_rdata_bus_raw[31:0]};
474: 
475:   `ASSERT(ImemRDataBusDisabledWhenCoreAccess_A, imem_access_core |-> !imem_rdata_bus_en_q)
476:   `ASSERT(ImemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> imem_rdata_bus_en_q)
477:   `ASSERT(ImemRDataBusDisabledWhenLocked_A, locking |=> !imem_rdata_bus_en_q)
478:   `ASSERT(ImemRDataBusReadAsZeroWhenLocked_A,
479:     imem_rvalid_bus & locking |-> imem_rdata_bus_raw == '0)
480: 
481:   assign imem_rdata_core = imem_rdata;
482: 
483:   // When an illegal bus access is seen, always return a dummy response the follow cycle.
484:   assign imem_rvalid_bus = (~imem_access_core & imem_rvalid) | imem_dummy_response_q;
485:   assign imem_rvalid_core = imem_access_core ? imem_rvalid : 1'b0;
486: 
487:   assign imem_byte_mask_bus = tl_win_h2d[TlWinImem].a_mask;
488: 
489:   // No imem errors reported for bus reads. Integrity is carried through on the bus so integrity
490:   // checking on TL responses will pick up any errors.
491:   assign imem_rerror_bus = 2'b00;
492: 
493:   // Data Memory (DMEM) ========================================================
494: 
495:   localparam int DmemSizeWords = DmemSizeByte / (WLEN / 8);
496:   localparam int DmemIndexWidth = vbits(DmemSizeWords);
497: 
498:   localparam int DmemBusSizeWords = int'(otbn_reg_pkg::OTBN_DMEM_SIZE) / (WLEN / 8);
499:   localparam int DmemBusIndexWidth = vbits(DmemBusSizeWords);
500: 
501:   // Access select to DMEM: core (1), or bus (0)
502:   logic dmem_access_core;
503: 
504:   logic dmem_req;
505:   logic dmem_gnt;
506:   logic dmem_write;
507:   logic [DmemIndexWidth-1:0] dmem_index;
508:   logic [ExtWLEN-1:0] dmem_wdata;
509:   logic [ExtWLEN-1:0] dmem_wmask;
510:   logic [ExtWLEN-1:0] dmem_rdata;
511:   logic dmem_rvalid;
512:   logic [BaseWordsPerWLEN*2-1:0] dmem_rerror_vec;
513:   logic dmem_rerror;
514:   logic dmem_illegal_bus_access;
515:   logic dmem_missed_gnt;
516: 
517:   logic dmem_req_core;
518:   logic dmem_write_core;
519:   logic [DmemIndexWidth-1:0] dmem_index_core;
520:   logic [ExtWLEN-1:0] dmem_wdata_core;
521:   logic [ExtWLEN-1:0] dmem_wmask_core;
522:   logic [BaseWordsPerWLEN-1:0] dmem_rmask_core_q, dmem_rmask_core_d;
523:   logic [ExtWLEN-1:0] dmem_rdata_core;
524:   logic dmem_rvalid_core;
525:   logic dmem_rerror_core;
526: 
527:   logic dmem_req_bus;
528:   logic dmem_dummy_response_q, dmem_dummy_response_d;
529:   logic dmem_write_bus;
530:   logic [DmemBusIndexWidth-1:0] dmem_index_bus;
531:   logic [ExtWLEN-1:0] dmem_wdata_bus;
532:   logic [ExtWLEN-1:0] dmem_wmask_bus;
533:   logic [ExtWLEN-1:0] dmem_rdata_bus, dmem_rdata_bus_raw;
534:   logic dmem_rdata_bus_en_q, dmem_rdata_bus_en_d;
535:   logic [DmemAddrWidth-1:0] dmem_addr_bus;
536:   logic unused_dmem_addr_bus;
537:   logic [31:0] dmem_wdata_narrow_bus;
538:   logic [top_pkg::TL_DBW-1:0] dmem_byte_mask_bus;
539:   logic dmem_rvalid_bus;
540:   logic dmem_wr_collision;
541:   logic dmem_wpending;
542:   logic [1:0] dmem_rerror_bus;
543: 
544:   logic dmem_bus_intg_violation;
545: 
546:   logic [DmemAddrWidth-1:0] dmem_addr_core;
547:   assign dmem_index_core = dmem_addr_core[DmemAddrWidth-1:DmemAddrWidth-DmemIndexWidth];
548: 
549:   logic unused_dmem_addr_core_wordbits;
550:   assign unused_dmem_addr_core_wordbits = ^dmem_addr_core[DmemAddrWidth-DmemIndexWidth-1:0];
551: 
552:   // SEC_CM: MEM.SCRAMBLE
553:   prim_ram_1p_scr #(
554:     .Width             (ExtWLEN),
555:     .Depth             (DmemSizeWords),
556:     .InstDepth         (DmemSizeWords),
557:     .DataBitsPerMask   (39),
558:     .EnableParity      (0),
559:     .ReplicateKeyStream(1)
560:   ) u_dmem (
561:     .clk_i,
562:     .rst_ni(rst_n),
563: 
564:     .key_valid_i(otbn_dmem_scramble_valid),
565:     .key_i      (otbn_dmem_scramble_key),
566:     .nonce_i    (otbn_dmem_scramble_nonce),
567: 
568:     .req_i       (dmem_req),
569:     .gnt_o       (dmem_gnt),
570:     .write_i     (dmem_write),
571:     .addr_i      (dmem_index),
572:     .wdata_i     (dmem_wdata),
573:     .wmask_i     (dmem_wmask),
574:     .intg_error_i(locking),
575: 
576:     .rdata_o  (dmem_rdata),
577:     .rvalid_o (dmem_rvalid),
578:     .raddr_o  (),
579:     .rerror_o (),
580:     .cfg_i    (ram_cfg_dmem_i),
581:     .cfg_rsp_o(ram_cfg_rsp_dmem_o),
582: 
583:     .wr_collision_o   (dmem_wr_collision),
584:     .write_pending_o  (dmem_wpending),
585: 
586:     .alert_o ()
587:   );
588: 
589:   // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
590:   assign dmem_missed_gnt = dmem_req & !dmem_gnt;
591: 
592:   always_ff @(posedge clk_i or negedge rst_ni) begin
593:     if (!rst_ni) begin
594:       dmem_rmask_core_q <= '0;
595:     end else begin
596:       if (dmem_req_core) begin
597:         dmem_rmask_core_q <= dmem_rmask_core_d;
598:       end
599:     end
600:   end
601: 
602:   // SEC_CM: DATA.MEM.INTEGRITY
603:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_intg_check
604:     logic [1:0] dmem_rerror_raw;
605: 
606:     // Separate check for dmem read data integrity outside of `u_dmem` as `prim_ram_1p_adv` doesn't
607:     // have functionality for only integrity checking, just fully integrated ECC. Integrity bits are
608:     // implemented on a 32-bit granule so separate checks are required for each.
609:     prim_secded_inv_39_32_dec u_dmem_intg_check (
610:       .data_i    (dmem_rdata[i_word*39+:39]),
611:       .data_o    (),
612:       .syndrome_o(),
613:       .err_o     (dmem_rerror_raw)
614:     );
615: 
616:     // Only report an error where the word was actually accessed. Otherwise uninitialised memory
617:     // that OTBN isn't using will cause false errors. dmem_rerror is only reported for reads from
618:     // OTBN. For Ibex reads integrity checking on TL responses will serve the same purpose.
619:     assign dmem_rerror_vec[i_word*2 +: 2] = {2{dmem_rmask_core_q[i_word] & dmem_rvalid & dmem_access_core}};
620:   end
621: 
622:   // dmem_rerror_vec is 2 bits wide and is used to report ECC errors. Bit 1 is set if there's an
623:   // uncorrectable error and bit 0 is set if there's a correctable error. However, we're treating
624:   // all errors as fatal, so OR the two signals together.
625:   assign dmem_rerror = |dmem_rerror_vec;
626: 
627:   // DMEM access from main TL-UL bus
628:   logic dmem_gnt_bus;
629:   // Always grant to bus accesses, when OTBN is running a dummy response is returned
630:   assign dmem_gnt_bus = dmem_req_bus;
631: 
632:   tlul_adapter_sram #(
633:     .SramAw          (DmemBusIndexWidth),
634:     .SramDw          (WLEN),
635:     .Outstanding     (1),
636:     .ByteAccess      (0),
637:     .ErrOnRead       (0),
638:     .EnableDataIntgPt(1),
639:     .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
640:   ) u_tlul_adapter_sram_dmem (
641:     .clk_i,
642:     .rst_ni                     (rst_n),
643:     .tl_i                       (tl_win_h2d[TlWinDmem]),
644:     .tl_o                       (tl_win_d2h[TlWinDmem]),
645:     .en_ifetch_i                (MuBi4False),
646:     .req_o                      (dmem_req_bus),
647:     .req_type_o                 (),
648:     .gnt_i                      (dmem_gnt_bus),
649:     .we_o                       (dmem_write_bus),
650:     .addr_o                     (dmem_index_bus),
651:     .wdata_o                    (dmem_wdata_bus),
652:     .wmask_o                    (dmem_wmask_bus),
653:     .intg_error_o               (dmem_bus_intg_violation),
654:     .user_rsvd_o                (),
655:     .rdata_i                    (dmem_rdata_bus),
656:     .rvalid_i                   (dmem_rvalid_bus),
657:     .rerror_i                   (dmem_rerror_bus),
658:     .compound_txn_in_progress_o (),
659:     .readback_en_i              (prim_mubi_pkg::MuBi4False),
660:     .readback_error_o           (),
661:     .wr_collision_i             (dmem_wr_collision),
662:     .write_pending_i            (dmem_wpending)
663:   );
664: 
665:   // Mux core and bus access into dmem
666:   assign dmem_access_core = busy_execute_q;
667: 
668:   assign dmem_req = dmem_access_core ? dmem_req_core : dmem_req_bus;
669:   assign dmem_write = dmem_access_core ? dmem_write_core : dmem_write_bus;
670:   assign dmem_wmask = dmem_access_core ? dmem_wmask_core : dmem_wmask_bus;
671:   // SEC_CM: DATA.MEM.SW_NOACCESS
672:   assign dmem_index = dmem_access_core ? dmem_index_core : dmem_index_bus;
673:   assign dmem_wdata = dmem_access_core ? dmem_wdata_core : dmem_wdata_bus;
674: 
675:   assign dmem_illegal_bus_access = dmem_req_bus & dmem_access_core;
676: 
677:   assign dmem_dummy_response_d = dmem_illegal_bus_access;
678:   always_ff @(posedge clk_i or negedge rst_ni) begin
679:     if (!rst_ni) begin
680:       dmem_dummy_response_q <= 1'b0;
681:     end else begin
682:       dmem_dummy_response_q <= dmem_dummy_response_d;
683:     end
684:   end
685: 
686:   // SEC_CM: DATA_REG_SW.SCA
687:   // Blank bus read data interface during core operation to avoid leaking DMEM data through the bus
688:   // unintentionally. Also blank when OTBN is returning a dummy response (responding to an illegal
689:   // bus access) and when OTBN is locked.
690:   assign dmem_rdata_bus_en_d = 1'b1;
691: 
692:   always_ff @(posedge clk_i or negedge rst_ni) begin
693:     if (!rst_ni) begin
694:         dmem_rdata_bus_en_q <= 1'b1;
695:     end else begin
696:         dmem_rdata_bus_en_q <= dmem_rdata_bus_en_d;
697:     end
698:   end
699: 
700:   prim_blanker #(.Width(ExtWLEN)) u_dmem_rdata_bus_blanker (
701:     .in_i (dmem_rdata),
702:     .en_i (dmem_rdata_bus_en_q),
703:     .out_o(dmem_rdata_bus_raw)
704:   );
705: 
706:   // When OTBN is locked all dmem bus reads should return 0. The blanker produces the 0s, this adds
707:   // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
708:   // through. Data bits are always left un-modified. A registered version of `locking` is used for
709:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
710:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
711:   // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
712:   // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
713:   // in so it is reasonable to proceed with returning the supplied integrity.
714:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_rdata_bus
715:     assign dmem_rdata_bus[i_word*39+:39] =
716:       {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : dmem_rdata_bus_raw[i_word*39+32+:7],
717:        dmem_rdata_bus_raw[i_word*39+:32]};
718:   end
719: 
720:   `ASSERT(DmemRDataBusDisabledWhenCoreAccess_A, dmem_access_core |-> !dmem_rdata_bus_en_q)
721:   `ASSERT(DmemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> dmem_rdata_bus_en_q)
722:   `ASSERT(DmemRDataBusDisabledWhenLocked_A, locking |=> !dmem_rdata_bus_en_q)
723:   `ASSERT(DmemRDataBusReadAsZeroWhenLocked_A,
724:     dmem_rvalid_bus & locking |-> dmem_rdata_bus_raw == '0)
725: 
726:   assign dmem_rdata_core = dmem_rdata;
727: 
728:   // When an illegal bus access is seen, always return a dummy response the follow cycle.
729:   assign dmem_rvalid_bus  = (~dmem_access_core & dmem_rvalid) | dmem_dummy_response_q;
730:   assign dmem_rvalid_core = dmem_access_core ? dmem_rvalid : 1'b0;
731: 
732:   // No dmem errors reported for bus reads. Integrity is carried through on the bus so integrity
733:   // checking on TL responses will pick up any errors.
734:   assign dmem_rerror_bus  = 2'b00;
735:   assign dmem_rerror_core = dmem_rerror;
736: 
737:   assign dmem_addr_bus = tl_win_h2d[TlWinDmem].a_address[DmemAddrWidth-1:0];
738:   assign dmem_wdata_narrow_bus = tl_win_h2d[TlWinDmem].a_data[31:0];
739:   assign dmem_byte_mask_bus = tl_win_h2d[TlWinDmem].a_mask;
740: 
741:   // Memory Load Integrity =====================================================
742:   // CRC logic below assumes a incoming data bus width of 32 bits
743:   `ASSERT_INIT(TLDWIs32Bit_A, top_pkg::TL_DW == 32)
744: 
745:   // Only advance CRC calculation on full 32-bit writes;
746:   assign mem_crc_data_in_valid   = ~(dmem_access_core | imem_access_core) &
747:       ((imem_req_bus & (imem_byte_mask_bus == 4'hf)) |
748:        (dmem_req_bus & (dmem_byte_mask_bus == 4'hf)));
749: 
750:   assign mem_crc_data_in.wr_data = imem_req_bus ? imem_wdata_bus[31:0] :
751:                                                   dmem_wdata_narrow_bus[31:0];
752:   assign mem_crc_data_in.index   = imem_req_bus ? {{15 - ImemIndexWidth{1'b0}}, imem_index_bus} :
753:                                                    {{15 - (DmemAddrWidth - 2){1'b0}},
754:                                                     dmem_addr_bus[DmemAddrWidth-1:2]};
755:   assign mem_crc_data_in.imem    = imem_req_bus;
756: 
757:   // Only the bits that factor into the dmem index and dmem word enables are required
758:   assign unused_dmem_addr_bus = ^{dmem_addr_bus[DmemAddrWidth-1:DmemIndexWidth],
759:                                   dmem_addr_bus[1:0]};
760: 
761:   // SEC_CM: WRITE.MEM.INTEGRITY
762:   prim_crc32 #(
763:     .BytesPerWord(6)
764:   ) u_mem_load_crc32 (
765:     .clk_i (clk_i),
766:     .rst_ni(rst_ni),
767: 
768:     .set_crc_i(set_crc),
769:     .crc_in_i (crc_in),
770: 
771:     .data_valid_i(mem_crc_data_in_valid),
772:     .data_i      (mem_crc_data_in),
773:     .crc_out_o   (crc_out)
774:   );
775: 
776:   assign set_crc = reg2hw.load_checksum.qe;
777:   assign crc_in = reg2hw.load_checksum.q;
778:   assign hw2reg.load_checksum.d = crc_out;
779: 
780:   // Registers =================================================================
781: 
782:   logic reg_bus_intg_violation;
783: 
784:   otbn_reg_top u_reg (
785:     .clk_i,
786:     .rst_ni  (rst_n),
787:     .tl_i,
788:     .tl_o,
789:     .tl_win_o(tl_win_h2d),
790:     .tl_win_i(tl_win_d2h),
791: 
792:     .reg2hw,
793:     .hw2reg,
794: 
795:     .intg_err_o(reg_bus_intg_violation)
796:   );
797: 
798:   // SEC_CM: BUS.INTEGRITY
799:   // SEC_CM: TLUL_FIFO.CTR.REDUN
800:   logic bus_intg_violation;
801:   assign bus_intg_violation = (imem_bus_intg_violation | dmem_bus_intg_violation |
802:                                reg_bus_intg_violation);
803: 
804:   // CMD register
805:   always_comb begin
806:     // start is flopped to avoid long timing paths from the TL fabric into OTBN internals.
807:     start_d       = 1'b0;
808:     dmem_sec_wipe = 1'b0;
809:     imem_sec_wipe = 1'b0;
810: 
811:     // Can only start a new command when idle.
812:     if (status_q == StatusIdle) begin
813:       if (reg2hw.cmd.qe) begin
814:         unique case (reg2hw.cmd.q)
815:           CmdExecute:     start_d       = 1'b1;
816:           CmdSecWipeDmem: dmem_sec_wipe = 1'b1;
817:           CmdSecWipeImem: imem_sec_wipe = 1'b1;
818:           default: ;
819:         endcase
820:       end
821:     end else if (busy_execute_q) begin
822:       // OTBN can command a secure wipe of IMEM and DMEM. This occurs when OTBN encounters a fatal
823:       // error.
824:       if (mems_sec_wipe) begin
825:         dmem_sec_wipe = 1'b1;
826:         imem_sec_wipe = 1'b1;
827:       end
828:     end
829:   end
830: 
831:   assign req_sec_wipe_urnd_keys = dmem_sec_wipe | imem_sec_wipe;
832: 
833:   assign illegal_bus_access_d = dmem_illegal_bus_access | imem_illegal_bus_access;
834: 
835:   // It should not be possible to request an imem or dmem access without it being granted. Either
836:   // a scramble key is present so the request will be granted or the core is busy obtaining a new
837:   // key, so no request can occur (the core won't generate one whilst awaiting a scrambling key and
838:   // the bus requests get an immediate dummy response bypassing the dmem or imem). A fatal error is
839:   // raised if request is seen without a grant.
840:   assign missed_gnt_error_d = dmem_missed_gnt | imem_missed_gnt;
841: 
842:   // Flop `illegal_bus_access_q` and `missed_gnt_error_q` to break timing paths from the TL
843:   // interface into the OTBN core.
844:   always_ff @(posedge clk_i or negedge rst_ni) begin
845:     if (!rst_ni) begin
846:       start_q              <= 1'b0;
847:       illegal_bus_access_q <= 1'b0;
848:       missed_gnt_error_q   <= 1'b0;
849:     end else begin
850:       start_q              <= start_d;
851:       illegal_bus_access_q <= illegal_bus_access_d;
852:       missed_gnt_error_q   <= missed_gnt_error_d;
853:     end
854:   end
855: 
856:   // STATUS register
857:   // imem/dmem scramble req can be busy when locked, so use a priority selection so locked status
858:   // always takes priority.
859:   //
860:   // Note that these signals are all "a cycle early". For example, the locking signal gets asserted
861:   // combinatorially on the cycle that an error is injected. The STATUS register change, done
862:   // interrupt and any change to the idle signal will be delayed by 2 cycles.
863:   assign status_d = locking                         ? StatusLocked          :
864:                     busy_secure_wipe                ? StatusBusySecWipeInt  :
865:                     busy_execute_d                  ? StatusBusyExecute     :
866:                     otbn_dmem_scramble_key_req_busy ? StatusBusySecWipeDmem :
867:                     otbn_imem_scramble_key_req_busy ? StatusBusySecWipeImem :
868:                                                       StatusIdle;
869:   always_ff @(posedge clk_i or negedge rst_ni) begin
870:     if (!rst_ni) begin
871:       status_q <= StatusBusySecWipeInt;
872:     end else begin
873:       status_q <= status_d;
874:     end
875:   end
876: 
877:   assign hw2reg.status.d = status_q;
878:   assign hw2reg.status.de = 1'b1;
879: 
880:   // Only certain combinations of the state variable {locking, busy_execute_d,
881:   // otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy} are possible.
882:   //
883:   // - Once locking is high, we guarantee never to see a new execution or the start of a key
884:   //   rotation. (Assertion: NoStartWhenLocked_A)
885: 
886:   `ASSERT(NoStartWhenLocked_A,
887:           locking |=> !($rose(busy_execute_d) ||
888:                         $rose(otbn_dmem_scramble_key_req_busy) ||
889:                         $rose(otbn_imem_scramble_key_req_busy)))
890: 
891:   // CTRL register
892:   assign software_errs_fatal_d =
893:     reg2hw.ctrl.qe && (status_q == StatusIdle) ? reg2hw.ctrl.q :
894:                                                  software_errs_fatal_q;
895: 
896:   always_ff @(posedge clk_i or negedge rst_ni) begin
897:     if (!rst_ni) begin
898:       software_errs_fatal_q <= 1'b0;
899:     end else begin
900:       software_errs_fatal_q <= software_errs_fatal_d;
901:     end
902:   end
903: 
904:   assign hw2reg.ctrl.d = software_errs_fatal_q;
905: 
906:   // ERR_BITS register
907:   // The error bits for an OTBN operation get stored on the cycle that done is
908:   // asserted. Software is expected to read them out before starting the next operation.
909: 
910:   assign hw2reg.err_bits.bad_data_addr.d = err_bits_q.bad_data_addr;
911:   assign hw2reg.err_bits.bad_insn_addr.d = err_bits_q.bad_insn_addr;
912:   assign hw2reg.err_bits.call_stack.d = err_bits_q.call_stack;
913:   assign hw2reg.err_bits.illegal_insn.d = err_bits_q.illegal_insn;
914:   assign hw2reg.err_bits.loop.d = err_bits_q.loop;
915:   assign hw2reg.err_bits.key_invalid.d = err_bits_q.key_invalid;
916:   assign hw2reg.err_bits.rnd_rep_chk_fail.d = err_bits_q.rnd_rep_chk_fail;
917:   assign hw2reg.err_bits.rnd_fips_chk_fail.d = err_bits_q.rnd_fips_chk_fail;
918:   assign hw2reg.err_bits.imem_intg_violation.d = err_bits_q.imem_intg_violation;
919:   assign hw2reg.err_bits.dmem_intg_violation.d = err_bits_q.dmem_intg_violation;
920:   assign hw2reg.err_bits.reg_intg_violation.d = err_bits_q.reg_intg_violation;
921:   assign hw2reg.err_bits.bus_intg_violation.d = err_bits_q.bus_intg_violation;
922:   assign hw2reg.err_bits.bad_internal_state.d = err_bits_q.bad_internal_state;
923:   assign hw2reg.err_bits.illegal_bus_access.d = err_bits_q.illegal_bus_access;
924:   assign hw2reg.err_bits.lifecycle_escalation.d = err_bits_q.lifecycle_escalation;
925:   assign hw2reg.err_bits.fatal_software.d = err_bits_q.fatal_software;
926: 
927:   assign err_bits_clear = reg2hw.err_bits.bad_data_addr.qe & is_not_running_q;
928:   assign err_bits_d = err_bits_clear ? '0 : err_bits;
929:   assign err_bits_en = err_bits_clear | done_core;
930: 
931:   logic unused_reg2hw_err_bits;
932: 
933:   // Majority of reg2hw.err_bits is unused as write values are ignored, all writes clear the
934:   // register to 0.
935:   assign unused_reg2hw_err_bits = ^{reg2hw.err_bits.bad_data_addr.q,
936:                                     reg2hw.err_bits.bad_insn_addr,
937:                                     reg2hw.err_bits.call_stack,
938:                                     reg2hw.err_bits.illegal_insn,
939:                                     reg2hw.err_bits.loop,
940:                                     reg2hw.err_bits.key_invalid,
941:                                     reg2hw.err_bits.rnd_rep_chk_fail,
942:                                     reg2hw.err_bits.rnd_fips_chk_fail,
943:                                     reg2hw.err_bits.imem_intg_violation,
944:                                     reg2hw.err_bits.dmem_intg_violation,
945:                                     reg2hw.err_bits.reg_intg_violation,
946:                                     reg2hw.err_bits.bus_intg_violation,
947:                                     reg2hw.err_bits.bad_internal_state,
948:                                     reg2hw.err_bits.illegal_bus_access,
949:                                     reg2hw.err_bits.lifecycle_escalation,
950:                                     reg2hw.err_bits.fatal_software};
951: 
952:   always_ff @(posedge clk_i or negedge rst_ni) begin
953:     if (!rst_ni) begin
954:       err_bits_q <= '0;
955:     end else if (err_bits_en) begin
956:       err_bits_q <= err_bits_d;
957:     end
958:   end
959: 
960:   // Latch the recoverable error signal from the core. This will be generated as a pulse some time
961:   // during the run (and before secure wipe finishes). Collect up this bit, clearing on the start or
962:   // end of an operation (start_q / done_core, respectively)
963:   assign recoverable_err_d = (recoverable_err_q | core_recoverable_err) & ~(start_q | done_core);
964:   always_ff @(posedge clk_i or negedge rst_ni) begin
965:     if (!rst_ni) begin
966:       recoverable_err_q <= '0;
967:     end else begin
968:       recoverable_err_q <= recoverable_err_d;
969:     end
970:   end
971: 
972:   // FATAL_ALERT_CAUSE register. The .de and .d values are equal for each bit, so that it can only
973:   // be set, not cleared.
974: `define DEF_FAC_BIT(NAME)                                         \
975:   assign hw2reg.fatal_alert_cause.``NAME``.d = 1'b1;              \
976:   assign hw2reg.fatal_alert_cause.``NAME``.de = err_bits.``NAME;
977: 
978:   `DEF_FAC_BIT(fatal_software)
979:   `DEF_FAC_BIT(lifecycle_escalation)
980:   `DEF_FAC_BIT(illegal_bus_access)
981:   `DEF_FAC_BIT(bad_internal_state)
982:   `DEF_FAC_BIT(bus_intg_violation)
983:   `DEF_FAC_BIT(reg_intg_violation)
984:   `DEF_FAC_BIT(dmem_intg_violation)
985:   `DEF_FAC_BIT(imem_intg_violation)
986: 
987: `undef DEF_FAC_BIT
988: 
989:   // INSN_CNT register
990:   logic [31:0] insn_cnt;
991:   logic        insn_cnt_clear;
992:   logic        unused_insn_cnt_q;
993:   assign hw2reg.insn_cnt.d = insn_cnt;
994:   assign insn_cnt_clear = reg2hw.insn_cnt.qe & is_not_running_q;
995:   // Ignore all write data to insn_cnt. All writes zero the register.
996:   assign unused_insn_cnt_q = ^reg2hw.insn_cnt.q;
997: 
998:   // Alerts ====================================================================
999: 
1000:   logic [NumAlerts-1:0] alert_test;
1001:   assign alert_test[AlertFatal] = reg2hw.alert_test.fatal.q & reg2hw.alert_test.fatal.qe;
1002:   assign alert_test[AlertRecov] = reg2hw.alert_test.recov.q & reg2hw.alert_test.recov.qe;
1003: 
1004:   logic [NumAlerts-1:0] alerts;
1005:   assign alerts[AlertFatal] = |{err_bits.fatal_software,
1006:                                 err_bits.lifecycle_escalation,
1007:                                 err_bits.illegal_bus_access,
1008:                                 err_bits.bad_internal_state,
1009:                                 err_bits.bus_intg_violation,
1010:                                 err_bits.reg_intg_violation,
1011:                                 err_bits.dmem_intg_violation,
1012:                                 err_bits.imem_intg_violation};
1013: 
1014:   assign alerts[AlertRecov] = (core_recoverable_err | recoverable_err_q) & done_core;
1015: 
1016:   for (genvar i = 0; i < NumAlerts; i++) begin : gen_alert_tx
1017:     prim_alert_sender #(
1018:       .AsyncOn(AlertAsyncOn[i]),
1019:       .IsFatal(i == AlertFatal)
1020:     ) u_prim_alert_sender (
1021:       .clk_i,
1022:       .rst_ni       (rst_n),
1023:       .alert_test_i (alert_test[i]),
1024:       .alert_req_i  (alerts[i]),
1025:       .alert_ack_o  (),
1026:       .alert_state_o(),
1027:       .alert_rx_i   (alert_rx_i[i]),
1028:       .alert_tx_o   (alert_tx_o[i])
1029:     );
1030:   end
1031: 
1032: 
1033:   // EDN Connections ============================================================
1034:   logic edn_rnd_req, edn_rnd_ack;
1035:   logic [EdnDataWidth-1:0] edn_rnd_data;
1036:   logic edn_rnd_fips, edn_rnd_err;
1037: 
1038:   logic edn_urnd_req, edn_urnd_ack;
1039:   logic [EdnDataWidth-1:0] edn_urnd_data;
1040: 
1041:   // These synchronize the data coming from EDN and stack the 32 bit EDN words to achieve an
1042:   // internal entropy width of 256 bit.
1043: 
1044:   prim_edn_req #(
1045:     .EnRstChks(1'b1),
1046:     .OutWidth(EdnDataWidth),
1047:     // SEC_CM: RND.BUS.CONSISTENCY
1048:     .RepCheck(1'b1)
1049:   ) u_prim_edn_rnd_req (
1050:     .clk_i,
1051:     .rst_ni     ( rst_n        ),
1052:     .req_chk_i  ( 1'b1         ),
1053:     .req_i      ( edn_rnd_req  ),
1054:     .ack_o      ( edn_rnd_ack  ),
1055:     .data_o     ( edn_rnd_data ),
1056:     .fips_o     ( edn_rnd_fips ),
1057:     .err_o      ( edn_rnd_err  ),
1058:     .clk_edn_i,
1059:     .rst_edn_ni,
1060:     .edn_o      ( edn_rnd_o ),
1061:     .edn_i      ( edn_rnd_i )
1062:   );
1063: 
1064:   prim_edn_req #(
1065:     .EnRstChks(1'b1),
1066:     .OutWidth(EdnDataWidth)
1067:   ) u_prim_edn_urnd_req (
1068:     .clk_i,
1069:     .rst_ni     ( rst_n         ),
1070:     .req_chk_i  ( 1'b1          ),
1071:     .req_i      ( edn_urnd_req  ),
1072:     .ack_o      ( edn_urnd_ack  ),
1073:     .data_o     ( edn_urnd_data ),
1074:     .fips_o     (               ), // unused
1075:     .err_o      (               ), // unused
1076:     .clk_edn_i,
1077:     .rst_edn_ni,
1078:     .edn_o      ( edn_urnd_o    ),
1079:     .edn_i      ( edn_urnd_i    )
1080:   );
1081: 
1082: 
1083:   // OTBN Core =================================================================
1084: 
1085:   always_ff @(posedge clk_i or negedge rst_n) begin
1086:     if (!rst_n) begin
1087:       busy_execute_q       <= 1'b0;
1088:       init_sec_wipe_done_q <= 1'b0;
1089:     end else begin
1090:       busy_execute_q       <= busy_execute_d;
1091:       init_sec_wipe_done_q <= init_sec_wipe_done_d;
1092:     end
1093:   end
1094:   assign busy_execute_d = (busy_execute_q | start_d) & ~done_core;
1095:   assign init_sec_wipe_done_d = init_sec_wipe_done_q | ~busy_secure_wipe;
1096: 
1097:   otbn_core #(
1098:     .RegFile(RegFile),
1099:     .DmemSizeByte(DmemSizeByte),
1100:     .ImemSizeByte(ImemSizeByte),
1101:     .RndCnstUrndPrngSeed(RndCnstUrndPrngSeed),
1102:     .SecMuteUrnd(SecMuteUrnd),
1103:     .SecSkipUrndReseedAtStart(SecSkipUrndReseedAtStart)
1104:   ) u_otbn_core (
1105:     .clk_i,
1106:     .rst_ni                      (rst_n),
1107: 
1108:     .start_i                     (start_q),
1109:     .done_o                      (done_core),
1110:     .locking_o                   (locking),
1111:     .secure_wipe_running_o       (busy_secure_wipe),
1112: 
1113:     .err_bits_o                  (core_err_bits),
1114:     .recoverable_err_o           (core_recoverable_err),
1115: 
1116:     .imem_req_o                  (imem_req_core),
1117:     .imem_addr_o                 (imem_addr_core),
1118:     .imem_rdata_i                (imem_rdata_core),
1119:     .imem_rvalid_i               (imem_rvalid_core),
1120: 
1121:     .dmem_req_o                  (dmem_req_core),
1122:     .dmem_write_o                (dmem_write_core),
1123:     .dmem_addr_o                 (dmem_addr_core),
1124:     .dmem_wdata_o                (dmem_wdata_core),
1125:     .dmem_wmask_o                (dmem_wmask_core),
1126:     .dmem_rmask_o                (dmem_rmask_core_d),
1127:     .dmem_rdata_i                (dmem_rdata_core),
1128:     .dmem_rvalid_i               (dmem_rvalid_core),
1129:     .dmem_rerror_i               (dmem_rerror_core),
1130: 
1131:     .edn_rnd_req_o               (edn_rnd_req),
1132:     .edn_rnd_ack_i               (edn_rnd_ack),
1133:     .edn_rnd_data_i              (edn_rnd_data),
1134:     .edn_rnd_fips_i              (edn_rnd_fips),
1135:     .edn_rnd_err_i               (edn_rnd_err),
1136: 
1137:     .edn_urnd_req_o              (edn_urnd_req),
1138:     .edn_urnd_ack_i              (edn_urnd_ack),
1139:     .edn_urnd_data_i             (edn_urnd_data),
1140: 
1141:     .insn_cnt_o                  (insn_cnt),
1142:     .insn_cnt_clear_i            (insn_cnt_clear),
1143: 
1144:     .mems_sec_wipe_o             (mems_sec_wipe),
1145:     .dmem_sec_wipe_urnd_key_o    (dmem_sec_wipe_urnd_key),
1146:     .imem_sec_wipe_urnd_key_o    (imem_sec_wipe_urnd_key),
1147:     .req_sec_wipe_urnd_keys_i    (req_sec_wipe_urnd_keys),
1148: 
1149:     .escalate_en_i               (core_escalate_en),
1150:     .rma_req_i                   (mubi_rma_req),
1151:     .rma_ack_o                   (mubi_rma_ack),
1152: 
1153:     .software_errs_fatal_i       (software_errs_fatal_q),
1154: 
1155:     .sideload_key_shares_i       (keymgr_key_i.key),
1156:     .sideload_key_shares_valid_i ({2{keymgr_key_i.valid}})
1157:   );
1158: 
1159:   always_ff @(posedge clk_i or negedge rst_n) begin
1160:     if (!rst_n) begin
1161:       locking_q <= 1'b0;
1162:     end else begin
1163:       locking_q <= locking;
1164:     end
1165:   end
1166: 
1167:   // Collect up the error bits that don't come from the core itself and latch them so that they'll
1168:   // be available when an operation finishes.
1169:   assign non_core_err_bits = '{
1170:     lifecycle_escalation: lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[0]),
1171:     illegal_bus_access:   illegal_bus_access_q,
1172:     bad_internal_state:   otbn_scramble_state_error | missed_gnt_error_q,
1173:     bus_intg_violation:   bus_intg_violation
1174:   };
1175: 
1176:   assign non_core_err_bits_d = non_core_err_bits_q | non_core_err_bits;
1177:   always_ff @(posedge clk_i or negedge rst_ni) begin
1178:     if (!rst_ni) begin
1179:       non_core_err_bits_q <= '0;
1180:     end else begin
1181:       non_core_err_bits_q <= non_core_err_bits_d;
1182:     end
1183:   end
1184: 
1185:   // Construct a full set of error bits from the core output
1186:   assign err_bits = '{
1187:     fatal_software:       core_err_bits.fatal_software,
1188:     lifecycle_escalation: non_core_err_bits_d.lifecycle_escalation,
1189:     illegal_bus_access:   non_core_err_bits_d.illegal_bus_access,
1190:     bad_internal_state:   |{core_err_bits.bad_internal_state,
1191:                             non_core_err_bits_d.bad_internal_state},
1192:     bus_intg_violation:   non_core_err_bits_d.bus_intg_violation,
1193:     reg_intg_violation:   core_err_bits.reg_intg_violation,
1194:     dmem_intg_violation:  core_err_bits.dmem_intg_violation,
1195:     imem_intg_violation:  core_err_bits.imem_intg_violation,
1196:     rnd_fips_chk_fail:    core_err_bits.rnd_fips_chk_fail,
1197:     rnd_rep_chk_fail:     core_err_bits.rnd_rep_chk_fail,
1198:     key_invalid:          core_err_bits.key_invalid,
1199:     loop:                 core_err_bits.loop,
1200:     illegal_insn:         core_err_bits.illegal_insn,
1201:     call_stack:           core_err_bits.call_stack,
1202:     bad_insn_addr:        core_err_bits.bad_insn_addr,
1203:     bad_data_addr:        core_err_bits.bad_data_addr
1204:   };
1205: 
1206:   // An error signal going down into the core to show that it should locally escalate. In
1207:   // accordance with the lc_ctrl spec, all values of the lc_escalate_en signal other than the OFF
1208:   // value must be interpreted as ON.
1209:   assign core_escalate_en = mubi4_bool_to_mubi(
1210:       |{non_core_err_bits.illegal_bus_access,
1211:         non_core_err_bits.bad_internal_state,
1212:         non_core_err_bits.bus_intg_violation,
1213:         lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[1])});
1214: 
1215:   // The core can never signal a write to IMEM
1216:   assign imem_write_core = 1'b0;
1217: 
1218: 
1219:   // Asserts ===================================================================
1220:   for (genvar i = 0; i < LoopStackDepth; ++i) begin : gen_loop_stack_cntr_asserts
1221:     `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(
1222:       LoopStackCntAlertCheck_A,
1223:       u_otbn_core.u_otbn_controller.u_otbn_loop_controller.g_loop_counters[i].u_loop_count,
1224:       alert_tx_o[AlertFatal]
1225:     )
1226:   end
1227: 
1228:   // GPR assertions for secure wipe
1229:   // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1230:   // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
1231:   // secure wiping complete.
1232:   // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
1233:   // because a fatal error affecting internal secure wiping could cause an immediate locking
1234:   // behaviour in which it's not guaranteed to see a succesful secure wipe.
1235:   for (genvar i = 2; i < NGpr; ++i) begin : gen_sec_wipe_gpr_asserts
1236:     // Initial secure wipe needs to initialise all registers to nonzero
1237:     `ASSERT(InitSecWipeNonZeroBaseRegs_A,
1238:       $fell(busy_secure_wipe) |->
1239:       u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
1240:         EccZeroWord,
1241:       clk_i,
1242:       !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1243:       u_otbn_core.u_otbn_start_stop_control.state_error_d)
1244:     // After execution, it's expected to see a change resulting with a nonzero register value
1245:     `ASSERT(SecWipeChangedBaseRegs_A,
1246:       $rose(busy_secure_wipe) |-> ((##[0:$]
1247:         u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
1248:           EccZeroWord &&
1249:         $changed(
1250:           u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q))
1251:         within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
1252:       clk_i,
1253:       !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1254:       u_otbn_core.u_otbn_start_stop_control.state_error_d)
1255:   end
1256: 
1257:   // We have several assertions that check that secure wipe worked properly. However, we've also got
1258:   // some tests where we force nets, stopping it from working properly! That's fine, and the tests
1259:   // are checking that some other mechanism catches the problem. However, we don't want the
1260:   // simulation to die with a failed assertion, so we put everything in a named block which we can
1261:   // turn off with $assertoff.
1262:   //
1263:   // The silly-looking name is to avoid a lint warning. Verible (correctly) points out that
1264:   // SystemVerilog doesn't allow bare begin/end blocks at module level. So I cheated and put
1265:   // everything in an if(1) block. But this is treated as a generate block, and our lint rules
1266:   // therefore expect its name to start with a "g_".
1267:   if (1) begin : g_secure_wipe_assertions
1268:     // WDR assertions for secure wipe
1269:     // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1270:     // goes to LOCKED state immediately after this error which means that it's not guaranteed to
1271:     // have secure wiping complete.
1272:     // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
1273:     // because a fatal error affecting internal secure wiping could cause an immediate locking
1274:     // behaviour in which it's not guaranteed to see a succesful secure wipe.
1275:     for (genvar i = 0; i < NWdr; ++i) begin : gen_sec_wipe_wdr_asserts
1276:       // Initial secure wipe needs to initialise all registers to nonzero
1277:       `ASSERT(InitSecWipeNonZeroWideRegs_A,
1278:               $fell(busy_secure_wipe) |->
1279:                 u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
1280:                   EccWideZeroWord,
1281:               clk_i,
1282:               !rst_ni || u_otbn_core.urnd_reseed_err ||
1283:                 u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1284:                 u_otbn_core.u_otbn_start_stop_control.state_error_d)
1285: 
1286:       // After execution, it's expected to see a change resulting with a nonzero register value
1287:       `ASSERT(SecWipeChangedWideRegs_A,
1288:               $rose(busy_secure_wipe) |-> ((##[0:$]
1289:                 u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
1290:                   EccWideZeroWord &&
1291:                 $changed(
1292:                   u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i]))
1293:                 within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
1294:             clk_i, !rst_ni || u_otbn_core.urnd_reseed_err ||
1295:               u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1296:     end
1297:   end
1298: 
1299:   // Secure wipe needs to invalidate call and loop stack, initialize MOD, ACC to nonzero and set
1300:   // FLAGS CSR to zero
1301:   // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1302:   // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
1303:   // secure wiping complete.
1304:   // 2. mubi_err_d of start_stop_control disables the secure wipe related assertions because a
1305:   // fatal error affecting internal secure wiping could cause an immediate locking behaviour
1306:   // in which it's not guaranteed to see a succesful secure wipe.
1307:   `ASSERT(SecWipeInvalidCallStack_A,
1308:           $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_rf_base.u_call_stack.top_valid_o),
1309:           clk_i,
1310:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1311:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1312:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1313:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1314:   `ASSERT(SecWipeInvalidLoopStack_A,
1315:           $fell(busy_secure_wipe) |->
1316:             (!u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.top_valid_o),
1317:           clk_i,
1318:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1319:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1320:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1321:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1322: 
1323:   `ASSERT(SecWipeNonZeroMod_A,
1324:           $fell(busy_secure_wipe) |-> u_otbn_core.u_otbn_alu_bignum.mod_intg_q != EccWideZeroWord,
1325:           clk_i,
1326:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1327:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1328:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1329:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1330: 
1331:   `ASSERT(SecWipeNonZeroACC_A,
1332:           $fell(busy_secure_wipe) |->
1333:             u_otbn_core.u_otbn_alu_bignum.ispr_acc_intg_i != EccWideZeroWord,
1334:           clk_i,
1335:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1336:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1337:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1338: 
1339:   `ASSERT(SecWipeNonZeroFlags_A,
1340:           $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_alu_bignum.flags_flattened),
1341:           clk_i,
1342:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1343:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1344:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1345:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1346: 
1347:   // Secure wipe of IMEM and DMEM first happens with a key change from URND (while valid is zero)
1348:   `ASSERT(ImemSecWipeRequiresUrndKey_A,
1349:           $rose(imem_sec_wipe) |=> (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)),
1350:           clk_i,
1351:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1352:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1353:   `ASSERT(DmemSecWipeRequiresUrndKey_A,
1354:           $rose(dmem_sec_wipe) |=> (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)),
1355:           clk_i,
1356:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1357:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1358: 
1359:   // Then it is guaranteed to have a valid key from OTP interface which is different from URND key
1360:   `ASSERT(ImemSecWipeRequiresOtpKey_A,
1361:           $rose(imem_sec_wipe) ##1 (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)) |=>
1362:             ##[0:$] otbn_imem_scramble_valid && $changed(otbn_imem_scramble_key),
1363:           clk_i,
1364:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1365:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1366:   `ASSERT(DmemSecWipeRequiresOtpKey_A,
1367:           $rose(dmem_sec_wipe) ##1 (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)) |=>
1368:             ##[0:$] otbn_dmem_scramble_valid && $changed(otbn_dmem_scramble_key),
1369:           clk_i,
1370:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1371:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1372: 
1373:   // All outputs should be known value after reset
1374:   `ASSERT_KNOWN(TlODValidKnown_A, tl_o.d_valid)
1375:   `ASSERT_KNOWN(TlOAReadyKnown_A, tl_o.a_ready)
1376:   `ASSERT_KNOWN(IdleOKnown_A, idle_o)
1377:   `ASSERT_KNOWN(IntrDoneOKnown_A, intr_done_o)
1378:   `ASSERT_KNOWN(AlertTxOKnown_A, alert_tx_o)
1379:   `ASSERT_KNOWN(EdnRndOKnown_A, edn_rnd_o, clk_edn_i, !rst_edn_ni)
1380:   `ASSERT_KNOWN(EdnUrndOKnown_A, edn_urnd_o, clk_edn_i, !rst_edn_ni)
1381:   `ASSERT_KNOWN(OtbnOtpKeyO_A, otbn_otp_key_o, clk_otp_i, !rst_otp_ni)
1382:   `ASSERT_KNOWN(ErrBitsKnown_A, err_bits)
1383: 
1384:   // Incoming key must be valid (other inputs go via prim modules that handle the X checks).
1385:   `ASSERT_KNOWN(KeyMgrKeyValid_A, keymgr_key_i.valid)
1386: 
1387:   // In locked state, the readable registers INSN_CNT, IMEM, and DMEM are expected to always read 0
1388:   // when accessed from the bus. For INSN_CNT, we use "|=>" so that the assertion lines up with
1389:   // "status.q" (a signal that isn't directly accessible here).
1390:   `ASSERT(LockedInsnCntReadsZero_A, (hw2reg.status.d == StatusLocked) |=> insn_cnt == 'd0)
1391:   `ASSERT(ExecuteOrLockedImemReadsZero_A,
1392:           (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & imem_rvalid_bus
1393:           |-> imem_rdata_bus == 'd0)
1394:   `ASSERT(ExecuteOrLockedDmemReadsZero_A,
1395:           (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & dmem_rvalid_bus
1396:           |-> dmem_rdata_bus == 'd0)
1397: 
1398:   // From the cycle the core is told to start to when it is done, it must always be busy executing,
1399:   // locking, or both -- even if the core is never done.  We use this property to enable blanking
1400:   // while the core is executing or locking, and this assertion ensures that there is no gap
1401:   // between execution and locking.
1402:   `ASSERT(BusyOrLockingFromStartToDone_A,
1403:           $rose(start_q) |-> (busy_execute_d | locking) |-> ##[0:$] $rose(done_core))
1404: 
1405:   // Error handling: if we pass an error signal down to the core then we should also be setting an
1406:   // error flag. Note that this uses err_bits, not err_bits_q, because the latter signal only gets
1407:   // asserted when an operation finishes.
1408:   `ASSERT(ErrBitIfEscalate_A, mubi4_test_true_loose(core_escalate_en) |=> |err_bits)
1409: 
1410:   // Constraint from package, check here as we cannot have `ASSERT_INIT in package
1411:   `ASSERT_INIT(WsrESizeMatchesParameter_A, $bits(wsr_e) == WsrNumWidth)
1412: 
1413:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnStartStopFsmCheck_A,
1414:     u_otbn_core.u_otbn_start_stop_control.u_state_regs, alert_tx_o[AlertFatal])
1415:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnControllerFsmCheck_A,
1416:     u_otbn_core.u_otbn_controller.u_state_regs, alert_tx_o[AlertFatal])
1417:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnScrambleCtrlFsmCheck_A,
1418:     u_otbn_scramble_ctrl.u_state_regs, alert_tx_o[AlertFatal])
1419: 
1420:   `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnCallStackWrPtrAlertCheck_A,
1421:     u_otbn_core.u_otbn_rf_base.u_call_stack.u_stack_wr_ptr, alert_tx_o[AlertFatal])
1422:   `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnLoopInfoStackWrPtrAlertCheck_A,
1423:     u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.u_stack_wr_ptr,
1424:     alert_tx_o[AlertFatal])
1425: 
1426:   // Alert assertions for reg_we onehot check
1427:   `ASSERT_PRIM_REG_WE_ONEHOT_ERROR_TRIGGER_ALERT(RegWeOnehotCheck_A,
1428:       u_reg, alert_tx_o[AlertFatal])
1429:   // other onehot checks
1430:   `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBaseOnehotCheck_A,
1431:       u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.u_prim_onehot_check,
1432:       alert_tx_o[AlertFatal])
1433:   `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBignumOnehotCheck_A,
1434:       u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.u_prim_onehot_check,
1435:       alert_tx_o[AlertFatal])
1436: 
1437:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemRspFifo,
1438:                                                u_tlul_adapter_sram_dmem.u_rspfifo,
1439:                                                alert_tx_o[AlertFatal])
1440:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemSramReqFifo,
1441:                                                u_tlul_adapter_sram_dmem.u_sramreqfifo,
1442:                                                alert_tx_o[AlertFatal])
1443:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemReqFifo,
1444:                                                u_tlul_adapter_sram_dmem.u_reqfifo,
1445:                                                alert_tx_o[AlertFatal])
1446: 
1447:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemRspFifo,
1448:                                                u_tlul_adapter_sram_imem.u_rspfifo,
1449:                                                alert_tx_o[AlertFatal])
1450:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemSramReqFifo,
1451:                                                u_tlul_adapter_sram_imem.u_sramreqfifo,
1452:                                                alert_tx_o[AlertFatal])
1453:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemReqFifo,
1454:                                                u_tlul_adapter_sram_imem.u_reqfifo,
1455:                                                alert_tx_o[AlertFatal])
1456: endmodule

================================== Ai Message ==================================
Tool Calls:
  read_file_with_line_numbers (call_2pVSJz8Lg78UfO0HaqkgJHbx)
 Call ID: call_2pVSJz8Lg78UfO0HaqkgJHbx
  Args:
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn_core.sv
================================= Tool Message =================================
Name: read_file_with_line_numbers

1: // Copyright lowRISC contributors (OpenTitan project).
2: // Licensed under the Apache License, Version 2.0, see LICENSE for details.
3: // SPDX-License-Identifier: Apache-2.0
4: 
5: `include "prim_assert.sv"
6: 
7: /**
8:  * OpenTitan Big Number Accelerator (OTBN) Core
9:  *
10:  * This module is the top-level of the OTBN processing core.
11:  */
12: // Below countermeasure (no data dependent control flow in OTBN ISA) is inherent to the design and
13: // has no directly associated RTL
14: // SEC_CM: CTRL_FLOW.SCA
15: module otbn_core
16:   import otbn_pkg::*;
17: #(
18:   // Register file implementation selection, see otbn_pkg.sv.
19:   parameter regfile_e RegFile = RegFileFF,
20: 
21:   // Size of the instruction memory, in bytes
22:   parameter int ImemSizeByte = 4096,
23:   // Size of the data memory, in bytes
24:   parameter int DmemSizeByte = 4096,
25: 
26:   // Default seed for URND PRNG
27:   parameter urnd_prng_seed_t RndCnstUrndPrngSeed = RndCnstUrndPrngSeedDefault,
28: 
29:   // Disable URND reseed and advance when not in use. Useful for SCA only.
30:   parameter bit SecMuteUrnd = 1'b0,
31:   parameter bit SecSkipUrndReseedAtStart = 1'b0,
32: 
33:   localparam int ImemAddrWidth = prim_util_pkg::vbits(ImemSizeByte),
34:   localparam int DmemAddrWidth = prim_util_pkg::vbits(DmemSizeByte)
35: ) (
36:   input logic clk_i,
37:   input logic rst_ni,
38: 
39:   input  logic start_i,   // start the operation
40:   output logic done_o,    // operation done
41:   output logic locking_o, // The core is in or is entering the locked state
42:   output logic secure_wipe_running_o, // the core is securely wiping its internal state
43: 
44:   output core_err_bits_t err_bits_o,  // valid when done_o is asserted
45:   output logic           recoverable_err_o,
46: 
47:   // Instruction memory (IMEM)
48:   output logic                     imem_req_o,
49:   output logic [ImemAddrWidth-1:0] imem_addr_o,
50:   input  logic [38:0]              imem_rdata_i,
51:   input  logic                     imem_rvalid_i,
52: 
53:   // Data memory (DMEM)
54:   output logic                        dmem_req_o,
55:   output logic                        dmem_write_o,
56:   output logic [DmemAddrWidth-1:0]    dmem_addr_o,
57:   output logic [ExtWLEN-1:0]          dmem_wdata_o,
58:   output logic [ExtWLEN-1:0]          dmem_wmask_o,
59:   output logic [BaseWordsPerWLEN-1:0] dmem_rmask_o,
60:   input  logic [ExtWLEN-1:0]          dmem_rdata_i,
61:   input  logic                        dmem_rvalid_i,
62:   input  logic                        dmem_rerror_i,
63: 
64:   // Entropy distribution network (EDN) connections
65:   // One for RND, the other for URND
66:   output logic                    edn_rnd_req_o,
67:   input  logic                    edn_rnd_ack_i,
68:   input  logic [EdnDataWidth-1:0] edn_rnd_data_i,
69:   input  logic                    edn_rnd_fips_i,
70:   input  logic                    edn_rnd_err_i,
71: 
72:   output logic                    edn_urnd_req_o,
73:   input  logic                    edn_urnd_ack_i,
74:   input  logic [EdnDataWidth-1:0] edn_urnd_data_i,
75: 
76:   output logic [31:0] insn_cnt_o,
77:   input  logic        insn_cnt_clear_i,
78: 
79:   output logic         mems_sec_wipe_o,          // Request secure wipe for imem and dmem
80:   input  logic         req_sec_wipe_urnd_keys_i, // Request URND bits for temporary scramble keys.
81:                                                  // Keys below are valid cycle after request.
82:   output logic [127:0] dmem_sec_wipe_urnd_key_o, // URND bits to give temporary dmem scramble key
83:   output logic [127:0] imem_sec_wipe_urnd_key_o, // URND bits to give temporary imem scramble key
84: 
85:   // Indicates an incoming escalation from some fatal error at the level above. The core needs to
86:   // halt and then enter a locked state.
87:   input prim_mubi_pkg::mubi4_t escalate_en_i,
88: 
89:   // Indicates an incoming RMA request. The core needs to halt, trigger a secure wipe immediately
90:   // and then enter a locked state.
91:   input  prim_mubi_pkg::mubi4_t rma_req_i,
92:   output prim_mubi_pkg::mubi4_t rma_ack_o,
93: 
94:   // When set software errors become fatal errors.
95:   input logic software_errs_fatal_i,
96: 
97:   input logic [1:0]                       sideload_key_shares_valid_i,
98:   input logic [1:0][SideloadKeyWidth-1:0] sideload_key_shares_i
99: );
100:   import prim_mubi_pkg::*;
101: 
102:   // Create a lint error to reduce the risk of accidentally enabling this feature.
103:   `ASSERT_STATIC_LINT_ERROR(OtbnSecMuteUrndNonDefault, SecMuteUrnd == 0)
104: 
105:   // Fetch request (the next instruction)
106:   logic [ImemAddrWidth-1:0] insn_fetch_req_addr;
107:   logic                     insn_fetch_req_valid;
108:   logic                     insn_fetch_req_valid_raw;
109: 
110:   // Fetch response (the current instruction before it is decoded)
111:   logic                     insn_fetch_resp_valid;
112:   logic [ImemAddrWidth-1:0] insn_fetch_resp_addr;
113:   logic [31:0]              insn_fetch_resp_data;
114:   logic                     insn_fetch_resp_clear;
115:   logic                     insn_fetch_err;
116:   logic                     insn_addr_err;
117: 
118:   rf_predec_bignum_t        rf_predec_bignum;
119:   alu_predec_bignum_t       alu_predec_bignum;
120:   ctrl_flow_predec_t        ctrl_flow_predec;
121:   logic [ImemAddrWidth-1:0] ctrl_flow_target_predec;
122:   ispr_predec_bignum_t      ispr_predec_bignum;
123:   mac_predec_bignum_t       mac_predec_bignum;
124:   logic                     lsu_addr_en_predec;
125: 
126:   logic [NWdr-1:0] rf_bignum_rd_a_indirect_onehot;
127:   logic [NWdr-1:0] rf_bignum_rd_b_indirect_onehot;
128:   logic [NWdr-1:0] rf_bignum_wr_indirect_onehot;
129:   logic            rf_bignum_indirect_en;
130: 
131:   // The currently executed instruction.
132:   logic                     insn_valid;
133:   logic                     insn_illegal;
134:   logic [ImemAddrWidth-1:0] insn_addr;
135:   insn_dec_base_t           insn_dec_base;
136:   insn_dec_bignum_t         insn_dec_bignum;
137:   insn_dec_shared_t         insn_dec_shared;
138: 
139:   logic [4:0]               rf_base_wr_addr;
140:   logic [4:0]               rf_base_wr_addr_ctrl;
141:   logic                     rf_base_wr_en;
142:   logic                     rf_base_wr_en_ctrl;
143:   logic                     rf_base_wr_commit;
144:   logic                     rf_base_wr_commit_ctrl;
145:   logic [31:0]              rf_base_wr_data_no_intg;
146:   logic [31:0]              rf_base_wr_data_no_intg_ctrl;
147:   logic [BaseIntgWidth-1:0] rf_base_wr_data_intg;
148:   logic                     rf_base_wr_data_intg_sel, rf_base_wr_data_intg_sel_ctrl;
149:   logic                     rf_base_wr_sec_wipe_err;
150:   logic [4:0]               rf_base_rd_addr_a;
151:   logic                     rf_base_rd_en_a;
152:   logic [BaseIntgWidth-1:0] rf_base_rd_data_a_intg;
153:   logic [4:0]               rf_base_rd_addr_b;
154:   logic                     rf_base_rd_en_b;
155:   logic [BaseIntgWidth-1:0] rf_base_rd_data_b_intg;
156:   logic                     rf_base_rd_commit;
157:   logic                     rf_base_call_stack_sw_err;
158:   logic                     rf_base_call_stack_hw_err;
159:   logic                     rf_base_intg_err;
160:   logic                     rf_base_spurious_we_err;
161:   logic                     rf_base_sec_wipe_err;
162: 
163:   alu_base_operation_t  alu_base_operation;
164:   alu_base_comparison_t alu_base_comparison;
165:   logic [31:0]          alu_base_operation_result;
166:   logic                 alu_base_comparison_result;
167: 
168:   logic                     lsu_load_req;
169:   logic                     lsu_store_req;
170:   insn_subset_e             lsu_req_subset;
171:   logic [DmemAddrWidth-1:0] lsu_addr;
172: 
173:   logic [BaseIntgWidth-1:0] lsu_base_wdata;
174:   logic [ExtWLEN-1:0]       lsu_bignum_wdata;
175: 
176:   logic [BaseIntgWidth-1:0] lsu_base_rdata;
177:   logic [ExtWLEN-1:0]       lsu_bignum_rdata;
178:   logic                     lsu_rdata_err;
179: 
180:   logic [WdrAw-1:0]   rf_bignum_wr_addr;
181:   logic [WdrAw-1:0]   rf_bignum_wr_addr_ctrl;
182:   logic [1:0]         rf_bignum_wr_en;
183:   logic [1:0]         rf_bignum_wr_en_ctrl;
184:   logic               rf_bignum_wr_commit;
185:   logic               rf_bignum_wr_commit_ctrl;
186:   logic [WLEN-1:0]    rf_bignum_wr_data_no_intg;
187:   logic [WLEN-1:0]    rf_bignum_wr_data_no_intg_ctrl;
188:   logic [ExtWLEN-1:0] rf_bignum_wr_data_intg;
189:   logic               rf_bignum_wr_data_intg_sel, rf_bignum_wr_data_intg_sel_ctrl;
190:   logic               rf_bignum_wr_sec_wipe_err;
191:   logic [WdrAw-1:0]   rf_bignum_rd_addr_a;
192:   logic               rf_bignum_rd_en_a;
193:   logic [ExtWLEN-1:0] rf_bignum_rd_data_a_intg;
194:   logic [WdrAw-1:0]   rf_bignum_rd_addr_b;
195:   logic               rf_bignum_rd_en_b;
196:   logic [ExtWLEN-1:0] rf_bignum_rd_data_b_intg;
197:   logic               rf_bignum_intg_err;
198:   logic               rf_bignum_spurious_we_err;
199: 
200:   alu_bignum_operation_t alu_bignum_operation;
201:   logic                  alu_bignum_operation_valid;
202:   logic                  alu_bignum_operation_commit;
203:   logic [WLEN-1:0]       alu_bignum_operation_result;
204:   logic                  alu_bignum_selection_flag;
205:   logic                  alu_bignum_reg_intg_violation_err;
206:   logic                  alu_bignum_sec_wipe_err;
207: 
208:   mac_bignum_operation_t mac_bignum_operation;
209:   logic [WLEN-1:0]       mac_bignum_operation_result;
210:   flags_t                mac_bignum_operation_flags;
211:   flags_t                mac_bignum_operation_flags_en;
212:   logic                  mac_bignum_en;
213:   logic                  mac_bignum_commit;
214:   logic                  mac_bignum_reg_intg_violation_err;
215:   logic                  mac_bignum_sec_wipe_err;
216: 
217:   ispr_e                       ispr_addr;
218:   logic [31:0]                 ispr_base_wdata;
219:   logic [BaseWordsPerWLEN-1:0] ispr_base_wr_en;
220:   logic [ExtWLEN-1:0]          ispr_bignum_wdata_intg;
221:   logic                        ispr_bignum_wr_en;
222:   logic [NFlagGroups-1:0]      ispr_flags_wr;
223:   logic                        ispr_wr_commit;
224:   logic [ExtWLEN-1:0]          ispr_rdata_intg;
225:   logic                        ispr_rd_en;
226:   logic [ExtWLEN-1:0]          ispr_acc_intg;
227:   logic [ExtWLEN-1:0]          ispr_acc_wr_data_intg;
228:   logic                        ispr_acc_wr_en;
229:   logic                        ispr_init;
230: 
231:   logic            rnd_req;
232:   logic            rnd_prefetch_req;
233:   logic            rnd_valid;
234:   logic [WLEN-1:0] rnd_data;
235:   logic            rnd_rep_err;
236:   logic            rnd_fips_err;
237: 
238:   logic            urnd_reseed_req;
239:   logic            urnd_reseed_ack;
240:   logic            urnd_reseed_err;
241:   logic            urnd_advance;
242:   logic            urnd_advance_start_stop_control;
243:   logic [WLEN-1:0] urnd_data;
244:   logic            urnd_all_zero;
245: 
246:   logic        controller_start;
247: 
248:   logic        state_reset;
249:   logic        insn_cnt_clear_int;
250:   logic [31:0] insn_cnt;
251: 
252:   logic secure_wipe_req, secure_wipe_ack;
253: 
254:   logic sec_wipe_wdr_d, sec_wipe_wdr_q;
255:   logic sec_wipe_wdr_urnd_d, sec_wipe_wdr_urnd_q;
256:   logic sec_wipe_base;
257:   logic sec_wipe_base_urnd;
258:   logic [4:0] sec_wipe_addr, sec_wipe_wdr_addr_q;
259: 
260:   logic sec_wipe_acc_urnd;
261:   logic sec_wipe_mod_urnd;
262:   logic sec_wipe_zero;
263:   logic sec_wipe_err;
264: 
265:   logic zero_flags;
266: 
267:   logic                     prefetch_en;
268:   logic                     prefetch_loop_active;
269:   logic [31:0]              prefetch_loop_iterations;
270:   logic [ImemAddrWidth:0]   prefetch_loop_end_addr;
271:   logic [ImemAddrWidth-1:0] prefetch_loop_jump_addr;
272: 
273:   mubi4_t               controller_fatal_escalate_en, controller_recov_escalate_en;
274:   mubi4_t               start_stop_escalate_en;
275:   controller_err_bits_t controller_err_bits;
276:   logic                 prefetch_ignore_errs;
277: 
278:   core_err_bits_t err_bits_q, err_bits_d;
279:   logic           mubi_err;
280: 
281:   logic start_stop_fatal_error;
282:   logic rf_bignum_predec_error, alu_bignum_predec_error, ispr_predec_error, mac_bignum_predec_error;
283:   logic controller_predec_error;
284:   logic rd_predec_error, predec_error;
285: 
286:   logic req_sec_wipe_urnd_keys_q;
287: 
288:   // Start stop control start OTBN execution when requested and deals with any pre start or post
289:   // stop actions.
290:   otbn_start_stop_control #(
291:     .SecMuteUrnd(SecMuteUrnd),
292:     .SecSkipUrndReseedAtStart(SecSkipUrndReseedAtStart)
293:   ) u_otbn_start_stop_control (
294:     .clk_i,
295:     .rst_ni,
296: 
297:     .start_i,
298:     .escalate_en_i(start_stop_escalate_en),
299:     .rma_req_i,
300:     .rma_ack_o,
301: 
302:     .controller_start_o(controller_start),
303: 
304:     .urnd_reseed_req_o (urnd_reseed_req),
305:     .urnd_reseed_ack_i (urnd_reseed_ack),
306:     .urnd_reseed_err_o (urnd_reseed_err),
307:     .urnd_advance_o    (urnd_advance_start_stop_control),
308: 
309:     .secure_wipe_req_i (secure_wipe_req),
310:     .secure_wipe_ack_o (secure_wipe_ack),
311:     .secure_wipe_running_o,
312:     .done_o,
313: 
314:     .sec_wipe_wdr_o      (sec_wipe_wdr_d),
315:     .sec_wipe_wdr_urnd_o (sec_wipe_wdr_urnd_d),
316:     .sec_wipe_base_o     (sec_wipe_base),
317:     .sec_wipe_base_urnd_o(sec_wipe_base_urnd),
318:     .sec_wipe_addr_o     (sec_wipe_addr),
319: 
320:     .sec_wipe_acc_urnd_o(sec_wipe_acc_urnd),
321:     .sec_wipe_mod_urnd_o(sec_wipe_mod_urnd),
322:     .sec_wipe_zero_o    (sec_wipe_zero),
323: 
324:     .ispr_init_o         (ispr_init),
325:     .state_reset_o       (state_reset),
326:     .insn_cnt_clear_int_o(insn_cnt_clear_int),
327:     .fatal_error_o       (start_stop_fatal_error)
328:   );
329: 
330:   // Depending on its usage, the instruction address (program counter) is qualified by two valid
331:   // signals: insn_fetch_resp_valid (together with the undecoded instruction data), and insn_valid
332:   // for valid decoded (i.e. legal) instructions. Duplicate the signal in the source code for
333:   // consistent grouping of signals with their valid signal.
334:   assign insn_addr = insn_fetch_resp_addr;
335: 
336:   // For secure wipe and ISPR initialization, flags need to be cleared to 0. This is achieved
337:   // through the blanking mechanism controlled by the instruction fetch/predecoder stage.
338:   assign zero_flags = sec_wipe_zero | ispr_init;
339: 
340:   // Instruction fetch unit
341:   otbn_instruction_fetch #(
342:     .ImemSizeByte(ImemSizeByte)
343:   ) u_otbn_instruction_fetch (
344:     .clk_i,
345:     .rst_ni,
346: 
347:     // Instruction memory interface
348:     .imem_req_o,
349:     .imem_addr_o,
350:     .imem_rdata_i,
351:     .imem_rvalid_i,
352: 
353:     // Instruction to fetch
354:     .insn_fetch_req_addr_i     (insn_fetch_req_addr),
355:     .insn_fetch_req_valid_i    (insn_fetch_req_valid),
356:     .insn_fetch_req_valid_raw_i(insn_fetch_req_valid_raw),
357: 
358:     // Fetched instruction
359:     .insn_fetch_resp_addr_o (insn_fetch_resp_addr),
360:     .insn_fetch_resp_valid_o(insn_fetch_resp_valid),
361:     .insn_fetch_resp_data_o (insn_fetch_resp_data),
362:     .insn_fetch_resp_clear_i(insn_fetch_resp_clear),
363:     .insn_fetch_err_o       (insn_fetch_err),
364:     .insn_addr_err_o        (insn_addr_err),
365: 
366:     .rf_predec_bignum_o       (rf_predec_bignum),
367:     .alu_predec_bignum_o      (alu_predec_bignum),
368:     .ctrl_flow_predec_o       (ctrl_flow_predec),
369:     .ctrl_flow_target_predec_o(ctrl_flow_target_predec),
370:     .ispr_predec_bignum_o     (ispr_predec_bignum),
371:     .mac_predec_bignum_o      (mac_predec_bignum),
372:     .lsu_addr_en_predec_o     (lsu_addr_en_predec),
373: 
374:     .rf_bignum_rd_a_indirect_onehot_i(rf_bignum_rd_a_indirect_onehot),
375:     .rf_bignum_rd_b_indirect_onehot_i(rf_bignum_rd_b_indirect_onehot),
376:     .rf_bignum_wr_indirect_onehot_i  (rf_bignum_wr_indirect_onehot),
377:     .rf_bignum_indirect_en_i         (rf_bignum_indirect_en),
378: 
379:     .prefetch_en_i             (prefetch_en),
380:     .prefetch_loop_active_i    (prefetch_loop_active),
381:     .prefetch_loop_iterations_i(prefetch_loop_iterations),
382:     .prefetch_loop_end_addr_i  (prefetch_loop_end_addr),
383:     .prefetch_loop_jump_addr_i (prefetch_loop_jump_addr),
384:     .prefetch_ignore_errs_i    (prefetch_ignore_errs),
385: 
386:     .sec_wipe_wdr_en_i  (sec_wipe_wdr_d),
387:     .sec_wipe_wdr_addr_i(sec_wipe_addr),
388: 
389:     .zero_flags_i(zero_flags)
390:   );
391: 
392:   // Instruction decoder
393:   otbn_decoder u_otbn_decoder (
394:     // The decoder is combinatorial; clk and rst are only used for assertions.
395:     .clk_i,
396:     .rst_ni,
397: 
398:     // Instruction to decode
399:     .insn_fetch_resp_data_i (insn_fetch_resp_data),
400:     .insn_fetch_resp_valid_i(insn_fetch_resp_valid),
401: 
402:     // Decoded instruction
403:     .insn_valid_o     (insn_valid),
404:     .insn_illegal_o   (insn_illegal),
405:     .insn_dec_base_o  (insn_dec_base),
406:     .insn_dec_bignum_o(insn_dec_bignum),
407:     .insn_dec_shared_o(insn_dec_shared)
408:   );
409: 
410:   // SEC_CM: CTRL.REDUN
411:   // ALU and MAC predecode is only relevant when there is a valid instruction, as without one it is
412:   // guaranteed there are no register reads (hence no sensitive data bits being fed into the blanked
413:   // data paths). RF and ISPR predecode must always be checked to ensure read and write data paths
414:   // are always correctly blanked.
415:   assign rd_predec_error = |{rf_predec_bignum.rf_ren_a,
416:                              rf_predec_bignum.rf_ren_b,
417:                              ispr_predec_bignum.ispr_rd_en} & ~insn_valid;
418: 
419:   assign predec_error =
420:     ((alu_bignum_predec_error | mac_bignum_predec_error | controller_predec_error) & insn_valid) |
421:      rf_bignum_predec_error                                                                      |
422:      ispr_predec_error                                                                           |
423:      rd_predec_error;
424: 
425:   assign sec_wipe_err = |{rf_base_wr_sec_wipe_err,
426:                           rf_base_sec_wipe_err,
427:                           rf_bignum_wr_sec_wipe_err,
428:                           alu_bignum_sec_wipe_err,
429:                           mac_bignum_sec_wipe_err};
430: 
431:   // Controller: coordinate between functional units, prepare their inputs (e.g. by muxing between
432:   // operand sources), and post-process their outputs as needed.
433:   otbn_controller #(
434:     .ImemSizeByte(ImemSizeByte),
435:     .DmemSizeByte(DmemSizeByte)
436:   ) u_otbn_controller (
437:     .clk_i,
438:     .rst_ni,
439: 
440:     .start_i         (controller_start),
441:     .locking_o,
442:     .err_bit_clear_i (start_i),
443: 
444:     .fatal_escalate_en_i(controller_fatal_escalate_en),
445:     .recov_escalate_en_i(controller_recov_escalate_en),
446:     .rma_req_i,
447:     .err_bits_o         (controller_err_bits),
448:     .recoverable_err_o,
449: 
450:     // Next instruction selection (to instruction fetch)
451:     .insn_fetch_req_addr_o     (insn_fetch_req_addr),
452:     .insn_fetch_req_valid_o    (insn_fetch_req_valid),
453:     .insn_fetch_req_valid_raw_o(insn_fetch_req_valid_raw),
454:     .insn_fetch_resp_clear_o   (insn_fetch_resp_clear),
455: 
456:     // The current instruction
457:     .insn_valid_i  (insn_valid),
458:     .insn_illegal_i(insn_illegal),
459:     .insn_addr_i   (insn_addr),
460: 
461:     // Decoded instruction from decoder
462:     .insn_dec_base_i  (insn_dec_base),
463:     .insn_dec_bignum_i(insn_dec_bignum),
464:     .insn_dec_shared_i(insn_dec_shared),
465: 
466:     // To/from base register file
467:     .rf_base_wr_addr_o          (rf_base_wr_addr_ctrl),
468:     .rf_base_wr_en_o            (rf_base_wr_en_ctrl),
469:     .rf_base_wr_commit_o        (rf_base_wr_commit_ctrl),
470:     .rf_base_wr_data_no_intg_o  (rf_base_wr_data_no_intg_ctrl),
471:     .rf_base_wr_data_intg_o     (rf_base_wr_data_intg),
472:     .rf_base_wr_data_intg_sel_o (rf_base_wr_data_intg_sel_ctrl),
473:     .rf_base_rd_addr_a_o        (rf_base_rd_addr_a),
474:     .rf_base_rd_en_a_o          (rf_base_rd_en_a),
475:     .rf_base_rd_data_a_intg_i   (rf_base_rd_data_a_intg),
476:     .rf_base_rd_addr_b_o        (rf_base_rd_addr_b),
477:     .rf_base_rd_en_b_o          (rf_base_rd_en_b),
478:     .rf_base_rd_data_b_intg_i   (rf_base_rd_data_b_intg),
479:     .rf_base_rd_commit_o        (rf_base_rd_commit),
480:     .rf_base_call_stack_sw_err_i(rf_base_call_stack_sw_err),
481:     .rf_base_call_stack_hw_err_i(rf_base_call_stack_hw_err),
482: 
483:     // To/from bignum register file
484:     .rf_bignum_wr_addr_o         (rf_bignum_wr_addr_ctrl),
485:     .rf_bignum_wr_en_o           (rf_bignum_wr_en_ctrl),
486:     .rf_bignum_wr_commit_o       (rf_bignum_wr_commit_ctrl),
487:     .rf_bignum_wr_data_no_intg_o (rf_bignum_wr_data_no_intg_ctrl),
488:     .rf_bignum_wr_data_intg_o    (rf_bignum_wr_data_intg),
489:     .rf_bignum_wr_data_intg_sel_o(rf_bignum_wr_data_intg_sel_ctrl),
490:     .rf_bignum_rd_addr_a_o       (rf_bignum_rd_addr_a),
491:     .rf_bignum_rd_en_a_o         (rf_bignum_rd_en_a),
492:     .rf_bignum_rd_data_a_intg_i  (rf_bignum_rd_data_a_intg),
493:     .rf_bignum_rd_addr_b_o       (rf_bignum_rd_addr_b),
494:     .rf_bignum_rd_en_b_o         (rf_bignum_rd_en_b),
495:     .rf_bignum_rd_data_b_intg_i  (rf_bignum_rd_data_b_intg),
496:     .rf_bignum_intg_err_i        (rf_bignum_intg_err),
497:     .rf_bignum_spurious_we_err_i (rf_bignum_spurious_we_err),
498: 
499:     .rf_bignum_rd_a_indirect_onehot_o(rf_bignum_rd_a_indirect_onehot),
500:     .rf_bignum_rd_b_indirect_onehot_o(rf_bignum_rd_b_indirect_onehot),
501:     .rf_bignum_wr_indirect_onehot_o  (rf_bignum_wr_indirect_onehot),
502:     .rf_bignum_indirect_en_o         (rf_bignum_indirect_en),
503: 
504:     // To/from base ALU
505:     .alu_base_operation_o        (alu_base_operation),
506:     .alu_base_comparison_o       (alu_base_comparison),
507:     .alu_base_operation_result_i (alu_base_operation_result),
508:     .alu_base_comparison_result_i(alu_base_comparison_result),
509: 
510:     // To/from bignum ALU
511:     .alu_bignum_operation_o       (alu_bignum_operation),
512:     .alu_bignum_operation_valid_o (alu_bignum_operation_valid),
513:     .alu_bignum_operation_commit_o(alu_bignum_operation_commit),
514:     .alu_bignum_operation_result_i(alu_bignum_operation_result),
515:     .alu_bignum_selection_flag_i  (alu_bignum_selection_flag),
516: 
517:     // To/from bignum MAC
518:     .mac_bignum_operation_o       (mac_bignum_operation),
519:     .mac_bignum_operation_result_i(mac_bignum_operation_result),
520:     .mac_bignum_en_o              (mac_bignum_en),
521:     .mac_bignum_commit_o          (mac_bignum_commit),
522: 
523:     // To/from LSU (base and bignum)
524:     .lsu_load_req_o          (lsu_load_req),
525:     .lsu_store_req_o         (lsu_store_req),
526:     .lsu_req_subset_o        (lsu_req_subset),
527:     .lsu_addr_o              (lsu_addr),
528:     .lsu_addr_en_predec_i    (lsu_addr_en_predec),
529: 
530:     .lsu_base_wdata_o  (lsu_base_wdata),
531:     .lsu_bignum_wdata_o(lsu_bignum_wdata),
532: 
533:     .lsu_base_rdata_i  (lsu_base_rdata),
534:     .lsu_bignum_rdata_i(lsu_bignum_rdata),
535: 
536:     // Isprs read/write (base and bignum)
537:     .ispr_addr_o             (ispr_addr),
538:     .ispr_base_wdata_o       (ispr_base_wdata),
539:     .ispr_base_wr_en_o       (ispr_base_wr_en),
540:     .ispr_bignum_wdata_intg_o(ispr_bignum_wdata_intg),
541:     .ispr_bignum_wr_en_o     (ispr_bignum_wr_en),
542:     .ispr_flags_wr_o         (ispr_flags_wr),
543:     .ispr_wr_commit_o        (ispr_wr_commit),
544:     .ispr_rdata_intg_i       (ispr_rdata_intg),
545:     .ispr_rd_en_o            (ispr_rd_en),
546: 
547:     // RND interface
548:     .rnd_req_o         (rnd_req),
549:     .rnd_prefetch_req_o(rnd_prefetch_req),
550:     .rnd_valid_i       (rnd_valid),
551: 
552:     .urnd_reseed_err_i(urnd_reseed_err),
553: 
554:     // Secure wipe
555:     .secure_wipe_req_o     (secure_wipe_req),
556:     .secure_wipe_ack_i     (secure_wipe_ack),
557:     .sec_wipe_zero_i       (sec_wipe_zero),
558:     .secure_wipe_running_i (secure_wipe_running_o),
559:     .sec_wipe_err_i        (sec_wipe_err),
560: 
561:     .state_reset_i       (state_reset),
562:     .insn_cnt_o          (insn_cnt),
563:     .insn_cnt_clear_int_i(insn_cnt_clear_int),
564:     .insn_cnt_clear_ext_i(insn_cnt_clear_i),
565:     .mems_sec_wipe_o,
566: 
567:     .software_errs_fatal_i,
568: 
569:     .sideload_key_shares_valid_i,
570: 
571:     .prefetch_en_o             (prefetch_en),
572:     .prefetch_loop_active_o    (prefetch_loop_active),
573:     .prefetch_loop_iterations_o(prefetch_loop_iterations),
574:     .prefetch_loop_end_addr_o  (prefetch_loop_end_addr),
575:     .prefetch_loop_jump_addr_o (prefetch_loop_jump_addr),
576:     .prefetch_ignore_errs_o    (prefetch_ignore_errs),
577: 
578:     .ctrl_flow_predec_i       (ctrl_flow_predec),
579:     .ctrl_flow_target_predec_i(ctrl_flow_target_predec),
580:     .predec_error_o           (controller_predec_error)
581:   );
582: 
583:   `ASSERT(InsnDataStableInStall, u_otbn_controller.state_q == OtbnStateStall |->
584:                                  insn_fetch_resp_data == $past(insn_fetch_resp_data))
585: 
586:   // Spot the fatal error bits from the controller
587:   logic controller_fatal_err;
588:   assign controller_fatal_err = |{controller_err_bits.fatal_software,
589:                                   controller_err_bits.bad_internal_state,
590:                                   controller_err_bits.reg_intg_violation};
591: 
592:   logic non_controller_reg_intg_violation;
593:   assign non_controller_reg_intg_violation =
594:       |{alu_bignum_reg_intg_violation_err, mac_bignum_reg_intg_violation_err, rf_base_intg_err};
595: 
596: 
597:   // Generate an err_bits output by combining errors from all the blocks in otbn_core
598:   assign err_bits_d = '{
599:     fatal_software:      controller_err_bits.fatal_software,
600:     bad_internal_state:  |{controller_err_bits.bad_internal_state,
601:                            start_stop_fatal_error,
602:                            urnd_all_zero,
603:                            predec_error,
604:                            insn_addr_err,
605:                            rf_base_spurious_we_err,
606:                            mubi_err},
607:     reg_intg_violation:  |{controller_err_bits.reg_intg_violation,
608:                            non_controller_reg_intg_violation},
609:     dmem_intg_violation: lsu_rdata_err,
610:     imem_intg_violation: insn_fetch_err,
611:     rnd_fips_chk_fail:   rnd_fips_err,
612:     rnd_rep_chk_fail:    rnd_rep_err,
613:     key_invalid:         controller_err_bits.key_invalid,
614:     loop:                controller_err_bits.loop,
615:     illegal_insn:        controller_err_bits.illegal_insn,
616:     call_stack:          controller_err_bits.call_stack,
617:     bad_insn_addr:       controller_err_bits.bad_insn_addr,
618:     bad_data_addr:       controller_err_bits.bad_data_addr
619:   };
620: 
621:   always_ff @(posedge clk_i or negedge rst_ni) begin
622:     if (!rst_ni) begin
623:       err_bits_q <= '0;
624:     end else begin
625:       if (start_i && !locking_o) begin
626:         err_bits_q <= '0;
627:       end else begin
628:         err_bits_q <= err_bits_q | err_bits_d;
629:       end
630:     end
631:   end
632:   assign err_bits_o = err_bits_q | err_bits_d;
633: 
634:   // Pass an "escalation" signal down to the controller by ORing in error signals from the other
635:   // modules in otbn_core. Note that each error signal except escalate_en_i that appears here also
636:   // appears somewhere in err_bits_o above (checked in ErrBitsIfControllerEscalate_A)
637:   assign controller_fatal_escalate_en =
638:       mubi4_or_hi(escalate_en_i,
639:                   mubi4_bool_to_mubi(|{start_stop_fatal_error, urnd_all_zero, predec_error,
640:                                        rf_base_intg_err, rf_base_spurious_we_err, lsu_rdata_err,
641:                                        insn_fetch_err, non_controller_reg_intg_violation,
642:                                        insn_addr_err}));
643: 
644:   assign controller_recov_escalate_en =
645:       mubi4_bool_to_mubi(|{rnd_rep_err, rnd_fips_err});
646: 
647:   // Similarly for the start/stop controller
648:   assign start_stop_escalate_en =
649:       mubi4_or_hi(escalate_en_i,
650:                   mubi4_bool_to_mubi(|{urnd_all_zero, rf_base_intg_err, rf_base_spurious_we_err,
651:                                        predec_error, lsu_rdata_err, insn_fetch_err,
652:                                        controller_fatal_err, insn_addr_err}));
653: 
654:   // Signal error if MuBi input signals take on invalid values as this means something bad is
655:   // happening. The explicit error detection is required as the mubi4_or_hi operations above
656:   // might mask invalid values depending on other input operands.
657:   assign mubi_err = mubi4_test_invalid(escalate_en_i);
658: 
659:   assign insn_cnt_o = insn_cnt;
660: 
661:   // Load store unit: read and write data from data memory
662:   otbn_lsu u_otbn_lsu (
663:     .clk_i,
664:     .rst_ni,
665: 
666:     // Data memory interface
667:     .dmem_req_o,
668:     .dmem_write_o,
669:     .dmem_addr_o,
670:     .dmem_wdata_o,
671:     .dmem_wmask_o,
672:     .dmem_rmask_o,
673:     .dmem_rdata_i,
674:     .dmem_rvalid_i,
675:     .dmem_rerror_i,
676: 
677:     .lsu_load_req_i  (lsu_load_req),
678:     .lsu_store_req_i (lsu_store_req),
679:     .lsu_req_subset_i(lsu_req_subset),
680:     .lsu_addr_i      (lsu_addr),
681: 
682:     .lsu_base_wdata_i  (lsu_base_wdata),
683:     .lsu_bignum_wdata_i(lsu_bignum_wdata),
684: 
685:     .lsu_base_rdata_o  (lsu_base_rdata),
686:     .lsu_bignum_rdata_o(lsu_bignum_rdata),
687:     .lsu_rdata_err_o   (lsu_rdata_err)
688:   );
689: 
690:   // Base Instruction Subset =======================================================================
691: 
692:   otbn_rf_base #(
693:     .RegFile(RegFile)
694:   ) u_otbn_rf_base (
695:     .clk_i,
696:     .rst_ni,
697: 
698:     .state_reset_i         (state_reset),
699:     .sec_wipe_stack_reset_i(sec_wipe_zero),
700:     .sec_wipe_running_i    (secure_wipe_running_o),
701: 
702:     .wr_addr_i         (rf_base_wr_addr),
703:     .wr_en_i           (rf_base_wr_en),
704:     .wr_data_no_intg_i (rf_base_wr_data_no_intg),
705:     .wr_data_intg_i    (rf_base_wr_data_intg),
706:     .wr_data_intg_sel_i(rf_base_wr_data_intg_sel),
707:     .wr_commit_i       (rf_base_wr_commit),
708: 
709:     .rd_addr_a_i     (rf_base_rd_addr_a),
710:     .rd_en_a_i       (rf_base_rd_en_a),
711:     .rd_data_a_intg_o(rf_base_rd_data_a_intg),
712:     .rd_addr_b_i     (rf_base_rd_addr_b),
713:     .rd_en_b_i       (rf_base_rd_en_b),
714:     .rd_data_b_intg_o(rf_base_rd_data_b_intg),
715:     .rd_commit_i     (rf_base_rd_commit),
716: 
717:     .call_stack_sw_err_o(rf_base_call_stack_sw_err),
718:     .call_stack_hw_err_o(rf_base_call_stack_hw_err),
719:     .intg_err_o         (rf_base_intg_err),
720:     .spurious_we_err_o  (rf_base_spurious_we_err),
721:     .sec_wipe_err_o     (rf_base_sec_wipe_err)
722:   );
723: 
724:   assign rf_base_wr_addr         = sec_wipe_base ? sec_wipe_addr : rf_base_wr_addr_ctrl;
725:   assign rf_base_wr_en           = sec_wipe_base ? 1'b1          : rf_base_wr_en_ctrl;
726:   assign rf_base_wr_commit       = sec_wipe_base ? 1'b1          : rf_base_wr_commit_ctrl;
727: 
728:   // Write data to Base RF
729:   always_comb begin
730:     if (sec_wipe_base) begin
731:       // Wipe the Base RF with either random numbers or zeroes.
732:       if (sec_wipe_base_urnd) begin
733:         rf_base_wr_data_no_intg = urnd_data[31:0];
734:       end else begin
735:         rf_base_wr_data_no_intg = 32'b0;
736:       end
737:       rf_base_wr_data_intg_sel = 0;
738:     end else begin
739:       rf_base_wr_data_no_intg = rf_base_wr_data_no_intg_ctrl;
740:       rf_base_wr_data_intg_sel = rf_base_wr_data_intg_sel_ctrl;
741:     end
742:   end
743: 
744:   assign rf_base_wr_sec_wipe_err = sec_wipe_base & ~secure_wipe_running_o;
745: 
746:   otbn_alu_base u_otbn_alu_base (
747:     .clk_i,
748:     .rst_ni,
749: 
750:     .operation_i        (alu_base_operation),
751:     .comparison_i       (alu_base_comparison),
752:     .operation_result_o (alu_base_operation_result),
753:     .comparison_result_o(alu_base_comparison_result)
754:   );
755: 
756:   otbn_rf_bignum #(
757:     .RegFile(RegFile)
758:   ) u_otbn_rf_bignum (
759:     .clk_i,
760:     .rst_ni,
761: 
762:     .wr_addr_i         (rf_bignum_wr_addr),
763:     .wr_en_i           (rf_bignum_wr_en),
764:     .wr_commit_i       (rf_bignum_wr_commit),
765:     .wr_data_no_intg_i (rf_bignum_wr_data_no_intg),
766:     .wr_data_intg_i    (rf_bignum_wr_data_intg),
767:     .wr_data_intg_sel_i(rf_bignum_wr_data_intg_sel),
768: 
769:     .rd_addr_a_i     (rf_bignum_rd_addr_a),
770:     .rd_en_a_i       (rf_bignum_rd_en_a),
771:     .rd_data_a_intg_o(rf_bignum_rd_data_a_intg),
772:     .rd_addr_b_i     (rf_bignum_rd_addr_b),
773:     .rd_en_b_i       (rf_bignum_rd_en_b),
774:     .rd_data_b_intg_o(rf_bignum_rd_data_b_intg),
775: 
776:     .intg_err_o(rf_bignum_intg_err),
777: 
778:     .rf_predec_bignum_i(rf_predec_bignum),
779:     .predec_error_o    (rf_bignum_predec_error),
780: 
781:     .spurious_we_err_o(rf_bignum_spurious_we_err)
782:   );
783: 
784:   always_ff @(posedge clk_i or negedge rst_ni) begin
785:     if(!rst_ni) begin
786:       sec_wipe_wdr_q <= 1'b0;
787:     end else begin
788:       sec_wipe_wdr_q <= sec_wipe_wdr_d;
789:     end
790:   end
791: 
792:   always_ff @(posedge clk_i) begin
793:     if (sec_wipe_wdr_d) begin
794:       sec_wipe_wdr_addr_q <= sec_wipe_addr;
795:       sec_wipe_wdr_urnd_q <= sec_wipe_wdr_urnd_d;
796:     end
797:   end
798: 
799:   assign rf_bignum_wr_addr   = sec_wipe_wdr_q ? sec_wipe_wdr_addr_q : rf_bignum_wr_addr_ctrl;
800:   assign rf_bignum_wr_en     = sec_wipe_wdr_q ? 2'b11               : rf_bignum_wr_en_ctrl;
801:   assign rf_bignum_wr_commit = sec_wipe_wdr_q ? 1'b1                : rf_bignum_wr_commit_ctrl;
802: 
803:   // Write data to WDR
804:   always_comb begin
805:     if (sec_wipe_wdr_q) begin
806:       // Wipe the WDR with either random numbers or zeroes.
807:       if (sec_wipe_wdr_urnd_q) begin
808:         rf_bignum_wr_data_no_intg = urnd_data;
809:       end else begin
810:         rf_bignum_wr_data_no_intg = 256'b0;
811:       end
812:       rf_bignum_wr_data_intg_sel = 0;
813:     end else begin
814:       rf_bignum_wr_data_no_intg = rf_bignum_wr_data_no_intg_ctrl;
815:       rf_bignum_wr_data_intg_sel = rf_bignum_wr_data_intg_sel_ctrl;
816:     end
817:   end
818: 
819:   assign rf_bignum_wr_sec_wipe_err = sec_wipe_wdr_q & ~secure_wipe_running_o;
820: 
821:   otbn_alu_bignum u_otbn_alu_bignum (
822:     .clk_i,
823:     .rst_ni,
824: 
825:     .operation_i       (alu_bignum_operation),
826:     .operation_valid_i (alu_bignum_operation_valid),
827:     .operation_commit_i(alu_bignum_operation_commit),
828:     .operation_result_o(alu_bignum_operation_result),
829:     .selection_flag_o  (alu_bignum_selection_flag),
830: 
831:     .alu_predec_bignum_i (alu_predec_bignum),
832:     .ispr_predec_bignum_i(ispr_predec_bignum),
833: 
834:     .ispr_addr_i             (ispr_addr),
835:     .ispr_base_wdata_i       (ispr_base_wdata),
836:     .ispr_base_wr_en_i       (ispr_base_wr_en),
837:     .ispr_bignum_wdata_intg_i(ispr_bignum_wdata_intg),
838:     .ispr_bignum_wr_en_i     (ispr_bignum_wr_en),
839:     .ispr_flags_wr_i         (ispr_flags_wr),
840:     .ispr_wr_commit_i        (ispr_wr_commit),
841:     .ispr_init_i             (ispr_init),
842:     .ispr_rdata_intg_o       (ispr_rdata_intg),
843:     .ispr_rd_en_i            (ispr_rd_en),
844: 
845:     .ispr_acc_intg_i        (ispr_acc_intg),
846:     .ispr_acc_wr_data_intg_o(ispr_acc_wr_data_intg),
847:     .ispr_acc_wr_en_o       (ispr_acc_wr_en),
848: 
849:     .reg_intg_violation_err_o(alu_bignum_reg_intg_violation_err),
850: 
851:     .sec_wipe_mod_urnd_i(sec_wipe_mod_urnd),
852:     .sec_wipe_running_i (secure_wipe_running_o),
853:     .sec_wipe_err_o     (alu_bignum_sec_wipe_err),
854: 
855:     .mac_operation_flags_i   (mac_bignum_operation_flags),
856:     .mac_operation_flags_en_i(mac_bignum_operation_flags_en),
857: 
858:     .rnd_data_i (rnd_data),
859:     .urnd_data_i(urnd_data),
860: 
861:     .sideload_key_shares_i,
862: 
863:     .alu_predec_error_o(alu_bignum_predec_error),
864:     .ispr_predec_error_o(ispr_predec_error)
865:   );
866: 
867:   otbn_mac_bignum u_otbn_mac_bignum (
868:     .clk_i,
869:     .rst_ni,
870: 
871:     .operation_i                    (mac_bignum_operation),
872:     .operation_result_o             (mac_bignum_operation_result),
873:     .operation_flags_o              (mac_bignum_operation_flags),
874:     .operation_flags_en_o           (mac_bignum_operation_flags_en),
875:     .operation_intg_violation_err_o (mac_bignum_reg_intg_violation_err),
876: 
877:     .mac_predec_bignum_i(mac_predec_bignum),
878:     .predec_error_o     (mac_bignum_predec_error),
879: 
880:     .urnd_data_i        (urnd_data),
881:     .sec_wipe_acc_urnd_i(sec_wipe_acc_urnd),
882:     .sec_wipe_running_i (secure_wipe_running_o),
883:     .sec_wipe_err_o     (mac_bignum_sec_wipe_err),
884: 
885:     .mac_en_i    (mac_bignum_en),
886:     .mac_commit_i(mac_bignum_commit),
887: 
888:     .ispr_acc_intg_o        (ispr_acc_intg),
889:     .ispr_acc_wr_data_intg_i(ispr_acc_wr_data_intg),
890:     .ispr_acc_wr_en_i       (ispr_acc_wr_en)
891:   );
892: 
893:   otbn_rnd #(
894:     .RndCnstUrndPrngSeed(RndCnstUrndPrngSeed)
895:   ) u_otbn_rnd (
896:     .clk_i,
897:     .rst_ni,
898: 
899:     .opn_start_i (controller_start),
900:     .opn_end_i   (secure_wipe_req),
901: 
902:     .rnd_req_i         (rnd_req),
903:     .rnd_prefetch_req_i(rnd_prefetch_req),
904:     .rnd_valid_o       (rnd_valid),
905:     .rnd_data_o        (rnd_data),
906:     .rnd_rep_err_o     (rnd_rep_err),
907:     .rnd_fips_err_o    (rnd_fips_err),
908: 
909:     .urnd_reseed_req_i (urnd_reseed_req),
910:     .urnd_reseed_ack_o (urnd_reseed_ack),
911:     .urnd_advance_i    (urnd_advance),
912:     .urnd_data_o       (urnd_data),
913:     .urnd_all_zero_o   (urnd_all_zero),
914: 
915:     .edn_rnd_req_o,
916:     .edn_rnd_ack_i,
917:     .edn_rnd_data_i,
918:     .edn_rnd_fips_i,
919:     .edn_rnd_err_i,
920: 
921:     .edn_urnd_req_o,
922:     .edn_urnd_ack_i,
923:     .edn_urnd_data_i
924:   );
925: 
926:   // Advance URND either when the start_stop_control commands it or when temporary secure wipe keys
927:   // are requested.
928:   // When SecMuteUrnd is enabled, signal urnd_advance_start_stop_control is muted. Therefore, it is
929:   // necessary to enable urnd_advance using ispr_predec_bignum.ispr_rd_en[IsprUrnd] whenever URND
930:   // data are consumed by the ALU.
931:   assign urnd_advance = urnd_advance_start_stop_control | req_sec_wipe_urnd_keys_q |
932:                         (SecMuteUrnd & ispr_predec_bignum.ispr_rd_en[IsprUrnd]);
933: 
934:   always_ff @(posedge clk_i or negedge rst_ni) begin
935:     if (!rst_ni) begin
936:       req_sec_wipe_urnd_keys_q <= 1'b0;
937:     end else begin
938:       req_sec_wipe_urnd_keys_q <= req_sec_wipe_urnd_keys_i;
939:     end
940:   end
941: 
942:   assign dmem_sec_wipe_urnd_key_o = urnd_data[127:0];
943:   assign imem_sec_wipe_urnd_key_o = urnd_data[255:128];
944: 
945:   // Asserts =======================================================================================
946: 
947:   // All outputs should be known.
948:   `ASSERT_KNOWN(DoneOKnown_A, done_o)
949:   `ASSERT_KNOWN(ImemReqOKnown_A, imem_req_o)
950:   `ASSERT_KNOWN_IF(ImemAddrOKnown_A, imem_addr_o, imem_req_o)
951:   `ASSERT_KNOWN(DmemReqOKnown_A, dmem_req_o)
952:   `ASSERT_KNOWN_IF(DmemWriteOKnown_A, dmem_write_o, dmem_req_o)
953:   `ASSERT_KNOWN_IF(DmemAddrOKnown_A, dmem_addr_o, dmem_req_o)
954:   `ASSERT_KNOWN_IF(DmemWdataOKnown_A, dmem_wdata_o, dmem_req_o & dmem_write_o)
955:   `ASSERT_KNOWN_IF(DmemWmaskOKnown_A, dmem_wmask_o, dmem_req_o & dmem_write_o)
956:   `ASSERT_KNOWN_IF(DmemRmaskOKnown_A, dmem_rmask_o, dmem_req_o)
957:   `ASSERT_KNOWN(EdnRndReqOKnown_A, edn_rnd_req_o)
958:   `ASSERT_KNOWN(EdnUrndReqOKnown_A, edn_urnd_req_o)
959:   `ASSERT_KNOWN(InsnCntOKnown_A, insn_cnt_o)
960:   `ASSERT_KNOWN(ErrBitsKnown_A, err_bits_o)
961: 
962:   // Keep the EDN requests active until they are acknowledged.
963:   `ASSERT(EdnRndReqStable_A, edn_rnd_req_o & ~edn_rnd_ack_i |=> edn_rnd_req_o)
964:   `ASSERT(EdnUrndReqStable_A, edn_urnd_req_o & ~edn_urnd_ack_i |=> edn_urnd_req_o)
965: 
966:   `ASSERT(OnlyWriteLoadDataBaseWhenDMemValid_A,
967:           rf_bignum_wr_en_ctrl & insn_dec_bignum.rf_wdata_sel == RfWdSelLsu |-> dmem_rvalid_i)
968:   `ASSERT(OnlyWriteLoadDataBignumWhenDMemValid_A,
969:           rf_base_wr_en_ctrl & insn_dec_base.rf_wdata_sel == RfWdSelLsu |-> dmem_rvalid_i)
970: 
971:   // Error handling: if we pass an error signal down to the controller then we should also be
972:   // setting an error flag, unless the signal came from above.
973:   `ASSERT(ErrBitsIfControllerEscalate_A,
974:           (mubi4_test_true_loose(controller_fatal_escalate_en) ||
975:            mubi4_test_true_loose(controller_recov_escalate_en)) &&
976:           mubi4_test_false_strict(escalate_en_i)
977:           |=> err_bits_q)
978: 
979:   // Similarly, if we pass an escalation signal down to the start/stop controller then we should
980:   // also be setting an error flag, unless the signal came from above.
981:   `ASSERT(ErrBitsIfStartStopEscalate_A,
982:           mubi4_test_true_loose(start_stop_escalate_en) && mubi4_test_false_strict(escalate_en_i)
983:           |=> err_bits_q)
984: 
985:   // The following assertions allow up to 4000 cycles from escalation until the start/stop FSM
986:   // locks. This is to allow the core to do a secure wipe (which involves waiting for data from the
987:   // EDN) before it changes status. The long wait here won't mask problems because the logic of "ask
988:   // for URND data" and "do the secure wipe once it arrives" is duplicated in the Python model,
989:   // against which the RTL is checked.
990: 
991:   `ASSERT(OtbnStartStopGlobalEscCntrMeasure_A, err_bits_q && mubi4_test_true_loose(escalate_en_i)
992:           && mubi4_test_true_loose(start_stop_escalate_en)|=> ##[1:4000]
993:           u_otbn_start_stop_control.state_q == otbn_pkg::OtbnStartStopStateLocked)
994: 
995:   `ASSERT(OtbnStartStopLocalEscCntrMeasure_A, err_bits_q && mubi4_test_false_strict(escalate_en_i)
996:           && mubi4_test_true_loose(start_stop_escalate_en) |=>  ##[1:4000]
997:           u_otbn_start_stop_control.state_q == otbn_pkg::OtbnStartStopStateLocked)
998: 
999:   // In contrast to the start/stop FSM, the controller FSM should lock quickly after an escalation,
1000:   // independent of the secure wipe.
1001: 
1002:   `ASSERT(OtbnControllerGlobalEscCntrMeasure_A, err_bits_q && mubi4_test_true_loose(escalate_en_i)
1003:           && mubi4_test_true_loose(controller_fatal_escalate_en)|=> ##[1:100]
1004:           u_otbn_controller.state_q == otbn_pkg::OtbnStateLocked)
1005: 
1006:   `ASSERT(OtbnControllerLocalEscCntrMeasure_A, err_bits_q && mubi4_test_false_strict(escalate_en_i)
1007:           && mubi4_test_true_loose(controller_fatal_escalate_en) |=>  ##[1:100]
1008:           u_otbn_controller.state_q == otbn_pkg::OtbnStateLocked)
1009: 
1010: endmodule

================================== Ai Message ==================================
Tool Calls:
  read_file_with_line_numbers (call_7Pf0r3hlb1b8hZdltfIAckV7)
 Call ID: call_7Pf0r3hlb1b8hZdltfIAckV7
  Args:
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn_controller.sv
================================= Tool Message =================================
Name: read_file_with_line_numbers

1: // Copyright lowRISC contributors (OpenTitan project).
2: // Licensed under the Apache License, Version 2.0, see LICENSE for details.
3: // SPDX-License-Identifier: Apache-2.0
4: 
5: `include "prim_assert.sv"
6: 
7: /**
8:  * OTBN Controller
9:  */
10: module otbn_controller
11:   import otbn_pkg::*;
12: #(
13:   // Size of the instruction memory, in bytes
14:   parameter int ImemSizeByte = 4096,
15:   // Size of the data memory, in bytes
16:   parameter int DmemSizeByte = 4096,
17: 
18:   localparam int ImemAddrWidth = prim_util_pkg::vbits(ImemSizeByte),
19:   localparam int DmemAddrWidth = prim_util_pkg::vbits(DmemSizeByte)
20: ) (
21:   input logic clk_i,
22:   input logic rst_ni,
23: 
24:   input  logic start_i,   // start the processing at address zero
25:   output logic locking_o, // Controller is in or is entering the locked state
26:   input  logic err_bit_clear_i,
27: 
28:   input prim_mubi_pkg::mubi4_t fatal_escalate_en_i,
29:   input prim_mubi_pkg::mubi4_t recov_escalate_en_i,
30:   input prim_mubi_pkg::mubi4_t rma_req_i,
31:   output controller_err_bits_t err_bits_o,
32:   output logic                 recoverable_err_o,
33: 
34:   // Next instruction selection (to instruction fetch)
35:   output logic                     insn_fetch_req_valid_o,
36:   output logic                     insn_fetch_req_valid_raw_o,
37:   output logic [ImemAddrWidth-1:0] insn_fetch_req_addr_o,
38:   output logic                     insn_fetch_resp_clear_o,
39: 
40:   // Fetched/decoded instruction
41:   input logic                     insn_valid_i,
42:   input logic                     insn_illegal_i,
43:   input logic [ImemAddrWidth-1:0] insn_addr_i,
44: 
45:   // Decoded instruction data
46:   input insn_dec_base_t   insn_dec_base_i,
47:   input insn_dec_bignum_t insn_dec_bignum_i,
48:   input insn_dec_shared_t insn_dec_shared_i,
49: 
50:   // Base register file
51:   output logic [4:0]               rf_base_wr_addr_o,
52:   output logic                     rf_base_wr_en_o,
53:   output logic                     rf_base_wr_commit_o,
54:   output logic [31:0]              rf_base_wr_data_no_intg_o,
55:   output logic [BaseIntgWidth-1:0] rf_base_wr_data_intg_o,
56:   output logic                     rf_base_wr_data_intg_sel_o,
57: 
58:   output logic [4:0]               rf_base_rd_addr_a_o,
59:   output logic                     rf_base_rd_en_a_o,
60:   input  logic [BaseIntgWidth-1:0] rf_base_rd_data_a_intg_i,
61:   output logic [4:0]               rf_base_rd_addr_b_o,
62:   output logic                     rf_base_rd_en_b_o,
63:   input  logic [BaseIntgWidth-1:0] rf_base_rd_data_b_intg_i,
64:   output logic                     rf_base_rd_commit_o,
65: 
66:   input logic rf_base_call_stack_sw_err_i,
67:   input logic rf_base_call_stack_hw_err_i,
68: 
69:   // Bignum register file (WDRs)
70:   output logic [4:0]         rf_bignum_wr_addr_o,
71:   output logic [1:0]         rf_bignum_wr_en_o,
72:   output logic               rf_bignum_wr_commit_o,
73:   output logic [WLEN-1:0]    rf_bignum_wr_data_no_intg_o,
74:   output logic [ExtWLEN-1:0] rf_bignum_wr_data_intg_o,
75:   output logic               rf_bignum_wr_data_intg_sel_o,
76: 
77:   output logic [4:0]         rf_bignum_rd_addr_a_o,
78:   output logic               rf_bignum_rd_en_a_o,
79:   input  logic [ExtWLEN-1:0] rf_bignum_rd_data_a_intg_i,
80: 
81:   output logic [4:0]         rf_bignum_rd_addr_b_o,
82:   output logic               rf_bignum_rd_en_b_o,
83:   input  logic [ExtWLEN-1:0] rf_bignum_rd_data_b_intg_i,
84: 
85:   input logic rf_bignum_intg_err_i,
86:   input logic rf_bignum_spurious_we_err_i,
87: 
88:   output logic [NWdr-1:0] rf_bignum_rd_a_indirect_onehot_o,
89:   output logic [NWdr-1:0] rf_bignum_rd_b_indirect_onehot_o,
90:   output logic [NWdr-1:0] rf_bignum_wr_indirect_onehot_o,
91:   output logic            rf_bignum_indirect_en_o,
92: 
93:   // Execution units
94: 
95:   // Base ALU
96:   output alu_base_operation_t  alu_base_operation_o,
97:   output alu_base_comparison_t alu_base_comparison_o,
98:   input  logic [31:0]          alu_base_operation_result_i,
99:   input  logic                 alu_base_comparison_result_i,
100: 
101:   // Bignum ALU
102:   output alu_bignum_operation_t alu_bignum_operation_o,
103:   output logic                  alu_bignum_operation_valid_o,
104:   output logic                  alu_bignum_operation_commit_o,
105:   input  logic [WLEN-1:0]       alu_bignum_operation_result_i,
106:   input  logic                  alu_bignum_selection_flag_i,
107: 
108:   // Bignum MAC
109:   output mac_bignum_operation_t mac_bignum_operation_o,
110:   input  logic [WLEN-1:0]       mac_bignum_operation_result_i,
111:   output logic                  mac_bignum_en_o,
112:   output logic                  mac_bignum_commit_o,
113: 
114:   // LSU
115:   output logic                     lsu_load_req_o,
116:   output logic                     lsu_store_req_o,
117:   output insn_subset_e             lsu_req_subset_o,
118:   output logic [DmemAddrWidth-1:0] lsu_addr_o,
119:   input  logic                     lsu_addr_en_predec_i,
120: 
121:   output logic [BaseIntgWidth-1:0] lsu_base_wdata_o,
122:   output logic [ExtWLEN-1:0]       lsu_bignum_wdata_o,
123: 
124:   input  logic [BaseIntgWidth-1:0] lsu_base_rdata_i,
125:   input  logic [ExtWLEN-1:0]       lsu_bignum_rdata_i,
126: 
127:   // Internal Special-Purpose Registers (ISPRs)
128:   output ispr_e                       ispr_addr_o,
129:   output logic [31:0]                 ispr_base_wdata_o,
130:   output logic [BaseWordsPerWLEN-1:0] ispr_base_wr_en_o,
131:   output logic [ExtWLEN-1:0]          ispr_bignum_wdata_intg_o,
132:   output logic                        ispr_bignum_wr_en_o,
133:   output logic [NFlagGroups-1:0]      ispr_flags_wr_o,
134:   output logic                        ispr_wr_commit_o,
135:   input  logic [ExtWLEN-1:0]          ispr_rdata_intg_i,
136:   output logic                        ispr_rd_en_o,
137: 
138:   // RND interface
139:   output logic rnd_req_o,
140:   output logic rnd_prefetch_req_o,
141:   input  logic rnd_valid_i,
142: 
143:   input  logic urnd_reseed_err_i,
144: 
145:   // Secure Wipe
146:   output logic secure_wipe_req_o,
147:   input  logic secure_wipe_ack_i,
148:   input  logic sec_wipe_zero_i,
149:   input  logic secure_wipe_running_i,
150:   input  logic sec_wipe_err_i,
151: 
152:   input  logic        state_reset_i,
153:   output logic [31:0] insn_cnt_o,
154:   input  logic        insn_cnt_clear_ext_i,
155:   input  logic        insn_cnt_clear_int_i,
156:   output logic        mems_sec_wipe_o,
157: 
158:   input  logic        software_errs_fatal_i,
159: 
160:   input logic [1:0] sideload_key_shares_valid_i,
161: 
162:   // Prefetch stage control
163:   output logic                     prefetch_en_o,
164:   output logic                     prefetch_loop_active_o,
165:   output logic [31:0]              prefetch_loop_iterations_o,
166:   output logic [ImemAddrWidth:0]   prefetch_loop_end_addr_o,
167:   output logic [ImemAddrWidth-1:0] prefetch_loop_jump_addr_o,
168:   output logic                     prefetch_ignore_errs_o,
169: 
170:   // Predecoded control
171:   input  ctrl_flow_predec_t        ctrl_flow_predec_i,
172:   input  logic [ImemAddrWidth-1:0] ctrl_flow_target_predec_i,
173:   output logic                     predec_error_o
174: );
175:   import prim_mubi_pkg::*;
176: 
177:   otbn_state_e state_q, state_d;
178: 
179: 
180:   controller_err_bits_t err_bits_q, err_bits_d;
181: 
182:   // The specific error signals that go into err_bits_d
183:   logic fatal_software_err, bad_internal_state_err, reg_intg_violation_err, key_invalid_err;
184:   logic illegal_insn_err, bad_data_addr_err, call_stack_sw_err, bad_insn_addr_err;
185: 
186:   logic err;
187:   logic internal_err;
188:   logic recoverable_err;
189:   logic software_err;
190:   logic non_insn_addr_software_err;
191:   logic fatal_err;
192:   logic internal_fatal_err;
193:   logic done_complete;
194:   logic executing;
195:   logic state_error, state_error_d, state_error_q;
196:   logic spurious_secure_wipe_ack_q, spurious_secure_wipe_ack_d;
197:   logic sec_wipe_err_q, sec_wipe_err_d;
198:   logic mubi_err_q, mubi_err_d;
199: 
200:   logic                     insn_fetch_req_valid_raw;
201:   logic [ImemAddrWidth-1:0] insn_fetch_req_addr_last;
202: 
203:   logic stall;
204:   logic ispr_stall;
205:   logic mem_stall;
206:   logic rf_indirect_stall;
207:   logic jump_or_branch;
208:   logic branch_taken;
209:   logic insn_executing;
210:   logic ld_insn_with_addr_from_call_stack, st_insn_with_addr_from_call_stack;
211:   logic [ImemAddrWidth-1:0] branch_target;
212:   logic                     branch_target_overflow;
213:   logic [ImemAddrWidth:0]   next_insn_addr_wide;
214:   logic [ImemAddrWidth-1:0] next_insn_addr;
215: 
216:   csr_e                                csr_addr;
217:   logic [$clog2(BaseWordsPerWLEN)-1:0] csr_sub_addr;
218:   logic [31:0]                         csr_rdata_raw;
219:   logic [31:0]                         csr_rdata;
220:   logic [BaseWordsPerWLEN-1:0]         csr_rdata_mux [32];
221:   logic [31:0]                         csr_wdata_raw;
222:   logic [31:0]                         csr_wdata;
223: 
224:   wsr_e                                wsr_addr;
225:   logic [WLEN-1:0]                     wsr_wdata;
226: 
227:   ispr_e                               ispr_addr_base;
228:   logic [$clog2(BaseWordsPerWLEN)-1:0] ispr_word_addr_base;
229:   logic [BaseWordsPerWLEN-1:0]         ispr_word_sel_base;
230: 
231:   ispr_e                               ispr_addr_bignum;
232: 
233:   logic                                ispr_wr_insn, ispr_rd_insn;
234:   logic                                ispr_wr_base_insn;
235:   logic                                ispr_wr_bignum_insn;
236:   logic                                ispr_rd_bignum_insn;
237: 
238:   logic                     lsu_load_req_raw;
239:   logic                     lsu_store_req_raw;
240:   logic [DmemAddrWidth-1:0] lsu_addr, lsu_addr_blanked, lsu_addr_saved_d, lsu_addr_saved_q;
241:   logic                     lsu_addr_saved_sel;
242:   logic                     expected_lsu_addr_en;
243: 
244:   logic                     expected_call_stack_push, expected_call_stack_pop;
245:   logic                     lsu_predec_error, branch_target_predec_error, ctrl_predec_error;
246: 
247:   logic rnd_req_raw;
248: 
249:   // Register read data with integrity stripped off
250:   logic [31:0]     rf_base_rd_data_a_no_intg;
251:   logic [31:0]     rf_base_rd_data_b_no_intg;
252:   logic [WLEN-1:0] rf_bignum_rd_data_a_no_intg;
253:   logic [WLEN-1:0] rf_bignum_rd_data_b_no_intg;
254: 
255:   logic [ExtWLEN-1:0] rf_bignum_rd_data_b_intg_blanked;
256:   logic [ExtWLEN-1:0] selection_result;
257: 
258:   logic [1:0] rf_bignum_wr_en_unbuf;
259:   logic [4:0] rf_bignum_wr_addr_unbuf;
260:   logic [4:0] rf_bignum_rd_addr_a_unbuf;
261:   logic       rf_bignum_rd_en_a_unbuf;
262:   logic [4:0] rf_bignum_rd_addr_b_unbuf;
263:   logic       rf_bignum_rd_en_b_unbuf;
264: 
265:   logic rf_bignum_rd_a_indirect_en;
266:   logic rf_bignum_rd_b_indirect_en;
267:   logic rf_bignum_wr_indirect_en;
268: 
269:   // Computed increments for indirect register index and memory address in BN.LID/BN.SID/BN.MOVR
270:   // instructions.
271:   logic [5:0]  rf_base_rd_data_a_inc;
272:   logic [5:0]  rf_base_rd_data_b_inc;
273:   logic [26:0] rf_base_rd_data_a_wlen_word_inc;
274: 
275:   // Read/Write enables for base register file before illegal instruction encoding are factored in
276:   logic rf_base_rd_en_a_raw, rf_base_rd_en_b_raw, rf_base_wr_en_raw;
277: 
278:   // Output of mux taking the above increments as inputs and choosing one to write back to base
279:   // register file with appropriate zero extension and padding to give a 32-bit result.
280:   logic [31:0]              increment_out;
281: 
282:   // Loop control, used to start a new loop
283:   logic        loop_start_req;
284:   logic        loop_start_commit;
285:   logic        loop_reset;
286:   logic [11:0] loop_bodysize;
287:   logic [31:0] loop_iterations;
288: 
289:   // Loop generated jumps. The loop controller asks to jump when execution reaches the end of a loop
290:   // body that hasn't completed all of its iterations.
291:   logic                     loop_jump;
292:   logic [ImemAddrWidth-1:0] loop_jump_addr;
293: 
294:   logic [WLEN-1:0] mac_bignum_rf_wr_data;
295: 
296:   logic loop_hw_err, loop_predec_err;
297:   logic csr_illegal_addr, wsr_illegal_addr, ispr_illegal_addr;
298:   logic imem_addr_err, loop_sw_err, ispr_err;
299:   logic dmem_addr_err_check, dmem_addr_err;
300:   logic dmem_addr_unaligned_base, dmem_addr_unaligned_bignum, dmem_addr_overflow;
301:   logic illegal_insn_static;
302:   logic key_invalid;
303: 
304:   logic rf_a_indirect_err, rf_b_indirect_err, rf_d_indirect_err, rf_indirect_err;
305: 
306:   // If we are doing an indirect access to the bignum register file, it's possible that the
307:   // address that we use for the access is architecturally unknown. This happens if it came from x1
308:   // and we've underflowed the call stack. When this happens, we want to ignore any read data
309:   // integrity errors and spurious write enable errors since the access to the bignum register file
310:   // didn't happen architecturally anyway.
311:   logic ignore_rf_bignum_intg_errs;
312:   logic rf_bignum_intg_err;
313:   logic ignore_rf_bignum_spurious_we_errs;
314:   logic rf_bignum_spurious_we_err;
315: 
316:   logic ispr_rdata_intg_err;
317: 
318:   logic [31:0] insn_cnt_d, insn_cnt_q;
319:   logic        insn_cnt_clear;
320: 
321:   logic [4:0] insn_bignum_rd_addr_a_q, insn_bignum_rd_addr_b_q, insn_bignum_wr_addr_q;
322: 
323:   logic       start_secure_wipe;
324:   logic       secure_wipe_running_q, secure_wipe_running_d;
325: 
326:   assign secure_wipe_running_d = start_secure_wipe | (secure_wipe_running_q & ~secure_wipe_ack_i);
327: 
328:   always_ff @(posedge clk_i or negedge rst_ni) begin
329:     if (!rst_ni) begin
330:       secure_wipe_running_q <= 1'b0;
331:     end else begin
332:       secure_wipe_running_q <= secure_wipe_running_d;
333:     end
334:   end
335:   assign secure_wipe_req_o = start_secure_wipe | secure_wipe_running_q; 
336: 
337:   // Spot spurious acks on the secure wipe interface. There is a an ack at the end of the initial
338:   // secure wipe, and as `secure_wipe_running_q` is only high during secure wipes triggered by this
339:   // controller, we have to ignore acks before the initial secure wipe is done.  Register this
340:   // signal to break a circular path (a secure wipe can be triggered by a stop, and a spurious
341:   // secure wipe ack can trigger a stop).
342:   always_ff @(posedge clk_i or negedge rst_ni) begin
343:     if (!rst_ni) begin
344:       spurious_secure_wipe_ack_q <= 1'b0;
345:     end else begin
346:       spurious_secure_wipe_ack_q <= spurious_secure_wipe_ack_d;
347:     end
348:   end
349:   assign spurious_secure_wipe_ack_d = spurious_secure_wipe_ack_q |
350:                                       (secure_wipe_ack_i      &
351:                                        ~secure_wipe_running_q &
352:                                        ~secure_wipe_running_i);
353: 
354:   // Detect and latch unexpected secure wipe signals.
355:   always_ff @(posedge clk_i or negedge rst_ni) begin
356:     if (!rst_ni) begin
357:       sec_wipe_err_q <= 1'b0;
358:     end else begin
359:       sec_wipe_err_q <= sec_wipe_err_d;
360:     end
361:   end
362:   assign sec_wipe_err_d = sec_wipe_err_q |
363:                           sec_wipe_err_i |
364:                           (sec_wipe_zero_i & ~secure_wipe_running_i);
365: 
366:   // Stall a cycle on loads to allow load data writeback to happen the following cycle. Stall not
367:   // required on stores as there is no response to deal with.
368:   assign mem_stall = lsu_load_req_raw;
369: 
370:   // Reads to RND must stall until data is available
371:   assign ispr_stall = rnd_req_raw & ~rnd_valid_i;
372: 
373:   assign rf_indirect_stall = insn_valid_i &
374:                              (state_q != OtbnStateStall) &
375:                              (insn_dec_shared_i.subset == InsnSubsetBignum) &
376:                              (insn_dec_bignum_i.rf_a_indirect |
377:                               insn_dec_bignum_i.rf_b_indirect |
378:                               insn_dec_bignum_i.rf_d_indirect);
379: 
380:   assign stall = mem_stall | ispr_stall | rf_indirect_stall;
381: 
382:   // OTBN is done when it was executing something (in state OtbnStateRun or OtbnStateStall)
383:   // and either it executes an ecall or an error occurs. A pulse on the done signal raises the
384:   // 'done' interrupt and also tells the top-level to update its ERR_BITS status
385:   // register. The calculation that ecall triggered done is factored out as `done_complete` to
386:   // avoid logic loops in the error handling logic.
387:   assign done_complete = (insn_valid_i & insn_dec_shared_i.ecall_insn);
388:   assign executing = (state_q == OtbnStateRun) ||
389:                      (state_q == OtbnStateStall);
390: 
391:   // Set the *locking* output when the next state is the *locked* state and no secure wipe is
392:   // running or there is a URND reseed error.  `locking_o` is thus set only after the secure wipe
393:   // has completed or if it cannot complete due to an URND reseed error (in which case
394:   // `secure_wipe_req_o` and `urnd_reseed_err_i` will remain high).  The condition for secure wipe
395:   // running involves `secure_wipe_running_i`, which is high for the initial secure wipe, and
396:   // `secure_wipe_req_o`, which is high for post-execution secure wipes.
397:   assign locking_o = (state_d == OtbnStateLocked) & (~(secure_wipe_running_i | secure_wipe_req_o) |
398:                                                      urnd_reseed_err_i | mubi_err_d);
399: 
400:   assign start_secure_wipe = executing & (done_complete | err);
401: 
402:   assign jump_or_branch = (insn_valid_i &
403:                            (insn_dec_shared_i.branch_insn | insn_dec_shared_i.jump_insn));
404: 
405:   // Branch taken when there is a valid branch instruction and comparison passes or a valid jump
406:   // instruction (which is always taken)
407:   assign branch_taken = insn_valid_i &
408:                         ((insn_dec_shared_i.branch_insn & alu_base_comparison_result_i) |
409:                          insn_dec_shared_i.jump_insn);
410:   // Branch target computed by base ALU (PC + imm)
411:   assign branch_target = alu_base_operation_result_i[ImemAddrWidth-1:0];
412:   assign branch_target_overflow = |alu_base_operation_result_i[31:ImemAddrWidth];
413: 
414:   assign next_insn_addr_wide = {1'b0, insn_addr_i} + 'd4;
415:   assign next_insn_addr = next_insn_addr_wide[ImemAddrWidth-1:0];
416: 
417:   // Record address for fetch request so it can be retried when an invalid response is received
418:   always_ff @(posedge clk_i) begin
419:     if (insn_fetch_req_valid_raw) begin
420:       insn_fetch_req_addr_last <= insn_fetch_req_addr_o;
421:     end
422:   end
423: 
424:   always_comb begin
425:     state_d                  = state_q;
426:     // `insn_fetch_req_valid_raw` is the value `insn_fetch_req_valid_o` before any errors are
427:     // considered.
428:     insn_fetch_req_valid_raw = 1'b0;
429:     insn_fetch_req_addr_o    = '0;
430:     insn_fetch_resp_clear_o  = 1'b1;
431:     prefetch_en_o            = 1'b0;
432: 
433:     state_error = 1'b0;
434: 
435:     unique case (state_q)
436:       OtbnStateHalt: begin
437:         if (start_i) begin
438:           state_d = OtbnStateRun;
439: 
440:           insn_fetch_req_addr_o    = '0;
441:           insn_fetch_req_valid_raw = 1'b1;
442:           prefetch_en_o            = 1'b1;
443:         end
444:       end
445:       OtbnStateRun: begin
446:         insn_fetch_req_valid_raw = 1'b1;
447:         prefetch_en_o            = 1'b1;
448: 
449:         if (!insn_valid_i) begin
450:           insn_fetch_req_addr_o = insn_fetch_req_addr_last;
451:         end else if (done_complete) begin
452:           state_d                  = OtbnStateHalt;
453:           insn_fetch_req_valid_raw = 1'b0;
454:           prefetch_en_o            = 1'b0;
455:         end else begin
456:           if (stall) begin
457:             // When stalling don't request a new fetch and don't clear response either to keep
458:             // current instruction.
459:             state_d                  = OtbnStateStall;
460:             insn_fetch_req_valid_raw = 1'b0;
461:             insn_fetch_resp_clear_o  = 1'b0;
462:           end else begin
463:             if (branch_taken) begin
464:               insn_fetch_req_addr_o = branch_target;
465:             end else if (loop_jump) begin
466:               insn_fetch_req_addr_o = loop_jump_addr;
467:             end else begin
468:               insn_fetch_req_addr_o = next_insn_addr;
469:             end
470:           end
471:         end
472:       end
473:       OtbnStateStall: begin
474:         prefetch_en_o = 1'b1;
475:         // When stalling refetch the same instruction to keep decode inputs constant
476:         if (stall) begin
477:           state_d                  = OtbnStateStall;
478:           //insn_fetch_req_addr_o = insn_addr_i;
479:           insn_fetch_req_valid_raw = 1'b0;
480:           insn_fetch_resp_clear_o  = 1'b0;
481:         end else begin
482:           insn_fetch_req_valid_raw = 1'b1;
483: 
484:           if (loop_jump) begin
485:             insn_fetch_req_addr_o = loop_jump_addr;
486:           end else begin
487:             insn_fetch_req_addr_o = next_insn_addr;
488:           end
489: 
490:           state_d = OtbnStateRun;
491:         end
492:       end
493:       OtbnStateLocked: begin
494:         insn_fetch_req_valid_raw = 1'b0;
495:         state_d                  = OtbnStateLocked;
496:       end
497:       default: begin
498:         // We should never get here. If we do (e.g. via a malicious glitch), error out immediately.
499:         // SEC_CM: CONTROLLER.FSM.LOCAL_ESC
500:         state_d = OtbnStateLocked;
501:         state_error = 1'b1;
502:       end
503:     endcase
504: 
505:     // On any error immediately halt, either going to OtbnStateLocked or OtbnStateHalt depending on
506:     // whether it was a fatal error.
507:     if (err) begin
508:       insn_fetch_resp_clear_o = 1'b1;
509: 
510:       if (fatal_err) begin
511:         // SEC_CM: CONTROLLER.FSM.GLOBAL_ESC
512:         state_d = OtbnStateLocked;
513:       end else begin
514:         state_d = OtbnStateHalt;
515:       end
516:     end
517: 
518:     // Regardless of what happens above enforce staying in OtnbStateLocked.
519:     if (state_q == OtbnStateLocked) begin
520:       state_d = OtbnStateLocked;
521:     end
522:   end
523: 
524:   assign state_error_d = state_error | state_error_q;
525: 
526:   prim_flop #(
527:     .Width(1),
528:     .ResetValue('0)
529:   ) u_state_error_flop (
530:     .clk_i,
531:     .rst_ni,
532: 
533:     .d_i(state_error_d),
534:     .q_o(state_error_q)
535:   );
536: 
537:   `ASSERT(InsnAlwaysValidInStall, state_q == OtbnStateStall |-> insn_valid_i)
538: 
539:   // Anything that moves us or keeps us in the stall state should cause `stall` to be asserted
540:   `ASSERT(StallIfNextStateStall, insn_valid_i & (state_d == OtbnStateStall) |-> stall)
541: 
542:   // The raw signal is needed by the instruction fetch stage for generating instruction address
543:   // errors (where instruction fetch and prefetch disagree on address). `err` will factor this in so
544:   // using the qualified signal results in a combinational loop.
545:   assign insn_fetch_req_valid_raw_o = insn_fetch_req_valid_raw;
546:   assign insn_fetch_req_valid_o     = err ? 1'b0 : insn_fetch_req_valid_raw;
547: 
548:   // Determine if there are any errors related to the Imem fetch address.
549:   always_comb begin
550:     imem_addr_err = 1'b0;
551: 
552:     if (insn_fetch_req_valid_raw) begin
553:       if (|insn_fetch_req_addr_o[1:0]) begin
554:         // Imem address is unaligned
555:         imem_addr_err = 1'b1;
556:       end else if (branch_taken) begin
557:         imem_addr_err = branch_target_overflow;
558:       end else begin
559:         imem_addr_err = next_insn_addr_wide[ImemAddrWidth] & insn_valid_i;
560:       end
561:     end
562:   end
563: 
564:   // Signal error if MuBi input signals take on invalid values as this means something bad is
565:   // happening. Register the error signal to break circular paths (instruction fetch errors factor
566:   // into fatal_escalate_en_i, RND errors factor into recov_escalate_en_i).
567:   assign mubi_err_d = |{mubi4_test_invalid(fatal_escalate_en_i),
568:                         mubi4_test_invalid(recov_escalate_en_i),
569:                         mubi_err_q};
570:   always_ff @(posedge clk_i or negedge rst_ni) begin
571:     if (!rst_ni) begin
572:       mubi_err_q <= 1'b0;
573:     end else begin
574:       mubi_err_q <= mubi_err_d;
575:     end
576:   end
577: 
578:   // Instruction is illegal based on the static properties of the instruction bits (illegal encoding
579:   // or illegal WSR/CSR referenced).
580:   assign illegal_insn_static = insn_illegal_i | ispr_err;
581: 
582:   assign fatal_software_err       = software_err & software_errs_fatal_i;
583:   assign bad_internal_state_err   = |{state_error_d, loop_hw_err, rf_base_call_stack_hw_err_i,
584:                                       rf_bignum_spurious_we_err, spurious_secure_wipe_ack_q,
585:                                       sec_wipe_err_q, mubi_err_q};
586:   assign reg_intg_violation_err   = rf_bignum_intg_err | ispr_rdata_intg_err;
587:   assign key_invalid_err          = ispr_rd_bignum_insn & insn_valid_i & key_invalid;
588:   assign illegal_insn_err         = illegal_insn_static | rf_indirect_err;
589:   assign call_stack_sw_err        = rf_base_call_stack_sw_err_i;
590: 
591:   // Flag a bad data address error if the data memory address is invalid and it does not come from
592:   // an empty call stack.  The second case cannot be decided as bad data address because the address
593:   // on top of the empty call stack may or may not be valid.  (Also, in most RTL simulators an empty
594:   // call stack that has never been pushed contains an unknown value, so this error bit would become
595:   // unknown.)  Thus, a data memory address coming from an empty call stack raises a call stack
596:   // error but never a bad data address error.
597:   assign bad_data_addr_err = dmem_addr_err &
598:                              ~(call_stack_sw_err &
599:                                (ld_insn_with_addr_from_call_stack |
600:                                 st_insn_with_addr_from_call_stack));
601: 
602:   // Identify load instructions that take the memory address from the call stack.
603:   assign ld_insn_with_addr_from_call_stack = insn_valid_i               &
604:                                              insn_dec_shared_i.ld_insn  &
605:                                              insn_dec_base_i.rf_ren_a   &
606:                                              (insn_dec_base_i.a == 5'd1);
607: 
608:   // Identify store instructions that take the memory address from the call stack.
609:   assign st_insn_with_addr_from_call_stack = insn_valid_i               &
610:                                              insn_dec_shared_i.st_insn  &
611:                                              insn_dec_base_i.rf_ren_a   &
612:                                              (insn_dec_base_i.a == 5'd1);
613: 
614:   // All software errors that aren't bad_insn_addr. Factored into bad_insn_addr so it is only raised
615:   // if other software errors haven't ocurred. As bad_insn_addr relates to the next instruction
616:   // begin fetched it cannot occur if the current instruction has seen an error and failed to
617:   // execute.
618:   assign non_insn_addr_software_err = |{key_invalid_err,
619:                                         loop_sw_err,
620:                                         illegal_insn_err,
621:                                         call_stack_sw_err,
622:                                         bad_data_addr_err};
623: 
624:   assign bad_insn_addr_err = imem_addr_err & ~non_insn_addr_software_err;
625: 
626:   assign err_bits_d = '{
627:     fatal_software:     fatal_software_err,
628:     bad_internal_state: bad_internal_state_err,
629:     reg_intg_violation: reg_intg_violation_err,
630:     key_invalid:        key_invalid_err,
631:     loop:               loop_sw_err,
632:     illegal_insn:       illegal_insn_err,
633:     call_stack:         call_stack_sw_err,
634:     bad_data_addr:      bad_data_addr_err,
635:     bad_insn_addr:      bad_insn_addr_err
636:   };
637: 
638:   always_ff @(posedge clk_i or negedge rst_ni) begin
639:     if (!rst_ni) begin
640:       err_bits_q <= '0;
641:     end else begin
642:       if (err_bit_clear_i && !locking_o) begin
643:         err_bits_q <= '0;
644:       end else begin
645:         err_bits_q <= err_bits_q | err_bits_d;
646:       end
647:     end
648:   end
649:   assign err_bits_o = err_bits_q;
650: 
651:   assign software_err = non_insn_addr_software_err | bad_insn_addr_err;
652: 
653:   assign recoverable_err = mubi4_test_true_loose(recov_escalate_en_i);
654: 
655:   assign internal_fatal_err = |{fatal_software_err,
656:                                 bad_internal_state_err,
657:                                 reg_intg_violation_err};
658: 
659:   // In case of an RMA request, just lock up the controller. This triggers the rotation of the
660:   // scrambling keys. The start/stop controller takes care of initiating the internal secure wipe
661:   // and eventually acknowledging the RMA request.
662:   assign fatal_err = |{internal_fatal_err,
663:                        mubi4_test_true_loose(fatal_escalate_en_i),
664:                        mubi4_test_true_strict(rma_req_i)};
665: 
666:   assign recoverable_err_o = recoverable_err | (software_err & ~software_errs_fatal_i);
667:   assign mems_sec_wipe_o   = (state_d == OtbnStateLocked) & (state_q != OtbnStateLocked);
668: 
669:   assign internal_err = software_err | internal_fatal_err;
670:   assign err          = software_err | recoverable_err | fatal_err;
671: 
672:   assign prefetch_ignore_errs_o = internal_err;
673: 
674:   // Instructions must not execute if there is an error
675:   assign insn_executing = insn_valid_i & ~err;
676: 
677:   `ASSERT(ErrBitSetOnErr,
678:       err & (mubi4_test_false_strict(fatal_escalate_en_i) &
679:              mubi4_test_false_strict(recov_escalate_en_i) &
680:              mubi4_test_false_loose(rma_req_i)) |=>
681:           err_bits_o)
682:   `ASSERT(ErrSetOnFatalErr, fatal_err |-> err)
683:   `ASSERT(SoftwareErrIfNonInsnAddrSoftwareErr, non_insn_addr_software_err |-> software_err)
684: 
685:   `ASSERT(ControllerStateValid,
686:           state_q inside {OtbnStateHalt, OtbnStateRun, OtbnStateStall, OtbnStateLocked})
687:   // Branch only takes effect in OtbnStateRun so must not go into stall state for branch
688:   // instructions.
689:   `ASSERT(NoStallOnBranch,
690:       insn_valid_i & insn_dec_shared_i.branch_insn |-> state_q != OtbnStateStall)
691: 
692:   // SEC_CM: CONTROLLER.FSM.SPARSE
693:   `PRIM_FLOP_SPARSE_FSM(u_state_regs, state_d, state_q, otbn_state_e, OtbnStateHalt)
694: 
695:   // SEC_CM: CTRL_FLOW.COUNT
696:   // Two explicit clear controls, one comes from external to otbn_core and the other is generated
697:   // internally (by otbn_start_stop_control).
698:   assign insn_cnt_clear =
699:     (state_q == OtbnStateLocked) | insn_cnt_clear_ext_i | insn_cnt_clear_int_i;
700: 
701:   always_comb begin
702:     if (insn_cnt_clear) begin
703:       insn_cnt_d = 32'd0;
704:     end else if (insn_executing & ~stall & (insn_cnt_q != 32'hffffffff)) begin
705:       insn_cnt_d = insn_cnt_q + 32'd1;
706:     end else begin
707:       insn_cnt_d = insn_cnt_q;
708:     end
709:   end
710: 
711:   always_ff @(posedge clk_i or negedge rst_ni) begin
712:     if (!rst_ni) begin
713:       insn_cnt_q <= 32'd0;
714:     end else begin
715:       insn_cnt_q <= insn_cnt_d;
716:     end
717:   end
718: 
719:   assign insn_cnt_o = insn_cnt_q;
720: 
721:   assign loop_reset = state_reset_i | sec_wipe_zero_i;
722: 
723:   otbn_loop_controller #(
724:     .ImemAddrWidth(ImemAddrWidth)
725:   ) u_otbn_loop_controller (
726:     .clk_i,
727:     .rst_ni,
728: 
729:     .state_reset_i(loop_reset),
730: 
731:     .insn_valid_i,
732:     .insn_addr_i,
733:     .next_insn_addr_i(next_insn_addr),
734: 
735:     .loop_start_req_i       (loop_start_req),
736:     .loop_start_commit_i    (loop_start_commit),
737:     .loop_bodysize_i        (loop_bodysize),
738:     .loop_iterations_i      (loop_iterations),
739:     .loop_end_addr_predec_i (ctrl_flow_target_predec_i),
740: 
741:     .loop_jump_o     (loop_jump),
742:     .loop_jump_addr_o(loop_jump_addr),
743: 
744:     .sw_err_o     (loop_sw_err),
745:     .hw_err_o     (loop_hw_err),
746:     .predec_err_o (loop_predec_err),
747: 
748:     .jump_or_branch_i(jump_or_branch),
749:     .otbn_stall_i    (stall),
750: 
751:     .prefetch_loop_active_o,
752:     .prefetch_loop_iterations_o,
753:     .prefetch_loop_end_addr_o,
754:     .prefetch_loop_jump_addr_o
755:   );
756: 
757:   // loop_start_req indicates the instruction wishes to start a loop, loop_start_commit confirms it
758:   // should occur.
759:   assign loop_start_req    = insn_valid_i & insn_dec_shared_i.loop_insn;
760:   assign loop_start_commit = insn_executing;
761:   assign loop_bodysize     = insn_dec_base_i.loop_bodysize;
762:   assign loop_iterations   = insn_dec_base_i.loop_immediate ? insn_dec_base_i.i :
763:                                                               rf_base_rd_data_a_no_intg;
764: 
765:   // Compute increments which can be optionally applied to indirect register accesses and memory
766:   // addresses in BN.LID/BN.SID/BN.MOVR instructions.
767:   assign rf_base_rd_data_a_inc           = rf_base_rd_data_a_no_intg[4:0] + 1'b1;
768:   assign rf_base_rd_data_b_inc           = rf_base_rd_data_b_no_intg[4:0] + 1'b1;
769:   // We can avoid a full 32-bit adder here because the offset is 32-bit aligned, so we know the
770:   // load/store address will only be valid if rf_base_rd_data_a_no_intg[4:0] is zero.
771:   assign rf_base_rd_data_a_wlen_word_inc = rf_base_rd_data_a_no_intg[31:5] + 27'h1;
772: 
773:   // Choose increment to write back to base register file, only one increment can be written as
774:   // there is only one write port. Note that where an instruction is incrementing the indirect
775:   // reference to its destination register (insn_dec_bignum_i.d_inc) that reference is read on the
776:   // B read port so the B increment is written back.
777:   always_comb begin
778:     unique case (1'b1)
779:       insn_dec_bignum_i.a_inc: begin
780:         increment_out = {26'b0, rf_base_rd_data_a_inc};
781:       end
782:       insn_dec_bignum_i.b_inc: begin
783:         increment_out = {26'b0, rf_base_rd_data_b_inc};
784:       end
785:       insn_dec_bignum_i.d_inc: begin
786:         increment_out = {26'b0, rf_base_rd_data_b_inc};
787:       end
788:       insn_dec_bignum_i.a_wlen_word_inc: begin
789:         increment_out = {rf_base_rd_data_a_wlen_word_inc, 5'b0};
790:       end
791:       default: begin
792:         // Whenever increment_out is written back to the register file, exactly one of the
793:         // increment selector signals is high. To prevent the automatic inference of latches in
794:         // case nothing is written back (rf_wdata_sel != RfWdSelIncr) and to save logic, we choose
795:         // a valid output as default.
796:         increment_out = {26'b0, rf_base_rd_data_a_inc};
797:       end
798:     endcase
799:   end
800: 
801:   // Base RF read/write address, enable and commit control
802:   always_comb begin
803:     rf_base_rd_addr_a_o = insn_dec_base_i.a;
804:     rf_base_rd_addr_b_o = insn_dec_base_i.b;
805:     rf_base_wr_addr_o   = insn_dec_base_i.d;
806: 
807:     // Only commit read or write if the instruction is executing (in particular a read commit pops
808:     // the call stack so must not occur where a valid instruction sees an error and doesn't
809:     // execute).
810:     rf_base_rd_commit_o = insn_executing;
811:     rf_base_wr_commit_o = insn_executing;
812: 
813:     rf_base_rd_en_a_raw = 1'b0;
814:     rf_base_rd_en_b_raw = 1'b0;
815:     rf_base_wr_en_raw   = 1'b0;
816: 
817:     if (insn_valid_i) begin
818:       if (insn_dec_shared_i.st_insn) begin
819:         // For stores, both base reads happen in the first cycle of the store instruction. For base
820:         // stores this is the same cycle as the request. For bignum stores this is the cycle before
821:         // the request (as the indirect register read to get the store data occurs the following
822:         // cycle).
823:         rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a &
824:           (rf_indirect_stall | (insn_dec_shared_i.subset == InsnSubsetBase));
825:         rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b &
826:           (rf_indirect_stall | (insn_dec_shared_i.subset == InsnSubsetBase));
827: 
828:         // Bignum stores can update the base register file where an increment is used.
829:         rf_base_wr_en_raw   = (insn_dec_shared_i.subset == InsnSubsetBignum) &
830:                               insn_dec_base_i.rf_we                          &
831:                               rf_indirect_stall;
832:       end else if (insn_dec_shared_i.ld_insn) begin
833:         // For loads, both base reads happen in the same cycle as the request. The address is
834:         // required for the request and the indirect destination register (only used for Bignum
835:         // loads) is flopped in ld_insn_bignum_wr_addr_q to correctly deal with the case where it's
836:         // updated by an increment.
837:         rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & lsu_load_req_raw;
838:         rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & lsu_load_req_raw;
839: 
840:         if (insn_dec_shared_i.subset == InsnSubsetBignum) begin
841:           // Bignum loads can update the base register file where an increment is used. This must
842:           // always happen in the same cycle as the request as this is where both registers are
843:           // read.
844:           rf_base_wr_en_raw = insn_dec_base_i.rf_we & lsu_load_req_raw & rf_indirect_stall;
845:         end else begin
846:           // For Base loads write the base register file when the instruction is unstalled (meaning
847:           // the load data is available).
848:           rf_base_wr_en_raw = insn_dec_base_i.rf_we & ~stall;
849:         end
850:       end else if (insn_dec_bignum_i.rf_wdata_sel == RfWdSelMovSel) begin
851:         // For MOVR base register reads occur in the first cycle of the instruction. The indirect
852:         // register read for the bignum data occurs in the following cycle.
853:         rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & rf_indirect_stall;
854:         rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & rf_indirect_stall;
855:         rf_base_wr_en_raw   = insn_dec_base_i.rf_we    & rf_indirect_stall;
856:       end else begin
857:         // For all other instructions the read and write happen when the instruction is unstalled.
858:         rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & ~stall;
859:         rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & ~stall;
860:         rf_base_wr_en_raw   = insn_dec_base_i.rf_we    & ~stall;
861:       end
862:     end
863: 
864:     if (insn_dec_shared_i.subset == InsnSubsetBignum) begin
865:       unique case (1'b1)
866:         insn_dec_bignum_i.a_inc,
867:         insn_dec_bignum_i.a_wlen_word_inc: begin
868:           rf_base_wr_addr_o = insn_dec_base_i.a;
869:         end
870: 
871:         insn_dec_bignum_i.b_inc,
872:         insn_dec_bignum_i.d_inc: begin
873:           rf_base_wr_addr_o = insn_dec_base_i.b;
874:         end
875:         default: ;
876:       endcase
877:     end
878: 
879:     rf_base_rd_en_a_o = rf_base_rd_en_a_raw & ~illegal_insn_static;
880:     rf_base_rd_en_b_o = rf_base_rd_en_b_raw & ~illegal_insn_static;
881:     rf_base_wr_en_o   = rf_base_wr_en_raw   & ~illegal_insn_static;
882:   end
883: 
884:   // Base ALU Operand A MUX
885:   always_comb begin
886:     unique case (insn_dec_base_i.op_a_sel)
887:       OpASelRegister: alu_base_operation_o.operand_a = rf_base_rd_data_a_no_intg;
888:       OpASelZero:     alu_base_operation_o.operand_a = '0;
889:       OpASelCurrPc:   alu_base_operation_o.operand_a = {{(32 - ImemAddrWidth){1'b0}}, insn_addr_i};
890:       default:        alu_base_operation_o.operand_a = rf_base_rd_data_a_no_intg;
891:     endcase
892:   end
893: 
894:   // Base ALU Operand B MUX
895:   always_comb begin
896:     unique case (insn_dec_base_i.op_b_sel)
897:       OpBSelRegister:  alu_base_operation_o.operand_b = rf_base_rd_data_b_no_intg;
898:       OpBSelImmediate: alu_base_operation_o.operand_b = insn_dec_base_i.i;
899:       default:         alu_base_operation_o.operand_b = rf_base_rd_data_b_no_intg;
900:     endcase
901:   end
902: 
903:   assign alu_base_operation_o.op = insn_dec_base_i.alu_op;
904: 
905:   assign alu_base_comparison_o.operand_a = rf_base_rd_data_a_no_intg;
906:   assign alu_base_comparison_o.operand_b = rf_base_rd_data_b_no_intg;
907:   assign alu_base_comparison_o.op = insn_dec_base_i.comparison_op;
908: 
909:   assign rf_base_rd_data_a_no_intg = rf_base_rd_data_a_intg_i[31:0];
910:   assign rf_base_rd_data_b_no_intg = rf_base_rd_data_b_intg_i[31:0];
911: 
912:   logic unused_rf_base_rd_a_intg_bits;
913: 
914:   // TODO(#18266): Implement GPR to ISPR end to end integrity path (ISPR writes from GPR take data
915:   // from base RF port A)
916:   assign unused_rf_base_rd_a_intg_bits = |rf_base_rd_data_a_intg_i[38:32];
917: 
918:   // Base register file write MUX. Depending on the data source, integrity bits do or don't have to
919:   // be appended:
920:   // - Data sources that require appending integrity bits go into `rf_base_wr_data_no_intg_o` and
921:   //   `rf_base_wr_data_intg_sel_o` is low.
922:   // - Data sources that already come with integrity bits go into `rf_base_wr_data_intg_o` and
923:   //   `rf_base_wr_data_intg_sel_o` is high.
924:   always_comb begin
925:     // Default values
926:     rf_base_wr_data_no_intg_o  = alu_base_operation_result_i;
927:     rf_base_wr_data_intg_o     = '0;
928:     rf_base_wr_data_intg_sel_o = 1'b0;
929: 
930:     unique case (insn_dec_base_i.rf_wdata_sel)
931:       RfWdSelEx: begin
932:         rf_base_wr_data_no_intg_o  = alu_base_operation_result_i;
933:       end
934:       RfWdSelNextPc: begin
935:         rf_base_wr_data_no_intg_o  = {{(32-(ImemAddrWidth+1)){1'b0}}, next_insn_addr_wide};
936:       end
937:       RfWdSelIspr: begin
938:         rf_base_wr_data_no_intg_o  = csr_rdata;
939:       end
940:       RfWdSelIncr: begin
941:         rf_base_wr_data_no_intg_o  = increment_out;
942:       end
943:       RfWdSelLsu: begin
944:         rf_base_wr_data_intg_sel_o = 1'b1;
945:         rf_base_wr_data_intg_o     = lsu_base_rdata_i;
946:       end
947:       default: ;
948:     endcase
949:   end
950: 
951:   for (genvar i = 0; i < BaseWordsPerWLEN; ++i) begin : g_rf_bignum_rd_data
952:     assign rf_bignum_rd_data_a_no_intg[i*32+:32] = rf_bignum_rd_data_a_intg_i[i*39+:32];
953:     assign rf_bignum_rd_data_b_no_intg[i*32+:32] = rf_bignum_rd_data_b_intg_i[i*39+:32];
954:   end
955: 
956:   // Bignum RF control signals from the controller aren't actually used, instead the predecoded
957:   // one-hot versions are. The predecoded versions get checked against the signals produced here.
958:   // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
959:   // always be identical).
960:   assign rf_bignum_rd_addr_a_unbuf = insn_dec_bignum_i.rf_a_indirect ? insn_bignum_rd_addr_a_q :
961:                                                                        insn_dec_bignum_i.a;
962: 
963:   prim_buf #(
964:     .Width(WdrAw)
965:   ) u_rf_bignum_rd_addr_a_buf (
966:     .in_i (rf_bignum_rd_addr_a_unbuf),
967:     .out_o(rf_bignum_rd_addr_a_o)
968:   );
969: 
970:   assign rf_bignum_rd_en_a_unbuf = insn_dec_bignum_i.rf_ren_a & insn_valid_i & ~stall;
971: 
972:   prim_buf #(
973:     .Width(1)
974:   ) u_rf_bignum_rd_en_a_buf (
975:     .in_i (rf_bignum_rd_en_a_unbuf),
976:     .out_o(rf_bignum_rd_en_a_o)
977:   );
978: 
979:   assign rf_bignum_rd_addr_b_unbuf = insn_dec_bignum_i.rf_b_indirect ? insn_bignum_rd_addr_b_q :
980:                                                                        insn_dec_bignum_i.b;
981: 
982:   prim_buf #(
983:     .Width(WdrAw)
984:   ) u_rf_bignum_rd_addr_b_buf (
985:     .in_i (rf_bignum_rd_addr_b_unbuf),
986:     .out_o(rf_bignum_rd_addr_b_o)
987:   );
988: 
989:   assign rf_bignum_rd_en_b_unbuf = insn_dec_bignum_i.rf_ren_b & insn_valid_i & ~stall;
990: 
991:   prim_buf #(
992:     .Width(1)
993:   ) u_rf_bignum_rd_en_b_buf (
994:     .in_i (rf_bignum_rd_en_b_unbuf),
995:     .out_o(rf_bignum_rd_en_b_o)
996:   );
997: 
998:   assign alu_bignum_operation_o.operand_a = rf_bignum_rd_data_a_no_intg;
999: 
1000:   // Base ALU Operand B MUX
1001:   always_comb begin
1002:     unique case (insn_dec_bignum_i.alu_op_b_sel)
1003:       OpBSelRegister:  alu_bignum_operation_o.operand_b = rf_bignum_rd_data_b_no_intg;
1004:       OpBSelImmediate: alu_bignum_operation_o.operand_b = insn_dec_bignum_i.i;
1005:       default:         alu_bignum_operation_o.operand_b = rf_bignum_rd_data_b_no_intg;
1006:     endcase
1007:   end
1008: 
1009:   assign alu_bignum_operation_o.op          = insn_dec_bignum_i.alu_op;
1010:   assign alu_bignum_operation_o.shift_right = insn_dec_bignum_i.alu_shift_right;
1011:   assign alu_bignum_operation_o.shift_amt   = insn_dec_bignum_i.alu_shift_amt;
1012:   assign alu_bignum_operation_o.flag_group  = insn_dec_bignum_i.alu_flag_group;
1013:   assign alu_bignum_operation_o.sel_flag    = insn_dec_bignum_i.alu_sel_flag;
1014:   assign alu_bignum_operation_o.alu_flag_en = insn_dec_bignum_i.alu_flag_en & insn_valid_i;
1015:   assign alu_bignum_operation_o.mac_flag_en = insn_dec_bignum_i.mac_flag_en & insn_valid_i;
1016: 
1017:   assign alu_bignum_operation_valid_o  = insn_valid_i;
1018:   assign alu_bignum_operation_commit_o = insn_executing;
1019: 
1020:   assign mac_bignum_operation_o.operand_a         = rf_bignum_rd_data_a_no_intg;
1021:   assign mac_bignum_operation_o.operand_b         = rf_bignum_rd_data_b_no_intg;
1022:   assign mac_bignum_operation_o.operand_a_qw_sel  = insn_dec_bignum_i.mac_op_a_qw_sel;
1023:   assign mac_bignum_operation_o.operand_b_qw_sel  = insn_dec_bignum_i.mac_op_b_qw_sel;
1024:   assign mac_bignum_operation_o.wr_hw_sel_upper   = insn_dec_bignum_i.mac_wr_hw_sel_upper;
1025:   assign mac_bignum_operation_o.pre_acc_shift_imm = insn_dec_bignum_i.mac_pre_acc_shift;
1026:   assign mac_bignum_operation_o.zero_acc          = insn_dec_bignum_i.mac_zero_acc;
1027:   assign mac_bignum_operation_o.shift_acc         = insn_dec_bignum_i.mac_shift_out;
1028: 
1029:   assign mac_bignum_en_o     = insn_valid_i & insn_dec_bignum_i.mac_en;
1030:   assign mac_bignum_commit_o = insn_executing;
1031: 
1032:   // Move / Conditional Select. Only select B register data when a selection instruction is being
1033:   // executed and the selection flag isn't set. To avoid undesirable SCA leakage between the two
1034:   // registers for non-selection instructions, the B register is blanked except for selection
1035:   // instructions.
1036:   // Note that blanking both registers is not feasible nor absolutely required because:
1037:   // - The flag group selection and flag selection are known in the predecoder stage but the actual
1038:   //   flag isn't.
1039:   // - Selecting the flag in the predocder stage using combinatorial inputs may lead to SCA leakage
1040:   //   between the still combinatorial flag groups and flags within a group which might be
1041:   //   undesirable as well.
1042:   // - When executing a selection instruction, programmers can expected that there will be some SCA
1043:   //   leakage between the two options. But it may be much lesse expected for such leakage to occur
1044:   //   for other instructions.
1045:   `ASSERT(SelFlagValid, insn_valid_i & insn_dec_bignum_i.sel_insn |->
1046:     insn_dec_bignum_i.alu_sel_flag inside {FlagC, FlagL, FlagM, FlagZ})
1047: 
1048:   // SEC_CM: DATA_REG_SW.SCA
1049:   prim_blanker #(.Width(ExtWLEN)) u_rf_bignum_rd_data_b_intg_blanker (
1050:     .in_i (rf_bignum_rd_data_b_intg_i),
1051:     .en_i (ctrl_flow_predec_i.sel_insn),
1052:     .out_o(rf_bignum_rd_data_b_intg_blanked)
1053:   );
1054: 
1055:   `ASSERT(BlankingBignumRdDataBSel,
1056:     ~(insn_valid_i & insn_dec_bignum_i.sel_insn) |-> rf_bignum_rd_data_b_intg_blanked == '0,
1057:     clk_i, !rst_ni || ctrl_predec_error || !insn_executing)
1058: 
1059:   assign selection_result =
1060:     ~ctrl_flow_predec_i.sel_insn | alu_bignum_selection_flag_i ? rf_bignum_rd_data_a_intg_i :
1061:                                                                  rf_bignum_rd_data_b_intg_blanked;
1062: 
1063:   // Bignum Register file write control
1064: 
1065:   always_comb begin
1066:     // By default write nothing
1067:     rf_bignum_wr_en_unbuf = 2'b00;
1068: 
1069:     // Only write if valid instruction wants a bignum rf write and it isn't stalled. If instruction
1070:     // doesn't execute (e.g. due to an error) the write won't commit.
1071:     if (insn_valid_i && insn_dec_bignum_i.rf_we && !rf_indirect_stall) begin
1072:       if (insn_dec_bignum_i.mac_en && insn_dec_bignum_i.mac_shift_out) begin
1073:         // Special handling for BN.MULQACC.SO, only enable upper or lower half depending on
1074:         // mac_wr_hw_sel_upper.
1075:         rf_bignum_wr_en_unbuf = insn_dec_bignum_i.mac_wr_hw_sel_upper ? 2'b10 : 2'b01;
1076:       end else begin
1077:         // For everything else write both halves immediately.
1078:         rf_bignum_wr_en_unbuf = 2'b11;
1079:       end
1080:     end
1081:   end
1082: 
1083:   // Bignum RF control signals from the controller aren't actually used, instead the predecoded
1084:   // one-hot versions are. The predecoded versions get checked against the signals produced here.
1085:   // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
1086:   // always be identical).
1087:   prim_buf #(
1088:     .Width(2)
1089:   ) u_bignum_wr_en_buf (
1090:     .in_i (rf_bignum_wr_en_unbuf),
1091:     .out_o(rf_bignum_wr_en_o)
1092:   );
1093: 
1094: 
1095:   assign rf_bignum_wr_commit_o = |rf_bignum_wr_en_o & insn_executing & !stall;
1096: 
1097:   assign rf_bignum_indirect_en_o    = insn_executing & rf_indirect_stall;
1098:   assign rf_bignum_rd_a_indirect_en = insn_executing & insn_dec_bignum_i.rf_a_indirect;
1099:   assign rf_bignum_rd_b_indirect_en = insn_executing & insn_dec_bignum_i.rf_b_indirect;
1100:   assign rf_bignum_wr_indirect_en   = insn_executing & insn_dec_bignum_i.rf_d_indirect;
1101: 
1102:   prim_onehot_enc #(
1103:     .OneHotWidth(NWdr)
1104:   ) rf_bignum_rd_a_idirect_onehot__enc (
1105:     .in_i  (rf_base_rd_data_a_no_intg[4:0]),
1106:     .en_i  (rf_bignum_rd_a_indirect_en),
1107:     .out_o (rf_bignum_rd_a_indirect_onehot_o)
1108:   );
1109: 
1110:   prim_onehot_enc #(
1111:     .OneHotWidth(NWdr)
1112:   ) rf_bignum_rd_b_indirect_onehot_enc (
1113:     .in_i  (rf_base_rd_data_b_no_intg[4:0]),
1114:     .en_i  (rf_bignum_rd_b_indirect_en),
1115:     .out_o (rf_bignum_rd_b_indirect_onehot_o)
1116:   );
1117: 
1118:   prim_onehot_enc #(
1119:     .OneHotWidth(NWdr)
1120:   ) rf_bignum_wr_indirect_onehot_enc (
1121:     .in_i  (rf_base_rd_data_b_no_intg[4:0]),
1122:     .en_i  (rf_bignum_wr_indirect_en),
1123:     .out_o (rf_bignum_wr_indirect_onehot_o)
1124:   );
1125: 
1126:   // For BN.LID sample the indirect destination register index in first cycle as an increment might
1127:   // change it for the second cycle where the load data is written to the bignum register file.
1128:   always_ff @(posedge clk_i) begin
1129:     if (insn_dec_bignum_i.rf_d_indirect) begin
1130:       insn_bignum_wr_addr_q <= rf_base_rd_data_b_no_intg[4:0];
1131:     end
1132: 
1133:     if (insn_dec_bignum_i.rf_a_indirect) begin
1134:       insn_bignum_rd_addr_a_q <= rf_base_rd_data_a_no_intg[4:0];
1135:     end
1136: 
1137:     if (insn_dec_bignum_i.rf_b_indirect) begin
1138:       insn_bignum_rd_addr_b_q <= rf_base_rd_data_b_no_intg[4:0];
1139:     end
1140:   end
1141: 
1142:   // Bignum RF control signals from the controller aren't actually used, instead the predecoded
1143:   // one-hot versions are. The predecoded versions get checked against the signals produced here.
1144:   // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
1145:   // always be identical).
1146:   assign rf_bignum_wr_addr_unbuf = insn_dec_bignum_i.rf_d_indirect ? insn_bignum_wr_addr_q :
1147:                                                                      insn_dec_bignum_i.d;
1148: 
1149:   prim_buf #(
1150:     .Width(WdrAw)
1151:   ) u_rf_bignum_wr_addr_buf (
1152:     .in_i (rf_bignum_wr_addr_unbuf),
1153:     .out_o(rf_bignum_wr_addr_o)
1154:   );
1155: 
1156:   // For the shift-out variant of BN.MULQACC the bottom half of the MAC result is written to one
1157:   // half of a desintation register specified by the instruction (mac_wr_hw_sel_upper). The bottom
1158:   // half of the MAC result must be placed in the appropriate half of the write data (the RF only
1159:   // accepts write data for the top half in the top half of the write data input). Otherwise
1160:   // (shift-out to bottom half and all other BN.MULQACC instructions) simply pass the MAC result
1161:   // through unchanged as write data.
1162:   assign mac_bignum_rf_wr_data[WLEN-1:WLEN/2] =
1163:       insn_dec_bignum_i.mac_wr_hw_sel_upper &&
1164:       insn_dec_bignum_i.mac_shift_out          ? mac_bignum_operation_result_i[WLEN/2-1:0] :
1165:                                                  mac_bignum_operation_result_i[WLEN-1:WLEN/2];
1166: 
1167:   assign mac_bignum_rf_wr_data[WLEN/2-1:0] = mac_bignum_operation_result_i[WLEN/2-1:0];
1168: 
1169:   // Bignum register file write MUX. Depending on the data source, integrity bits do or don't have
1170:   // to be appended; see comments on the "Base register file write MUX" for details.
1171:   always_comb begin
1172:     // Default values
1173:     rf_bignum_wr_data_intg_sel_o = 1'b0;
1174:     rf_bignum_wr_data_intg_o     = '0;
1175:     rf_bignum_wr_data_no_intg_o  = alu_bignum_operation_result_i;
1176: 
1177:     unique case (insn_dec_bignum_i.rf_wdata_sel)
1178:       RfWdSelEx: begin
1179:         rf_bignum_wr_data_no_intg_o  = alu_bignum_operation_result_i;
1180:       end
1181:       RfWdSelMac: begin
1182:         rf_bignum_wr_data_no_intg_o  = mac_bignum_rf_wr_data;
1183:       end
1184:       RfWdSelIspr: begin
1185:         rf_bignum_wr_data_intg_sel_o = 1'b1;
1186:         rf_bignum_wr_data_intg_o     = ispr_rdata_intg_i;
1187:       end
1188:       RfWdSelMovSel: begin
1189:         rf_bignum_wr_data_intg_sel_o = 1'b1;
1190:         rf_bignum_wr_data_intg_o     = selection_result;
1191:       end
1192:       RfWdSelLsu: begin
1193:         rf_bignum_wr_data_intg_sel_o = 1'b1;
1194:         //SEC_CM: BUS.INTEGRITY
1195:         rf_bignum_wr_data_intg_o     = lsu_bignum_rdata_i;
1196:       end
1197:       default: ;
1198:     endcase
1199:   end
1200: 
1201:   assign rf_a_indirect_err = insn_dec_bignum_i.rf_a_indirect    &
1202:                              (|rf_base_rd_data_a_no_intg[31:5]) &
1203:                              ~rf_base_call_stack_sw_err_i       &
1204:                              rf_base_rd_en_a_o;
1205: 
1206:   assign rf_b_indirect_err = insn_dec_bignum_i.rf_b_indirect    &
1207:                              (|rf_base_rd_data_b_no_intg[31:5]) &
1208:                              ~rf_base_call_stack_sw_err_i       &
1209:                              rf_base_rd_en_b_o;
1210: 
1211:   assign rf_d_indirect_err = insn_dec_bignum_i.rf_d_indirect    &
1212:                              (|rf_base_rd_data_b_no_intg[31:5]) &
1213:                              ~rf_base_call_stack_sw_err_i       &
1214:                              rf_base_rd_en_b_o;
1215: 
1216:   assign rf_indirect_err =
1217:       insn_valid_i & (rf_a_indirect_err | rf_b_indirect_err | rf_d_indirect_err);
1218: 
1219: 
1220:   // If the source registers are indirectly indexed and there is a stack error, the source
1221:   // register indices were illegal due to a stack pop error. In this case, ignore bignum RF read
1222:   // integrity errors.
1223:   assign ignore_rf_bignum_intg_errs = (insn_dec_bignum_i.rf_a_indirect |
1224:                                        insn_dec_bignum_i.rf_b_indirect) &
1225:                                       rf_base_call_stack_sw_err_i;
1226: 
1227:   assign rf_bignum_intg_err = rf_bignum_intg_err_i & ~ignore_rf_bignum_intg_errs;
1228: 
1229:   // If the destination register is indirectly indexed and there is a stack error, the destination
1230:   // register index was illegal due to a stack pop error. In this case, ignore bignum RF
1231:   // write-enable errors.
1232:   assign ignore_rf_bignum_spurious_we_errs = insn_dec_bignum_i.rf_d_indirect &
1233:                                              rf_base_call_stack_sw_err_i;
1234: 
1235:   assign rf_bignum_spurious_we_err = rf_bignum_spurious_we_err_i &
1236:                                      ~ignore_rf_bignum_spurious_we_errs;
1237: 
1238:   // CSR/WSR/ISPR handling
1239:   // ISPRs (Internal Special Purpose Registers) are the internal registers. CSRs and WSRs are the
1240:   // ISA visible versions of those registers in the base and bignum ISAs respectively.
1241: 
1242:   assign csr_addr     = csr_e'(insn_dec_base_i.i[11:0]);
1243:   assign csr_sub_addr = insn_dec_base_i.i[$clog2(BaseWordsPerWLEN)-1:0];
1244: 
1245:   always_comb begin
1246:     ispr_addr_base      = IsprMod;
1247:     ispr_word_addr_base = '0;
1248:     csr_illegal_addr    = 1'b0;
1249: 
1250:     unique case (csr_addr)
1251:       CsrFlags, CsrFg0, CsrFg1: begin
1252:         ispr_addr_base      = IsprFlags;
1253:         ispr_word_addr_base = '0;
1254:       end
1255:       CsrMod0, CsrMod1, CsrMod2, CsrMod3, CsrMod4, CsrMod5, CsrMod6, CsrMod7: begin
1256:         ispr_addr_base      = IsprMod;
1257:         ispr_word_addr_base = csr_sub_addr;
1258:       end
1259:       CsrRndPrefetch: begin
1260:         // Reading from RND_PREFETCH results in 0, there is no ISPR to read so no address is set.
1261:         // The csr_rdata mux logic takes care of producing the 0.
1262:       end
1263:       CsrRnd: begin
1264:         ispr_addr_base      = IsprRnd;
1265:         ispr_word_addr_base = '0;
1266:       end
1267:       CsrUrnd: begin
1268:         ispr_addr_base      = IsprUrnd;
1269:         ispr_word_addr_base = '0;
1270:       end
1271:       default: csr_illegal_addr = 1'b1;
1272:     endcase
1273:   end
1274: 
1275:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_word_sel_base
1276:     assign ispr_word_sel_base[i_word] = ispr_word_addr_base == i_word;
1277:   end
1278: 
1279:   // Decode wide ISPR read data.
1280:   logic [WLEN-1:0]                ispr_rdata;
1281:   logic [2*BaseWordsPerWLEN-1:0]  ispr_rdata_intg_err_wide;
1282:   logic [BaseWordsPerWLEN-1:0]    ispr_rdata_intg_err_narrow;
1283:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_rdata_dec
1284:     prim_secded_inv_39_32_dec i_secded_dec (
1285:       .data_i     (ispr_rdata_intg_i[i_word*39+:39]),
1286:       .data_o     (/* unused because we abort on any integrity error */),
1287:       .syndrome_o (/* unused */),
1288:       .err_o      (ispr_rdata_intg_err_wide[i_word*2+:2])
1289:     );
1290:     assign ispr_rdata[i_word*32+:32] = ispr_rdata_intg_i[i_word*39+:32];
1291:     assign ispr_rdata_intg_err_narrow[i_word] = |(ispr_rdata_intg_err_wide[i_word*2+:2]);
1292:   end
1293: 
1294:   // Propagate integrity error only if wide ISPR is used.
1295: 
1296:   // Handle ISPR integrity error detection. We've got a bitmask of ISPR words that failed their
1297:   // integrity check (ispr_rdata_intg_err_narrow), but a nonzero entry may not be a problem if we
1298:   // don't actually use the data.
1299:   //
1300:   // The situations when the data is actually used are:
1301:   //
1302:   //   (1) This is a bignum instruction that writes back to the bignum register file by reading an
1303:   //       ISPR. In this case, we actually pass the data through with integrity bits, but it
1304:   //       shouldn't hurt to add fault detection at this point.
1305:   //
1306:   //   (2) This instruction consumes the data by selecting a word from an ISPR and then writing it
1307:   //       back. This happens for things like CSRRS instructions, where the data flows to the base
1308:   //       register file through rf_base_wr_data_no_intg_o and back to the ISPR through
1309:   //       ispr_base_wdata_o. The word used is given by the onehot ispr_word_sel_base mask.
1310:   //
1311:   // In both cases, there's a special case for the RND_PREFETCH register, which doesn't actually
1312:   // have any backing data. It reads as zero with invalid integrity bits which we want to ignore.
1313: 
1314:   // Are we reading all the ISPR data? (case (1) above)
1315:   logic all_ispr_words_used;
1316:   assign all_ispr_words_used = (insn_dec_bignum_i.rf_wdata_sel == RfWdSelIspr);
1317: 
1318:   // Are we reading just one word of the ISPR data? (case (2) above).
1319:   logic one_ispr_word_used;
1320:   assign one_ispr_word_used = ispr_rd_insn & (insn_dec_shared_i.subset == InsnSubsetBase);
1321: 
1322:   // A bit-mask giving which ISPR words are being read
1323:   logic [BaseWordsPerWLEN-1:0] ispr_read_mask;
1324:   assign ispr_read_mask = all_ispr_words_used ? '1 :
1325:                           one_ispr_word_used  ? ispr_word_sel_base : '0;
1326: 
1327:   // Use ispr_read_mask to qualify the error bit-mask that came out of the integrity decoder.
1328:   logic [BaseWordsPerWLEN-1:0] ispr_rdata_used_intg_err;
1329:   assign ispr_rdata_used_intg_err = ispr_read_mask & ispr_rdata_intg_err_narrow;
1330: 
1331:   // We only architecturally read the ISPR when there's a non-stalled instruction. This is also the
1332:   // place where we factor in the special RND_PREFETCH behaviour. We also need to squash any
1333:   // integrity errors if we're reading a sideload key which isn't currently valid (this will
1334:   // generate a key_invalid error, but we shouldn't have any behaviour that depends on what happens
1335:   // to be on the pins)
1336:   logic non_prefetch_insn_running;
1337:   assign non_prefetch_insn_running = (insn_valid_i & ~stall &
1338:                                       (csr_addr != CsrRndPrefetch) & ~key_invalid);
1339: 
1340:   assign ispr_rdata_intg_err = non_prefetch_insn_running & |(ispr_rdata_used_intg_err);
1341: 
1342:   `ASSERT_KNOWN(IsprRdataIntgErrKnown_A, ispr_rdata_intg_err)
1343: 
1344:   for (genvar i_bit = 0; i_bit < 32; i_bit++) begin : g_csr_rdata_mux
1345:     for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_csr_rdata_mux_inner
1346:       assign csr_rdata_mux[i_bit][i_word] =
1347:           ispr_rdata[i_word*32 + i_bit] & ispr_word_sel_base[i_word];
1348:     end
1349: 
1350:     assign csr_rdata_raw[i_bit] = |csr_rdata_mux[i_bit];
1351:   end
1352: 
1353:   // Specialised read data handling for CSR reads where raw read data needs modification.
1354:   always_comb begin
1355:     csr_rdata = csr_rdata_raw;
1356: 
1357:     unique case (csr_addr)
1358:       // For FG0/FG1 select out appropriate bits from FLAGS ISPR and pad the rest with zeros.
1359:       CsrFg0:         csr_rdata = {28'b0, csr_rdata_raw[3:0]};
1360:       CsrFg1:         csr_rdata = {28'b0, csr_rdata_raw[7:4]};
1361:       CsrRndPrefetch: csr_rdata = '0;
1362:       default: ;
1363:     endcase
1364:   end
1365: 
1366:   assign csr_wdata_raw = insn_dec_shared_i.ispr_rs_insn ? csr_rdata | rf_base_rd_data_a_no_intg :
1367:                                                           rf_base_rd_data_a_no_intg;
1368: 
1369:   // Specialised write data handling for CSR writes where raw write data needs modification.
1370:   always_comb begin
1371:     csr_wdata = csr_wdata_raw;
1372: 
1373:     unique case (csr_addr)
1374:       // For FG0/FG1 only modify relevant part of FLAGS ISPR.
1375:       CsrFg0: csr_wdata = {24'b0, csr_rdata_raw[7:4], csr_wdata_raw[3:0]};
1376:       CsrFg1: csr_wdata = {24'b0, csr_wdata_raw[3:0], csr_rdata_raw[3:0]};
1377:       default: ;
1378:     endcase
1379:   end
1380: 
1381:   // ISPR RS (read and set) must not be combined with ISPR RD or WR (read or write). ISPR RD and
1382:   // WR (read and write) is allowed.
1383:   `ASSERT(NoIsprRorWAndRs, insn_valid_i |-> ~(insn_dec_shared_i.ispr_rs_insn   &
1384:                                               (insn_dec_shared_i.ispr_rd_insn |
1385:                                                insn_dec_shared_i.ispr_wr_insn)))
1386: 
1387: 
1388:   assign wsr_addr = wsr_e'(insn_dec_bignum_i.i[WsrNumWidth-1:0]);
1389: 
1390:   always_comb begin
1391:     ispr_addr_bignum = IsprMod;
1392:     wsr_illegal_addr = 1'b0;
1393:     key_invalid      = 1'b0;
1394: 
1395:     unique case (wsr_addr)
1396:       WsrMod:  ispr_addr_bignum = IsprMod;
1397:       WsrRnd:  ispr_addr_bignum = IsprRnd;
1398:       WsrUrnd: ispr_addr_bignum = IsprUrnd;
1399:       WsrAcc:  ispr_addr_bignum = IsprAcc;
1400:       WsrKeyS0L: begin
1401:         ispr_addr_bignum = IsprKeyS0L;
1402:         key_invalid = ~sideload_key_shares_valid_i[0];
1403:       end
1404:       WsrKeyS0H: begin
1405:         ispr_addr_bignum = IsprKeyS0H;
1406:         key_invalid = ~sideload_key_shares_valid_i[0];
1407:       end
1408:       WsrKeyS1L: begin
1409:         ispr_addr_bignum = IsprKeyS1L;
1410:         key_invalid = ~sideload_key_shares_valid_i[1];
1411:       end
1412:       WsrKeyS1H: begin
1413:         ispr_addr_bignum = IsprKeyS1H;
1414:         key_invalid = ~sideload_key_shares_valid_i[1];
1415:       end
1416:       default: wsr_illegal_addr = 1'b1;
1417:     endcase
1418:   end
1419: 
1420:   assign wsr_wdata = insn_dec_shared_i.ispr_rs_insn ? ispr_rdata | rf_bignum_rd_data_a_no_intg :
1421:                                                       rf_bignum_rd_data_a_no_intg;
1422: 
1423:   assign ispr_illegal_addr = insn_dec_shared_i.subset == InsnSubsetBase ? csr_illegal_addr :
1424:                                                                           wsr_illegal_addr;
1425: 
1426:   assign ispr_err = ispr_illegal_addr & insn_valid_i & (insn_dec_shared_i.ispr_rd_insn |
1427:                                                         insn_dec_shared_i.ispr_wr_insn |
1428:                                                         insn_dec_shared_i.ispr_rs_insn);
1429: 
1430:   assign ispr_wr_insn = insn_dec_shared_i.ispr_wr_insn | insn_dec_shared_i.ispr_rs_insn;
1431:   assign ispr_rd_insn = insn_dec_shared_i.ispr_rd_insn | insn_dec_shared_i.ispr_rs_insn;
1432: 
1433:   assign ispr_flags_wr_o = insn_dec_shared_i.ispr_flags_wr;
1434: 
1435:   // Write to RND_PREFETCH must not produce ISR write
1436:   assign ispr_wr_base_insn =
1437:     ispr_wr_insn & (insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr != CsrRndPrefetch);
1438: 
1439:   assign ispr_wr_bignum_insn = ispr_wr_insn & (insn_dec_shared_i.subset == InsnSubsetBignum);
1440:   assign ispr_rd_bignum_insn = ispr_rd_insn & (insn_dec_shared_i.subset == InsnSubsetBignum);
1441: 
1442:   assign ispr_addr_o         = insn_dec_shared_i.subset == InsnSubsetBase ? ispr_addr_base :
1443:                                                                             ispr_addr_bignum;
1444:   assign ispr_base_wdata_o   = csr_wdata;
1445:   assign ispr_base_wr_en_o   = {BaseWordsPerWLEN{ispr_wr_base_insn & insn_valid_i}} &
1446:                                ispr_word_sel_base;
1447: 
1448:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_bignum_wdata_enc
1449:     prim_secded_inv_39_32_enc i_secded_enc (
1450:       .data_i(wsr_wdata[i_word*32+:32]),
1451:       .data_o(ispr_bignum_wdata_intg_o[i_word*39+:39])
1452:     );
1453:   end
1454:   assign ispr_bignum_wr_en_o = ispr_wr_bignum_insn & insn_valid_i;
1455: 
1456:   assign ispr_wr_commit_o = ispr_wr_insn & insn_executing; 
1457:   
1458:   assign ispr_rd_en_o     = ispr_rd_insn & insn_valid_i &
1459:     ~((insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr == CsrRndPrefetch));
1460: 
1461:   // For BN.SID the LSU address is computed in the first cycle by the base ALU. The store request
1462:   // itself occurs in the second cycle when the store data is available (from the indirect register
1463:   // read). The calculated address is saved in a flop here so it's available for use in the second
1464:   // cycle.
1465:   assign lsu_addr_saved_d = alu_base_operation_result_i[DmemAddrWidth-1:0];
1466:   always_ff @(posedge clk_i) begin
1467:     lsu_addr_saved_q <= lsu_addr_saved_d;
1468:   end
1469: 
1470:   //assign expected_lsu_addr_en_predec = insn_valid & insn_dec_shared_i.ld_insn
1471: 
1472:   // lsu_load_req_raw/lsu_store_req_raw indicate an instruction wishes to perform a store or a load.
1473:   // lsu_load_req_o/lsu_store_req_o factor in whether an instruction is actually executing (it may
1474:   // be suppressed due an error) and command the load or store to happen when asserted.
1475:   assign lsu_load_req_raw = insn_valid_i & insn_dec_shared_i.ld_insn & (state_q == OtbnStateRun);
1476:   assign lsu_load_req_o   = insn_executing & lsu_load_req_raw;
1477: 
1478:   assign lsu_store_req_raw = insn_valid_i & insn_dec_shared_i.st_insn & ~rf_indirect_stall;
1479:   assign lsu_store_req_o   = insn_executing & lsu_store_req_raw;
1480: 
1481:   assign lsu_req_subset_o = insn_dec_shared_i.subset;
1482: 
1483:   // To simplify blanking logic all two cycle memory operations (BN.LID, BN.SID, LW) present the
1484:   // calculated address in their first cycle and the saved address in the second cycle. This results
1485:   // in lsu_addr_o remaining stable for the entire instruction. Only SW is a single cycle
1486:   // instruction so it only presents the calculated address. The stability property is checked by an
1487:   // assertion.
1488:   assign lsu_addr_saved_sel =
1489:     insn_valid_i & ((insn_dec_shared_i.subset == InsnSubsetBignum) ||
1490:                     insn_dec_shared_i.ld_insn                         ? ~stall : 1'b0);
1491: 
1492:   assign lsu_addr = lsu_addr_saved_sel ? lsu_addr_saved_q                                :
1493:                                          alu_base_operation_result_i[DmemAddrWidth-1:0];
1494: 
1495:   // SEC_CM: CTRL.REDUN
1496:   assign expected_lsu_addr_en =
1497:     insn_valid_i & (insn_dec_shared_i.ld_insn | insn_dec_shared_i.st_insn);
1498: 
1499:   assign lsu_predec_error = expected_lsu_addr_en != lsu_addr_en_predec_i;
1500: 
1501:   assign expected_call_stack_push =
1502:     insn_valid_i & insn_dec_base_i.rf_we & rf_base_wr_addr_o == 5'd1;
1503: 
1504:   assign expected_call_stack_pop = insn_valid_i &
1505:                                    ((insn_dec_base_i.rf_ren_a & rf_base_rd_addr_a_o == 5'd1) |
1506:                                     (insn_dec_base_i.rf_ren_b & rf_base_rd_addr_b_o == 5'd1));
1507: 
1508:   // Check branch target against the precalculated target from pre-decode. Pre-decode cannot
1509:   // calculate the jump target of a JALR as it requires a register read so this is excluded from the
1510:   // check (by looking at the ALU op a selection).
1511:   assign branch_target_predec_error =
1512:     insn_dec_shared_i.branch_insn                                            &
1513:     insn_dec_shared_i.jump_insn & insn_dec_base_i.op_a_sel != OpASelRegister &
1514:     (ctrl_flow_target_predec_i != branch_target);
1515: 
1516:   assign ctrl_predec_error =
1517:     |{ctrl_flow_predec_i.jump_insn       != (insn_dec_shared_i.jump_insn   & insn_valid_i),
1518:       ctrl_flow_predec_i.loop_insn       != (insn_dec_shared_i.loop_insn   & insn_valid_i),
1519:       ctrl_flow_predec_i.branch_insn     != (insn_dec_shared_i.branch_insn & insn_valid_i),
1520:       ctrl_flow_predec_i.sel_insn        != (insn_dec_bignum_i.sel_insn    & insn_valid_i),
1521:       ctrl_flow_predec_i.call_stack_push != expected_call_stack_push,
1522:       ctrl_flow_predec_i.call_stack_pop  != expected_call_stack_pop,
1523:       branch_target_predec_error,
1524:       loop_predec_err};
1525: 
1526:   assign predec_error_o = lsu_predec_error | ctrl_predec_error;
1527: 
1528:   // SEC_CM: DATA_REG_SW.SCA
1529:   prim_blanker #(.Width(DmemAddrWidth)) u_lsu_addr_blanker (
1530:     .in_i (lsu_addr),
1531:     .en_i (lsu_addr_en_predec_i),
1532:     .out_o(lsu_addr_blanked)
1533:   );
1534: 
1535:   // Check stability property described above (see the lsu_addr_saved_sel signal) holds.
1536:   `ASSERT(LsuAddrBlankedStable_A, insn_valid_i & stall & ~err |=> $stable(lsu_addr_blanked))
1537: 
1538:   assign lsu_addr_o = lsu_addr_blanked; 
1539: 
1540:   assign lsu_base_wdata_o   = rf_base_rd_data_b_intg_i;
1541:   assign lsu_bignum_wdata_o = rf_bignum_rd_data_b_intg_i;
1542: 
1543:   assign dmem_addr_unaligned_bignum =
1544:       (lsu_req_subset_o == InsnSubsetBignum) & (|lsu_addr_o[$clog2(WLEN/8)-1:0]);
1545:   assign dmem_addr_unaligned_base   =
1546:       (lsu_req_subset_o == InsnSubsetBase)   & (|lsu_addr_o[1:0]);
1547:   assign dmem_addr_overflow         = |alu_base_operation_result_i[31:DmemAddrWidth];
1548: 
1549:   // A dmem address is checked the cycle it is available. For bignum stores this is the first cycle
1550:   // where the base register file read occurs, with the store request occurring the following cycle.
1551:   // For all other loads and stores the dmem address is available the same cycle as the request.
1552:   assign dmem_addr_err_check =
1553:     (lsu_req_subset_o == InsnSubsetBignum) &
1554:     insn_dec_shared_i.st_insn               ? rf_indirect_stall :
1555:                                               lsu_load_req_raw | lsu_store_req_raw;
1556: 
1557:   assign dmem_addr_err =
1558:       insn_valid_i & dmem_addr_err_check & (dmem_addr_overflow         |
1559:                                             dmem_addr_unaligned_bignum |
1560:                                             dmem_addr_unaligned_base);
1561: 
1562:   assign rnd_req_raw = insn_valid_i & ispr_rd_insn & (ispr_addr_o == IsprRnd);
1563:   // Don't factor rnd_rep/fips_err_i into rnd_req_o. This would lead to a combo loop.
1564:   assign rnd_req_o = rnd_req_raw & insn_valid_i & ~(software_err | fatal_err);
1565: 
1566:   assign rnd_prefetch_req_o = insn_executing & ispr_wr_insn &
1567:       (insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr == CsrRndPrefetch);
1568: endmodule

================================== Ai Message ==================================
Tool Calls:
  run_anomaly_detector_agent (call_JCWd6FbVzf7QkEr62xOpOnxn)
 Call ID: call_JCWd6FbVzf7QkEr62xOpOnxn
  Args:
    design_filepath: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv
    top_module: otbn
    security_objective: Bus access control to IMEM/DMEM windows (enforce idle-only), error signaling, data blanking while busy/locked
================================ Human Message =================================

Are there security concerns related to Bus access control to IMEM/DMEM windows (enforce idle-only), error signaling, data blanking while busy/locked in the provided RTL:
    The design filepath is:

    /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv

    The RTL code is:
    '''verilog
    // Copyright lowRISC contributors (OpenTitan project).
// Licensed under the Apache License, Version 2.0, see LICENSE for details.
// SPDX-License-Identifier: Apache-2.0

`include "prim_assert.sv"
`include "prim_fifo_assert.svh"

/**
 * OpenTitan Big Number Accelerator (OTBN)
 */
module otbn
  import prim_alert_pkg::*;
  import otbn_pkg::*;
  import otbn_reg_pkg::*;
#(
  parameter bit                   Stub         = 1'b0,
  parameter regfile_e             RegFile      = RegFileFF,
  parameter logic [NumAlerts-1:0] AlertAsyncOn = {NumAlerts{1'b1}},

  // Default seed for URND PRNG
  parameter urnd_prng_seed_t RndCnstUrndPrngSeed = RndCnstUrndPrngSeedDefault,

  // Disable URND advance when not in use. Useful for SCA only.
  parameter bit SecMuteUrnd = 1'b0,
  // Skip URND re-seed at the start of an operation. Useful for SCA only.
  parameter bit SecSkipUrndReseedAtStart = 1'b0,

  // Default seed and nonce for scrambling
  parameter otp_ctrl_pkg::otbn_key_t   RndCnstOtbnKey   = RndCnstOtbnKeyDefault,
  parameter otp_ctrl_pkg::otbn_nonce_t RndCnstOtbnNonce = RndCnstOtbnNonceDefault
) (
  input clk_i,
  input rst_ni,

  input  tlul_pkg::tl_h2d_t tl_i,
  output tlul_pkg::tl_d2h_t tl_o,

  // Inter-module signals
  output prim_mubi_pkg::mubi4_t idle_o,

  // Interrupts
  output logic intr_done_o,

  // Alerts
  input  prim_alert_pkg::alert_rx_t [NumAlerts-1:0] alert_rx_i,
  output prim_alert_pkg::alert_tx_t [NumAlerts-1:0] alert_tx_o,

  // Lifecycle interfaces
  input  lc_ctrl_pkg::lc_tx_t lc_escalate_en_i,

  input  lc_ctrl_pkg::lc_tx_t lc_rma_req_i,
  output lc_ctrl_pkg::lc_tx_t lc_rma_ack_o,

  // Memory configuration
  input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_imem_i,
  input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_dmem_i,
  output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_imem_o,
  output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_dmem_o,

  // EDN clock and interface
  input                     clk_edn_i,
  input                     rst_edn_ni,
  output edn_pkg::edn_req_t edn_rnd_o,
  input  edn_pkg::edn_rsp_t edn_rnd_i,

  output edn_pkg::edn_req_t edn_urnd_o,
  input  edn_pkg::edn_rsp_t edn_urnd_i,

  // Key request to OTP (running on clk_fixed)
  input                                   clk_otp_i,
  input                                   rst_otp_ni,
  output otp_ctrl_pkg::otbn_otp_key_req_t otbn_otp_key_o,
  input  otp_ctrl_pkg::otbn_otp_key_rsp_t otbn_otp_key_i,

  input keymgr_pkg::otbn_key_req_t keymgr_key_i
);

  import prim_mubi_pkg::*;
  import prim_util_pkg::vbits;

  logic rst_n;

  // hold module in reset permanently when stubbing
  if (Stub) begin : gen_stub_otbn
    assign rst_n = 1'b0;
  end else begin : gen_real_otbn
    assign rst_n = rst_ni;
  end

  // The OTBN_*_SIZE parameters are auto-generated by regtool and come from the bus window sizes;
  // they are given in bytes and must be powers of two.
  //
  // DMEM is actually a bit bigger than OTBN_DMEM_SIZE: there are an extra DmemScratchSizeByte bytes
  // that aren't accessible over the bus.
  localparam int ImemSizeByte = int'(otbn_reg_pkg::OTBN_IMEM_SIZE);
  localparam int DmemSizeByte = int'(otbn_reg_pkg::OTBN_DMEM_SIZE + DmemScratchSizeByte);

  localparam int ImemAddrWidth = vbits(ImemSizeByte);
  localparam int DmemAddrWidth = vbits(DmemSizeByte);

  `ASSERT_INIT(ImemSizePowerOfTwo, 2 ** ImemAddrWidth == ImemSizeByte)
  `ASSERT_INIT(DmemSizePowerOfTwo, 2 ** DmemAddrWidth == DmemSizeByte)

  logic start_d, start_q;
  logic busy_execute_d, busy_execute_q;
  logic done, done_core, locking, locking_q;
  logic busy_secure_wipe;
  logic init_sec_wipe_done_d, init_sec_wipe_done_q;
  logic illegal_bus_access_d, illegal_bus_access_q;
  logic missed_gnt_error_d, missed_gnt_error_q;
  logic dmem_sec_wipe;
  logic imem_sec_wipe;
  logic mems_sec_wipe;
  logic req_sec_wipe_urnd_keys;
  logic [127:0] dmem_sec_wipe_urnd_key, imem_sec_wipe_urnd_key;

  logic core_recoverable_err, recoverable_err_d, recoverable_err_q;
  mubi4_t core_escalate_en;

  core_err_bits_t     core_err_bits;
  non_core_err_bits_t non_core_err_bits, non_core_err_bits_d, non_core_err_bits_q;
  err_bits_t          err_bits, err_bits_d, err_bits_q;
  logic               err_bits_en;

  // ERR_BITS register should be cleared due to a write request from the host processor
  // when OTBN is not running.
  logic err_bits_clear;

  logic software_errs_fatal_q, software_errs_fatal_d;

  otbn_reg2hw_t reg2hw;
  otbn_hw2reg_t hw2reg;
  status_e      status_d, status_q;

  // Bus device windows, as specified in otbn.hjson
  typedef enum logic {
    TlWinImem = 1'b0,
    TlWinDmem = 1'b1
  } tl_win_e;

  tlul_pkg::tl_h2d_t tl_win_h2d[2];
  tlul_pkg::tl_d2h_t tl_win_d2h[2];

  // The clock can be gated and some registers can be updated as long as OTBN isn't currently
  // running. Other registers can only be updated when OTBN is in the Idle state (which also implies
  // we are not locked).
  logic is_not_running_d, is_not_running_q;
  logic otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy;

  assign is_not_running_d = ~|{busy_execute_d,
                               otbn_dmem_scramble_key_req_busy,
                               otbn_imem_scramble_key_req_busy,
                               busy_secure_wipe};

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if(!rst_ni) begin
      // OTBN starts busy, performing the initial secure wipe.
      is_not_running_q  <= 1'b0;
    end else begin
      is_not_running_q  <= is_not_running_d;
    end
  end

  // Inter-module signals ======================================================

  // Note: This is not the same thing as STATUS == IDLE. For example, we want to allow clock gating
  // when locked.
  prim_mubi4_sender #(
    .ResetValue(prim_mubi_pkg::MuBi4True)
  ) u_prim_mubi4_sender (
    .clk_i,
    .rst_ni,
    .mubi_i(mubi4_bool_to_mubi(is_not_running_q)),
    .mubi_o(idle_o)
  );

  // Lifecycle ==================================================================

  localparam int unsigned LcEscalateCopies = 2;
  lc_ctrl_pkg::lc_tx_t [LcEscalateCopies-1:0] lc_escalate_en;
  prim_lc_sync #(
    .NumCopies(LcEscalateCopies)
  ) u_lc_escalate_en_sync (
    .clk_i,
    .rst_ni,
    .lc_en_i(lc_escalate_en_i),
    .lc_en_o(lc_escalate_en)
  );

  lc_ctrl_pkg::lc_tx_t lc_rma_req;
  prim_lc_sync #(
    .NumCopies(1)
  ) u_lc_rma_req_sync (
    .clk_i,
    .rst_ni,
    .lc_en_i(lc_rma_req_i),
    .lc_en_o({lc_rma_req})
  );

  // Internally, OTBN uses MUBI types.
  mubi4_t mubi_rma_req, mubi_rma_ack;
  assign mubi_rma_req = lc_ctrl_pkg::lc_to_mubi4(lc_rma_req);

  // When stubbing, forward req to ack.
  if (Stub) begin : gen_stub_rma_ack
    assign lc_rma_ack_o = lc_rma_req;
  end else begin : gen_real_rma_ack
    assign lc_rma_ack_o = lc_ctrl_pkg::mubi4_to_lc(mubi_rma_ack);
  end

  // Interrupts ================================================================

  assign done = is_busy_status(status_q) & ~is_busy_status(status_d) & init_sec_wipe_done_q;

  prim_intr_hw #(
    .Width(1)
  ) u_intr_hw_done (
    .clk_i,
    .rst_ni                (rst_n),
    .event_intr_i          (done),
    .reg2hw_intr_enable_q_i(reg2hw.intr_enable.q),
    .reg2hw_intr_test_q_i  (reg2hw.intr_test.q),
    .reg2hw_intr_test_qe_i (reg2hw.intr_test.qe),
    .reg2hw_intr_state_q_i (reg2hw.intr_state.q),
    .hw2reg_intr_state_de_o(hw2reg.intr_state.de),
    .hw2reg_intr_state_d_o (hw2reg.intr_state.d),
    .intr_o                (intr_done_o)
  );

  // Instruction Memory (IMEM) =================================================

  localparam int ImemSizeWords = ImemSizeByte / 4;
  localparam int ImemIndexWidth = vbits(ImemSizeWords);

  // Access select to IMEM: core (1), or bus (0)
  logic imem_access_core;

  logic imem_req;
  logic imem_gnt;
  logic imem_write;
  logic imem_wr_collision;
  logic imem_wpending;
  logic [ImemIndexWidth-1:0] imem_index;
  logic [38:0] imem_wdata;
  logic [38:0] imem_wmask;
  logic [38:0] imem_rdata;
  logic imem_rvalid;
  logic imem_illegal_bus_access;
  logic imem_missed_gnt;

  logic imem_req_core;
  logic imem_write_core;
  logic [ImemIndexWidth-1:0] imem_index_core;
  logic [38:0] imem_rdata_core;
  logic imem_rvalid_core;

  logic imem_req_bus;
  logic imem_dummy_response_q, imem_dummy_response_d;
  logic imem_write_bus;
  logic [ImemIndexWidth-1:0] imem_index_bus;
  logic [38:0] imem_wdata_bus;
  logic [38:0] imem_wmask_bus;
  logic [38:0] imem_rdata_bus, imem_rdata_bus_raw;
  logic imem_rdata_bus_en_q, imem_rdata_bus_en_d;
  logic [top_pkg::TL_DBW-1:0] imem_byte_mask_bus;
  logic imem_rvalid_bus;
  logic [1:0] imem_rerror_bus;

  logic imem_bus_intg_violation;

  typedef struct packed {
    logic        imem;
    logic [14:0] index;
    logic [31:0] wr_data;
  } mem_crc_data_in_t;

  logic             mem_crc_data_in_valid;
  mem_crc_data_in_t mem_crc_data_in;
  logic             set_crc;
  logic [31:0]      crc_in, crc_out;

  logic [ImemAddrWidth-1:0] imem_addr_core;
  assign imem_index_core = imem_addr_core[ImemAddrWidth-1:2];

  logic [1:0] unused_imem_addr_core_wordbits;
  assign unused_imem_addr_core_wordbits = imem_addr_core[1:0];

  otp_ctrl_pkg::otbn_key_t otbn_imem_scramble_key;
  otbn_imem_nonce_t        otbn_imem_scramble_nonce;
  logic                    otbn_imem_scramble_valid;
  logic                    unused_otbn_imem_scramble_key_seed_valid;

  otp_ctrl_pkg::otbn_key_t otbn_dmem_scramble_key;
  otbn_dmem_nonce_t        otbn_dmem_scramble_nonce;
  logic                    otbn_dmem_scramble_valid;
  logic                    unused_otbn_dmem_scramble_key_seed_valid;


  logic otbn_scramble_state_error;

  // SEC_CM: SCRAMBLE.KEY.SIDELOAD
  otbn_scramble_ctrl #(
    .RndCnstOtbnKey  (RndCnstOtbnKey),
    .RndCnstOtbnNonce(RndCnstOtbnNonce)
  ) u_otbn_scramble_ctrl (
    .clk_i,
    .rst_ni,

    .clk_otp_i,
    .rst_otp_ni,

    .otbn_otp_key_o,
    .otbn_otp_key_i,

    .otbn_dmem_scramble_key_o           (otbn_dmem_scramble_key),
    .otbn_dmem_scramble_nonce_o         (otbn_dmem_scramble_nonce),
    .otbn_dmem_scramble_valid_o         (otbn_dmem_scramble_valid),
    .otbn_dmem_scramble_key_seed_valid_o(unused_otbn_dmem_scramble_key_seed_valid),

    .otbn_imem_scramble_key_o           (otbn_imem_scramble_key),
    .otbn_imem_scramble_nonce_o         (otbn_imem_scramble_nonce),
    .otbn_imem_scramble_valid_o         (otbn_imem_scramble_valid),
    .otbn_imem_scramble_key_seed_valid_o(unused_otbn_imem_scramble_key_seed_valid),

    .otbn_dmem_scramble_sec_wipe_i    (dmem_sec_wipe),
    .otbn_dmem_scramble_sec_wipe_key_i(dmem_sec_wipe_urnd_key),
    .otbn_imem_scramble_sec_wipe_i    (imem_sec_wipe),
    .otbn_imem_scramble_sec_wipe_key_i(imem_sec_wipe_urnd_key),

    .otbn_dmem_scramble_key_req_busy_o(otbn_dmem_scramble_key_req_busy),
    .otbn_imem_scramble_key_req_busy_o(otbn_imem_scramble_key_req_busy),

    .state_error_o(otbn_scramble_state_error)
  );

  // SEC_CM: MEM.SCRAMBLE
  prim_ram_1p_scr #(
    .Width          (39),
    .Depth          (ImemSizeWords),
    .InstDepth      (ImemSizeWords),
    .DataBitsPerMask(39),
    .EnableParity   (0)
  ) u_imem (
    .clk_i,
    .rst_ni(rst_n),

    .key_valid_i(otbn_imem_scramble_valid),
    .key_i      (otbn_imem_scramble_key),
    .nonce_i    (otbn_imem_scramble_nonce),

    .req_i       (imem_req),
    .gnt_o       (imem_gnt),
    .write_i     (imem_write),
    .addr_i      (imem_index),
    .wdata_i     (imem_wdata),
    .wmask_i     (imem_wmask),
    .intg_error_i(locking),

    .rdata_o  (imem_rdata),
    .rvalid_o (imem_rvalid),
    .raddr_o  (),
    .rerror_o (),
    .cfg_i    (ram_cfg_imem_i),
    .cfg_rsp_o(ram_cfg_rsp_imem_o),

    .wr_collision_o   (imem_wr_collision),
    .write_pending_o  (imem_wpending),

    .alert_o ()
  );

  // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
  assign imem_missed_gnt = imem_req & ~imem_gnt;

  // IMEM access from main TL-UL bus
  logic imem_gnt_bus;
  // Always grant to bus accesses, when OTBN is running a dummy response is returned
  assign imem_gnt_bus = imem_req_bus;

  tlul_adapter_sram #(
    .SramAw          (ImemIndexWidth),
    .SramDw          (32),
    .Outstanding     (1),
    .ByteAccess      (0),
    .ErrOnRead       (0),
    .EnableDataIntgPt(1),
    .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
  ) u_tlul_adapter_sram_imem (
    .clk_i,
    .rst_ni                     (rst_n),
    .tl_i                       (tl_win_h2d[TlWinImem]),
    .tl_o                       (tl_win_d2h[TlWinImem]),
    .en_ifetch_i                (MuBi4False),
    .req_o                      (imem_req_bus),
    .req_type_o                 (),
    .gnt_i                      (imem_gnt_bus),
    .we_o                       (imem_write_bus),
    .addr_o                     (imem_index_bus),
    .wdata_o                    (imem_wdata_bus),
    .wmask_o                    (imem_wmask_bus),
    .intg_error_o               (imem_bus_intg_violation),
    .user_rsvd_o                (),
    .rdata_i                    (imem_rdata_bus),
    .rvalid_i                   (imem_rvalid_bus),
    .rerror_i                   (imem_rerror_bus),
    .compound_txn_in_progress_o (),
    .readback_en_i              (prim_mubi_pkg::MuBi4False),
    .readback_error_o           (),
    .wr_collision_i             (imem_wr_collision),
    .write_pending_i            (imem_wpending)
  );


  // Mux core and bus access into IMEM
  assign imem_access_core = busy_execute_q | start_q;

  assign imem_req   = imem_access_core ? imem_req_core        : imem_req_bus;
  assign imem_write = imem_access_core ? imem_write_core      : imem_write_bus;
  assign imem_index = imem_access_core ? imem_index_core      : imem_index_bus;
  assign imem_wdata = imem_access_core ? '0                   : imem_wdata_bus;

  assign imem_illegal_bus_access = imem_req_bus & imem_access_core;

  assign imem_dummy_response_d = imem_illegal_bus_access;
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      imem_dummy_response_q <= 1'b0;
    end else begin
      imem_dummy_response_q <= imem_dummy_response_d;
    end
  end

  // The instruction memory only supports 32b word writes, so we hardcode its
  // wmask here.
  //
  // Since this could cause confusion if the bus tried to do a partial write
  // (which wasn't caught in the TLUL adapter for some reason), we assert that
  // the wmask signal from the bus is indeed '1 when it requests a write. We
  // don't have the corresponding check for writes from the core because the
  // core cannot perform writes (and has no imem_wmask_o port).
  assign imem_wmask = imem_access_core ? '1 : imem_wmask_bus;
  `ASSERT(ImemWmaskBusIsFullWord_A, imem_req_bus && imem_write_bus |-> imem_wmask_bus == '1)

  // SEC_CM: DATA_REG_SW.SCA
  // Blank bus read data interface during core operation to avoid leaking the currently executed
  // instruction from IMEM through the bus unintentionally. Also blank when OTBN is returning
  // a dummy response (responding to an illegal bus access) and when OTBN is locked.
  assign imem_rdata_bus_en_d = 1'b1;

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
        imem_rdata_bus_en_q <= 1'b1;
    end else begin
        imem_rdata_bus_en_q <= imem_rdata_bus_en_d;
    end
  end

  prim_blanker #(.Width(39)) u_imem_rdata_bus_blanker (
    .in_i (imem_rdata),
    .en_i (imem_rdata_bus_en_q),
    .out_o(imem_rdata_bus_raw)
  );

  // When OTBN is locked all imem bus reads should return 0. The blanker produces the 0s, this adds
  // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
  // through. Data bits are always left un-modified. A registered version of `locking` is used for
  // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
  // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
  // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
  // in so it is reasonable to proceed with returning the supplied integrity.
  assign imem_rdata_bus =
    {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : imem_rdata_bus_raw[38:32],
     imem_rdata_bus_raw[31:0]};

  `ASSERT(ImemRDataBusDisabledWhenCoreAccess_A, imem_access_core |-> !imem_rdata_bus_en_q)
  `ASSERT(ImemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> imem_rdata_bus_en_q)
  `ASSERT(ImemRDataBusDisabledWhenLocked_A, locking |=> !imem_rdata_bus_en_q)
  `ASSERT(ImemRDataBusReadAsZeroWhenLocked_A,
    imem_rvalid_bus & locking |-> imem_rdata_bus_raw == '0)

  assign imem_rdata_core = imem_rdata;

  // When an illegal bus access is seen, always return a dummy response the follow cycle.
  assign imem_rvalid_bus = (~imem_access_core & imem_rvalid) | imem_dummy_response_q;
  assign imem_rvalid_core = imem_access_core ? imem_rvalid : 1'b0;

  assign imem_byte_mask_bus = tl_win_h2d[TlWinImem].a_mask;

  // No imem errors reported for bus reads. Integrity is carried through on the bus so integrity
  // checking on TL responses will pick up any errors.
  assign imem_rerror_bus = 2'b00;

  // Data Memory (DMEM) ========================================================

  localparam int DmemSizeWords = DmemSizeByte / (WLEN / 8);
  localparam int DmemIndexWidth = vbits(DmemSizeWords);

  localparam int DmemBusSizeWords = int'(otbn_reg_pkg::OTBN_DMEM_SIZE) / (WLEN / 8);
  localparam int DmemBusIndexWidth = vbits(DmemBusSizeWords);

  // Access select to DMEM: core (1), or bus (0)
  logic dmem_access_core;

  logic dmem_req;
  logic dmem_gnt;
  logic dmem_write;
  logic [DmemIndexWidth-1:0] dmem_index;
  logic [ExtWLEN-1:0] dmem_wdata;
  logic [ExtWLEN-1:0] dmem_wmask;
  logic [ExtWLEN-1:0] dmem_rdata;
  logic dmem_rvalid;
  logic [BaseWordsPerWLEN*2-1:0] dmem_rerror_vec;
  logic dmem_rerror;
  logic dmem_illegal_bus_access;
  logic dmem_missed_gnt;

  logic dmem_req_core;
  logic dmem_write_core;
  logic [DmemIndexWidth-1:0] dmem_index_core;
  logic [ExtWLEN-1:0] dmem_wdata_core;
  logic [ExtWLEN-1:0] dmem_wmask_core;
  logic [BaseWordsPerWLEN-1:0] dmem_rmask_core_q, dmem_rmask_core_d;
  logic [ExtWLEN-1:0] dmem_rdata_core;
  logic dmem_rvalid_core;
  logic dmem_rerror_core;

  logic dmem_req_bus;
  logic dmem_dummy_response_q, dmem_dummy_response_d;
  logic dmem_write_bus;
  logic [DmemBusIndexWidth-1:0] dmem_index_bus;
  logic [ExtWLEN-1:0] dmem_wdata_bus;
  logic [ExtWLEN-1:0] dmem_wmask_bus;
  logic [ExtWLEN-1:0] dmem_rdata_bus, dmem_rdata_bus_raw;
  logic dmem_rdata_bus_en_q, dmem_rdata_bus_en_d;
  logic [DmemAddrWidth-1:0] dmem_addr_bus;
  logic unused_dmem_addr_bus;
  logic [31:0] dmem_wdata_narrow_bus;
  logic [top_pkg::TL_DBW-1:0] dmem_byte_mask_bus;
  logic dmem_rvalid_bus;
  logic dmem_wr_collision;
  logic dmem_wpending;
  logic [1:0] dmem_rerror_bus;

  logic dmem_bus_intg_violation;

  logic [DmemAddrWidth-1:0] dmem_addr_core;
  assign dmem_index_core = dmem_addr_core[DmemAddrWidth-1:DmemAddrWidth-DmemIndexWidth];

  logic unused_dmem_addr_core_wordbits;
  assign unused_dmem_addr_core_wordbits = ^dmem_addr_core[DmemAddrWidth-DmemIndexWidth-1:0];

  // SEC_CM: MEM.SCRAMBLE
  prim_ram_1p_scr #(
    .Width             (ExtWLEN),
    .Depth             (DmemSizeWords),
    .InstDepth         (DmemSizeWords),
    .DataBitsPerMask   (39),
    .EnableParity      (0),
    .ReplicateKeyStream(1)
  ) u_dmem (
    .clk_i,
    .rst_ni(rst_n),

    .key_valid_i(otbn_dmem_scramble_valid),
    .key_i      (otbn_dmem_scramble_key),
    .nonce_i    (otbn_dmem_scramble_nonce),

    .req_i       (dmem_req),
    .gnt_o       (dmem_gnt),
    .write_i     (dmem_write),
    .addr_i      (dmem_index),
    .wdata_i     (dmem_wdata),
    .wmask_i     (dmem_wmask),
    .intg_error_i(locking),

    .rdata_o  (dmem_rdata),
    .rvalid_o (dmem_rvalid),
    .raddr_o  (),
    .rerror_o (),
    .cfg_i    (ram_cfg_dmem_i),
    .cfg_rsp_o(ram_cfg_rsp_dmem_o),

    .wr_collision_o   (dmem_wr_collision),
    .write_pending_o  (dmem_wpending),

    .alert_o ()
  );

  // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
  assign dmem_missed_gnt = dmem_req & !dmem_gnt;

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      dmem_rmask_core_q <= '0;
    end else begin
      if (dmem_req_core) begin
        dmem_rmask_core_q <= dmem_rmask_core_d;
      end
    end
  end

  // SEC_CM: DATA.MEM.INTEGRITY
  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_intg_check
    logic [1:0] dmem_rerror_raw;

    // Separate check for dmem read data integrity outside of `u_dmem` as `prim_ram_1p_adv` doesn't
    // have functionality for only integrity checking, just fully integrated ECC. Integrity bits are
    // implemented on a 32-bit granule so separate checks are required for each.
    prim_secded_inv_39_32_dec u_dmem_intg_check (
      .data_i    (dmem_rdata[i_word*39+:39]),
      .data_o    (),
      .syndrome_o(),
      .err_o     (dmem_rerror_raw)
    );

    // Only report an error where the word was actually accessed. Otherwise uninitialised memory
    // that OTBN isn't using will cause false errors. dmem_rerror is only reported for reads from
    // OTBN. For Ibex reads integrity checking on TL responses will serve the same purpose.
    assign dmem_rerror_vec[i_word*2 +: 2] = {2{dmem_rmask_core_q[i_word] & dmem_rvalid & dmem_access_core}};
  end

  // dmem_rerror_vec is 2 bits wide and is used to report ECC errors. Bit 1 is set if there's an
  // uncorrectable error and bit 0 is set if there's a correctable error. However, we're treating
  // all errors as fatal, so OR the two signals together.
  assign dmem_rerror = |dmem_rerror_vec;

  // DMEM access from main TL-UL bus
  logic dmem_gnt_bus;
  // Always grant to bus accesses, when OTBN is running a dummy response is returned
  assign dmem_gnt_bus = dmem_req_bus;

  tlul_adapter_sram #(
    .SramAw          (DmemBusIndexWidth),
    .SramDw          (WLEN),
    .Outstanding     (1),
    .ByteAccess      (0),
    .ErrOnRead       (0),
    .EnableDataIntgPt(1),
    .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
  ) u_tlul_adapter_sram_dmem (
    .clk_i,
    .rst_ni                     (rst_n),
    .tl_i                       (tl_win_h2d[TlWinDmem]),
    .tl_o                       (tl_win_d2h[TlWinDmem]),
    .en_ifetch_i                (MuBi4False),
    .req_o                      (dmem_req_bus),
    .req_type_o                 (),
    .gnt_i                      (dmem_gnt_bus),
    .we_o                       (dmem_write_bus),
    .addr_o                     (dmem_index_bus),
    .wdata_o                    (dmem_wdata_bus),
    .wmask_o                    (dmem_wmask_bus),
    .intg_error_o               (dmem_bus_intg_violation),
    .user_rsvd_o                (),
    .rdata_i                    (dmem_rdata_bus),
    .rvalid_i                   (dmem_rvalid_bus),
    .rerror_i                   (dmem_rerror_bus),
    .compound_txn_in_progress_o (),
    .readback_en_i              (prim_mubi_pkg::MuBi4False),
    .readback_error_o           (),
    .wr_collision_i             (dmem_wr_collision),
    .write_pending_i            (dmem_wpending)
  );

  // Mux core and bus access into dmem
  assign dmem_access_core = busy_execute_q;

  assign dmem_req = dmem_access_core ? dmem_req_core : dmem_req_bus;
  assign dmem_write = dmem_access_core ? dmem_write_core : dmem_write_bus;
  assign dmem_wmask = dmem_access_core ? dmem_wmask_core : dmem_wmask_bus;
  // SEC_CM: DATA.MEM.SW_NOACCESS
  assign dmem_index = dmem_access_core ? dmem_index_core : dmem_index_bus;
  assign dmem_wdata = dmem_access_core ? dmem_wdata_core : dmem_wdata_bus;

  assign dmem_illegal_bus_access = dmem_req_bus & dmem_access_core;

  assign dmem_dummy_response_d = dmem_illegal_bus_access;
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      dmem_dummy_response_q <= 1'b0;
    end else begin
      dmem_dummy_response_q <= dmem_dummy_response_d;
    end
  end

  // SEC_CM: DATA_REG_SW.SCA
  // Blank bus read data interface during core operation to avoid leaking DMEM data through the bus
  // unintentionally. Also blank when OTBN is returning a dummy response (responding to an illegal
  // bus access) and when OTBN is locked.
  assign dmem_rdata_bus_en_d = 1'b1;

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
        dmem_rdata_bus_en_q <= 1'b1;
    end else begin
        dmem_rdata_bus_en_q <= dmem_rdata_bus_en_d;
    end
  end

  prim_blanker #(.Width(ExtWLEN)) u_dmem_rdata_bus_blanker (
    .in_i (dmem_rdata),
    .en_i (dmem_rdata_bus_en_q),
    .out_o(dmem_rdata_bus_raw)
  );

  // When OTBN is locked all dmem bus reads should return 0. The blanker produces the 0s, this adds
  // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
  // through. Data bits are always left un-modified. A registered version of `locking` is used for
  // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
  // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
  // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
  // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
  // in so it is reasonable to proceed with returning the supplied integrity.
  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_rdata_bus
    assign dmem_rdata_bus[i_word*39+:39] =
      {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : dmem_rdata_bus_raw[i_word*39+32+:7],
       dmem_rdata_bus_raw[i_word*39+:32]};
  end

  `ASSERT(DmemRDataBusDisabledWhenCoreAccess_A, dmem_access_core |-> !dmem_rdata_bus_en_q)
  `ASSERT(DmemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> dmem_rdata_bus_en_q)
  `ASSERT(DmemRDataBusDisabledWhenLocked_A, locking |=> !dmem_rdata_bus_en_q)
  `ASSERT(DmemRDataBusReadAsZeroWhenLocked_A,
    dmem_rvalid_bus & locking |-> dmem_rdata_bus_raw == '0)

  assign dmem_rdata_core = dmem_rdata;

  // When an illegal bus access is seen, always return a dummy response the follow cycle.
  assign dmem_rvalid_bus  = (~dmem_access_core & dmem_rvalid) | dmem_dummy_response_q;
  assign dmem_rvalid_core = dmem_access_core ? dmem_rvalid : 1'b0;

  // No dmem errors reported for bus reads. Integrity is carried through on the bus so integrity
  // checking on TL responses will pick up any errors.
  assign dmem_rerror_bus  = 2'b00;
  assign dmem_rerror_core = dmem_rerror;

  assign dmem_addr_bus = tl_win_h2d[TlWinDmem].a_address[DmemAddrWidth-1:0];
  assign dmem_wdata_narrow_bus = tl_win_h2d[TlWinDmem].a_data[31:0];
  assign dmem_byte_mask_bus = tl_win_h2d[TlWinDmem].a_mask;

  // Memory Load Integrity =====================================================
  // CRC logic below assumes a incoming data bus width of 32 bits
  `ASSERT_INIT(TLDWIs32Bit_A, top_pkg::TL_DW == 32)

  // Only advance CRC calculation on full 32-bit writes;
  assign mem_crc_data_in_valid   = ~(dmem_access_core | imem_access_core) &
      ((imem_req_bus & (imem_byte_mask_bus == 4'hf)) |
       (dmem_req_bus & (dmem_byte_mask_bus == 4'hf)));

  assign mem_crc_data_in.wr_data = imem_req_bus ? imem_wdata_bus[31:0] :
                                                  dmem_wdata_narrow_bus[31:0];
  assign mem_crc_data_in.index   = imem_req_bus ? {{15 - ImemIndexWidth{1'b0}}, imem_index_bus} :
                                                   {{15 - (DmemAddrWidth - 2){1'b0}},
                                                    dmem_addr_bus[DmemAddrWidth-1:2]};
  assign mem_crc_data_in.imem    = imem_req_bus;

  // Only the bits that factor into the dmem index and dmem word enables are required
  assign unused_dmem_addr_bus = ^{dmem_addr_bus[DmemAddrWidth-1:DmemIndexWidth],
                                  dmem_addr_bus[1:0]};

  // SEC_CM: WRITE.MEM.INTEGRITY
  prim_crc32 #(
    .BytesPerWord(6)
  ) u_mem_load_crc32 (
    .clk_i (clk_i),
    .rst_ni(rst_ni),

    .set_crc_i(set_crc),
    .crc_in_i (crc_in),

    .data_valid_i(mem_crc_data_in_valid),
    .data_i      (mem_crc_data_in),
    .crc_out_o   (crc_out)
  );

  assign set_crc = reg2hw.load_checksum.qe;
  assign crc_in = reg2hw.load_checksum.q;
  assign hw2reg.load_checksum.d = crc_out;

  // Registers =================================================================

  logic reg_bus_intg_violation;

  otbn_reg_top u_reg (
    .clk_i,
    .rst_ni  (rst_n),
    .tl_i,
    .tl_o,
    .tl_win_o(tl_win_h2d),
    .tl_win_i(tl_win_d2h),

    .reg2hw,
    .hw2reg,

    .intg_err_o(reg_bus_intg_violation)
  );

  // SEC_CM: BUS.INTEGRITY
  // SEC_CM: TLUL_FIFO.CTR.REDUN
  logic bus_intg_violation;
  assign bus_intg_violation = (imem_bus_intg_violation | dmem_bus_intg_violation |
                               reg_bus_intg_violation);

  // CMD register
  always_comb begin
    // start is flopped to avoid long timing paths from the TL fabric into OTBN internals.
    start_d       = 1'b0;
    dmem_sec_wipe = 1'b0;
    imem_sec_wipe = 1'b0;

    // Can only start a new command when idle.
    if (status_q == StatusIdle) begin
      if (reg2hw.cmd.qe) begin
        unique case (reg2hw.cmd.q)
          CmdExecute:     start_d       = 1'b1;
          CmdSecWipeDmem: dmem_sec_wipe = 1'b1;
          CmdSecWipeImem: imem_sec_wipe = 1'b1;
          default: ;
        endcase
      end
    end else if (busy_execute_q) begin
      // OTBN can command a secure wipe of IMEM and DMEM. This occurs when OTBN encounters a fatal
      // error.
      if (mems_sec_wipe) begin
        dmem_sec_wipe = 1'b1;
        imem_sec_wipe = 1'b1;
      end
    end
  end

  assign req_sec_wipe_urnd_keys = dmem_sec_wipe | imem_sec_wipe;

  assign illegal_bus_access_d = dmem_illegal_bus_access | imem_illegal_bus_access;

  // It should not be possible to request an imem or dmem access without it being granted. Either
  // a scramble key is present so the request will be granted or the core is busy obtaining a new
  // key, so no request can occur (the core won't generate one whilst awaiting a scrambling key and
  // the bus requests get an immediate dummy response bypassing the dmem or imem). A fatal error is
  // raised if request is seen without a grant.
  assign missed_gnt_error_d = dmem_missed_gnt | imem_missed_gnt;

  // Flop `illegal_bus_access_q` and `missed_gnt_error_q` to break timing paths from the TL
  // interface into the OTBN core.
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      start_q              <= 1'b0;
      illegal_bus_access_q <= 1'b0;
      missed_gnt_error_q   <= 1'b0;
    end else begin
      start_q              <= start_d;
      illegal_bus_access_q <= illegal_bus_access_d;
      missed_gnt_error_q   <= missed_gnt_error_d;
    end
  end

  // STATUS register
  // imem/dmem scramble req can be busy when locked, so use a priority selection so locked status
  // always takes priority.
  //
  // Note that these signals are all "a cycle early". For example, the locking signal gets asserted
  // combinatorially on the cycle that an error is injected. The STATUS register change, done
  // interrupt and any change to the idle signal will be delayed by 2 cycles.
  assign status_d = locking                         ? StatusLocked          :
                    busy_secure_wipe                ? StatusBusySecWipeInt  :
                    busy_execute_d                  ? StatusBusyExecute     :
                    otbn_dmem_scramble_key_req_busy ? StatusBusySecWipeDmem :
                    otbn_imem_scramble_key_req_busy ? StatusBusySecWipeImem :
                                                      StatusIdle;
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      status_q <= StatusBusySecWipeInt;
    end else begin
      status_q <= status_d;
    end
  end

  assign hw2reg.status.d = status_q;
  assign hw2reg.status.de = 1'b1;

  // Only certain combinations of the state variable {locking, busy_execute_d,
  // otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy} are possible.
  //
  // - Once locking is high, we guarantee never to see a new execution or the start of a key
  //   rotation. (Assertion: NoStartWhenLocked_A)

  `ASSERT(NoStartWhenLocked_A,
          locking |=> !($rose(busy_execute_d) ||
                        $rose(otbn_dmem_scramble_key_req_busy) ||
                        $rose(otbn_imem_scramble_key_req_busy)))

  // CTRL register
  assign software_errs_fatal_d =
    reg2hw.ctrl.qe && (status_q == StatusIdle) ? reg2hw.ctrl.q :
                                                 software_errs_fatal_q;

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      software_errs_fatal_q <= 1'b0;
    end else begin
      software_errs_fatal_q <= software_errs_fatal_d;
    end
  end

  assign hw2reg.ctrl.d = software_errs_fatal_q;

  // ERR_BITS register
  // The error bits for an OTBN operation get stored on the cycle that done is
  // asserted. Software is expected to read them out before starting the next operation.

  assign hw2reg.err_bits.bad_data_addr.d = err_bits_q.bad_data_addr;
  assign hw2reg.err_bits.bad_insn_addr.d = err_bits_q.bad_insn_addr;
  assign hw2reg.err_bits.call_stack.d = err_bits_q.call_stack;
  assign hw2reg.err_bits.illegal_insn.d = err_bits_q.illegal_insn;
  assign hw2reg.err_bits.loop.d = err_bits_q.loop;
  assign hw2reg.err_bits.key_invalid.d = err_bits_q.key_invalid;
  assign hw2reg.err_bits.rnd_rep_chk_fail.d = err_bits_q.rnd_rep_chk_fail;
  assign hw2reg.err_bits.rnd_fips_chk_fail.d = err_bits_q.rnd_fips_chk_fail;
  assign hw2reg.err_bits.imem_intg_violation.d = err_bits_q.imem_intg_violation;
  assign hw2reg.err_bits.dmem_intg_violation.d = err_bits_q.dmem_intg_violation;
  assign hw2reg.err_bits.reg_intg_violation.d = err_bits_q.reg_intg_violation;
  assign hw2reg.err_bits.bus_intg_violation.d = err_bits_q.bus_intg_violation;
  assign hw2reg.err_bits.bad_internal_state.d = err_bits_q.bad_internal_state;
  assign hw2reg.err_bits.illegal_bus_access.d = err_bits_q.illegal_bus_access;
  assign hw2reg.err_bits.lifecycle_escalation.d = err_bits_q.lifecycle_escalation;
  assign hw2reg.err_bits.fatal_software.d = err_bits_q.fatal_software;

  assign err_bits_clear = reg2hw.err_bits.bad_data_addr.qe & is_not_running_q;
  assign err_bits_d = err_bits_clear ? '0 : err_bits;
  assign err_bits_en = err_bits_clear | done_core;

  logic unused_reg2hw_err_bits;

  // Majority of reg2hw.err_bits is unused as write values are ignored, all writes clear the
  // register to 0.
  assign unused_reg2hw_err_bits = ^{reg2hw.err_bits.bad_data_addr.q,
                                    reg2hw.err_bits.bad_insn_addr,
                                    reg2hw.err_bits.call_stack,
                                    reg2hw.err_bits.illegal_insn,
                                    reg2hw.err_bits.loop,
                                    reg2hw.err_bits.key_invalid,
                                    reg2hw.err_bits.rnd_rep_chk_fail,
                                    reg2hw.err_bits.rnd_fips_chk_fail,
                                    reg2hw.err_bits.imem_intg_violation,
                                    reg2hw.err_bits.dmem_intg_violation,
                                    reg2hw.err_bits.reg_intg_violation,
                                    reg2hw.err_bits.bus_intg_violation,
                                    reg2hw.err_bits.bad_internal_state,
                                    reg2hw.err_bits.illegal_bus_access,
                                    reg2hw.err_bits.lifecycle_escalation,
                                    reg2hw.err_bits.fatal_software};

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      err_bits_q <= '0;
    end else if (err_bits_en) begin
      err_bits_q <= err_bits_d;
    end
  end

  // Latch the recoverable error signal from the core. This will be generated as a pulse some time
  // during the run (and before secure wipe finishes). Collect up this bit, clearing on the start or
  // end of an operation (start_q / done_core, respectively)
  assign recoverable_err_d = (recoverable_err_q | core_recoverable_err) & ~(start_q | done_core);
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      recoverable_err_q <= '0;
    end else begin
      recoverable_err_q <= recoverable_err_d;
    end
  end

  // FATAL_ALERT_CAUSE register. The .de and .d values are equal for each bit, so that it can only
  // be set, not cleared.
`define DEF_FAC_BIT(NAME)                                         \
  assign hw2reg.fatal_alert_cause.``NAME``.d = 1'b1;              \
  assign hw2reg.fatal_alert_cause.``NAME``.de = err_bits.``NAME;

  `DEF_FAC_BIT(fatal_software)
  `DEF_FAC_BIT(lifecycle_escalation)
  `DEF_FAC_BIT(illegal_bus_access)
  `DEF_FAC_BIT(bad_internal_state)
  `DEF_FAC_BIT(bus_intg_violation)
  `DEF_FAC_BIT(reg_intg_violation)
  `DEF_FAC_BIT(dmem_intg_violation)
  `DEF_FAC_BIT(imem_intg_violation)

`undef DEF_FAC_BIT

  // INSN_CNT register
  logic [31:0] insn_cnt;
  logic        insn_cnt_clear;
  logic        unused_insn_cnt_q;
  assign hw2reg.insn_cnt.d = insn_cnt;
  assign insn_cnt_clear = reg2hw.insn_cnt.qe & is_not_running_q;
  // Ignore all write data to insn_cnt. All writes zero the register.
  assign unused_insn_cnt_q = ^reg2hw.insn_cnt.q;

  // Alerts ====================================================================

  logic [NumAlerts-1:0] alert_test;
  assign alert_test[AlertFatal] = reg2hw.alert_test.fatal.q & reg2hw.alert_test.fatal.qe;
  assign alert_test[AlertRecov] = reg2hw.alert_test.recov.q & reg2hw.alert_test.recov.qe;

  logic [NumAlerts-1:0] alerts;
  assign alerts[AlertFatal] = |{err_bits.fatal_software,
                                err_bits.lifecycle_escalation,
                                err_bits.illegal_bus_access,
                                err_bits.bad_internal_state,
                                err_bits.bus_intg_violation,
                                err_bits.reg_intg_violation,
                                err_bits.dmem_intg_violation,
                                err_bits.imem_intg_violation};

  assign alerts[AlertRecov] = (core_recoverable_err | recoverable_err_q) & done_core;

  for (genvar i = 0; i < NumAlerts; i++) begin : gen_alert_tx
    prim_alert_sender #(
      .AsyncOn(AlertAsyncOn[i]),
      .IsFatal(i == AlertFatal)
    ) u_prim_alert_sender (
      .clk_i,
      .rst_ni       (rst_n),
      .alert_test_i (alert_test[i]),
      .alert_req_i  (alerts[i]),
      .alert_ack_o  (),
      .alert_state_o(),
      .alert_rx_i   (alert_rx_i[i]),
      .alert_tx_o   (alert_tx_o[i])
    );
  end


  // EDN Connections ============================================================
  logic edn_rnd_req, edn_rnd_ack;
  logic [EdnDataWidth-1:0] edn_rnd_data;
  logic edn_rnd_fips, edn_rnd_err;

  logic edn_urnd_req, edn_urnd_ack;
  logic [EdnDataWidth-1:0] edn_urnd_data;

  // These synchronize the data coming from EDN and stack the 32 bit EDN words to achieve an
  // internal entropy width of 256 bit.

  prim_edn_req #(
    .EnRstChks(1'b1),
    .OutWidth(EdnDataWidth),
    // SEC_CM: RND.BUS.CONSISTENCY
    .RepCheck(1'b1)
  ) u_prim_edn_rnd_req (
    .clk_i,
    .rst_ni     ( rst_n        ),
    .req_chk_i  ( 1'b1         ),
    .req_i      ( edn_rnd_req  ),
    .ack_o      ( edn_rnd_ack  ),
    .data_o     ( edn_rnd_data ),
    .fips_o     ( edn_rnd_fips ),
    .err_o      ( edn_rnd_err  ),
    .clk_edn_i,
    .rst_edn_ni,
    .edn_o      ( edn_rnd_o ),
    .edn_i      ( edn_rnd_i )
  );

  prim_edn_req #(
    .EnRstChks(1'b1),
    .OutWidth(EdnDataWidth)
  ) u_prim_edn_urnd_req (
    .clk_i,
    .rst_ni     ( rst_n         ),
    .req_chk_i  ( 1'b1          ),
    .req_i      ( edn_urnd_req  ),
    .ack_o      ( edn_urnd_ack  ),
    .data_o     ( edn_urnd_data ),
    .fips_o     (               ), // unused
    .err_o      (               ), // unused
    .clk_edn_i,
    .rst_edn_ni,
    .edn_o      ( edn_urnd_o    ),
    .edn_i      ( edn_urnd_i    )
  );


  // OTBN Core =================================================================

  always_ff @(posedge clk_i or negedge rst_n) begin
    if (!rst_n) begin
      busy_execute_q       <= 1'b0;
      init_sec_wipe_done_q <= 1'b0;
    end else begin
      busy_execute_q       <= busy_execute_d;
      init_sec_wipe_done_q <= init_sec_wipe_done_d;
    end
  end
  assign busy_execute_d = (busy_execute_q | start_d) & ~done_core;
  assign init_sec_wipe_done_d = init_sec_wipe_done_q | ~busy_secure_wipe;

  otbn_core #(
    .RegFile(RegFile),
    .DmemSizeByte(DmemSizeByte),
    .ImemSizeByte(ImemSizeByte),
    .RndCnstUrndPrngSeed(RndCnstUrndPrngSeed),
    .SecMuteUrnd(SecMuteUrnd),
    .SecSkipUrndReseedAtStart(SecSkipUrndReseedAtStart)
  ) u_otbn_core (
    .clk_i,
    .rst_ni                      (rst_n),

    .start_i                     (start_q),
    .done_o                      (done_core),
    .locking_o                   (locking),
    .secure_wipe_running_o       (busy_secure_wipe),

    .err_bits_o                  (core_err_bits),
    .recoverable_err_o           (core_recoverable_err),

    .imem_req_o                  (imem_req_core),
    .imem_addr_o                 (imem_addr_core),
    .imem_rdata_i                (imem_rdata_core),
    .imem_rvalid_i               (imem_rvalid_core),

    .dmem_req_o                  (dmem_req_core),
    .dmem_write_o                (dmem_write_core),
    .dmem_addr_o                 (dmem_addr_core),
    .dmem_wdata_o                (dmem_wdata_core),
    .dmem_wmask_o                (dmem_wmask_core),
    .dmem_rmask_o                (dmem_rmask_core_d),
    .dmem_rdata_i                (dmem_rdata_core),
    .dmem_rvalid_i               (dmem_rvalid_core),
    .dmem_rerror_i               (dmem_rerror_core),

    .edn_rnd_req_o               (edn_rnd_req),
    .edn_rnd_ack_i               (edn_rnd_ack),
    .edn_rnd_data_i              (edn_rnd_data),
    .edn_rnd_fips_i              (edn_rnd_fips),
    .edn_rnd_err_i               (edn_rnd_err),

    .edn_urnd_req_o              (edn_urnd_req),
    .edn_urnd_ack_i              (edn_urnd_ack),
    .edn_urnd_data_i             (edn_urnd_data),

    .insn_cnt_o                  (insn_cnt),
    .insn_cnt_clear_i            (insn_cnt_clear),

    .mems_sec_wipe_o             (mems_sec_wipe),
    .dmem_sec_wipe_urnd_key_o    (dmem_sec_wipe_urnd_key),
    .imem_sec_wipe_urnd_key_o    (imem_sec_wipe_urnd_key),
    .req_sec_wipe_urnd_keys_i    (req_sec_wipe_urnd_keys),

    .escalate_en_i               (core_escalate_en),
    .rma_req_i                   (mubi_rma_req),
    .rma_ack_o                   (mubi_rma_ack),

    .software_errs_fatal_i       (software_errs_fatal_q),

    .sideload_key_shares_i       (keymgr_key_i.key),
    .sideload_key_shares_valid_i ({2{keymgr_key_i.valid}})
  );

  always_ff @(posedge clk_i or negedge rst_n) begin
    if (!rst_n) begin
      locking_q <= 1'b0;
    end else begin
      locking_q <= locking;
    end
  end

  // Collect up the error bits that don't come from the core itself and latch them so that they'll
  // be available when an operation finishes.
  assign non_core_err_bits = '{
    lifecycle_escalation: lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[0]),
    illegal_bus_access:   illegal_bus_access_q,
    bad_internal_state:   otbn_scramble_state_error | missed_gnt_error_q,
    bus_intg_violation:   bus_intg_violation
  };

  assign non_core_err_bits_d = non_core_err_bits_q | non_core_err_bits;
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      non_core_err_bits_q <= '0;
    end else begin
      non_core_err_bits_q <= non_core_err_bits_d;
    end
  end

  // Construct a full set of error bits from the core output
  assign err_bits = '{
    fatal_software:       core_err_bits.fatal_software,
    lifecycle_escalation: non_core_err_bits_d.lifecycle_escalation,
    illegal_bus_access:   non_core_err_bits_d.illegal_bus_access,
    bad_internal_state:   |{core_err_bits.bad_internal_state,
                            non_core_err_bits_d.bad_internal_state},
    bus_intg_violation:   non_core_err_bits_d.bus_intg_violation,
    reg_intg_violation:   core_err_bits.reg_intg_violation,
    dmem_intg_violation:  core_err_bits.dmem_intg_violation,
    imem_intg_violation:  core_err_bits.imem_intg_violation,
    rnd_fips_chk_fail:    core_err_bits.rnd_fips_chk_fail,
    rnd_rep_chk_fail:     core_err_bits.rnd_rep_chk_fail,
    key_invalid:          core_err_bits.key_invalid,
    loop:                 core_err_bits.loop,
    illegal_insn:         core_err_bits.illegal_insn,
    call_stack:           core_err_bits.call_stack,
    bad_insn_addr:        core_err_bits.bad_insn_addr,
    bad_data_addr:        core_err_bits.bad_data_addr
  };

  // An error signal going down into the core to show that it should locally escalate. In
  // accordance with the lc_ctrl spec, all values of the lc_escalate_en signal other than the OFF
  // value must be interpreted as ON.
  assign core_escalate_en = mubi4_bool_to_mubi(
      |{non_core_err_bits.illegal_bus_access,
        non_core_err_bits.bad_internal_state,
        non_core_err_bits.bus_intg_violation,
        lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[1])});

  // The core can never signal a write to IMEM
  assign imem_write_core = 1'b0;


  // Asserts ===================================================================
  for (genvar i = 0; i < LoopStackDepth; ++i) begin : gen_loop_stack_cntr_asserts
    `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(
      LoopStackCntAlertCheck_A,
      u_otbn_core.u_otbn_controller.u_otbn_loop_controller.g_loop_counters[i].u_loop_count,
      alert_tx_o[AlertFatal]
    )
  end

  // GPR assertions for secure wipe
  // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
  // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
  // secure wiping complete.
  // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
  // because a fatal error affecting internal secure wiping could cause an immediate locking
  // behaviour in which it's not guaranteed to see a succesful secure wipe.
  for (genvar i = 2; i < NGpr; ++i) begin : gen_sec_wipe_gpr_asserts
    // Initial secure wipe needs to initialise all registers to nonzero
    `ASSERT(InitSecWipeNonZeroBaseRegs_A,
      $fell(busy_secure_wipe) |->
      u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
        EccZeroWord,
      clk_i,
      !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
      u_otbn_core.u_otbn_start_stop_control.state_error_d)
    // After execution, it's expected to see a change resulting with a nonzero register value
    `ASSERT(SecWipeChangedBaseRegs_A,
      $rose(busy_secure_wipe) |-> ((##[0:$]
        u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
          EccZeroWord &&
        $changed(
          u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q))
        within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
      clk_i,
      !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
      u_otbn_core.u_otbn_start_stop_control.state_error_d)
  end

  // We have several assertions that check that secure wipe worked properly. However, we've also got
  // some tests where we force nets, stopping it from working properly! That's fine, and the tests
  // are checking that some other mechanism catches the problem. However, we don't want the
  // simulation to die with a failed assertion, so we put everything in a named block which we can
  // turn off with $assertoff.
  //
  // The silly-looking name is to avoid a lint warning. Verible (correctly) points out that
  // SystemVerilog doesn't allow bare begin/end blocks at module level. So I cheated and put
  // everything in an if(1) block. But this is treated as a generate block, and our lint rules
  // therefore expect its name to start with a "g_".
  if (1) begin : g_secure_wipe_assertions
    // WDR assertions for secure wipe
    // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
    // goes to LOCKED state immediately after this error which means that it's not guaranteed to
    // have secure wiping complete.
    // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
    // because a fatal error affecting internal secure wiping could cause an immediate locking
    // behaviour in which it's not guaranteed to see a succesful secure wipe.
    for (genvar i = 0; i < NWdr; ++i) begin : gen_sec_wipe_wdr_asserts
      // Initial secure wipe needs to initialise all registers to nonzero
      `ASSERT(InitSecWipeNonZeroWideRegs_A,
              $fell(busy_secure_wipe) |->
                u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
                  EccWideZeroWord,
              clk_i,
              !rst_ni || u_otbn_core.urnd_reseed_err ||
                u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
                u_otbn_core.u_otbn_start_stop_control.state_error_d)

      // After execution, it's expected to see a change resulting with a nonzero register value
      `ASSERT(SecWipeChangedWideRegs_A,
              $rose(busy_secure_wipe) |-> ((##[0:$]
                u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
                  EccWideZeroWord &&
                $changed(
                  u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i]))
                within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
            clk_i, !rst_ni || u_otbn_core.urnd_reseed_err ||
              u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
    end
  end

  // Secure wipe needs to invalidate call and loop stack, initialize MOD, ACC to nonzero and set
  // FLAGS CSR to zero
  // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
  // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
  // secure wiping complete.
  // 2. mubi_err_d of start_stop_control disables the secure wipe related assertions because a
  // fatal error affecting internal secure wiping could cause an immediate locking behaviour
  // in which it's not guaranteed to see a succesful secure wipe.
  `ASSERT(SecWipeInvalidCallStack_A,
          $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_rf_base.u_call_stack.top_valid_o),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)
  `ASSERT(SecWipeInvalidLoopStack_A,
          $fell(busy_secure_wipe) |->
            (!u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.top_valid_o),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)

  `ASSERT(SecWipeNonZeroMod_A,
          $fell(busy_secure_wipe) |-> u_otbn_core.u_otbn_alu_bignum.mod_intg_q != EccWideZeroWord,
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)

  `ASSERT(SecWipeNonZeroACC_A,
          $fell(busy_secure_wipe) |->
            u_otbn_core.u_otbn_alu_bignum.ispr_acc_intg_i != EccWideZeroWord,
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)

  `ASSERT(SecWipeNonZeroFlags_A,
          $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_alu_bignum.flags_flattened),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)

  // Secure wipe of IMEM and DMEM first happens with a key change from URND (while valid is zero)
  `ASSERT(ImemSecWipeRequiresUrndKey_A,
          $rose(imem_sec_wipe) |=> (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
  `ASSERT(DmemSecWipeRequiresUrndKey_A,
          $rose(dmem_sec_wipe) |=> (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d)

  // Then it is guaranteed to have a valid key from OTP interface which is different from URND key
  `ASSERT(ImemSecWipeRequiresOtpKey_A,
          $rose(imem_sec_wipe) ##1 (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)) |=>
            ##[0:$] otbn_imem_scramble_valid && $changed(otbn_imem_scramble_key),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
  `ASSERT(DmemSecWipeRequiresOtpKey_A,
          $rose(dmem_sec_wipe) ##1 (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)) |=>
            ##[0:$] otbn_dmem_scramble_valid && $changed(otbn_dmem_scramble_key),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d)

  // All outputs should be known value after reset
  `ASSERT_KNOWN(TlODValidKnown_A, tl_o.d_valid)
  `ASSERT_KNOWN(TlOAReadyKnown_A, tl_o.a_ready)
  `ASSERT_KNOWN(IdleOKnown_A, idle_o)
  `ASSERT_KNOWN(IntrDoneOKnown_A, intr_done_o)
  `ASSERT_KNOWN(AlertTxOKnown_A, alert_tx_o)
  `ASSERT_KNOWN(EdnRndOKnown_A, edn_rnd_o, clk_edn_i, !rst_edn_ni)
  `ASSERT_KNOWN(EdnUrndOKnown_A, edn_urnd_o, clk_edn_i, !rst_edn_ni)
  `ASSERT_KNOWN(OtbnOtpKeyO_A, otbn_otp_key_o, clk_otp_i, !rst_otp_ni)
  `ASSERT_KNOWN(ErrBitsKnown_A, err_bits)

  // Incoming key must be valid (other inputs go via prim modules that handle the X checks).
  `ASSERT_KNOWN(KeyMgrKeyValid_A, keymgr_key_i.valid)

  // In locked state, the readable registers INSN_CNT, IMEM, and DMEM are expected to always read 0
  // when accessed from the bus. For INSN_CNT, we use "|=>" so that the assertion lines up with
  // "status.q" (a signal that isn't directly accessible here).
  `ASSERT(LockedInsnCntReadsZero_A, (hw2reg.status.d == StatusLocked) |=> insn_cnt == 'd0)
  `ASSERT(ExecuteOrLockedImemReadsZero_A,
          (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & imem_rvalid_bus
          |-> imem_rdata_bus == 'd0)
  `ASSERT(ExecuteOrLockedDmemReadsZero_A,
          (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & dmem_rvalid_bus
          |-> dmem_rdata_bus == 'd0)

  // From the cycle the core is told to start to when it is done, it must always be busy executing,
  // locking, or both -- even if the core is never done.  We use this property to enable blanking
  // while the core is executing or locking, and this assertion ensures that there is no gap
  // between execution and locking.
  `ASSERT(BusyOrLockingFromStartToDone_A,
          $rose(start_q) |-> (busy_execute_d | locking) |-> ##[0:$] $rose(done_core))

  // Error handling: if we pass an error signal down to the core then we should also be setting an
  // error flag. Note that this uses err_bits, not err_bits_q, because the latter signal only gets
  // asserted when an operation finishes.
  `ASSERT(ErrBitIfEscalate_A, mubi4_test_true_loose(core_escalate_en) |=> |err_bits)

  // Constraint from package, check here as we cannot have `ASSERT_INIT in package
  `ASSERT_INIT(WsrESizeMatchesParameter_A, $bits(wsr_e) == WsrNumWidth)

  `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnStartStopFsmCheck_A,
    u_otbn_core.u_otbn_start_stop_control.u_state_regs, alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnControllerFsmCheck_A,
    u_otbn_core.u_otbn_controller.u_state_regs, alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnScrambleCtrlFsmCheck_A,
    u_otbn_scramble_ctrl.u_state_regs, alert_tx_o[AlertFatal])

  `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnCallStackWrPtrAlertCheck_A,
    u_otbn_core.u_otbn_rf_base.u_call_stack.u_stack_wr_ptr, alert_tx_o[AlertFatal])
  `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnLoopInfoStackWrPtrAlertCheck_A,
    u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.u_stack_wr_ptr,
    alert_tx_o[AlertFatal])

  // Alert assertions for reg_we onehot check
  `ASSERT_PRIM_REG_WE_ONEHOT_ERROR_TRIGGER_ALERT(RegWeOnehotCheck_A,
      u_reg, alert_tx_o[AlertFatal])
  // other onehot checks
  `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBaseOnehotCheck_A,
      u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.u_prim_onehot_check,
      alert_tx_o[AlertFatal])
  `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBignumOnehotCheck_A,
      u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.u_prim_onehot_check,
      alert_tx_o[AlertFatal])

  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemRspFifo,
                                               u_tlul_adapter_sram_dmem.u_rspfifo,
                                               alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemSramReqFifo,
                                               u_tlul_adapter_sram_dmem.u_sramreqfifo,
                                               alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemReqFifo,
                                               u_tlul_adapter_sram_dmem.u_reqfifo,
                                               alert_tx_o[AlertFatal])

  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemRspFifo,
                                               u_tlul_adapter_sram_imem.u_rspfifo,
                                               alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemSramReqFifo,
                                               u_tlul_adapter_sram_imem.u_sramreqfifo,
                                               alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemReqFifo,
                                               u_tlul_adapter_sram_imem.u_reqfifo,
                                               alert_tx_o[AlertFatal])
endmodule

    '''

    Use the anomaly detector tool to identify lines in the design RTL that are anomalous.
    Then determine whether the identified anomalous line(s) represent a security issue or not.

    
================================== Ai Message ==================================
Tool Calls:
  anomaly_detector_tool (call_hczbWbwg1TeAHazASg1gX7Xn)
 Call ID: call_hczbWbwg1TeAHazASg1gX7Xn
  Args:
    design_filepath: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv
================================= Tool Message =================================
Name: anomaly_detector_tool

Successfully executed:
```LLM Anomaly Detector tool
```
Output:
Here are clusters of similar verilog constructs in the RTL file:



Cluster 0:
assign rst_n = 1'b0;
assign rst_n = rst_ni;


Cluster 1:
assign is_not_running_d = ~|{busy_execute_d,
assign imem_index_core = imem_addr_core[ImemAddrWidth-1:2];
assign unused_imem_addr_core_wordbits = imem_addr_core[1:0];
assign imem_missed_gnt = imem_req & ~imem_gnt;
assign imem_gnt_bus = imem_req_bus;
assign imem_access_core = busy_execute_q | start_q;
assign imem_req   = imem_access_core ? imem_req_core        : imem_req_bus;
assign imem_write = imem_access_core ? imem_write_core      : imem_write_bus;
assign imem_index = imem_access_core ? imem_index_core      : imem_index_bus;
assign imem_wdata = imem_access_core ? '0                   : imem_wdata_bus;
assign imem_illegal_bus_access = imem_req_bus & imem_access_core;
assign imem_dummy_response_d = imem_illegal_bus_access;
assign imem_wmask = imem_access_core ? '1 : imem_wmask_bus;
assign imem_rdata_bus_en_d = 1'b1;
assign imem_rdata_bus =
assign imem_rdata_core = imem_rdata;
assign imem_rvalid_bus = (~imem_access_core & imem_rvalid) | imem_dummy_response_q;
assign imem_rvalid_core = imem_access_core ? imem_rvalid : 1'b0;
assign imem_byte_mask_bus = tl_win_h2d[TlWinImem].a_mask;
assign imem_rerror_bus = 2'b00;
assign dmem_index_core = dmem_addr_core[DmemAddrWidth-1:DmemAddrWidth-DmemIndexWidth];
assign unused_dmem_addr_core_wordbits = ^dmem_addr_core[DmemAddrWidth-DmemIndexWidth-1:0];
assign dmem_missed_gnt = dmem_req & !dmem_gnt;
assign dmem_rerror_vec[i_word*2 +: 2] = {2{dmem_rmask_core_q[i_word] & dmem_rvalid & dmem_access_core}};
assign dmem_rerror = |dmem_rerror_vec;
assign dmem_gnt_bus = dmem_req_bus;
assign dmem_access_core = busy_execute_q;
assign dmem_req = dmem_access_core ? dmem_req_core : dmem_req_bus;
assign dmem_write = dmem_access_core ? dmem_write_core : dmem_write_bus;
assign dmem_wmask = dmem_access_core ? dmem_wmask_core : dmem_wmask_bus;
assign dmem_index = dmem_access_core ? dmem_index_core : dmem_index_bus;
assign dmem_wdata = dmem_access_core ? dmem_wdata_core : dmem_wdata_bus;
assign dmem_illegal_bus_access = dmem_req_bus & dmem_access_core;
assign dmem_dummy_response_d = dmem_illegal_bus_access;
assign dmem_rdata_bus_en_d = 1'b1;
assign dmem_rdata_bus[i_word*39+:39] =
assign dmem_rdata_core = dmem_rdata;
assign dmem_rvalid_bus  = (~dmem_access_core & dmem_rvalid) | dmem_dummy_response_q;
assign dmem_rvalid_core = dmem_access_core ? dmem_rvalid : 1'b0;
assign dmem_rerror_bus  = 2'b00;
assign dmem_rerror_core = dmem_rerror;
assign dmem_addr_bus = tl_win_h2d[TlWinDmem].a_address[DmemAddrWidth-1:0];
assign dmem_wdata_narrow_bus = tl_win_h2d[TlWinDmem].a_data[31:0];
assign dmem_byte_mask_bus = tl_win_h2d[TlWinDmem].a_mask;
assign mem_crc_data_in_valid   = ~(dmem_access_core | imem_access_core) &
assign mem_crc_data_in.wr_data = imem_req_bus ? imem_wdata_bus[31:0] :
assign mem_crc_data_in.index   = imem_req_bus ? {{15 - ImemIndexWidth{1'b0}}, imem_index_bus} :
assign mem_crc_data_in.imem    = imem_req_bus;
assign unused_dmem_addr_bus = ^{dmem_addr_bus[DmemAddrWidth-1:DmemIndexWidth],
assign set_crc = reg2hw.load_checksum.qe;
assign crc_in = reg2hw.load_checksum.q;
assign hw2reg.load_checksum.d = crc_out;
assign bus_intg_violation = (imem_bus_intg_violation | dmem_bus_intg_violation |
assign illegal_bus_access_d = dmem_illegal_bus_access | imem_illegal_bus_access;
assign missed_gnt_error_d = dmem_missed_gnt | imem_missed_gnt;
assign hw2reg.status.d = status_q;
assign hw2reg.status.de = 1'b1;
assign hw2reg.ctrl.d = software_errs_fatal_q;
assign hw2reg.err_bits.bad_data_addr.d = err_bits_q.bad_data_addr;
assign hw2reg.err_bits.bad_insn_addr.d = err_bits_q.bad_insn_addr;
assign hw2reg.err_bits.call_stack.d = err_bits_q.call_stack;
assign hw2reg.err_bits.illegal_insn.d = err_bits_q.illegal_insn;
assign hw2reg.err_bits.loop.d = err_bits_q.loop;
assign hw2reg.err_bits.key_invalid.d = err_bits_q.key_invalid;
assign hw2reg.err_bits.rnd_rep_chk_fail.d = err_bits_q.rnd_rep_chk_fail;
assign hw2reg.err_bits.rnd_fips_chk_fail.d = err_bits_q.rnd_fips_chk_fail;
assign hw2reg.err_bits.imem_intg_violation.d = err_bits_q.imem_intg_violation;
assign hw2reg.err_bits.dmem_intg_violation.d = err_bits_q.dmem_intg_violation;
assign hw2reg.err_bits.reg_intg_violation.d = err_bits_q.reg_intg_violation;
assign hw2reg.err_bits.bus_intg_violation.d = err_bits_q.bus_intg_violation;
assign hw2reg.err_bits.bad_internal_state.d = err_bits_q.bad_internal_state;
assign hw2reg.err_bits.illegal_bus_access.d = err_bits_q.illegal_bus_access;
assign hw2reg.err_bits.lifecycle_escalation.d = err_bits_q.lifecycle_escalation;
assign hw2reg.err_bits.fatal_software.d = err_bits_q.fatal_software;
assign err_bits_clear = reg2hw.err_bits.bad_data_addr.qe & is_not_running_q;
assign err_bits_d = err_bits_clear ? '0 : err_bits;
assign err_bits_en = err_bits_clear | done_core;
assign unused_reg2hw_err_bits = ^{reg2hw.err_bits.bad_data_addr.q,
assign recoverable_err_d = (recoverable_err_q | core_recoverable_err) & ~(start_q | done_core);
assign hw2reg.fatal_alert_cause.``NAME``.d = 1'b1;              \
assign hw2reg.fatal_alert_cause.``NAME``.de = err_bits.``NAME;
assign hw2reg.insn_cnt.d = insn_cnt;
assign insn_cnt_clear = reg2hw.insn_cnt.qe & is_not_running_q;
assign unused_insn_cnt_q = ^reg2hw.insn_cnt.q;
assign alert_test[AlertFatal] = reg2hw.alert_test.fatal.q & reg2hw.alert_test.fatal.qe;
assign alert_test[AlertRecov] = reg2hw.alert_test.recov.q & reg2hw.alert_test.recov.qe;
assign alerts[AlertFatal] = |{err_bits.fatal_software,
assign alerts[AlertRecov] = (core_recoverable_err | recoverable_err_q) & done_core;
assign busy_execute_d = (busy_execute_q | start_d) & ~done_core;
assign non_core_err_bits = '{
assign non_core_err_bits_d = non_core_err_bits_q | non_core_err_bits;
assign err_bits = '{
assign imem_write_core = 1'b0;


Cluster 2:
assign mubi_rma_req = lc_ctrl_pkg::lc_to_mubi4(lc_rma_req);
assign lc_rma_ack_o = lc_rma_req;
assign lc_rma_ack_o = lc_ctrl_pkg::mubi4_to_lc(mubi_rma_ack);


Cluster 3:
assign done = is_busy_status(status_q) & ~is_busy_status(status_d) & init_sec_wipe_done_q;
assign req_sec_wipe_urnd_keys = dmem_sec_wipe | imem_sec_wipe;
assign init_sec_wipe_done_d = init_sec_wipe_done_q | ~busy_secure_wipe;

================================== Ai Message ==================================

I ran the anomaly detector on the supplied otbn.sv. It produced several clusters; the most notable anomalies (and the ones with potential security impact) are the two unconditional blanker-enable assignments:

- imem: the line
  assign imem_rdata_bus_en_d = 1'b1;
- dmem: the line
  assign dmem_rdata_bus_en_d = 1'b1;

Why these are anomalous
- The comments and surrounding code make the intended behaviour clear: the bus read data interfaces must be blanked during core execution (to avoid leaking IMEM/DMEM contents), when OTBN returns a dummy response for an illegal bus access, and when OTBN is locked.
- Several assertions depend on the blanker enable being controlled by OTBN state:
  - `ASSERT(ImemRDataBusDisabledWhenCoreAccess_A, imem_access_core |-> !imem_rdata_bus_en_q)`
  - `ASSERT(ImemRDataBusDisabledWhenLocked_A, locking |=> !imem_rdata_bus_en_q)`
  - `ASSERT(DmemRDataBusDisabledWhenCoreAccess_A, dmem_access_core |-> !dmem_rdata_bus_en_q)`
  - `ASSERT(DmemRDataBusDisabledWhenLocked_A, locking |=> !dmem_rdata_bus_en_q)`
  - plus other asserts that check reads are zero during Execute/Locked etc.
- Despite those intentions the code currently assigns the "next" enable signals to a constant 1'b1. There is no other place in the module that updates imem_rdata_bus_en_d or dmem_rdata_bus_en_d. That means the blanker enable registers imem_rdata_bus_en_q / dmem_rdata_bus_en_q will stay 1 (pass-through) every cycle unless something else modifies them  which contradicts the stated intent and the assertions.

Security impact
- High risk (data leakage): If imem_rdata_bus_en_q / dmem_rdata_bus_en_q remain asserted (pass-through), bus reads may return live IMEM/DMEM data while the core is executing, during dummy responses to illegal accesses, or while OTBN is locked. That leaks sensitive internal memory contents to the host bus and defeats the security countermeasure described in the comments.
- Medium/High depending on blanker semantics: this assumes prim_blanker passes data through when en_i==1 and blanks (outputs zeros) when en_i==0. If prim_blanker has inverted logic then the current code could instead always blank reads (availability problem)  but the comments & assertions make the intended semantics (disable bus reads while core runs) clear, so unconditional 1'b1 is an anomaly regardless.
- The assertions that depend on this gating would fail (simulation/formal). If assertions are disabled in a synthesis or test build, the functional bug could be missed and remain a security vulnerability in silicon.

Recommended fixes
1. Drive the blanker enable signals with the intended conditions instead of a constant. For example (expressed in behavioral terms  pick combinational or registered signals consistent with your timing requirements):

   - imem:
     imem_rdata_bus_en_d <= ~(imem_access_core | imem_dummy_response_d | locking);

   - dmem:
     dmem_rdata_bus_en_d <= ~(dmem_access_core | dmem_dummy_response_d | locking);

   Rationale:
   - When the core accesses memory (imem_access_core / dmem_access_core) we must disable bus-read pass-through (i.e., en=0) to prevent leakage.
   - When we are returning a dummy response for illegal bus access (dummy_response_d) we should blank (disable) the bus read.
   - When locked, bus reads should be blanked.

   Notes:
   - Use the same registration convention used elsewhere: the code registers ..._en_q <= ..._en_d. If you need the blanking to take immediate effect on the same cycle as a combinational signal (e.g. locking asserted combinatorially), choose carefully whether to use locking or locking_q  the existing code uses locking_q when assembling rdata_bus to ensure timing, so review exactly which form you want to depend on for en_d. The assertions use both styles (`|-> !imem_rdata_bus_en_q` for imem_access_core and `|=> !imem_rdata_bus_en_q` for locking), so setting en_d = ~(imem_access_core | imem_dummy_response_d | locking) should satisfy the intent (locking is combinational and will cause en_q to be cleared next cycle).

2. Add/update comments to make the required relationship explicit, and make sure assertions reflect exact register/clocking behavior.

3. Re-run formal/sim checks (the existing assertions will catch mismatches). Ensure prim_blanker semantics are documented and understood in the code so en=0 really blanks (not the other way around).

Suggested minimal code replace example
(Replace the unconditional assignments with logic computing en_d; adapt to your style/clocking needs)

  // instead of: assign imem_rdata_bus_en_d = 1'b1;
  assign imem_rdata_bus_en_d = ~(imem_access_core | imem_dummy_response_d | locking);

  // instead of: assign dmem_rdata_bus_en_d = 1'b1;
  assign dmem_rdata_bus_en_d = ~(dmem_access_core | dmem_dummy_response_d | locking);

(If you want the blanking to go into effect one cycle earlier/later, use locking_q or dummy_response_q variants  but ensure the assertions are matched to that timing.)

Other notes from the clusters
- The detector showed many repetitive assign lines; none of the other assignments stood out as contradictory to their comments/intent  e.g. imem/dmem always-grant to bus (imem_gnt_bus = imem_req_bus etc.) is an intentional design choice (they return dummy responses instead of blocking the bus), and other error/miss logic (illegal_bus_access, missed_gnt_error) are consistent and used elsewhere.
- There are a few slices/manipulations of ECC bits and raw data which are consistent with the blanker/ECC logic; those look intentional.

Summary
- The unconditional imem_rdata_bus_en_d = 1'b1 and dmem_rdata_bus_en_d = 1'b1 are anomalous and are a likely security bug (data leakage, high severity). They should be replaced with combinational logic that disables pass-through when the core is accessing the memory, when a dummy response is being returned, and when the design is locked. After making that change, re-run the existing assertions/formal checks to validate the behaviour.
================================= Tool Message =================================
Name: run_anomaly_detector_agent

I ran the anomaly detector on the supplied otbn.sv. It produced several clusters; the most notable anomalies (and the ones with potential security impact) are the two unconditional blanker-enable assignments:

- imem: the line
  assign imem_rdata_bus_en_d = 1'b1;
- dmem: the line
  assign dmem_rdata_bus_en_d = 1'b1;

Why these are anomalous
- The comments and surrounding code make the intended behaviour clear: the bus read data interfaces must be blanked during core execution (to avoid leaking IMEM/DMEM contents), when OTBN returns a dummy response for an illegal bus access, and when OTBN is locked.
- Several assertions depend on the blanker enable being controlled by OTBN state:
  - `ASSERT(ImemRDataBusDisabledWhenCoreAccess_A, imem_access_core |-> !imem_rdata_bus_en_q)`
  - `ASSERT(ImemRDataBusDisabledWhenLocked_A, locking |=> !imem_rdata_bus_en_q)`
  - `ASSERT(DmemRDataBusDisabledWhenCoreAccess_A, dmem_access_core |-> !dmem_rdata_bus_en_q)`
  - `ASSERT(DmemRDataBusDisabledWhenLocked_A, locking |=> !dmem_rdata_bus_en_q)`
  - plus other asserts that check reads are zero during Execute/Locked etc.
- Despite those intentions the code currently assigns the "next" enable signals to a constant 1'b1. There is no other place in the module that updates imem_rdata_bus_en_d or dmem_rdata_bus_en_d. That means the blanker enable registers imem_rdata_bus_en_q / dmem_rdata_bus_en_q will stay 1 (pass-through) every cycle unless something else modifies them  which contradicts the stated intent and the assertions.

Security impact
- High risk (data leakage): If imem_rdata_bus_en_q / dmem_rdata_bus_en_q remain asserted (pass-through), bus reads may return live IMEM/DMEM data while the core is executing, during dummy responses to illegal accesses, or while OTBN is locked. That leaks sensitive internal memory contents to the host bus and defeats the security countermeasure described in the comments.
- Medium/High depending on blanker semantics: this assumes prim_blanker passes data through when en_i==1 and blanks (outputs zeros) when en_i==0. If prim_blanker has inverted logic then the current code could instead always blank reads (availability problem)  but the comments & assertions make the intended semantics (disable bus reads while core runs) clear, so unconditional 1'b1 is an anomaly regardless.
- The assertions that depend on this gating would fail (simulation/formal). If assertions are disabled in a synthesis or test build, the functional bug could be missed and remain a security vulnerability in silicon.

Recommended fixes
1. Drive the blanker enable signals with the intended conditions instead of a constant. For example (expressed in behavioral terms  pick combinational or registered signals consistent with your timing requirements):

   - imem:
     imem_rdata_bus_en_d <= ~(imem_access_core | imem_dummy_response_d | locking);

   - dmem:
     dmem_rdata_bus_en_d <= ~(dmem_access_core | dmem_dummy_response_d | locking);

   Rationale:
   - When the core accesses memory (imem_access_core / dmem_access_core) we must disable bus-read pass-through (i.e., en=0) to prevent leakage.
   - When we are returning a dummy response for illegal bus access (dummy_response_d) we should blank (disable) the bus read.
   - When locked, bus reads should be blanked.

   Notes:
   - Use the same registration convention used elsewhere: the code registers ..._en_q <= ..._en_d. If you need the blanking to take immediate effect on the same cycle as a combinational signal (e.g. locking asserted combinatorially), choose carefully whether to use locking or locking_q  the existing code uses locking_q when assembling rdata_bus to ensure timing, so review exactly which form you want to depend on for en_d. The assertions use both styles (`|-> !imem_rdata_bus_en_q` for imem_access_core and `|=> !imem_rdata_bus_en_q` for locking), so setting en_d = ~(imem_access_core | imem_dummy_response_d | locking) should satisfy the intent (locking is combinational and will cause en_q to be cleared next cycle).

2. Add/update comments to make the required relationship explicit, and make sure assertions reflect exact register/clocking behavior.

3. Re-run formal/sim checks (the existing assertions will catch mismatches). Ensure prim_blanker semantics are documented and understood in the code so en=0 really blanks (not the other way around).

Suggested minimal code replace example
(Replace the unconditional assignments with logic computing en_d; adapt to your style/clocking needs)

  // instead of: assign imem_rdata_bus_en_d = 1'b1;
  assign imem_rdata_bus_en_d = ~(imem_access_core | imem_dummy_response_d | locking);

  // instead of: assign dmem_rdata_bus_en_d = 1'b1;
  assign dmem_rdata_bus_en_d = ~(dmem_access_core | dmem_dummy_response_d | locking);

(If you want the blanking to go into effect one cycle earlier/later, use locking_q or dummy_response_q variants  but ensure the assertions are matched to that timing.)

Other notes from the clusters
- The detector showed many repetitive assign lines; none of the other assignments stood out as contradictory to their comments/intent  e.g. imem/dmem always-grant to bus (imem_gnt_bus = imem_req_bus etc.) is an intentional design choice (they return dummy responses instead of blocking the bus), and other error/miss logic (illegal_bus_access, missed_gnt_error) are consistent and used elsewhere.
- There are a few slices/manipulations of ECC bits and raw data which are consistent with the blanker/ECC logic; those look intentional.

Summary
- The unconditional imem_rdata_bus_en_d = 1'b1 and dmem_rdata_bus_en_d = 1'b1 are anomalous and are a likely security bug (data leakage, high severity). They should be replaced with combinational logic that disables pass-through when the core is accessing the memory, when a dummy response is being returned, and when the design is locked. After making that change, re-run the existing assertions/formal checks to validate the behaviour.
================================== Ai Message ==================================
Tool Calls:
  run_similar_bug_agent (call_iuJAHFaslm4FadDuKTtAbz46)
 Call ID: call_iuJAHFaslm4FadDuKTtAbz46
  Args:
    bug: assign imem_rdata_bus_en_d = 1'b1;
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv
================================ Human Message =================================

This bug was previously found in another file of this design:
    assign imem_rdata_bus_en_d = 1'b1;
    
    Please check the RTL code in the file /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv for similar bugs.
================================ Human Message =================================

This bug was previously found in another file of this design:
    assign imem_rdata_bus_en_d = 1'b1;
    
    Please check the RTL code in the file /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv for similar bugs.
================================== Ai Message ==================================

[{'text': "I'll help you find similar bugs in the specified file. I'll use the similar_bug_tool to search for lines that match the given bug pattern.", 'type': 'text'}, {'id': 'toolu_015GyjCiSjiP8SpNf8UWBEKt', 'input': {'bug': "assign imem_rdata_bus_en_d = 1'b1;", 'ip_file': '/home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv'}, 'name': 'similar_bug_tool', 'type': 'tool_use'}]
Tool Calls:
  similar_bug_tool (toolu_015GyjCiSjiP8SpNf8UWBEKt)
 Call ID: toolu_015GyjCiSjiP8SpNf8UWBEKt
  Args:
    bug: assign imem_rdata_bus_en_d = 1'b1;
    ip_file: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv
================================= Tool Message =================================
Name: similar_bug_tool


Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 448: assign imem_rdata_bus_en_d = 1'b1;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 690: assign dmem_rdata_bus_en_d = 1'b1;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 452: imem_rdata_bus_en_q <= 1'b1;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 694: dmem_rdata_bus_en_q <= 1'b1;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 264: logic imem_rdata_bus_en_q, imem_rdata_bus_en_d;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 454: 
        imem_rdata_bus_en_q <= imem_rdata_bus_en_d;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 378: assign imem_gnt_bus = imem_req_bus;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 460: .en_i (imem_rdata_bus_en_q),
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 534: logic dmem_rdata_bus_en_q, dmem_rdata_bus_en_d;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 1393: |-> imem_rdata_bus == 'd0)
================================= Tool Message =================================
Name: similar_bug_tool


Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 448: assign imem_rdata_bus_en_d = 1'b1;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 690: assign dmem_rdata_bus_en_d = 1'b1;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 452: imem_rdata_bus_en_q <= 1'b1;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 694: dmem_rdata_bus_en_q <= 1'b1;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 264: logic imem_rdata_bus_en_q, imem_rdata_bus_en_d;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 454: 
        imem_rdata_bus_en_q <= imem_rdata_bus_en_d;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 378: assign imem_gnt_bus = imem_req_bus;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 460: .en_i (imem_rdata_bus_en_q),
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 534: logic dmem_rdata_bus_en_q, dmem_rdata_bus_en_d;
Found similar bug in /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv at line 1393: |-> imem_rdata_bus == 'd0)
================================== Ai Message ==================================

[{'text': 'Let me verify the context of these lines by reading the file:', 'type': 'text'}, {'id': 'toolu_01CkBxotkAmZUUHNUW5M8B6d', 'input': {'file_path': '/home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv'}, 'name': 'read_file_with_line_numbers', 'type': 'tool_use'}]
Tool Calls:
  read_file_with_line_numbers (toolu_01CkBxotkAmZUUHNUW5M8B6d)
 Call ID: toolu_01CkBxotkAmZUUHNUW5M8B6d
  Args:
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv
================================= Tool Message =================================
Name: read_file_with_line_numbers

1: // Copyright lowRISC contributors (OpenTitan project).
2: // Licensed under the Apache License, Version 2.0, see LICENSE for details.
3: // SPDX-License-Identifier: Apache-2.0
4: 
5: `include "prim_assert.sv"
6: `include "prim_fifo_assert.svh"
7: 
8: /**
9:  * OpenTitan Big Number Accelerator (OTBN)
10:  */
11: module otbn
12:   import prim_alert_pkg::*;
13:   import otbn_pkg::*;
14:   import otbn_reg_pkg::*;
15: #(
16:   parameter bit                   Stub         = 1'b0,
17:   parameter regfile_e             RegFile      = RegFileFF,
18:   parameter logic [NumAlerts-1:0] AlertAsyncOn = {NumAlerts{1'b1}},
19: 
20:   // Default seed for URND PRNG
21:   parameter urnd_prng_seed_t RndCnstUrndPrngSeed = RndCnstUrndPrngSeedDefault,
22: 
23:   // Disable URND advance when not in use. Useful for SCA only.
24:   parameter bit SecMuteUrnd = 1'b0,
25:   // Skip URND re-seed at the start of an operation. Useful for SCA only.
26:   parameter bit SecSkipUrndReseedAtStart = 1'b0,
27: 
28:   // Default seed and nonce for scrambling
29:   parameter otp_ctrl_pkg::otbn_key_t   RndCnstOtbnKey   = RndCnstOtbnKeyDefault,
30:   parameter otp_ctrl_pkg::otbn_nonce_t RndCnstOtbnNonce = RndCnstOtbnNonceDefault
31: ) (
32:   input clk_i,
33:   input rst_ni,
34: 
35:   input  tlul_pkg::tl_h2d_t tl_i,
36:   output tlul_pkg::tl_d2h_t tl_o,
37: 
38:   // Inter-module signals
39:   output prim_mubi_pkg::mubi4_t idle_o,
40: 
41:   // Interrupts
42:   output logic intr_done_o,
43: 
44:   // Alerts
45:   input  prim_alert_pkg::alert_rx_t [NumAlerts-1:0] alert_rx_i,
46:   output prim_alert_pkg::alert_tx_t [NumAlerts-1:0] alert_tx_o,
47: 
48:   // Lifecycle interfaces
49:   input  lc_ctrl_pkg::lc_tx_t lc_escalate_en_i,
50: 
51:   input  lc_ctrl_pkg::lc_tx_t lc_rma_req_i,
52:   output lc_ctrl_pkg::lc_tx_t lc_rma_ack_o,
53: 
54:   // Memory configuration
55:   input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_imem_i,
56:   input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_dmem_i,
57:   output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_imem_o,
58:   output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_dmem_o,
59: 
60:   // EDN clock and interface
61:   input                     clk_edn_i,
62:   input                     rst_edn_ni,
63:   output edn_pkg::edn_req_t edn_rnd_o,
64:   input  edn_pkg::edn_rsp_t edn_rnd_i,
65: 
66:   output edn_pkg::edn_req_t edn_urnd_o,
67:   input  edn_pkg::edn_rsp_t edn_urnd_i,
68: 
69:   // Key request to OTP (running on clk_fixed)
70:   input                                   clk_otp_i,
71:   input                                   rst_otp_ni,
72:   output otp_ctrl_pkg::otbn_otp_key_req_t otbn_otp_key_o,
73:   input  otp_ctrl_pkg::otbn_otp_key_rsp_t otbn_otp_key_i,
74: 
75:   input keymgr_pkg::otbn_key_req_t keymgr_key_i
76: );
77: 
78:   import prim_mubi_pkg::*;
79:   import prim_util_pkg::vbits;
80: 
81:   logic rst_n;
82: 
83:   // hold module in reset permanently when stubbing
84:   if (Stub) begin : gen_stub_otbn
85:     assign rst_n = 1'b0;
86:   end else begin : gen_real_otbn
87:     assign rst_n = rst_ni;
88:   end
89: 
90:   // The OTBN_*_SIZE parameters are auto-generated by regtool and come from the bus window sizes;
91:   // they are given in bytes and must be powers of two.
92:   //
93:   // DMEM is actually a bit bigger than OTBN_DMEM_SIZE: there are an extra DmemScratchSizeByte bytes
94:   // that aren't accessible over the bus.
95:   localparam int ImemSizeByte = int'(otbn_reg_pkg::OTBN_IMEM_SIZE);
96:   localparam int DmemSizeByte = int'(otbn_reg_pkg::OTBN_DMEM_SIZE + DmemScratchSizeByte);
97: 
98:   localparam int ImemAddrWidth = vbits(ImemSizeByte);
99:   localparam int DmemAddrWidth = vbits(DmemSizeByte);
100: 
101:   `ASSERT_INIT(ImemSizePowerOfTwo, 2 ** ImemAddrWidth == ImemSizeByte)
102:   `ASSERT_INIT(DmemSizePowerOfTwo, 2 ** DmemAddrWidth == DmemSizeByte)
103: 
104:   logic start_d, start_q;
105:   logic busy_execute_d, busy_execute_q;
106:   logic done, done_core, locking, locking_q;
107:   logic busy_secure_wipe;
108:   logic init_sec_wipe_done_d, init_sec_wipe_done_q;
109:   logic illegal_bus_access_d, illegal_bus_access_q;
110:   logic missed_gnt_error_d, missed_gnt_error_q;
111:   logic dmem_sec_wipe;
112:   logic imem_sec_wipe;
113:   logic mems_sec_wipe;
114:   logic req_sec_wipe_urnd_keys;
115:   logic [127:0] dmem_sec_wipe_urnd_key, imem_sec_wipe_urnd_key;
116: 
117:   logic core_recoverable_err, recoverable_err_d, recoverable_err_q;
118:   mubi4_t core_escalate_en;
119: 
120:   core_err_bits_t     core_err_bits;
121:   non_core_err_bits_t non_core_err_bits, non_core_err_bits_d, non_core_err_bits_q;
122:   err_bits_t          err_bits, err_bits_d, err_bits_q;
123:   logic               err_bits_en;
124: 
125:   // ERR_BITS register should be cleared due to a write request from the host processor
126:   // when OTBN is not running.
127:   logic err_bits_clear;
128: 
129:   logic software_errs_fatal_q, software_errs_fatal_d;
130: 
131:   otbn_reg2hw_t reg2hw;
132:   otbn_hw2reg_t hw2reg;
133:   status_e      status_d, status_q;
134: 
135:   // Bus device windows, as specified in otbn.hjson
136:   typedef enum logic {
137:     TlWinImem = 1'b0,
138:     TlWinDmem = 1'b1
139:   } tl_win_e;
140: 
141:   tlul_pkg::tl_h2d_t tl_win_h2d[2];
142:   tlul_pkg::tl_d2h_t tl_win_d2h[2];
143: 
144:   // The clock can be gated and some registers can be updated as long as OTBN isn't currently
145:   // running. Other registers can only be updated when OTBN is in the Idle state (which also implies
146:   // we are not locked).
147:   logic is_not_running_d, is_not_running_q;
148:   logic otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy;
149: 
150:   assign is_not_running_d = ~|{busy_execute_d,
151:                                otbn_dmem_scramble_key_req_busy,
152:                                otbn_imem_scramble_key_req_busy,
153:                                busy_secure_wipe};
154: 
155:   always_ff @(posedge clk_i or negedge rst_ni) begin
156:     if(!rst_ni) begin
157:       // OTBN starts busy, performing the initial secure wipe.
158:       is_not_running_q  <= 1'b0;
159:     end else begin
160:       is_not_running_q  <= is_not_running_d;
161:     end
162:   end
163: 
164:   // Inter-module signals ======================================================
165: 
166:   // Note: This is not the same thing as STATUS == IDLE. For example, we want to allow clock gating
167:   // when locked.
168:   prim_mubi4_sender #(
169:     .ResetValue(prim_mubi_pkg::MuBi4True)
170:   ) u_prim_mubi4_sender (
171:     .clk_i,
172:     .rst_ni,
173:     .mubi_i(mubi4_bool_to_mubi(is_not_running_q)),
174:     .mubi_o(idle_o)
175:   );
176: 
177:   // Lifecycle ==================================================================
178: 
179:   localparam int unsigned LcEscalateCopies = 2;
180:   lc_ctrl_pkg::lc_tx_t [LcEscalateCopies-1:0] lc_escalate_en;
181:   prim_lc_sync #(
182:     .NumCopies(LcEscalateCopies)
183:   ) u_lc_escalate_en_sync (
184:     .clk_i,
185:     .rst_ni,
186:     .lc_en_i(lc_escalate_en_i),
187:     .lc_en_o(lc_escalate_en)
188:   );
189: 
190:   lc_ctrl_pkg::lc_tx_t lc_rma_req;
191:   prim_lc_sync #(
192:     .NumCopies(1)
193:   ) u_lc_rma_req_sync (
194:     .clk_i,
195:     .rst_ni,
196:     .lc_en_i(lc_rma_req_i),
197:     .lc_en_o({lc_rma_req})
198:   );
199: 
200:   // Internally, OTBN uses MUBI types.
201:   mubi4_t mubi_rma_req, mubi_rma_ack;
202:   assign mubi_rma_req = lc_ctrl_pkg::lc_to_mubi4(lc_rma_req);
203: 
204:   // When stubbing, forward req to ack.
205:   if (Stub) begin : gen_stub_rma_ack
206:     assign lc_rma_ack_o = lc_rma_req;
207:   end else begin : gen_real_rma_ack
208:     assign lc_rma_ack_o = lc_ctrl_pkg::mubi4_to_lc(mubi_rma_ack);
209:   end
210: 
211:   // Interrupts ================================================================
212: 
213:   assign done = is_busy_status(status_q) & ~is_busy_status(status_d) & init_sec_wipe_done_q;
214: 
215:   prim_intr_hw #(
216:     .Width(1)
217:   ) u_intr_hw_done (
218:     .clk_i,
219:     .rst_ni                (rst_n),
220:     .event_intr_i          (done),
221:     .reg2hw_intr_enable_q_i(reg2hw.intr_enable.q),
222:     .reg2hw_intr_test_q_i  (reg2hw.intr_test.q),
223:     .reg2hw_intr_test_qe_i (reg2hw.intr_test.qe),
224:     .reg2hw_intr_state_q_i (reg2hw.intr_state.q),
225:     .hw2reg_intr_state_de_o(hw2reg.intr_state.de),
226:     .hw2reg_intr_state_d_o (hw2reg.intr_state.d),
227:     .intr_o                (intr_done_o)
228:   );
229: 
230:   // Instruction Memory (IMEM) =================================================
231: 
232:   localparam int ImemSizeWords = ImemSizeByte / 4;
233:   localparam int ImemIndexWidth = vbits(ImemSizeWords);
234: 
235:   // Access select to IMEM: core (1), or bus (0)
236:   logic imem_access_core;
237: 
238:   logic imem_req;
239:   logic imem_gnt;
240:   logic imem_write;
241:   logic imem_wr_collision;
242:   logic imem_wpending;
243:   logic [ImemIndexWidth-1:0] imem_index;
244:   logic [38:0] imem_wdata;
245:   logic [38:0] imem_wmask;
246:   logic [38:0] imem_rdata;
247:   logic imem_rvalid;
248:   logic imem_illegal_bus_access;
249:   logic imem_missed_gnt;
250: 
251:   logic imem_req_core;
252:   logic imem_write_core;
253:   logic [ImemIndexWidth-1:0] imem_index_core;
254:   logic [38:0] imem_rdata_core;
255:   logic imem_rvalid_core;
256: 
257:   logic imem_req_bus;
258:   logic imem_dummy_response_q, imem_dummy_response_d;
259:   logic imem_write_bus;
260:   logic [ImemIndexWidth-1:0] imem_index_bus;
261:   logic [38:0] imem_wdata_bus;
262:   logic [38:0] imem_wmask_bus;
263:   logic [38:0] imem_rdata_bus, imem_rdata_bus_raw;
264:   logic imem_rdata_bus_en_q, imem_rdata_bus_en_d;
265:   logic [top_pkg::TL_DBW-1:0] imem_byte_mask_bus;
266:   logic imem_rvalid_bus;
267:   logic [1:0] imem_rerror_bus;
268: 
269:   logic imem_bus_intg_violation;
270: 
271:   typedef struct packed {
272:     logic        imem;
273:     logic [14:0] index;
274:     logic [31:0] wr_data;
275:   } mem_crc_data_in_t;
276: 
277:   logic             mem_crc_data_in_valid;
278:   mem_crc_data_in_t mem_crc_data_in;
279:   logic             set_crc;
280:   logic [31:0]      crc_in, crc_out;
281: 
282:   logic [ImemAddrWidth-1:0] imem_addr_core;
283:   assign imem_index_core = imem_addr_core[ImemAddrWidth-1:2];
284: 
285:   logic [1:0] unused_imem_addr_core_wordbits;
286:   assign unused_imem_addr_core_wordbits = imem_addr_core[1:0];
287: 
288:   otp_ctrl_pkg::otbn_key_t otbn_imem_scramble_key;
289:   otbn_imem_nonce_t        otbn_imem_scramble_nonce;
290:   logic                    otbn_imem_scramble_valid;
291:   logic                    unused_otbn_imem_scramble_key_seed_valid;
292: 
293:   otp_ctrl_pkg::otbn_key_t otbn_dmem_scramble_key;
294:   otbn_dmem_nonce_t        otbn_dmem_scramble_nonce;
295:   logic                    otbn_dmem_scramble_valid;
296:   logic                    unused_otbn_dmem_scramble_key_seed_valid;
297: 
298: 
299:   logic otbn_scramble_state_error;
300: 
301:   // SEC_CM: SCRAMBLE.KEY.SIDELOAD
302:   otbn_scramble_ctrl #(
303:     .RndCnstOtbnKey  (RndCnstOtbnKey),
304:     .RndCnstOtbnNonce(RndCnstOtbnNonce)
305:   ) u_otbn_scramble_ctrl (
306:     .clk_i,
307:     .rst_ni,
308: 
309:     .clk_otp_i,
310:     .rst_otp_ni,
311: 
312:     .otbn_otp_key_o,
313:     .otbn_otp_key_i,
314: 
315:     .otbn_dmem_scramble_key_o           (otbn_dmem_scramble_key),
316:     .otbn_dmem_scramble_nonce_o         (otbn_dmem_scramble_nonce),
317:     .otbn_dmem_scramble_valid_o         (otbn_dmem_scramble_valid),
318:     .otbn_dmem_scramble_key_seed_valid_o(unused_otbn_dmem_scramble_key_seed_valid),
319: 
320:     .otbn_imem_scramble_key_o           (otbn_imem_scramble_key),
321:     .otbn_imem_scramble_nonce_o         (otbn_imem_scramble_nonce),
322:     .otbn_imem_scramble_valid_o         (otbn_imem_scramble_valid),
323:     .otbn_imem_scramble_key_seed_valid_o(unused_otbn_imem_scramble_key_seed_valid),
324: 
325:     .otbn_dmem_scramble_sec_wipe_i    (dmem_sec_wipe),
326:     .otbn_dmem_scramble_sec_wipe_key_i(dmem_sec_wipe_urnd_key),
327:     .otbn_imem_scramble_sec_wipe_i    (imem_sec_wipe),
328:     .otbn_imem_scramble_sec_wipe_key_i(imem_sec_wipe_urnd_key),
329: 
330:     .otbn_dmem_scramble_key_req_busy_o(otbn_dmem_scramble_key_req_busy),
331:     .otbn_imem_scramble_key_req_busy_o(otbn_imem_scramble_key_req_busy),
332: 
333:     .state_error_o(otbn_scramble_state_error)
334:   );
335: 
336:   // SEC_CM: MEM.SCRAMBLE
337:   prim_ram_1p_scr #(
338:     .Width          (39),
339:     .Depth          (ImemSizeWords),
340:     .InstDepth      (ImemSizeWords),
341:     .DataBitsPerMask(39),
342:     .EnableParity   (0)
343:   ) u_imem (
344:     .clk_i,
345:     .rst_ni(rst_n),
346: 
347:     .key_valid_i(otbn_imem_scramble_valid),
348:     .key_i      (otbn_imem_scramble_key),
349:     .nonce_i    (otbn_imem_scramble_nonce),
350: 
351:     .req_i       (imem_req),
352:     .gnt_o       (imem_gnt),
353:     .write_i     (imem_write),
354:     .addr_i      (imem_index),
355:     .wdata_i     (imem_wdata),
356:     .wmask_i     (imem_wmask),
357:     .intg_error_i(locking),
358: 
359:     .rdata_o  (imem_rdata),
360:     .rvalid_o (imem_rvalid),
361:     .raddr_o  (),
362:     .rerror_o (),
363:     .cfg_i    (ram_cfg_imem_i),
364:     .cfg_rsp_o(ram_cfg_rsp_imem_o),
365: 
366:     .wr_collision_o   (imem_wr_collision),
367:     .write_pending_o  (imem_wpending),
368: 
369:     .alert_o ()
370:   );
371: 
372:   // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
373:   assign imem_missed_gnt = imem_req & ~imem_gnt;
374: 
375:   // IMEM access from main TL-UL bus
376:   logic imem_gnt_bus;
377:   // Always grant to bus accesses, when OTBN is running a dummy response is returned
378:   assign imem_gnt_bus = imem_req_bus;
379: 
380:   tlul_adapter_sram #(
381:     .SramAw          (ImemIndexWidth),
382:     .SramDw          (32),
383:     .Outstanding     (1),
384:     .ByteAccess      (0),
385:     .ErrOnRead       (0),
386:     .EnableDataIntgPt(1),
387:     .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
388:   ) u_tlul_adapter_sram_imem (
389:     .clk_i,
390:     .rst_ni                     (rst_n),
391:     .tl_i                       (tl_win_h2d[TlWinImem]),
392:     .tl_o                       (tl_win_d2h[TlWinImem]),
393:     .en_ifetch_i                (MuBi4False),
394:     .req_o                      (imem_req_bus),
395:     .req_type_o                 (),
396:     .gnt_i                      (imem_gnt_bus),
397:     .we_o                       (imem_write_bus),
398:     .addr_o                     (imem_index_bus),
399:     .wdata_o                    (imem_wdata_bus),
400:     .wmask_o                    (imem_wmask_bus),
401:     .intg_error_o               (imem_bus_intg_violation),
402:     .user_rsvd_o                (),
403:     .rdata_i                    (imem_rdata_bus),
404:     .rvalid_i                   (imem_rvalid_bus),
405:     .rerror_i                   (imem_rerror_bus),
406:     .compound_txn_in_progress_o (),
407:     .readback_en_i              (prim_mubi_pkg::MuBi4False),
408:     .readback_error_o           (),
409:     .wr_collision_i             (imem_wr_collision),
410:     .write_pending_i            (imem_wpending)
411:   );
412: 
413: 
414:   // Mux core and bus access into IMEM
415:   assign imem_access_core = busy_execute_q | start_q;
416: 
417:   assign imem_req   = imem_access_core ? imem_req_core        : imem_req_bus;
418:   assign imem_write = imem_access_core ? imem_write_core      : imem_write_bus;
419:   assign imem_index = imem_access_core ? imem_index_core      : imem_index_bus;
420:   assign imem_wdata = imem_access_core ? '0                   : imem_wdata_bus;
421: 
422:   assign imem_illegal_bus_access = imem_req_bus & imem_access_core;
423: 
424:   assign imem_dummy_response_d = imem_illegal_bus_access;
425:   always_ff @(posedge clk_i or negedge rst_ni) begin
426:     if (!rst_ni) begin
427:       imem_dummy_response_q <= 1'b0;
428:     end else begin
429:       imem_dummy_response_q <= imem_dummy_response_d;
430:     end
431:   end
432: 
433:   // The instruction memory only supports 32b word writes, so we hardcode its
434:   // wmask here.
435:   //
436:   // Since this could cause confusion if the bus tried to do a partial write
437:   // (which wasn't caught in the TLUL adapter for some reason), we assert that
438:   // the wmask signal from the bus is indeed '1 when it requests a write. We
439:   // don't have the corresponding check for writes from the core because the
440:   // core cannot perform writes (and has no imem_wmask_o port).
441:   assign imem_wmask = imem_access_core ? '1 : imem_wmask_bus;
442:   `ASSERT(ImemWmaskBusIsFullWord_A, imem_req_bus && imem_write_bus |-> imem_wmask_bus == '1)
443: 
444:   // SEC_CM: DATA_REG_SW.SCA
445:   // Blank bus read data interface during core operation to avoid leaking the currently executed
446:   // instruction from IMEM through the bus unintentionally. Also blank when OTBN is returning
447:   // a dummy response (responding to an illegal bus access) and when OTBN is locked.
448:   assign imem_rdata_bus_en_d = 1'b1;
449: 
450:   always_ff @(posedge clk_i or negedge rst_ni) begin
451:     if (!rst_ni) begin
452:         imem_rdata_bus_en_q <= 1'b1;
453:     end else begin
454:         imem_rdata_bus_en_q <= imem_rdata_bus_en_d;
455:     end
456:   end
457: 
458:   prim_blanker #(.Width(39)) u_imem_rdata_bus_blanker (
459:     .in_i (imem_rdata),
460:     .en_i (imem_rdata_bus_en_q),
461:     .out_o(imem_rdata_bus_raw)
462:   );
463: 
464:   // When OTBN is locked all imem bus reads should return 0. The blanker produces the 0s, this adds
465:   // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
466:   // through. Data bits are always left un-modified. A registered version of `locking` is used for
467:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
468:   // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
469:   // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
470:   // in so it is reasonable to proceed with returning the supplied integrity.
471:   assign imem_rdata_bus =
472:     {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : imem_rdata_bus_raw[38:32],
473:      imem_rdata_bus_raw[31:0]};
474: 
475:   `ASSERT(ImemRDataBusDisabledWhenCoreAccess_A, imem_access_core |-> !imem_rdata_bus_en_q)
476:   `ASSERT(ImemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> imem_rdata_bus_en_q)
477:   `ASSERT(ImemRDataBusDisabledWhenLocked_A, locking |=> !imem_rdata_bus_en_q)
478:   `ASSERT(ImemRDataBusReadAsZeroWhenLocked_A,
479:     imem_rvalid_bus & locking |-> imem_rdata_bus_raw == '0)
480: 
481:   assign imem_rdata_core = imem_rdata;
482: 
483:   // When an illegal bus access is seen, always return a dummy response the follow cycle.
484:   assign imem_rvalid_bus = (~imem_access_core & imem_rvalid) | imem_dummy_response_q;
485:   assign imem_rvalid_core = imem_access_core ? imem_rvalid : 1'b0;
486: 
487:   assign imem_byte_mask_bus = tl_win_h2d[TlWinImem].a_mask;
488: 
489:   // No imem errors reported for bus reads. Integrity is carried through on the bus so integrity
490:   // checking on TL responses will pick up any errors.
491:   assign imem_rerror_bus = 2'b00;
492: 
493:   // Data Memory (DMEM) ========================================================
494: 
495:   localparam int DmemSizeWords = DmemSizeByte / (WLEN / 8);
496:   localparam int DmemIndexWidth = vbits(DmemSizeWords);
497: 
498:   localparam int DmemBusSizeWords = int'(otbn_reg_pkg::OTBN_DMEM_SIZE) / (WLEN / 8);
499:   localparam int DmemBusIndexWidth = vbits(DmemBusSizeWords);
500: 
501:   // Access select to DMEM: core (1), or bus (0)
502:   logic dmem_access_core;
503: 
504:   logic dmem_req;
505:   logic dmem_gnt;
506:   logic dmem_write;
507:   logic [DmemIndexWidth-1:0] dmem_index;
508:   logic [ExtWLEN-1:0] dmem_wdata;
509:   logic [ExtWLEN-1:0] dmem_wmask;
510:   logic [ExtWLEN-1:0] dmem_rdata;
511:   logic dmem_rvalid;
512:   logic [BaseWordsPerWLEN*2-1:0] dmem_rerror_vec;
513:   logic dmem_rerror;
514:   logic dmem_illegal_bus_access;
515:   logic dmem_missed_gnt;
516: 
517:   logic dmem_req_core;
518:   logic dmem_write_core;
519:   logic [DmemIndexWidth-1:0] dmem_index_core;
520:   logic [ExtWLEN-1:0] dmem_wdata_core;
521:   logic [ExtWLEN-1:0] dmem_wmask_core;
522:   logic [BaseWordsPerWLEN-1:0] dmem_rmask_core_q, dmem_rmask_core_d;
523:   logic [ExtWLEN-1:0] dmem_rdata_core;
524:   logic dmem_rvalid_core;
525:   logic dmem_rerror_core;
526: 
527:   logic dmem_req_bus;
528:   logic dmem_dummy_response_q, dmem_dummy_response_d;
529:   logic dmem_write_bus;
530:   logic [DmemBusIndexWidth-1:0] dmem_index_bus;
531:   logic [ExtWLEN-1:0] dmem_wdata_bus;
532:   logic [ExtWLEN-1:0] dmem_wmask_bus;
533:   logic [ExtWLEN-1:0] dmem_rdata_bus, dmem_rdata_bus_raw;
534:   logic dmem_rdata_bus_en_q, dmem_rdata_bus_en_d;
535:   logic [DmemAddrWidth-1:0] dmem_addr_bus;
536:   logic unused_dmem_addr_bus;
537:   logic [31:0] dmem_wdata_narrow_bus;
538:   logic [top_pkg::TL_DBW-1:0] dmem_byte_mask_bus;
539:   logic dmem_rvalid_bus;
540:   logic dmem_wr_collision;
541:   logic dmem_wpending;
542:   logic [1:0] dmem_rerror_bus;
543: 
544:   logic dmem_bus_intg_violation;
545: 
546:   logic [DmemAddrWidth-1:0] dmem_addr_core;
547:   assign dmem_index_core = dmem_addr_core[DmemAddrWidth-1:DmemAddrWidth-DmemIndexWidth];
548: 
549:   logic unused_dmem_addr_core_wordbits;
550:   assign unused_dmem_addr_core_wordbits = ^dmem_addr_core[DmemAddrWidth-DmemIndexWidth-1:0];
551: 
552:   // SEC_CM: MEM.SCRAMBLE
553:   prim_ram_1p_scr #(
554:     .Width             (ExtWLEN),
555:     .Depth             (DmemSizeWords),
556:     .InstDepth         (DmemSizeWords),
557:     .DataBitsPerMask   (39),
558:     .EnableParity      (0),
559:     .ReplicateKeyStream(1)
560:   ) u_dmem (
561:     .clk_i,
562:     .rst_ni(rst_n),
563: 
564:     .key_valid_i(otbn_dmem_scramble_valid),
565:     .key_i      (otbn_dmem_scramble_key),
566:     .nonce_i    (otbn_dmem_scramble_nonce),
567: 
568:     .req_i       (dmem_req),
569:     .gnt_o       (dmem_gnt),
570:     .write_i     (dmem_write),
571:     .addr_i      (dmem_index),
572:     .wdata_i     (dmem_wdata),
573:     .wmask_i     (dmem_wmask),
574:     .intg_error_i(locking),
575: 
576:     .rdata_o  (dmem_rdata),
577:     .rvalid_o (dmem_rvalid),
578:     .raddr_o  (),
579:     .rerror_o (),
580:     .cfg_i    (ram_cfg_dmem_i),
581:     .cfg_rsp_o(ram_cfg_rsp_dmem_o),
582: 
583:     .wr_collision_o   (dmem_wr_collision),
584:     .write_pending_o  (dmem_wpending),
585: 
586:     .alert_o ()
587:   );
588: 
589:   // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
590:   assign dmem_missed_gnt = dmem_req & !dmem_gnt;
591: 
592:   always_ff @(posedge clk_i or negedge rst_ni) begin
593:     if (!rst_ni) begin
594:       dmem_rmask_core_q <= '0;
595:     end else begin
596:       if (dmem_req_core) begin
597:         dmem_rmask_core_q <= dmem_rmask_core_d;
598:       end
599:     end
600:   end
601: 
602:   // SEC_CM: DATA.MEM.INTEGRITY
603:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_intg_check
604:     logic [1:0] dmem_rerror_raw;
605: 
606:     // Separate check for dmem read data integrity outside of `u_dmem` as `prim_ram_1p_adv` doesn't
607:     // have functionality for only integrity checking, just fully integrated ECC. Integrity bits are
608:     // implemented on a 32-bit granule so separate checks are required for each.
609:     prim_secded_inv_39_32_dec u_dmem_intg_check (
610:       .data_i    (dmem_rdata[i_word*39+:39]),
611:       .data_o    (),
612:       .syndrome_o(),
613:       .err_o     (dmem_rerror_raw)
614:     );
615: 
616:     // Only report an error where the word was actually accessed. Otherwise uninitialised memory
617:     // that OTBN isn't using will cause false errors. dmem_rerror is only reported for reads from
618:     // OTBN. For Ibex reads integrity checking on TL responses will serve the same purpose.
619:     assign dmem_rerror_vec[i_word*2 +: 2] = {2{dmem_rmask_core_q[i_word] & dmem_rvalid & dmem_access_core}};
620:   end
621: 
622:   // dmem_rerror_vec is 2 bits wide and is used to report ECC errors. Bit 1 is set if there's an
623:   // uncorrectable error and bit 0 is set if there's a correctable error. However, we're treating
624:   // all errors as fatal, so OR the two signals together.
625:   assign dmem_rerror = |dmem_rerror_vec;
626: 
627:   // DMEM access from main TL-UL bus
628:   logic dmem_gnt_bus;
629:   // Always grant to bus accesses, when OTBN is running a dummy response is returned
630:   assign dmem_gnt_bus = dmem_req_bus;
631: 
632:   tlul_adapter_sram #(
633:     .SramAw          (DmemBusIndexWidth),
634:     .SramDw          (WLEN),
635:     .Outstanding     (1),
636:     .ByteAccess      (0),
637:     .ErrOnRead       (0),
638:     .EnableDataIntgPt(1),
639:     .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
640:   ) u_tlul_adapter_sram_dmem (
641:     .clk_i,
642:     .rst_ni                     (rst_n),
643:     .tl_i                       (tl_win_h2d[TlWinDmem]),
644:     .tl_o                       (tl_win_d2h[TlWinDmem]),
645:     .en_ifetch_i                (MuBi4False),
646:     .req_o                      (dmem_req_bus),
647:     .req_type_o                 (),
648:     .gnt_i                      (dmem_gnt_bus),
649:     .we_o                       (dmem_write_bus),
650:     .addr_o                     (dmem_index_bus),
651:     .wdata_o                    (dmem_wdata_bus),
652:     .wmask_o                    (dmem_wmask_bus),
653:     .intg_error_o               (dmem_bus_intg_violation),
654:     .user_rsvd_o                (),
655:     .rdata_i                    (dmem_rdata_bus),
656:     .rvalid_i                   (dmem_rvalid_bus),
657:     .rerror_i                   (dmem_rerror_bus),
658:     .compound_txn_in_progress_o (),
659:     .readback_en_i              (prim_mubi_pkg::MuBi4False),
660:     .readback_error_o           (),
661:     .wr_collision_i             (dmem_wr_collision),
662:     .write_pending_i            (dmem_wpending)
663:   );
664: 
665:   // Mux core and bus access into dmem
666:   assign dmem_access_core = busy_execute_q;
667: 
668:   assign dmem_req = dmem_access_core ? dmem_req_core : dmem_req_bus;
669:   assign dmem_write = dmem_access_core ? dmem_write_core : dmem_write_bus;
670:   assign dmem_wmask = dmem_access_core ? dmem_wmask_core : dmem_wmask_bus;
671:   // SEC_CM: DATA.MEM.SW_NOACCESS
672:   assign dmem_index = dmem_access_core ? dmem_index_core : dmem_index_bus;
673:   assign dmem_wdata = dmem_access_core ? dmem_wdata_core : dmem_wdata_bus;
674: 
675:   assign dmem_illegal_bus_access = dmem_req_bus & dmem_access_core;
676: 
677:   assign dmem_dummy_response_d = dmem_illegal_bus_access;
678:   always_ff @(posedge clk_i or negedge rst_ni) begin
679:     if (!rst_ni) begin
680:       dmem_dummy_response_q <= 1'b0;
681:     end else begin
682:       dmem_dummy_response_q <= dmem_dummy_response_d;
683:     end
684:   end
685: 
686:   // SEC_CM: DATA_REG_SW.SCA
687:   // Blank bus read data interface during core operation to avoid leaking DMEM data through the bus
688:   // unintentionally. Also blank when OTBN is returning a dummy response (responding to an illegal
689:   // bus access) and when OTBN is locked.
690:   assign dmem_rdata_bus_en_d = 1'b1;
691: 
692:   always_ff @(posedge clk_i or negedge rst_ni) begin
693:     if (!rst_ni) begin
694:         dmem_rdata_bus_en_q <= 1'b1;
695:     end else begin
696:         dmem_rdata_bus_en_q <= dmem_rdata_bus_en_d;
697:     end
698:   end
699: 
700:   prim_blanker #(.Width(ExtWLEN)) u_dmem_rdata_bus_blanker (
701:     .in_i (dmem_rdata),
702:     .en_i (dmem_rdata_bus_en_q),
703:     .out_o(dmem_rdata_bus_raw)
704:   );
705: 
706:   // When OTBN is locked all dmem bus reads should return 0. The blanker produces the 0s, this adds
707:   // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
708:   // through. Data bits are always left un-modified. A registered version of `locking` is used for
709:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
710:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
711:   // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
712:   // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
713:   // in so it is reasonable to proceed with returning the supplied integrity.
714:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_rdata_bus
715:     assign dmem_rdata_bus[i_word*39+:39] =
716:       {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : dmem_rdata_bus_raw[i_word*39+32+:7],
717:        dmem_rdata_bus_raw[i_word*39+:32]};
718:   end
719: 
720:   `ASSERT(DmemRDataBusDisabledWhenCoreAccess_A, dmem_access_core |-> !dmem_rdata_bus_en_q)
721:   `ASSERT(DmemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> dmem_rdata_bus_en_q)
722:   `ASSERT(DmemRDataBusDisabledWhenLocked_A, locking |=> !dmem_rdata_bus_en_q)
723:   `ASSERT(DmemRDataBusReadAsZeroWhenLocked_A,
724:     dmem_rvalid_bus & locking |-> dmem_rdata_bus_raw == '0)
725: 
726:   assign dmem_rdata_core = dmem_rdata;
727: 
728:   // When an illegal bus access is seen, always return a dummy response the follow cycle.
729:   assign dmem_rvalid_bus  = (~dmem_access_core & dmem_rvalid) | dmem_dummy_response_q;
730:   assign dmem_rvalid_core = dmem_access_core ? dmem_rvalid : 1'b0;
731: 
732:   // No dmem errors reported for bus reads. Integrity is carried through on the bus so integrity
733:   // checking on TL responses will pick up any errors.
734:   assign dmem_rerror_bus  = 2'b00;
735:   assign dmem_rerror_core = dmem_rerror;
736: 
737:   assign dmem_addr_bus = tl_win_h2d[TlWinDmem].a_address[DmemAddrWidth-1:0];
738:   assign dmem_wdata_narrow_bus = tl_win_h2d[TlWinDmem].a_data[31:0];
739:   assign dmem_byte_mask_bus = tl_win_h2d[TlWinDmem].a_mask;
740: 
741:   // Memory Load Integrity =====================================================
742:   // CRC logic below assumes a incoming data bus width of 32 bits
743:   `ASSERT_INIT(TLDWIs32Bit_A, top_pkg::TL_DW == 32)
744: 
745:   // Only advance CRC calculation on full 32-bit writes;
746:   assign mem_crc_data_in_valid   = ~(dmem_access_core | imem_access_core) &
747:       ((imem_req_bus & (imem_byte_mask_bus == 4'hf)) |
748:        (dmem_req_bus & (dmem_byte_mask_bus == 4'hf)));
749: 
750:   assign mem_crc_data_in.wr_data = imem_req_bus ? imem_wdata_bus[31:0] :
751:                                                   dmem_wdata_narrow_bus[31:0];
752:   assign mem_crc_data_in.index   = imem_req_bus ? {{15 - ImemIndexWidth{1'b0}}, imem_index_bus} :
753:                                                    {{15 - (DmemAddrWidth - 2){1'b0}},
754:                                                     dmem_addr_bus[DmemAddrWidth-1:2]};
755:   assign mem_crc_data_in.imem    = imem_req_bus;
756: 
757:   // Only the bits that factor into the dmem index and dmem word enables are required
758:   assign unused_dmem_addr_bus = ^{dmem_addr_bus[DmemAddrWidth-1:DmemIndexWidth],
759:                                   dmem_addr_bus[1:0]};
760: 
761:   // SEC_CM: WRITE.MEM.INTEGRITY
762:   prim_crc32 #(
763:     .BytesPerWord(6)
764:   ) u_mem_load_crc32 (
765:     .clk_i (clk_i),
766:     .rst_ni(rst_ni),
767: 
768:     .set_crc_i(set_crc),
769:     .crc_in_i (crc_in),
770: 
771:     .data_valid_i(mem_crc_data_in_valid),
772:     .data_i      (mem_crc_data_in),
773:     .crc_out_o   (crc_out)
774:   );
775: 
776:   assign set_crc = reg2hw.load_checksum.qe;
777:   assign crc_in = reg2hw.load_checksum.q;
778:   assign hw2reg.load_checksum.d = crc_out;
779: 
780:   // Registers =================================================================
781: 
782:   logic reg_bus_intg_violation;
783: 
784:   otbn_reg_top u_reg (
785:     .clk_i,
786:     .rst_ni  (rst_n),
787:     .tl_i,
788:     .tl_o,
789:     .tl_win_o(tl_win_h2d),
790:     .tl_win_i(tl_win_d2h),
791: 
792:     .reg2hw,
793:     .hw2reg,
794: 
795:     .intg_err_o(reg_bus_intg_violation)
796:   );
797: 
798:   // SEC_CM: BUS.INTEGRITY
799:   // SEC_CM: TLUL_FIFO.CTR.REDUN
800:   logic bus_intg_violation;
801:   assign bus_intg_violation = (imem_bus_intg_violation | dmem_bus_intg_violation |
802:                                reg_bus_intg_violation);
803: 
804:   // CMD register
805:   always_comb begin
806:     // start is flopped to avoid long timing paths from the TL fabric into OTBN internals.
807:     start_d       = 1'b0;
808:     dmem_sec_wipe = 1'b0;
809:     imem_sec_wipe = 1'b0;
810: 
811:     // Can only start a new command when idle.
812:     if (status_q == StatusIdle) begin
813:       if (reg2hw.cmd.qe) begin
814:         unique case (reg2hw.cmd.q)
815:           CmdExecute:     start_d       = 1'b1;
816:           CmdSecWipeDmem: dmem_sec_wipe = 1'b1;
817:           CmdSecWipeImem: imem_sec_wipe = 1'b1;
818:           default: ;
819:         endcase
820:       end
821:     end else if (busy_execute_q) begin
822:       // OTBN can command a secure wipe of IMEM and DMEM. This occurs when OTBN encounters a fatal
823:       // error.
824:       if (mems_sec_wipe) begin
825:         dmem_sec_wipe = 1'b1;
826:         imem_sec_wipe = 1'b1;
827:       end
828:     end
829:   end
830: 
831:   assign req_sec_wipe_urnd_keys = dmem_sec_wipe | imem_sec_wipe;
832: 
833:   assign illegal_bus_access_d = dmem_illegal_bus_access | imem_illegal_bus_access;
834: 
835:   // It should not be possible to request an imem or dmem access without it being granted. Either
836:   // a scramble key is present so the request will be granted or the core is busy obtaining a new
837:   // key, so no request can occur (the core won't generate one whilst awaiting a scrambling key and
838:   // the bus requests get an immediate dummy response bypassing the dmem or imem). A fatal error is
839:   // raised if request is seen without a grant.
840:   assign missed_gnt_error_d = dmem_missed_gnt | imem_missed_gnt;
841: 
842:   // Flop `illegal_bus_access_q` and `missed_gnt_error_q` to break timing paths from the TL
843:   // interface into the OTBN core.
844:   always_ff @(posedge clk_i or negedge rst_ni) begin
845:     if (!rst_ni) begin
846:       start_q              <= 1'b0;
847:       illegal_bus_access_q <= 1'b0;
848:       missed_gnt_error_q   <= 1'b0;
849:     end else begin
850:       start_q              <= start_d;
851:       illegal_bus_access_q <= illegal_bus_access_d;
852:       missed_gnt_error_q   <= missed_gnt_error_d;
853:     end
854:   end
855: 
856:   // STATUS register
857:   // imem/dmem scramble req can be busy when locked, so use a priority selection so locked status
858:   // always takes priority.
859:   //
860:   // Note that these signals are all "a cycle early". For example, the locking signal gets asserted
861:   // combinatorially on the cycle that an error is injected. The STATUS register change, done
862:   // interrupt and any change to the idle signal will be delayed by 2 cycles.
863:   assign status_d = locking                         ? StatusLocked          :
864:                     busy_secure_wipe                ? StatusBusySecWipeInt  :
865:                     busy_execute_d                  ? StatusBusyExecute     :
866:                     otbn_dmem_scramble_key_req_busy ? StatusBusySecWipeDmem :
867:                     otbn_imem_scramble_key_req_busy ? StatusBusySecWipeImem :
868:                                                       StatusIdle;
869:   always_ff @(posedge clk_i or negedge rst_ni) begin
870:     if (!rst_ni) begin
871:       status_q <= StatusBusySecWipeInt;
872:     end else begin
873:       status_q <= status_d;
874:     end
875:   end
876: 
877:   assign hw2reg.status.d = status_q;
878:   assign hw2reg.status.de = 1'b1;
879: 
880:   // Only certain combinations of the state variable {locking, busy_execute_d,
881:   // otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy} are possible.
882:   //
883:   // - Once locking is high, we guarantee never to see a new execution or the start of a key
884:   //   rotation. (Assertion: NoStartWhenLocked_A)
885: 
886:   `ASSERT(NoStartWhenLocked_A,
887:           locking |=> !($rose(busy_execute_d) ||
888:                         $rose(otbn_dmem_scramble_key_req_busy) ||
889:                         $rose(otbn_imem_scramble_key_req_busy)))
890: 
891:   // CTRL register
892:   assign software_errs_fatal_d =
893:     reg2hw.ctrl.qe && (status_q == StatusIdle) ? reg2hw.ctrl.q :
894:                                                  software_errs_fatal_q;
895: 
896:   always_ff @(posedge clk_i or negedge rst_ni) begin
897:     if (!rst_ni) begin
898:       software_errs_fatal_q <= 1'b0;
899:     end else begin
900:       software_errs_fatal_q <= software_errs_fatal_d;
901:     end
902:   end
903: 
904:   assign hw2reg.ctrl.d = software_errs_fatal_q;
905: 
906:   // ERR_BITS register
907:   // The error bits for an OTBN operation get stored on the cycle that done is
908:   // asserted. Software is expected to read them out before starting the next operation.
909: 
910:   assign hw2reg.err_bits.bad_data_addr.d = err_bits_q.bad_data_addr;
911:   assign hw2reg.err_bits.bad_insn_addr.d = err_bits_q.bad_insn_addr;
912:   assign hw2reg.err_bits.call_stack.d = err_bits_q.call_stack;
913:   assign hw2reg.err_bits.illegal_insn.d = err_bits_q.illegal_insn;
914:   assign hw2reg.err_bits.loop.d = err_bits_q.loop;
915:   assign hw2reg.err_bits.key_invalid.d = err_bits_q.key_invalid;
916:   assign hw2reg.err_bits.rnd_rep_chk_fail.d = err_bits_q.rnd_rep_chk_fail;
917:   assign hw2reg.err_bits.rnd_fips_chk_fail.d = err_bits_q.rnd_fips_chk_fail;
918:   assign hw2reg.err_bits.imem_intg_violation.d = err_bits_q.imem_intg_violation;
919:   assign hw2reg.err_bits.dmem_intg_violation.d = err_bits_q.dmem_intg_violation;
920:   assign hw2reg.err_bits.reg_intg_violation.d = err_bits_q.reg_intg_violation;
921:   assign hw2reg.err_bits.bus_intg_violation.d = err_bits_q.bus_intg_violation;
922:   assign hw2reg.err_bits.bad_internal_state.d = err_bits_q.bad_internal_state;
923:   assign hw2reg.err_bits.illegal_bus_access.d = err_bits_q.illegal_bus_access;
924:   assign hw2reg.err_bits.lifecycle_escalation.d = err_bits_q.lifecycle_escalation;
925:   assign hw2reg.err_bits.fatal_software.d = err_bits_q.fatal_software;
926: 
927:   assign err_bits_clear = reg2hw.err_bits.bad_data_addr.qe & is_not_running_q;
928:   assign err_bits_d = err_bits_clear ? '0 : err_bits;
929:   assign err_bits_en = err_bits_clear | done_core;
930: 
931:   logic unused_reg2hw_err_bits;
932: 
933:   // Majority of reg2hw.err_bits is unused as write values are ignored, all writes clear the
934:   // register to 0.
935:   assign unused_reg2hw_err_bits = ^{reg2hw.err_bits.bad_data_addr.q,
936:                                     reg2hw.err_bits.bad_insn_addr,
937:                                     reg2hw.err_bits.call_stack,
938:                                     reg2hw.err_bits.illegal_insn,
939:                                     reg2hw.err_bits.loop,
940:                                     reg2hw.err_bits.key_invalid,
941:                                     reg2hw.err_bits.rnd_rep_chk_fail,
942:                                     reg2hw.err_bits.rnd_fips_chk_fail,
943:                                     reg2hw.err_bits.imem_intg_violation,
944:                                     reg2hw.err_bits.dmem_intg_violation,
945:                                     reg2hw.err_bits.reg_intg_violation,
946:                                     reg2hw.err_bits.bus_intg_violation,
947:                                     reg2hw.err_bits.bad_internal_state,
948:                                     reg2hw.err_bits.illegal_bus_access,
949:                                     reg2hw.err_bits.lifecycle_escalation,
950:                                     reg2hw.err_bits.fatal_software};
951: 
952:   always_ff @(posedge clk_i or negedge rst_ni) begin
953:     if (!rst_ni) begin
954:       err_bits_q <= '0;
955:     end else if (err_bits_en) begin
956:       err_bits_q <= err_bits_d;
957:     end
958:   end
959: 
960:   // Latch the recoverable error signal from the core. This will be generated as a pulse some time
961:   // during the run (and before secure wipe finishes). Collect up this bit, clearing on the start or
962:   // end of an operation (start_q / done_core, respectively)
963:   assign recoverable_err_d = (recoverable_err_q | core_recoverable_err) & ~(start_q | done_core);
964:   always_ff @(posedge clk_i or negedge rst_ni) begin
965:     if (!rst_ni) begin
966:       recoverable_err_q <= '0;
967:     end else begin
968:       recoverable_err_q <= recoverable_err_d;
969:     end
970:   end
971: 
972:   // FATAL_ALERT_CAUSE register. The .de and .d values are equal for each bit, so that it can only
973:   // be set, not cleared.
974: `define DEF_FAC_BIT(NAME)                                         \
975:   assign hw2reg.fatal_alert_cause.``NAME``.d = 1'b1;              \
976:   assign hw2reg.fatal_alert_cause.``NAME``.de = err_bits.``NAME;
977: 
978:   `DEF_FAC_BIT(fatal_software)
979:   `DEF_FAC_BIT(lifecycle_escalation)
980:   `DEF_FAC_BIT(illegal_bus_access)
981:   `DEF_FAC_BIT(bad_internal_state)
982:   `DEF_FAC_BIT(bus_intg_violation)
983:   `DEF_FAC_BIT(reg_intg_violation)
984:   `DEF_FAC_BIT(dmem_intg_violation)
985:   `DEF_FAC_BIT(imem_intg_violation)
986: 
987: `undef DEF_FAC_BIT
988: 
989:   // INSN_CNT register
990:   logic [31:0] insn_cnt;
991:   logic        insn_cnt_clear;
992:   logic        unused_insn_cnt_q;
993:   assign hw2reg.insn_cnt.d = insn_cnt;
994:   assign insn_cnt_clear = reg2hw.insn_cnt.qe & is_not_running_q;
995:   // Ignore all write data to insn_cnt. All writes zero the register.
996:   assign unused_insn_cnt_q = ^reg2hw.insn_cnt.q;
997: 
998:   // Alerts ====================================================================
999: 
1000:   logic [NumAlerts-1:0] alert_test;
1001:   assign alert_test[AlertFatal] = reg2hw.alert_test.fatal.q & reg2hw.alert_test.fatal.qe;
1002:   assign alert_test[AlertRecov] = reg2hw.alert_test.recov.q & reg2hw.alert_test.recov.qe;
1003: 
1004:   logic [NumAlerts-1:0] alerts;
1005:   assign alerts[AlertFatal] = |{err_bits.fatal_software,
1006:                                 err_bits.lifecycle_escalation,
1007:                                 err_bits.illegal_bus_access,
1008:                                 err_bits.bad_internal_state,
1009:                                 err_bits.bus_intg_violation,
1010:                                 err_bits.reg_intg_violation,
1011:                                 err_bits.dmem_intg_violation,
1012:                                 err_bits.imem_intg_violation};
1013: 
1014:   assign alerts[AlertRecov] = (core_recoverable_err | recoverable_err_q) & done_core;
1015: 
1016:   for (genvar i = 0; i < NumAlerts; i++) begin : gen_alert_tx
1017:     prim_alert_sender #(
1018:       .AsyncOn(AlertAsyncOn[i]),
1019:       .IsFatal(i == AlertFatal)
1020:     ) u_prim_alert_sender (
1021:       .clk_i,
1022:       .rst_ni       (rst_n),
1023:       .alert_test_i (alert_test[i]),
1024:       .alert_req_i  (alerts[i]),
1025:       .alert_ack_o  (),
1026:       .alert_state_o(),
1027:       .alert_rx_i   (alert_rx_i[i]),
1028:       .alert_tx_o   (alert_tx_o[i])
1029:     );
1030:   end
1031: 
1032: 
1033:   // EDN Connections ============================================================
1034:   logic edn_rnd_req, edn_rnd_ack;
1035:   logic [EdnDataWidth-1:0] edn_rnd_data;
1036:   logic edn_rnd_fips, edn_rnd_err;
1037: 
1038:   logic edn_urnd_req, edn_urnd_ack;
1039:   logic [EdnDataWidth-1:0] edn_urnd_data;
1040: 
1041:   // These synchronize the data coming from EDN and stack the 32 bit EDN words to achieve an
1042:   // internal entropy width of 256 bit.
1043: 
1044:   prim_edn_req #(
1045:     .EnRstChks(1'b1),
1046:     .OutWidth(EdnDataWidth),
1047:     // SEC_CM: RND.BUS.CONSISTENCY
1048:     .RepCheck(1'b1)
1049:   ) u_prim_edn_rnd_req (
1050:     .clk_i,
1051:     .rst_ni     ( rst_n        ),
1052:     .req_chk_i  ( 1'b1         ),
1053:     .req_i      ( edn_rnd_req  ),
1054:     .ack_o      ( edn_rnd_ack  ),
1055:     .data_o     ( edn_rnd_data ),
1056:     .fips_o     ( edn_rnd_fips ),
1057:     .err_o      ( edn_rnd_err  ),
1058:     .clk_edn_i,
1059:     .rst_edn_ni,
1060:     .edn_o      ( edn_rnd_o ),
1061:     .edn_i      ( edn_rnd_i )
1062:   );
1063: 
1064:   prim_edn_req #(
1065:     .EnRstChks(1'b1),
1066:     .OutWidth(EdnDataWidth)
1067:   ) u_prim_edn_urnd_req (
1068:     .clk_i,
1069:     .rst_ni     ( rst_n         ),
1070:     .req_chk_i  ( 1'b1          ),
1071:     .req_i      ( edn_urnd_req  ),
1072:     .ack_o      ( edn_urnd_ack  ),
1073:     .data_o     ( edn_urnd_data ),
1074:     .fips_o     (               ), // unused
1075:     .err_o      (               ), // unused
1076:     .clk_edn_i,
1077:     .rst_edn_ni,
1078:     .edn_o      ( edn_urnd_o    ),
1079:     .edn_i      ( edn_urnd_i    )
1080:   );
1081: 
1082: 
1083:   // OTBN Core =================================================================
1084: 
1085:   always_ff @(posedge clk_i or negedge rst_n) begin
1086:     if (!rst_n) begin
1087:       busy_execute_q       <= 1'b0;
1088:       init_sec_wipe_done_q <= 1'b0;
1089:     end else begin
1090:       busy_execute_q       <= busy_execute_d;
1091:       init_sec_wipe_done_q <= init_sec_wipe_done_d;
1092:     end
1093:   end
1094:   assign busy_execute_d = (busy_execute_q | start_d) & ~done_core;
1095:   assign init_sec_wipe_done_d = init_sec_wipe_done_q | ~busy_secure_wipe;
1096: 
1097:   otbn_core #(
1098:     .RegFile(RegFile),
1099:     .DmemSizeByte(DmemSizeByte),
1100:     .ImemSizeByte(ImemSizeByte),
1101:     .RndCnstUrndPrngSeed(RndCnstUrndPrngSeed),
1102:     .SecMuteUrnd(SecMuteUrnd),
1103:     .SecSkipUrndReseedAtStart(SecSkipUrndReseedAtStart)
1104:   ) u_otbn_core (
1105:     .clk_i,
1106:     .rst_ni                      (rst_n),
1107: 
1108:     .start_i                     (start_q),
1109:     .done_o                      (done_core),
1110:     .locking_o                   (locking),
1111:     .secure_wipe_running_o       (busy_secure_wipe),
1112: 
1113:     .err_bits_o                  (core_err_bits),
1114:     .recoverable_err_o           (core_recoverable_err),
1115: 
1116:     .imem_req_o                  (imem_req_core),
1117:     .imem_addr_o                 (imem_addr_core),
1118:     .imem_rdata_i                (imem_rdata_core),
1119:     .imem_rvalid_i               (imem_rvalid_core),
1120: 
1121:     .dmem_req_o                  (dmem_req_core),
1122:     .dmem_write_o                (dmem_write_core),
1123:     .dmem_addr_o                 (dmem_addr_core),
1124:     .dmem_wdata_o                (dmem_wdata_core),
1125:     .dmem_wmask_o                (dmem_wmask_core),
1126:     .dmem_rmask_o                (dmem_rmask_core_d),
1127:     .dmem_rdata_i                (dmem_rdata_core),
1128:     .dmem_rvalid_i               (dmem_rvalid_core),
1129:     .dmem_rerror_i               (dmem_rerror_core),
1130: 
1131:     .edn_rnd_req_o               (edn_rnd_req),
1132:     .edn_rnd_ack_i               (edn_rnd_ack),
1133:     .edn_rnd_data_i              (edn_rnd_data),
1134:     .edn_rnd_fips_i              (edn_rnd_fips),
1135:     .edn_rnd_err_i               (edn_rnd_err),
1136: 
1137:     .edn_urnd_req_o              (edn_urnd_req),
1138:     .edn_urnd_ack_i              (edn_urnd_ack),
1139:     .edn_urnd_data_i             (edn_urnd_data),
1140: 
1141:     .insn_cnt_o                  (insn_cnt),
1142:     .insn_cnt_clear_i            (insn_cnt_clear),
1143: 
1144:     .mems_sec_wipe_o             (mems_sec_wipe),
1145:     .dmem_sec_wipe_urnd_key_o    (dmem_sec_wipe_urnd_key),
1146:     .imem_sec_wipe_urnd_key_o    (imem_sec_wipe_urnd_key),
1147:     .req_sec_wipe_urnd_keys_i    (req_sec_wipe_urnd_keys),
1148: 
1149:     .escalate_en_i               (core_escalate_en),
1150:     .rma_req_i                   (mubi_rma_req),
1151:     .rma_ack_o                   (mubi_rma_ack),
1152: 
1153:     .software_errs_fatal_i       (software_errs_fatal_q),
1154: 
1155:     .sideload_key_shares_i       (keymgr_key_i.key),
1156:     .sideload_key_shares_valid_i ({2{keymgr_key_i.valid}})
1157:   );
1158: 
1159:   always_ff @(posedge clk_i or negedge rst_n) begin
1160:     if (!rst_n) begin
1161:       locking_q <= 1'b0;
1162:     end else begin
1163:       locking_q <= locking;
1164:     end
1165:   end
1166: 
1167:   // Collect up the error bits that don't come from the core itself and latch them so that they'll
1168:   // be available when an operation finishes.
1169:   assign non_core_err_bits = '{
1170:     lifecycle_escalation: lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[0]),
1171:     illegal_bus_access:   illegal_bus_access_q,
1172:     bad_internal_state:   otbn_scramble_state_error | missed_gnt_error_q,
1173:     bus_intg_violation:   bus_intg_violation
1174:   };
1175: 
1176:   assign non_core_err_bits_d = non_core_err_bits_q | non_core_err_bits;
1177:   always_ff @(posedge clk_i or negedge rst_ni) begin
1178:     if (!rst_ni) begin
1179:       non_core_err_bits_q <= '0;
1180:     end else begin
1181:       non_core_err_bits_q <= non_core_err_bits_d;
1182:     end
1183:   end
1184: 
1185:   // Construct a full set of error bits from the core output
1186:   assign err_bits = '{
1187:     fatal_software:       core_err_bits.fatal_software,
1188:     lifecycle_escalation: non_core_err_bits_d.lifecycle_escalation,
1189:     illegal_bus_access:   non_core_err_bits_d.illegal_bus_access,
1190:     bad_internal_state:   |{core_err_bits.bad_internal_state,
1191:                             non_core_err_bits_d.bad_internal_state},
1192:     bus_intg_violation:   non_core_err_bits_d.bus_intg_violation,
1193:     reg_intg_violation:   core_err_bits.reg_intg_violation,
1194:     dmem_intg_violation:  core_err_bits.dmem_intg_violation,
1195:     imem_intg_violation:  core_err_bits.imem_intg_violation,
1196:     rnd_fips_chk_fail:    core_err_bits.rnd_fips_chk_fail,
1197:     rnd_rep_chk_fail:     core_err_bits.rnd_rep_chk_fail,
1198:     key_invalid:          core_err_bits.key_invalid,
1199:     loop:                 core_err_bits.loop,
1200:     illegal_insn:         core_err_bits.illegal_insn,
1201:     call_stack:           core_err_bits.call_stack,
1202:     bad_insn_addr:        core_err_bits.bad_insn_addr,
1203:     bad_data_addr:        core_err_bits.bad_data_addr
1204:   };
1205: 
1206:   // An error signal going down into the core to show that it should locally escalate. In
1207:   // accordance with the lc_ctrl spec, all values of the lc_escalate_en signal other than the OFF
1208:   // value must be interpreted as ON.
1209:   assign core_escalate_en = mubi4_bool_to_mubi(
1210:       |{non_core_err_bits.illegal_bus_access,
1211:         non_core_err_bits.bad_internal_state,
1212:         non_core_err_bits.bus_intg_violation,
1213:         lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[1])});
1214: 
1215:   // The core can never signal a write to IMEM
1216:   assign imem_write_core = 1'b0;
1217: 
1218: 
1219:   // Asserts ===================================================================
1220:   for (genvar i = 0; i < LoopStackDepth; ++i) begin : gen_loop_stack_cntr_asserts
1221:     `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(
1222:       LoopStackCntAlertCheck_A,
1223:       u_otbn_core.u_otbn_controller.u_otbn_loop_controller.g_loop_counters[i].u_loop_count,
1224:       alert_tx_o[AlertFatal]
1225:     )
1226:   end
1227: 
1228:   // GPR assertions for secure wipe
1229:   // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1230:   // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
1231:   // secure wiping complete.
1232:   // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
1233:   // because a fatal error affecting internal secure wiping could cause an immediate locking
1234:   // behaviour in which it's not guaranteed to see a succesful secure wipe.
1235:   for (genvar i = 2; i < NGpr; ++i) begin : gen_sec_wipe_gpr_asserts
1236:     // Initial secure wipe needs to initialise all registers to nonzero
1237:     `ASSERT(InitSecWipeNonZeroBaseRegs_A,
1238:       $fell(busy_secure_wipe) |->
1239:       u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
1240:         EccZeroWord,
1241:       clk_i,
1242:       !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1243:       u_otbn_core.u_otbn_start_stop_control.state_error_d)
1244:     // After execution, it's expected to see a change resulting with a nonzero register value
1245:     `ASSERT(SecWipeChangedBaseRegs_A,
1246:       $rose(busy_secure_wipe) |-> ((##[0:$]
1247:         u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
1248:           EccZeroWord &&
1249:         $changed(
1250:           u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q))
1251:         within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
1252:       clk_i,
1253:       !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1254:       u_otbn_core.u_otbn_start_stop_control.state_error_d)
1255:   end
1256: 
1257:   // We have several assertions that check that secure wipe worked properly. However, we've also got
1258:   // some tests where we force nets, stopping it from working properly! That's fine, and the tests
1259:   // are checking that some other mechanism catches the problem. However, we don't want the
1260:   // simulation to die with a failed assertion, so we put everything in a named block which we can
1261:   // turn off with $assertoff.
1262:   //
1263:   // The silly-looking name is to avoid a lint warning. Verible (correctly) points out that
1264:   // SystemVerilog doesn't allow bare begin/end blocks at module level. So I cheated and put
1265:   // everything in an if(1) block. But this is treated as a generate block, and our lint rules
1266:   // therefore expect its name to start with a "g_".
1267:   if (1) begin : g_secure_wipe_assertions
1268:     // WDR assertions for secure wipe
1269:     // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1270:     // goes to LOCKED state immediately after this error which means that it's not guaranteed to
1271:     // have secure wiping complete.
1272:     // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
1273:     // because a fatal error affecting internal secure wiping could cause an immediate locking
1274:     // behaviour in which it's not guaranteed to see a succesful secure wipe.
1275:     for (genvar i = 0; i < NWdr; ++i) begin : gen_sec_wipe_wdr_asserts
1276:       // Initial secure wipe needs to initialise all registers to nonzero
1277:       `ASSERT(InitSecWipeNonZeroWideRegs_A,
1278:               $fell(busy_secure_wipe) |->
1279:                 u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
1280:                   EccWideZeroWord,
1281:               clk_i,
1282:               !rst_ni || u_otbn_core.urnd_reseed_err ||
1283:                 u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1284:                 u_otbn_core.u_otbn_start_stop_control.state_error_d)
1285: 
1286:       // After execution, it's expected to see a change resulting with a nonzero register value
1287:       `ASSERT(SecWipeChangedWideRegs_A,
1288:               $rose(busy_secure_wipe) |-> ((##[0:$]
1289:                 u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
1290:                   EccWideZeroWord &&
1291:                 $changed(
1292:                   u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i]))
1293:                 within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
1294:             clk_i, !rst_ni || u_otbn_core.urnd_reseed_err ||
1295:               u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1296:     end
1297:   end
1298: 
1299:   // Secure wipe needs to invalidate call and loop stack, initialize MOD, ACC to nonzero and set
1300:   // FLAGS CSR to zero
1301:   // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1302:   // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
1303:   // secure wiping complete.
1304:   // 2. mubi_err_d of start_stop_control disables the secure wipe related assertions because a
1305:   // fatal error affecting internal secure wiping could cause an immediate locking behaviour
1306:   // in which it's not guaranteed to see a succesful secure wipe.
1307:   `ASSERT(SecWipeInvalidCallStack_A,
1308:           $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_rf_base.u_call_stack.top_valid_o),
1309:           clk_i,
1310:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1311:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1312:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1313:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1314:   `ASSERT(SecWipeInvalidLoopStack_A,
1315:           $fell(busy_secure_wipe) |->
1316:             (!u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.top_valid_o),
1317:           clk_i,
1318:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1319:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1320:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1321:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1322: 
1323:   `ASSERT(SecWipeNonZeroMod_A,
1324:           $fell(busy_secure_wipe) |-> u_otbn_core.u_otbn_alu_bignum.mod_intg_q != EccWideZeroWord,
1325:           clk_i,
1326:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1327:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1328:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1329:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1330: 
1331:   `ASSERT(SecWipeNonZeroACC_A,
1332:           $fell(busy_secure_wipe) |->
1333:             u_otbn_core.u_otbn_alu_bignum.ispr_acc_intg_i != EccWideZeroWord,
1334:           clk_i,
1335:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1336:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1337:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1338: 
1339:   `ASSERT(SecWipeNonZeroFlags_A,
1340:           $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_alu_bignum.flags_flattened),
1341:           clk_i,
1342:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1343:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1344:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1345:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1346: 
1347:   // Secure wipe of IMEM and DMEM first happens with a key change from URND (while valid is zero)
1348:   `ASSERT(ImemSecWipeRequiresUrndKey_A,
1349:           $rose(imem_sec_wipe) |=> (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)),
1350:           clk_i,
1351:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1352:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1353:   `ASSERT(DmemSecWipeRequiresUrndKey_A,
1354:           $rose(dmem_sec_wipe) |=> (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)),
1355:           clk_i,
1356:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1357:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1358: 
1359:   // Then it is guaranteed to have a valid key from OTP interface which is different from URND key
1360:   `ASSERT(ImemSecWipeRequiresOtpKey_A,
1361:           $rose(imem_sec_wipe) ##1 (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)) |=>
1362:             ##[0:$] otbn_imem_scramble_valid && $changed(otbn_imem_scramble_key),
1363:           clk_i,
1364:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1365:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1366:   `ASSERT(DmemSecWipeRequiresOtpKey_A,
1367:           $rose(dmem_sec_wipe) ##1 (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)) |=>
1368:             ##[0:$] otbn_dmem_scramble_valid && $changed(otbn_dmem_scramble_key),
1369:           clk_i,
1370:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1371:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1372: 
1373:   // All outputs should be known value after reset
1374:   `ASSERT_KNOWN(TlODValidKnown_A, tl_o.d_valid)
1375:   `ASSERT_KNOWN(TlOAReadyKnown_A, tl_o.a_ready)
1376:   `ASSERT_KNOWN(IdleOKnown_A, idle_o)
1377:   `ASSERT_KNOWN(IntrDoneOKnown_A, intr_done_o)
1378:   `ASSERT_KNOWN(AlertTxOKnown_A, alert_tx_o)
1379:   `ASSERT_KNOWN(EdnRndOKnown_A, edn_rnd_o, clk_edn_i, !rst_edn_ni)
1380:   `ASSERT_KNOWN(EdnUrndOKnown_A, edn_urnd_o, clk_edn_i, !rst_edn_ni)
1381:   `ASSERT_KNOWN(OtbnOtpKeyO_A, otbn_otp_key_o, clk_otp_i, !rst_otp_ni)
1382:   `ASSERT_KNOWN(ErrBitsKnown_A, err_bits)
1383: 
1384:   // Incoming key must be valid (other inputs go via prim modules that handle the X checks).
1385:   `ASSERT_KNOWN(KeyMgrKeyValid_A, keymgr_key_i.valid)
1386: 
1387:   // In locked state, the readable registers INSN_CNT, IMEM, and DMEM are expected to always read 0
1388:   // when accessed from the bus. For INSN_CNT, we use "|=>" so that the assertion lines up with
1389:   // "status.q" (a signal that isn't directly accessible here).
1390:   `ASSERT(LockedInsnCntReadsZero_A, (hw2reg.status.d == StatusLocked) |=> insn_cnt == 'd0)
1391:   `ASSERT(ExecuteOrLockedImemReadsZero_A,
1392:           (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & imem_rvalid_bus
1393:           |-> imem_rdata_bus == 'd0)
1394:   `ASSERT(ExecuteOrLockedDmemReadsZero_A,
1395:           (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & dmem_rvalid_bus
1396:           |-> dmem_rdata_bus == 'd0)
1397: 
1398:   // From the cycle the core is told to start to when it is done, it must always be busy executing,
1399:   // locking, or both -- even if the core is never done.  We use this property to enable blanking
1400:   // while the core is executing or locking, and this assertion ensures that there is no gap
1401:   // between execution and locking.
1402:   `ASSERT(BusyOrLockingFromStartToDone_A,
1403:           $rose(start_q) |-> (busy_execute_d | locking) |-> ##[0:$] $rose(done_core))
1404: 
1405:   // Error handling: if we pass an error signal down to the core then we should also be setting an
1406:   // error flag. Note that this uses err_bits, not err_bits_q, because the latter signal only gets
1407:   // asserted when an operation finishes.
1408:   `ASSERT(ErrBitIfEscalate_A, mubi4_test_true_loose(core_escalate_en) |=> |err_bits)
1409: 
1410:   // Constraint from package, check here as we cannot have `ASSERT_INIT in package
1411:   `ASSERT_INIT(WsrESizeMatchesParameter_A, $bits(wsr_e) == WsrNumWidth)
1412: 
1413:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnStartStopFsmCheck_A,
1414:     u_otbn_core.u_otbn_start_stop_control.u_state_regs, alert_tx_o[AlertFatal])
1415:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnControllerFsmCheck_A,
1416:     u_otbn_core.u_otbn_controller.u_state_regs, alert_tx_o[AlertFatal])
1417:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnScrambleCtrlFsmCheck_A,
1418:     u_otbn_scramble_ctrl.u_state_regs, alert_tx_o[AlertFatal])
1419: 
1420:   `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnCallStackWrPtrAlertCheck_A,
1421:     u_otbn_core.u_otbn_rf_base.u_call_stack.u_stack_wr_ptr, alert_tx_o[AlertFatal])
1422:   `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnLoopInfoStackWrPtrAlertCheck_A,
1423:     u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.u_stack_wr_ptr,
1424:     alert_tx_o[AlertFatal])
1425: 
1426:   // Alert assertions for reg_we onehot check
1427:   `ASSERT_PRIM_REG_WE_ONEHOT_ERROR_TRIGGER_ALERT(RegWeOnehotCheck_A,
1428:       u_reg, alert_tx_o[AlertFatal])
1429:   // other onehot checks
1430:   `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBaseOnehotCheck_A,
1431:       u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.u_prim_onehot_check,
1432:       alert_tx_o[AlertFatal])
1433:   `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBignumOnehotCheck_A,
1434:       u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.u_prim_onehot_check,
1435:       alert_tx_o[AlertFatal])
1436: 
1437:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemRspFifo,
1438:                                                u_tlul_adapter_sram_dmem.u_rspfifo,
1439:                                                alert_tx_o[AlertFatal])
1440:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemSramReqFifo,
1441:                                                u_tlul_adapter_sram_dmem.u_sramreqfifo,
1442:                                                alert_tx_o[AlertFatal])
1443:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemReqFifo,
1444:                                                u_tlul_adapter_sram_dmem.u_reqfifo,
1445:                                                alert_tx_o[AlertFatal])
1446: 
1447:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemRspFifo,
1448:                                                u_tlul_adapter_sram_imem.u_rspfifo,
1449:                                                alert_tx_o[AlertFatal])
1450:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemSramReqFifo,
1451:                                                u_tlul_adapter_sram_imem.u_sramreqfifo,
1452:                                                alert_tx_o[AlertFatal])
1453:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemReqFifo,
1454:                                                u_tlul_adapter_sram_imem.u_reqfifo,
1455:                                                alert_tx_o[AlertFatal])
1456: endmodule

================================= Tool Message =================================
Name: read_file_with_line_numbers

1: // Copyright lowRISC contributors (OpenTitan project).
2: // Licensed under the Apache License, Version 2.0, see LICENSE for details.
3: // SPDX-License-Identifier: Apache-2.0
4: 
5: `include "prim_assert.sv"
6: `include "prim_fifo_assert.svh"
7: 
8: /**
9:  * OpenTitan Big Number Accelerator (OTBN)
10:  */
11: module otbn
12:   import prim_alert_pkg::*;
13:   import otbn_pkg::*;
14:   import otbn_reg_pkg::*;
15: #(
16:   parameter bit                   Stub         = 1'b0,
17:   parameter regfile_e             RegFile      = RegFileFF,
18:   parameter logic [NumAlerts-1:0] AlertAsyncOn = {NumAlerts{1'b1}},
19: 
20:   // Default seed for URND PRNG
21:   parameter urnd_prng_seed_t RndCnstUrndPrngSeed = RndCnstUrndPrngSeedDefault,
22: 
23:   // Disable URND advance when not in use. Useful for SCA only.
24:   parameter bit SecMuteUrnd = 1'b0,
25:   // Skip URND re-seed at the start of an operation. Useful for SCA only.
26:   parameter bit SecSkipUrndReseedAtStart = 1'b0,
27: 
28:   // Default seed and nonce for scrambling
29:   parameter otp_ctrl_pkg::otbn_key_t   RndCnstOtbnKey   = RndCnstOtbnKeyDefault,
30:   parameter otp_ctrl_pkg::otbn_nonce_t RndCnstOtbnNonce = RndCnstOtbnNonceDefault
31: ) (
32:   input clk_i,
33:   input rst_ni,
34: 
35:   input  tlul_pkg::tl_h2d_t tl_i,
36:   output tlul_pkg::tl_d2h_t tl_o,
37: 
38:   // Inter-module signals
39:   output prim_mubi_pkg::mubi4_t idle_o,
40: 
41:   // Interrupts
42:   output logic intr_done_o,
43: 
44:   // Alerts
45:   input  prim_alert_pkg::alert_rx_t [NumAlerts-1:0] alert_rx_i,
46:   output prim_alert_pkg::alert_tx_t [NumAlerts-1:0] alert_tx_o,
47: 
48:   // Lifecycle interfaces
49:   input  lc_ctrl_pkg::lc_tx_t lc_escalate_en_i,
50: 
51:   input  lc_ctrl_pkg::lc_tx_t lc_rma_req_i,
52:   output lc_ctrl_pkg::lc_tx_t lc_rma_ack_o,
53: 
54:   // Memory configuration
55:   input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_imem_i,
56:   input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_dmem_i,
57:   output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_imem_o,
58:   output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_dmem_o,
59: 
60:   // EDN clock and interface
61:   input                     clk_edn_i,
62:   input                     rst_edn_ni,
63:   output edn_pkg::edn_req_t edn_rnd_o,
64:   input  edn_pkg::edn_rsp_t edn_rnd_i,
65: 
66:   output edn_pkg::edn_req_t edn_urnd_o,
67:   input  edn_pkg::edn_rsp_t edn_urnd_i,
68: 
69:   // Key request to OTP (running on clk_fixed)
70:   input                                   clk_otp_i,
71:   input                                   rst_otp_ni,
72:   output otp_ctrl_pkg::otbn_otp_key_req_t otbn_otp_key_o,
73:   input  otp_ctrl_pkg::otbn_otp_key_rsp_t otbn_otp_key_i,
74: 
75:   input keymgr_pkg::otbn_key_req_t keymgr_key_i
76: );
77: 
78:   import prim_mubi_pkg::*;
79:   import prim_util_pkg::vbits;
80: 
81:   logic rst_n;
82: 
83:   // hold module in reset permanently when stubbing
84:   if (Stub) begin : gen_stub_otbn
85:     assign rst_n = 1'b0;
86:   end else begin : gen_real_otbn
87:     assign rst_n = rst_ni;
88:   end
89: 
90:   // The OTBN_*_SIZE parameters are auto-generated by regtool and come from the bus window sizes;
91:   // they are given in bytes and must be powers of two.
92:   //
93:   // DMEM is actually a bit bigger than OTBN_DMEM_SIZE: there are an extra DmemScratchSizeByte bytes
94:   // that aren't accessible over the bus.
95:   localparam int ImemSizeByte = int'(otbn_reg_pkg::OTBN_IMEM_SIZE);
96:   localparam int DmemSizeByte = int'(otbn_reg_pkg::OTBN_DMEM_SIZE + DmemScratchSizeByte);
97: 
98:   localparam int ImemAddrWidth = vbits(ImemSizeByte);
99:   localparam int DmemAddrWidth = vbits(DmemSizeByte);
100: 
101:   `ASSERT_INIT(ImemSizePowerOfTwo, 2 ** ImemAddrWidth == ImemSizeByte)
102:   `ASSERT_INIT(DmemSizePowerOfTwo, 2 ** DmemAddrWidth == DmemSizeByte)
103: 
104:   logic start_d, start_q;
105:   logic busy_execute_d, busy_execute_q;
106:   logic done, done_core, locking, locking_q;
107:   logic busy_secure_wipe;
108:   logic init_sec_wipe_done_d, init_sec_wipe_done_q;
109:   logic illegal_bus_access_d, illegal_bus_access_q;
110:   logic missed_gnt_error_d, missed_gnt_error_q;
111:   logic dmem_sec_wipe;
112:   logic imem_sec_wipe;
113:   logic mems_sec_wipe;
114:   logic req_sec_wipe_urnd_keys;
115:   logic [127:0] dmem_sec_wipe_urnd_key, imem_sec_wipe_urnd_key;
116: 
117:   logic core_recoverable_err, recoverable_err_d, recoverable_err_q;
118:   mubi4_t core_escalate_en;
119: 
120:   core_err_bits_t     core_err_bits;
121:   non_core_err_bits_t non_core_err_bits, non_core_err_bits_d, non_core_err_bits_q;
122:   err_bits_t          err_bits, err_bits_d, err_bits_q;
123:   logic               err_bits_en;
124: 
125:   // ERR_BITS register should be cleared due to a write request from the host processor
126:   // when OTBN is not running.
127:   logic err_bits_clear;
128: 
129:   logic software_errs_fatal_q, software_errs_fatal_d;
130: 
131:   otbn_reg2hw_t reg2hw;
132:   otbn_hw2reg_t hw2reg;
133:   status_e      status_d, status_q;
134: 
135:   // Bus device windows, as specified in otbn.hjson
136:   typedef enum logic {
137:     TlWinImem = 1'b0,
138:     TlWinDmem = 1'b1
139:   } tl_win_e;
140: 
141:   tlul_pkg::tl_h2d_t tl_win_h2d[2];
142:   tlul_pkg::tl_d2h_t tl_win_d2h[2];
143: 
144:   // The clock can be gated and some registers can be updated as long as OTBN isn't currently
145:   // running. Other registers can only be updated when OTBN is in the Idle state (which also implies
146:   // we are not locked).
147:   logic is_not_running_d, is_not_running_q;
148:   logic otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy;
149: 
150:   assign is_not_running_d = ~|{busy_execute_d,
151:                                otbn_dmem_scramble_key_req_busy,
152:                                otbn_imem_scramble_key_req_busy,
153:                                busy_secure_wipe};
154: 
155:   always_ff @(posedge clk_i or negedge rst_ni) begin
156:     if(!rst_ni) begin
157:       // OTBN starts busy, performing the initial secure wipe.
158:       is_not_running_q  <= 1'b0;
159:     end else begin
160:       is_not_running_q  <= is_not_running_d;
161:     end
162:   end
163: 
164:   // Inter-module signals ======================================================
165: 
166:   // Note: This is not the same thing as STATUS == IDLE. For example, we want to allow clock gating
167:   // when locked.
168:   prim_mubi4_sender #(
169:     .ResetValue(prim_mubi_pkg::MuBi4True)
170:   ) u_prim_mubi4_sender (
171:     .clk_i,
172:     .rst_ni,
173:     .mubi_i(mubi4_bool_to_mubi(is_not_running_q)),
174:     .mubi_o(idle_o)
175:   );
176: 
177:   // Lifecycle ==================================================================
178: 
179:   localparam int unsigned LcEscalateCopies = 2;
180:   lc_ctrl_pkg::lc_tx_t [LcEscalateCopies-1:0] lc_escalate_en;
181:   prim_lc_sync #(
182:     .NumCopies(LcEscalateCopies)
183:   ) u_lc_escalate_en_sync (
184:     .clk_i,
185:     .rst_ni,
186:     .lc_en_i(lc_escalate_en_i),
187:     .lc_en_o(lc_escalate_en)
188:   );
189: 
190:   lc_ctrl_pkg::lc_tx_t lc_rma_req;
191:   prim_lc_sync #(
192:     .NumCopies(1)
193:   ) u_lc_rma_req_sync (
194:     .clk_i,
195:     .rst_ni,
196:     .lc_en_i(lc_rma_req_i),
197:     .lc_en_o({lc_rma_req})
198:   );
199: 
200:   // Internally, OTBN uses MUBI types.
201:   mubi4_t mubi_rma_req, mubi_rma_ack;
202:   assign mubi_rma_req = lc_ctrl_pkg::lc_to_mubi4(lc_rma_req);
203: 
204:   // When stubbing, forward req to ack.
205:   if (Stub) begin : gen_stub_rma_ack
206:     assign lc_rma_ack_o = lc_rma_req;
207:   end else begin : gen_real_rma_ack
208:     assign lc_rma_ack_o = lc_ctrl_pkg::mubi4_to_lc(mubi_rma_ack);
209:   end
210: 
211:   // Interrupts ================================================================
212: 
213:   assign done = is_busy_status(status_q) & ~is_busy_status(status_d) & init_sec_wipe_done_q;
214: 
215:   prim_intr_hw #(
216:     .Width(1)
217:   ) u_intr_hw_done (
218:     .clk_i,
219:     .rst_ni                (rst_n),
220:     .event_intr_i          (done),
221:     .reg2hw_intr_enable_q_i(reg2hw.intr_enable.q),
222:     .reg2hw_intr_test_q_i  (reg2hw.intr_test.q),
223:     .reg2hw_intr_test_qe_i (reg2hw.intr_test.qe),
224:     .reg2hw_intr_state_q_i (reg2hw.intr_state.q),
225:     .hw2reg_intr_state_de_o(hw2reg.intr_state.de),
226:     .hw2reg_intr_state_d_o (hw2reg.intr_state.d),
227:     .intr_o                (intr_done_o)
228:   );
229: 
230:   // Instruction Memory (IMEM) =================================================
231: 
232:   localparam int ImemSizeWords = ImemSizeByte / 4;
233:   localparam int ImemIndexWidth = vbits(ImemSizeWords);
234: 
235:   // Access select to IMEM: core (1), or bus (0)
236:   logic imem_access_core;
237: 
238:   logic imem_req;
239:   logic imem_gnt;
240:   logic imem_write;
241:   logic imem_wr_collision;
242:   logic imem_wpending;
243:   logic [ImemIndexWidth-1:0] imem_index;
244:   logic [38:0] imem_wdata;
245:   logic [38:0] imem_wmask;
246:   logic [38:0] imem_rdata;
247:   logic imem_rvalid;
248:   logic imem_illegal_bus_access;
249:   logic imem_missed_gnt;
250: 
251:   logic imem_req_core;
252:   logic imem_write_core;
253:   logic [ImemIndexWidth-1:0] imem_index_core;
254:   logic [38:0] imem_rdata_core;
255:   logic imem_rvalid_core;
256: 
257:   logic imem_req_bus;
258:   logic imem_dummy_response_q, imem_dummy_response_d;
259:   logic imem_write_bus;
260:   logic [ImemIndexWidth-1:0] imem_index_bus;
261:   logic [38:0] imem_wdata_bus;
262:   logic [38:0] imem_wmask_bus;
263:   logic [38:0] imem_rdata_bus, imem_rdata_bus_raw;
264:   logic imem_rdata_bus_en_q, imem_rdata_bus_en_d;
265:   logic [top_pkg::TL_DBW-1:0] imem_byte_mask_bus;
266:   logic imem_rvalid_bus;
267:   logic [1:0] imem_rerror_bus;
268: 
269:   logic imem_bus_intg_violation;
270: 
271:   typedef struct packed {
272:     logic        imem;
273:     logic [14:0] index;
274:     logic [31:0] wr_data;
275:   } mem_crc_data_in_t;
276: 
277:   logic             mem_crc_data_in_valid;
278:   mem_crc_data_in_t mem_crc_data_in;
279:   logic             set_crc;
280:   logic [31:0]      crc_in, crc_out;
281: 
282:   logic [ImemAddrWidth-1:0] imem_addr_core;
283:   assign imem_index_core = imem_addr_core[ImemAddrWidth-1:2];
284: 
285:   logic [1:0] unused_imem_addr_core_wordbits;
286:   assign unused_imem_addr_core_wordbits = imem_addr_core[1:0];
287: 
288:   otp_ctrl_pkg::otbn_key_t otbn_imem_scramble_key;
289:   otbn_imem_nonce_t        otbn_imem_scramble_nonce;
290:   logic                    otbn_imem_scramble_valid;
291:   logic                    unused_otbn_imem_scramble_key_seed_valid;
292: 
293:   otp_ctrl_pkg::otbn_key_t otbn_dmem_scramble_key;
294:   otbn_dmem_nonce_t        otbn_dmem_scramble_nonce;
295:   logic                    otbn_dmem_scramble_valid;
296:   logic                    unused_otbn_dmem_scramble_key_seed_valid;
297: 
298: 
299:   logic otbn_scramble_state_error;
300: 
301:   // SEC_CM: SCRAMBLE.KEY.SIDELOAD
302:   otbn_scramble_ctrl #(
303:     .RndCnstOtbnKey  (RndCnstOtbnKey),
304:     .RndCnstOtbnNonce(RndCnstOtbnNonce)
305:   ) u_otbn_scramble_ctrl (
306:     .clk_i,
307:     .rst_ni,
308: 
309:     .clk_otp_i,
310:     .rst_otp_ni,
311: 
312:     .otbn_otp_key_o,
313:     .otbn_otp_key_i,
314: 
315:     .otbn_dmem_scramble_key_o           (otbn_dmem_scramble_key),
316:     .otbn_dmem_scramble_nonce_o         (otbn_dmem_scramble_nonce),
317:     .otbn_dmem_scramble_valid_o         (otbn_dmem_scramble_valid),
318:     .otbn_dmem_scramble_key_seed_valid_o(unused_otbn_dmem_scramble_key_seed_valid),
319: 
320:     .otbn_imem_scramble_key_o           (otbn_imem_scramble_key),
321:     .otbn_imem_scramble_nonce_o         (otbn_imem_scramble_nonce),
322:     .otbn_imem_scramble_valid_o         (otbn_imem_scramble_valid),
323:     .otbn_imem_scramble_key_seed_valid_o(unused_otbn_imem_scramble_key_seed_valid),
324: 
325:     .otbn_dmem_scramble_sec_wipe_i    (dmem_sec_wipe),
326:     .otbn_dmem_scramble_sec_wipe_key_i(dmem_sec_wipe_urnd_key),
327:     .otbn_imem_scramble_sec_wipe_i    (imem_sec_wipe),
328:     .otbn_imem_scramble_sec_wipe_key_i(imem_sec_wipe_urnd_key),
329: 
330:     .otbn_dmem_scramble_key_req_busy_o(otbn_dmem_scramble_key_req_busy),
331:     .otbn_imem_scramble_key_req_busy_o(otbn_imem_scramble_key_req_busy),
332: 
333:     .state_error_o(otbn_scramble_state_error)
334:   );
335: 
336:   // SEC_CM: MEM.SCRAMBLE
337:   prim_ram_1p_scr #(
338:     .Width          (39),
339:     .Depth          (ImemSizeWords),
340:     .InstDepth      (ImemSizeWords),
341:     .DataBitsPerMask(39),
342:     .EnableParity   (0)
343:   ) u_imem (
344:     .clk_i,
345:     .rst_ni(rst_n),
346: 
347:     .key_valid_i(otbn_imem_scramble_valid),
348:     .key_i      (otbn_imem_scramble_key),
349:     .nonce_i    (otbn_imem_scramble_nonce),
350: 
351:     .req_i       (imem_req),
352:     .gnt_o       (imem_gnt),
353:     .write_i     (imem_write),
354:     .addr_i      (imem_index),
355:     .wdata_i     (imem_wdata),
356:     .wmask_i     (imem_wmask),
357:     .intg_error_i(locking),
358: 
359:     .rdata_o  (imem_rdata),
360:     .rvalid_o (imem_rvalid),
361:     .raddr_o  (),
362:     .rerror_o (),
363:     .cfg_i    (ram_cfg_imem_i),
364:     .cfg_rsp_o(ram_cfg_rsp_imem_o),
365: 
366:     .wr_collision_o   (imem_wr_collision),
367:     .write_pending_o  (imem_wpending),
368: 
369:     .alert_o ()
370:   );
371: 
372:   // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
373:   assign imem_missed_gnt = imem_req & ~imem_gnt;
374: 
375:   // IMEM access from main TL-UL bus
376:   logic imem_gnt_bus;
377:   // Always grant to bus accesses, when OTBN is running a dummy response is returned
378:   assign imem_gnt_bus = imem_req_bus;
379: 
380:   tlul_adapter_sram #(
381:     .SramAw          (ImemIndexWidth),
382:     .SramDw          (32),
383:     .Outstanding     (1),
384:     .ByteAccess      (0),
385:     .ErrOnRead       (0),
386:     .EnableDataIntgPt(1),
387:     .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
388:   ) u_tlul_adapter_sram_imem (
389:     .clk_i,
390:     .rst_ni                     (rst_n),
391:     .tl_i                       (tl_win_h2d[TlWinImem]),
392:     .tl_o                       (tl_win_d2h[TlWinImem]),
393:     .en_ifetch_i                (MuBi4False),
394:     .req_o                      (imem_req_bus),
395:     .req_type_o                 (),
396:     .gnt_i                      (imem_gnt_bus),
397:     .we_o                       (imem_write_bus),
398:     .addr_o                     (imem_index_bus),
399:     .wdata_o                    (imem_wdata_bus),
400:     .wmask_o                    (imem_wmask_bus),
401:     .intg_error_o               (imem_bus_intg_violation),
402:     .user_rsvd_o                (),
403:     .rdata_i                    (imem_rdata_bus),
404:     .rvalid_i                   (imem_rvalid_bus),
405:     .rerror_i                   (imem_rerror_bus),
406:     .compound_txn_in_progress_o (),
407:     .readback_en_i              (prim_mubi_pkg::MuBi4False),
408:     .readback_error_o           (),
409:     .wr_collision_i             (imem_wr_collision),
410:     .write_pending_i            (imem_wpending)
411:   );
412: 
413: 
414:   // Mux core and bus access into IMEM
415:   assign imem_access_core = busy_execute_q | start_q;
416: 
417:   assign imem_req   = imem_access_core ? imem_req_core        : imem_req_bus;
418:   assign imem_write = imem_access_core ? imem_write_core      : imem_write_bus;
419:   assign imem_index = imem_access_core ? imem_index_core      : imem_index_bus;
420:   assign imem_wdata = imem_access_core ? '0                   : imem_wdata_bus;
421: 
422:   assign imem_illegal_bus_access = imem_req_bus & imem_access_core;
423: 
424:   assign imem_dummy_response_d = imem_illegal_bus_access;
425:   always_ff @(posedge clk_i or negedge rst_ni) begin
426:     if (!rst_ni) begin
427:       imem_dummy_response_q <= 1'b0;
428:     end else begin
429:       imem_dummy_response_q <= imem_dummy_response_d;
430:     end
431:   end
432: 
433:   // The instruction memory only supports 32b word writes, so we hardcode its
434:   // wmask here.
435:   //
436:   // Since this could cause confusion if the bus tried to do a partial write
437:   // (which wasn't caught in the TLUL adapter for some reason), we assert that
438:   // the wmask signal from the bus is indeed '1 when it requests a write. We
439:   // don't have the corresponding check for writes from the core because the
440:   // core cannot perform writes (and has no imem_wmask_o port).
441:   assign imem_wmask = imem_access_core ? '1 : imem_wmask_bus;
442:   `ASSERT(ImemWmaskBusIsFullWord_A, imem_req_bus && imem_write_bus |-> imem_wmask_bus == '1)
443: 
444:   // SEC_CM: DATA_REG_SW.SCA
445:   // Blank bus read data interface during core operation to avoid leaking the currently executed
446:   // instruction from IMEM through the bus unintentionally. Also blank when OTBN is returning
447:   // a dummy response (responding to an illegal bus access) and when OTBN is locked.
448:   assign imem_rdata_bus_en_d = 1'b1;
449: 
450:   always_ff @(posedge clk_i or negedge rst_ni) begin
451:     if (!rst_ni) begin
452:         imem_rdata_bus_en_q <= 1'b1;
453:     end else begin
454:         imem_rdata_bus_en_q <= imem_rdata_bus_en_d;
455:     end
456:   end
457: 
458:   prim_blanker #(.Width(39)) u_imem_rdata_bus_blanker (
459:     .in_i (imem_rdata),
460:     .en_i (imem_rdata_bus_en_q),
461:     .out_o(imem_rdata_bus_raw)
462:   );
463: 
464:   // When OTBN is locked all imem bus reads should return 0. The blanker produces the 0s, this adds
465:   // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
466:   // through. Data bits are always left un-modified. A registered version of `locking` is used for
467:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
468:   // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
469:   // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
470:   // in so it is reasonable to proceed with returning the supplied integrity.
471:   assign imem_rdata_bus =
472:     {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : imem_rdata_bus_raw[38:32],
473:      imem_rdata_bus_raw[31:0]};
474: 
475:   `ASSERT(ImemRDataBusDisabledWhenCoreAccess_A, imem_access_core |-> !imem_rdata_bus_en_q)
476:   `ASSERT(ImemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> imem_rdata_bus_en_q)
477:   `ASSERT(ImemRDataBusDisabledWhenLocked_A, locking |=> !imem_rdata_bus_en_q)
478:   `ASSERT(ImemRDataBusReadAsZeroWhenLocked_A,
479:     imem_rvalid_bus & locking |-> imem_rdata_bus_raw == '0)
480: 
481:   assign imem_rdata_core = imem_rdata;
482: 
483:   // When an illegal bus access is seen, always return a dummy response the follow cycle.
484:   assign imem_rvalid_bus = (~imem_access_core & imem_rvalid) | imem_dummy_response_q;
485:   assign imem_rvalid_core = imem_access_core ? imem_rvalid : 1'b0;
486: 
487:   assign imem_byte_mask_bus = tl_win_h2d[TlWinImem].a_mask;
488: 
489:   // No imem errors reported for bus reads. Integrity is carried through on the bus so integrity
490:   // checking on TL responses will pick up any errors.
491:   assign imem_rerror_bus = 2'b00;
492: 
493:   // Data Memory (DMEM) ========================================================
494: 
495:   localparam int DmemSizeWords = DmemSizeByte / (WLEN / 8);
496:   localparam int DmemIndexWidth = vbits(DmemSizeWords);
497: 
498:   localparam int DmemBusSizeWords = int'(otbn_reg_pkg::OTBN_DMEM_SIZE) / (WLEN / 8);
499:   localparam int DmemBusIndexWidth = vbits(DmemBusSizeWords);
500: 
501:   // Access select to DMEM: core (1), or bus (0)
502:   logic dmem_access_core;
503: 
504:   logic dmem_req;
505:   logic dmem_gnt;
506:   logic dmem_write;
507:   logic [DmemIndexWidth-1:0] dmem_index;
508:   logic [ExtWLEN-1:0] dmem_wdata;
509:   logic [ExtWLEN-1:0] dmem_wmask;
510:   logic [ExtWLEN-1:0] dmem_rdata;
511:   logic dmem_rvalid;
512:   logic [BaseWordsPerWLEN*2-1:0] dmem_rerror_vec;
513:   logic dmem_rerror;
514:   logic dmem_illegal_bus_access;
515:   logic dmem_missed_gnt;
516: 
517:   logic dmem_req_core;
518:   logic dmem_write_core;
519:   logic [DmemIndexWidth-1:0] dmem_index_core;
520:   logic [ExtWLEN-1:0] dmem_wdata_core;
521:   logic [ExtWLEN-1:0] dmem_wmask_core;
522:   logic [BaseWordsPerWLEN-1:0] dmem_rmask_core_q, dmem_rmask_core_d;
523:   logic [ExtWLEN-1:0] dmem_rdata_core;
524:   logic dmem_rvalid_core;
525:   logic dmem_rerror_core;
526: 
527:   logic dmem_req_bus;
528:   logic dmem_dummy_response_q, dmem_dummy_response_d;
529:   logic dmem_write_bus;
530:   logic [DmemBusIndexWidth-1:0] dmem_index_bus;
531:   logic [ExtWLEN-1:0] dmem_wdata_bus;
532:   logic [ExtWLEN-1:0] dmem_wmask_bus;
533:   logic [ExtWLEN-1:0] dmem_rdata_bus, dmem_rdata_bus_raw;
534:   logic dmem_rdata_bus_en_q, dmem_rdata_bus_en_d;
535:   logic [DmemAddrWidth-1:0] dmem_addr_bus;
536:   logic unused_dmem_addr_bus;
537:   logic [31:0] dmem_wdata_narrow_bus;
538:   logic [top_pkg::TL_DBW-1:0] dmem_byte_mask_bus;
539:   logic dmem_rvalid_bus;
540:   logic dmem_wr_collision;
541:   logic dmem_wpending;
542:   logic [1:0] dmem_rerror_bus;
543: 
544:   logic dmem_bus_intg_violation;
545: 
546:   logic [DmemAddrWidth-1:0] dmem_addr_core;
547:   assign dmem_index_core = dmem_addr_core[DmemAddrWidth-1:DmemAddrWidth-DmemIndexWidth];
548: 
549:   logic unused_dmem_addr_core_wordbits;
550:   assign unused_dmem_addr_core_wordbits = ^dmem_addr_core[DmemAddrWidth-DmemIndexWidth-1:0];
551: 
552:   // SEC_CM: MEM.SCRAMBLE
553:   prim_ram_1p_scr #(
554:     .Width             (ExtWLEN),
555:     .Depth             (DmemSizeWords),
556:     .InstDepth         (DmemSizeWords),
557:     .DataBitsPerMask   (39),
558:     .EnableParity      (0),
559:     .ReplicateKeyStream(1)
560:   ) u_dmem (
561:     .clk_i,
562:     .rst_ni(rst_n),
563: 
564:     .key_valid_i(otbn_dmem_scramble_valid),
565:     .key_i      (otbn_dmem_scramble_key),
566:     .nonce_i    (otbn_dmem_scramble_nonce),
567: 
568:     .req_i       (dmem_req),
569:     .gnt_o       (dmem_gnt),
570:     .write_i     (dmem_write),
571:     .addr_i      (dmem_index),
572:     .wdata_i     (dmem_wdata),
573:     .wmask_i     (dmem_wmask),
574:     .intg_error_i(locking),
575: 
576:     .rdata_o  (dmem_rdata),
577:     .rvalid_o (dmem_rvalid),
578:     .raddr_o  (),
579:     .rerror_o (),
580:     .cfg_i    (ram_cfg_dmem_i),
581:     .cfg_rsp_o(ram_cfg_rsp_dmem_o),
582: 
583:     .wr_collision_o   (dmem_wr_collision),
584:     .write_pending_o  (dmem_wpending),
585: 
586:     .alert_o ()
587:   );
588: 
589:   // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
590:   assign dmem_missed_gnt = dmem_req & !dmem_gnt;
591: 
592:   always_ff @(posedge clk_i or negedge rst_ni) begin
593:     if (!rst_ni) begin
594:       dmem_rmask_core_q <= '0;
595:     end else begin
596:       if (dmem_req_core) begin
597:         dmem_rmask_core_q <= dmem_rmask_core_d;
598:       end
599:     end
600:   end
601: 
602:   // SEC_CM: DATA.MEM.INTEGRITY
603:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_intg_check
604:     logic [1:0] dmem_rerror_raw;
605: 
606:     // Separate check for dmem read data integrity outside of `u_dmem` as `prim_ram_1p_adv` doesn't
607:     // have functionality for only integrity checking, just fully integrated ECC. Integrity bits are
608:     // implemented on a 32-bit granule so separate checks are required for each.
609:     prim_secded_inv_39_32_dec u_dmem_intg_check (
610:       .data_i    (dmem_rdata[i_word*39+:39]),
611:       .data_o    (),
612:       .syndrome_o(),
613:       .err_o     (dmem_rerror_raw)
614:     );
615: 
616:     // Only report an error where the word was actually accessed. Otherwise uninitialised memory
617:     // that OTBN isn't using will cause false errors. dmem_rerror is only reported for reads from
618:     // OTBN. For Ibex reads integrity checking on TL responses will serve the same purpose.
619:     assign dmem_rerror_vec[i_word*2 +: 2] = {2{dmem_rmask_core_q[i_word] & dmem_rvalid & dmem_access_core}};
620:   end
621: 
622:   // dmem_rerror_vec is 2 bits wide and is used to report ECC errors. Bit 1 is set if there's an
623:   // uncorrectable error and bit 0 is set if there's a correctable error. However, we're treating
624:   // all errors as fatal, so OR the two signals together.
625:   assign dmem_rerror = |dmem_rerror_vec;
626: 
627:   // DMEM access from main TL-UL bus
628:   logic dmem_gnt_bus;
629:   // Always grant to bus accesses, when OTBN is running a dummy response is returned
630:   assign dmem_gnt_bus = dmem_req_bus;
631: 
632:   tlul_adapter_sram #(
633:     .SramAw          (DmemBusIndexWidth),
634:     .SramDw          (WLEN),
635:     .Outstanding     (1),
636:     .ByteAccess      (0),
637:     .ErrOnRead       (0),
638:     .EnableDataIntgPt(1),
639:     .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
640:   ) u_tlul_adapter_sram_dmem (
641:     .clk_i,
642:     .rst_ni                     (rst_n),
643:     .tl_i                       (tl_win_h2d[TlWinDmem]),
644:     .tl_o                       (tl_win_d2h[TlWinDmem]),
645:     .en_ifetch_i                (MuBi4False),
646:     .req_o                      (dmem_req_bus),
647:     .req_type_o                 (),
648:     .gnt_i                      (dmem_gnt_bus),
649:     .we_o                       (dmem_write_bus),
650:     .addr_o                     (dmem_index_bus),
651:     .wdata_o                    (dmem_wdata_bus),
652:     .wmask_o                    (dmem_wmask_bus),
653:     .intg_error_o               (dmem_bus_intg_violation),
654:     .user_rsvd_o                (),
655:     .rdata_i                    (dmem_rdata_bus),
656:     .rvalid_i                   (dmem_rvalid_bus),
657:     .rerror_i                   (dmem_rerror_bus),
658:     .compound_txn_in_progress_o (),
659:     .readback_en_i              (prim_mubi_pkg::MuBi4False),
660:     .readback_error_o           (),
661:     .wr_collision_i             (dmem_wr_collision),
662:     .write_pending_i            (dmem_wpending)
663:   );
664: 
665:   // Mux core and bus access into dmem
666:   assign dmem_access_core = busy_execute_q;
667: 
668:   assign dmem_req = dmem_access_core ? dmem_req_core : dmem_req_bus;
669:   assign dmem_write = dmem_access_core ? dmem_write_core : dmem_write_bus;
670:   assign dmem_wmask = dmem_access_core ? dmem_wmask_core : dmem_wmask_bus;
671:   // SEC_CM: DATA.MEM.SW_NOACCESS
672:   assign dmem_index = dmem_access_core ? dmem_index_core : dmem_index_bus;
673:   assign dmem_wdata = dmem_access_core ? dmem_wdata_core : dmem_wdata_bus;
674: 
675:   assign dmem_illegal_bus_access = dmem_req_bus & dmem_access_core;
676: 
677:   assign dmem_dummy_response_d = dmem_illegal_bus_access;
678:   always_ff @(posedge clk_i or negedge rst_ni) begin
679:     if (!rst_ni) begin
680:       dmem_dummy_response_q <= 1'b0;
681:     end else begin
682:       dmem_dummy_response_q <= dmem_dummy_response_d;
683:     end
684:   end
685: 
686:   // SEC_CM: DATA_REG_SW.SCA
687:   // Blank bus read data interface during core operation to avoid leaking DMEM data through the bus
688:   // unintentionally. Also blank when OTBN is returning a dummy response (responding to an illegal
689:   // bus access) and when OTBN is locked.
690:   assign dmem_rdata_bus_en_d = 1'b1;
691: 
692:   always_ff @(posedge clk_i or negedge rst_ni) begin
693:     if (!rst_ni) begin
694:         dmem_rdata_bus_en_q <= 1'b1;
695:     end else begin
696:         dmem_rdata_bus_en_q <= dmem_rdata_bus_en_d;
697:     end
698:   end
699: 
700:   prim_blanker #(.Width(ExtWLEN)) u_dmem_rdata_bus_blanker (
701:     .in_i (dmem_rdata),
702:     .en_i (dmem_rdata_bus_en_q),
703:     .out_o(dmem_rdata_bus_raw)
704:   );
705: 
706:   // When OTBN is locked all dmem bus reads should return 0. The blanker produces the 0s, this adds
707:   // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
708:   // through. Data bits are always left un-modified. A registered version of `locking` is used for
709:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
710:   // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
711:   // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
712:   // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
713:   // in so it is reasonable to proceed with returning the supplied integrity.
714:   for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_rdata_bus
715:     assign dmem_rdata_bus[i_word*39+:39] =
716:       {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : dmem_rdata_bus_raw[i_word*39+32+:7],
717:        dmem_rdata_bus_raw[i_word*39+:32]};
718:   end
719: 
720:   `ASSERT(DmemRDataBusDisabledWhenCoreAccess_A, dmem_access_core |-> !dmem_rdata_bus_en_q)
721:   `ASSERT(DmemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> dmem_rdata_bus_en_q)
722:   `ASSERT(DmemRDataBusDisabledWhenLocked_A, locking |=> !dmem_rdata_bus_en_q)
723:   `ASSERT(DmemRDataBusReadAsZeroWhenLocked_A,
724:     dmem_rvalid_bus & locking |-> dmem_rdata_bus_raw == '0)
725: 
726:   assign dmem_rdata_core = dmem_rdata;
727: 
728:   // When an illegal bus access is seen, always return a dummy response the follow cycle.
729:   assign dmem_rvalid_bus  = (~dmem_access_core & dmem_rvalid) | dmem_dummy_response_q;
730:   assign dmem_rvalid_core = dmem_access_core ? dmem_rvalid : 1'b0;
731: 
732:   // No dmem errors reported for bus reads. Integrity is carried through on the bus so integrity
733:   // checking on TL responses will pick up any errors.
734:   assign dmem_rerror_bus  = 2'b00;
735:   assign dmem_rerror_core = dmem_rerror;
736: 
737:   assign dmem_addr_bus = tl_win_h2d[TlWinDmem].a_address[DmemAddrWidth-1:0];
738:   assign dmem_wdata_narrow_bus = tl_win_h2d[TlWinDmem].a_data[31:0];
739:   assign dmem_byte_mask_bus = tl_win_h2d[TlWinDmem].a_mask;
740: 
741:   // Memory Load Integrity =====================================================
742:   // CRC logic below assumes a incoming data bus width of 32 bits
743:   `ASSERT_INIT(TLDWIs32Bit_A, top_pkg::TL_DW == 32)
744: 
745:   // Only advance CRC calculation on full 32-bit writes;
746:   assign mem_crc_data_in_valid   = ~(dmem_access_core | imem_access_core) &
747:       ((imem_req_bus & (imem_byte_mask_bus == 4'hf)) |
748:        (dmem_req_bus & (dmem_byte_mask_bus == 4'hf)));
749: 
750:   assign mem_crc_data_in.wr_data = imem_req_bus ? imem_wdata_bus[31:0] :
751:                                                   dmem_wdata_narrow_bus[31:0];
752:   assign mem_crc_data_in.index   = imem_req_bus ? {{15 - ImemIndexWidth{1'b0}}, imem_index_bus} :
753:                                                    {{15 - (DmemAddrWidth - 2){1'b0}},
754:                                                     dmem_addr_bus[DmemAddrWidth-1:2]};
755:   assign mem_crc_data_in.imem    = imem_req_bus;
756: 
757:   // Only the bits that factor into the dmem index and dmem word enables are required
758:   assign unused_dmem_addr_bus = ^{dmem_addr_bus[DmemAddrWidth-1:DmemIndexWidth],
759:                                   dmem_addr_bus[1:0]};
760: 
761:   // SEC_CM: WRITE.MEM.INTEGRITY
762:   prim_crc32 #(
763:     .BytesPerWord(6)
764:   ) u_mem_load_crc32 (
765:     .clk_i (clk_i),
766:     .rst_ni(rst_ni),
767: 
768:     .set_crc_i(set_crc),
769:     .crc_in_i (crc_in),
770: 
771:     .data_valid_i(mem_crc_data_in_valid),
772:     .data_i      (mem_crc_data_in),
773:     .crc_out_o   (crc_out)
774:   );
775: 
776:   assign set_crc = reg2hw.load_checksum.qe;
777:   assign crc_in = reg2hw.load_checksum.q;
778:   assign hw2reg.load_checksum.d = crc_out;
779: 
780:   // Registers =================================================================
781: 
782:   logic reg_bus_intg_violation;
783: 
784:   otbn_reg_top u_reg (
785:     .clk_i,
786:     .rst_ni  (rst_n),
787:     .tl_i,
788:     .tl_o,
789:     .tl_win_o(tl_win_h2d),
790:     .tl_win_i(tl_win_d2h),
791: 
792:     .reg2hw,
793:     .hw2reg,
794: 
795:     .intg_err_o(reg_bus_intg_violation)
796:   );
797: 
798:   // SEC_CM: BUS.INTEGRITY
799:   // SEC_CM: TLUL_FIFO.CTR.REDUN
800:   logic bus_intg_violation;
801:   assign bus_intg_violation = (imem_bus_intg_violation | dmem_bus_intg_violation |
802:                                reg_bus_intg_violation);
803: 
804:   // CMD register
805:   always_comb begin
806:     // start is flopped to avoid long timing paths from the TL fabric into OTBN internals.
807:     start_d       = 1'b0;
808:     dmem_sec_wipe = 1'b0;
809:     imem_sec_wipe = 1'b0;
810: 
811:     // Can only start a new command when idle.
812:     if (status_q == StatusIdle) begin
813:       if (reg2hw.cmd.qe) begin
814:         unique case (reg2hw.cmd.q)
815:           CmdExecute:     start_d       = 1'b1;
816:           CmdSecWipeDmem: dmem_sec_wipe = 1'b1;
817:           CmdSecWipeImem: imem_sec_wipe = 1'b1;
818:           default: ;
819:         endcase
820:       end
821:     end else if (busy_execute_q) begin
822:       // OTBN can command a secure wipe of IMEM and DMEM. This occurs when OTBN encounters a fatal
823:       // error.
824:       if (mems_sec_wipe) begin
825:         dmem_sec_wipe = 1'b1;
826:         imem_sec_wipe = 1'b1;
827:       end
828:     end
829:   end
830: 
831:   assign req_sec_wipe_urnd_keys = dmem_sec_wipe | imem_sec_wipe;
832: 
833:   assign illegal_bus_access_d = dmem_illegal_bus_access | imem_illegal_bus_access;
834: 
835:   // It should not be possible to request an imem or dmem access without it being granted. Either
836:   // a scramble key is present so the request will be granted or the core is busy obtaining a new
837:   // key, so no request can occur (the core won't generate one whilst awaiting a scrambling key and
838:   // the bus requests get an immediate dummy response bypassing the dmem or imem). A fatal error is
839:   // raised if request is seen without a grant.
840:   assign missed_gnt_error_d = dmem_missed_gnt | imem_missed_gnt;
841: 
842:   // Flop `illegal_bus_access_q` and `missed_gnt_error_q` to break timing paths from the TL
843:   // interface into the OTBN core.
844:   always_ff @(posedge clk_i or negedge rst_ni) begin
845:     if (!rst_ni) begin
846:       start_q              <= 1'b0;
847:       illegal_bus_access_q <= 1'b0;
848:       missed_gnt_error_q   <= 1'b0;
849:     end else begin
850:       start_q              <= start_d;
851:       illegal_bus_access_q <= illegal_bus_access_d;
852:       missed_gnt_error_q   <= missed_gnt_error_d;
853:     end
854:   end
855: 
856:   // STATUS register
857:   // imem/dmem scramble req can be busy when locked, so use a priority selection so locked status
858:   // always takes priority.
859:   //
860:   // Note that these signals are all "a cycle early". For example, the locking signal gets asserted
861:   // combinatorially on the cycle that an error is injected. The STATUS register change, done
862:   // interrupt and any change to the idle signal will be delayed by 2 cycles.
863:   assign status_d = locking                         ? StatusLocked          :
864:                     busy_secure_wipe                ? StatusBusySecWipeInt  :
865:                     busy_execute_d                  ? StatusBusyExecute     :
866:                     otbn_dmem_scramble_key_req_busy ? StatusBusySecWipeDmem :
867:                     otbn_imem_scramble_key_req_busy ? StatusBusySecWipeImem :
868:                                                       StatusIdle;
869:   always_ff @(posedge clk_i or negedge rst_ni) begin
870:     if (!rst_ni) begin
871:       status_q <= StatusBusySecWipeInt;
872:     end else begin
873:       status_q <= status_d;
874:     end
875:   end
876: 
877:   assign hw2reg.status.d = status_q;
878:   assign hw2reg.status.de = 1'b1;
879: 
880:   // Only certain combinations of the state variable {locking, busy_execute_d,
881:   // otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy} are possible.
882:   //
883:   // - Once locking is high, we guarantee never to see a new execution or the start of a key
884:   //   rotation. (Assertion: NoStartWhenLocked_A)
885: 
886:   `ASSERT(NoStartWhenLocked_A,
887:           locking |=> !($rose(busy_execute_d) ||
888:                         $rose(otbn_dmem_scramble_key_req_busy) ||
889:                         $rose(otbn_imem_scramble_key_req_busy)))
890: 
891:   // CTRL register
892:   assign software_errs_fatal_d =
893:     reg2hw.ctrl.qe && (status_q == StatusIdle) ? reg2hw.ctrl.q :
894:                                                  software_errs_fatal_q;
895: 
896:   always_ff @(posedge clk_i or negedge rst_ni) begin
897:     if (!rst_ni) begin
898:       software_errs_fatal_q <= 1'b0;
899:     end else begin
900:       software_errs_fatal_q <= software_errs_fatal_d;
901:     end
902:   end
903: 
904:   assign hw2reg.ctrl.d = software_errs_fatal_q;
905: 
906:   // ERR_BITS register
907:   // The error bits for an OTBN operation get stored on the cycle that done is
908:   // asserted. Software is expected to read them out before starting the next operation.
909: 
910:   assign hw2reg.err_bits.bad_data_addr.d = err_bits_q.bad_data_addr;
911:   assign hw2reg.err_bits.bad_insn_addr.d = err_bits_q.bad_insn_addr;
912:   assign hw2reg.err_bits.call_stack.d = err_bits_q.call_stack;
913:   assign hw2reg.err_bits.illegal_insn.d = err_bits_q.illegal_insn;
914:   assign hw2reg.err_bits.loop.d = err_bits_q.loop;
915:   assign hw2reg.err_bits.key_invalid.d = err_bits_q.key_invalid;
916:   assign hw2reg.err_bits.rnd_rep_chk_fail.d = err_bits_q.rnd_rep_chk_fail;
917:   assign hw2reg.err_bits.rnd_fips_chk_fail.d = err_bits_q.rnd_fips_chk_fail;
918:   assign hw2reg.err_bits.imem_intg_violation.d = err_bits_q.imem_intg_violation;
919:   assign hw2reg.err_bits.dmem_intg_violation.d = err_bits_q.dmem_intg_violation;
920:   assign hw2reg.err_bits.reg_intg_violation.d = err_bits_q.reg_intg_violation;
921:   assign hw2reg.err_bits.bus_intg_violation.d = err_bits_q.bus_intg_violation;
922:   assign hw2reg.err_bits.bad_internal_state.d = err_bits_q.bad_internal_state;
923:   assign hw2reg.err_bits.illegal_bus_access.d = err_bits_q.illegal_bus_access;
924:   assign hw2reg.err_bits.lifecycle_escalation.d = err_bits_q.lifecycle_escalation;
925:   assign hw2reg.err_bits.fatal_software.d = err_bits_q.fatal_software;
926: 
927:   assign err_bits_clear = reg2hw.err_bits.bad_data_addr.qe & is_not_running_q;
928:   assign err_bits_d = err_bits_clear ? '0 : err_bits;
929:   assign err_bits_en = err_bits_clear | done_core;
930: 
931:   logic unused_reg2hw_err_bits;
932: 
933:   // Majority of reg2hw.err_bits is unused as write values are ignored, all writes clear the
934:   // register to 0.
935:   assign unused_reg2hw_err_bits = ^{reg2hw.err_bits.bad_data_addr.q,
936:                                     reg2hw.err_bits.bad_insn_addr,
937:                                     reg2hw.err_bits.call_stack,
938:                                     reg2hw.err_bits.illegal_insn,
939:                                     reg2hw.err_bits.loop,
940:                                     reg2hw.err_bits.key_invalid,
941:                                     reg2hw.err_bits.rnd_rep_chk_fail,
942:                                     reg2hw.err_bits.rnd_fips_chk_fail,
943:                                     reg2hw.err_bits.imem_intg_violation,
944:                                     reg2hw.err_bits.dmem_intg_violation,
945:                                     reg2hw.err_bits.reg_intg_violation,
946:                                     reg2hw.err_bits.bus_intg_violation,
947:                                     reg2hw.err_bits.bad_internal_state,
948:                                     reg2hw.err_bits.illegal_bus_access,
949:                                     reg2hw.err_bits.lifecycle_escalation,
950:                                     reg2hw.err_bits.fatal_software};
951: 
952:   always_ff @(posedge clk_i or negedge rst_ni) begin
953:     if (!rst_ni) begin
954:       err_bits_q <= '0;
955:     end else if (err_bits_en) begin
956:       err_bits_q <= err_bits_d;
957:     end
958:   end
959: 
960:   // Latch the recoverable error signal from the core. This will be generated as a pulse some time
961:   // during the run (and before secure wipe finishes). Collect up this bit, clearing on the start or
962:   // end of an operation (start_q / done_core, respectively)
963:   assign recoverable_err_d = (recoverable_err_q | core_recoverable_err) & ~(start_q | done_core);
964:   always_ff @(posedge clk_i or negedge rst_ni) begin
965:     if (!rst_ni) begin
966:       recoverable_err_q <= '0;
967:     end else begin
968:       recoverable_err_q <= recoverable_err_d;
969:     end
970:   end
971: 
972:   // FATAL_ALERT_CAUSE register. The .de and .d values are equal for each bit, so that it can only
973:   // be set, not cleared.
974: `define DEF_FAC_BIT(NAME)                                         \
975:   assign hw2reg.fatal_alert_cause.``NAME``.d = 1'b1;              \
976:   assign hw2reg.fatal_alert_cause.``NAME``.de = err_bits.``NAME;
977: 
978:   `DEF_FAC_BIT(fatal_software)
979:   `DEF_FAC_BIT(lifecycle_escalation)
980:   `DEF_FAC_BIT(illegal_bus_access)
981:   `DEF_FAC_BIT(bad_internal_state)
982:   `DEF_FAC_BIT(bus_intg_violation)
983:   `DEF_FAC_BIT(reg_intg_violation)
984:   `DEF_FAC_BIT(dmem_intg_violation)
985:   `DEF_FAC_BIT(imem_intg_violation)
986: 
987: `undef DEF_FAC_BIT
988: 
989:   // INSN_CNT register
990:   logic [31:0] insn_cnt;
991:   logic        insn_cnt_clear;
992:   logic        unused_insn_cnt_q;
993:   assign hw2reg.insn_cnt.d = insn_cnt;
994:   assign insn_cnt_clear = reg2hw.insn_cnt.qe & is_not_running_q;
995:   // Ignore all write data to insn_cnt. All writes zero the register.
996:   assign unused_insn_cnt_q = ^reg2hw.insn_cnt.q;
997: 
998:   // Alerts ====================================================================
999: 
1000:   logic [NumAlerts-1:0] alert_test;
1001:   assign alert_test[AlertFatal] = reg2hw.alert_test.fatal.q & reg2hw.alert_test.fatal.qe;
1002:   assign alert_test[AlertRecov] = reg2hw.alert_test.recov.q & reg2hw.alert_test.recov.qe;
1003: 
1004:   logic [NumAlerts-1:0] alerts;
1005:   assign alerts[AlertFatal] = |{err_bits.fatal_software,
1006:                                 err_bits.lifecycle_escalation,
1007:                                 err_bits.illegal_bus_access,
1008:                                 err_bits.bad_internal_state,
1009:                                 err_bits.bus_intg_violation,
1010:                                 err_bits.reg_intg_violation,
1011:                                 err_bits.dmem_intg_violation,
1012:                                 err_bits.imem_intg_violation};
1013: 
1014:   assign alerts[AlertRecov] = (core_recoverable_err | recoverable_err_q) & done_core;
1015: 
1016:   for (genvar i = 0; i < NumAlerts; i++) begin : gen_alert_tx
1017:     prim_alert_sender #(
1018:       .AsyncOn(AlertAsyncOn[i]),
1019:       .IsFatal(i == AlertFatal)
1020:     ) u_prim_alert_sender (
1021:       .clk_i,
1022:       .rst_ni       (rst_n),
1023:       .alert_test_i (alert_test[i]),
1024:       .alert_req_i  (alerts[i]),
1025:       .alert_ack_o  (),
1026:       .alert_state_o(),
1027:       .alert_rx_i   (alert_rx_i[i]),
1028:       .alert_tx_o   (alert_tx_o[i])
1029:     );
1030:   end
1031: 
1032: 
1033:   // EDN Connections ============================================================
1034:   logic edn_rnd_req, edn_rnd_ack;
1035:   logic [EdnDataWidth-1:0] edn_rnd_data;
1036:   logic edn_rnd_fips, edn_rnd_err;
1037: 
1038:   logic edn_urnd_req, edn_urnd_ack;
1039:   logic [EdnDataWidth-1:0] edn_urnd_data;
1040: 
1041:   // These synchronize the data coming from EDN and stack the 32 bit EDN words to achieve an
1042:   // internal entropy width of 256 bit.
1043: 
1044:   prim_edn_req #(
1045:     .EnRstChks(1'b1),
1046:     .OutWidth(EdnDataWidth),
1047:     // SEC_CM: RND.BUS.CONSISTENCY
1048:     .RepCheck(1'b1)
1049:   ) u_prim_edn_rnd_req (
1050:     .clk_i,
1051:     .rst_ni     ( rst_n        ),
1052:     .req_chk_i  ( 1'b1         ),
1053:     .req_i      ( edn_rnd_req  ),
1054:     .ack_o      ( edn_rnd_ack  ),
1055:     .data_o     ( edn_rnd_data ),
1056:     .fips_o     ( edn_rnd_fips ),
1057:     .err_o      ( edn_rnd_err  ),
1058:     .clk_edn_i,
1059:     .rst_edn_ni,
1060:     .edn_o      ( edn_rnd_o ),
1061:     .edn_i      ( edn_rnd_i )
1062:   );
1063: 
1064:   prim_edn_req #(
1065:     .EnRstChks(1'b1),
1066:     .OutWidth(EdnDataWidth)
1067:   ) u_prim_edn_urnd_req (
1068:     .clk_i,
1069:     .rst_ni     ( rst_n         ),
1070:     .req_chk_i  ( 1'b1          ),
1071:     .req_i      ( edn_urnd_req  ),
1072:     .ack_o      ( edn_urnd_ack  ),
1073:     .data_o     ( edn_urnd_data ),
1074:     .fips_o     (               ), // unused
1075:     .err_o      (               ), // unused
1076:     .clk_edn_i,
1077:     .rst_edn_ni,
1078:     .edn_o      ( edn_urnd_o    ),
1079:     .edn_i      ( edn_urnd_i    )
1080:   );
1081: 
1082: 
1083:   // OTBN Core =================================================================
1084: 
1085:   always_ff @(posedge clk_i or negedge rst_n) begin
1086:     if (!rst_n) begin
1087:       busy_execute_q       <= 1'b0;
1088:       init_sec_wipe_done_q <= 1'b0;
1089:     end else begin
1090:       busy_execute_q       <= busy_execute_d;
1091:       init_sec_wipe_done_q <= init_sec_wipe_done_d;
1092:     end
1093:   end
1094:   assign busy_execute_d = (busy_execute_q | start_d) & ~done_core;
1095:   assign init_sec_wipe_done_d = init_sec_wipe_done_q | ~busy_secure_wipe;
1096: 
1097:   otbn_core #(
1098:     .RegFile(RegFile),
1099:     .DmemSizeByte(DmemSizeByte),
1100:     .ImemSizeByte(ImemSizeByte),
1101:     .RndCnstUrndPrngSeed(RndCnstUrndPrngSeed),
1102:     .SecMuteUrnd(SecMuteUrnd),
1103:     .SecSkipUrndReseedAtStart(SecSkipUrndReseedAtStart)
1104:   ) u_otbn_core (
1105:     .clk_i,
1106:     .rst_ni                      (rst_n),
1107: 
1108:     .start_i                     (start_q),
1109:     .done_o                      (done_core),
1110:     .locking_o                   (locking),
1111:     .secure_wipe_running_o       (busy_secure_wipe),
1112: 
1113:     .err_bits_o                  (core_err_bits),
1114:     .recoverable_err_o           (core_recoverable_err),
1115: 
1116:     .imem_req_o                  (imem_req_core),
1117:     .imem_addr_o                 (imem_addr_core),
1118:     .imem_rdata_i                (imem_rdata_core),
1119:     .imem_rvalid_i               (imem_rvalid_core),
1120: 
1121:     .dmem_req_o                  (dmem_req_core),
1122:     .dmem_write_o                (dmem_write_core),
1123:     .dmem_addr_o                 (dmem_addr_core),
1124:     .dmem_wdata_o                (dmem_wdata_core),
1125:     .dmem_wmask_o                (dmem_wmask_core),
1126:     .dmem_rmask_o                (dmem_rmask_core_d),
1127:     .dmem_rdata_i                (dmem_rdata_core),
1128:     .dmem_rvalid_i               (dmem_rvalid_core),
1129:     .dmem_rerror_i               (dmem_rerror_core),
1130: 
1131:     .edn_rnd_req_o               (edn_rnd_req),
1132:     .edn_rnd_ack_i               (edn_rnd_ack),
1133:     .edn_rnd_data_i              (edn_rnd_data),
1134:     .edn_rnd_fips_i              (edn_rnd_fips),
1135:     .edn_rnd_err_i               (edn_rnd_err),
1136: 
1137:     .edn_urnd_req_o              (edn_urnd_req),
1138:     .edn_urnd_ack_i              (edn_urnd_ack),
1139:     .edn_urnd_data_i             (edn_urnd_data),
1140: 
1141:     .insn_cnt_o                  (insn_cnt),
1142:     .insn_cnt_clear_i            (insn_cnt_clear),
1143: 
1144:     .mems_sec_wipe_o             (mems_sec_wipe),
1145:     .dmem_sec_wipe_urnd_key_o    (dmem_sec_wipe_urnd_key),
1146:     .imem_sec_wipe_urnd_key_o    (imem_sec_wipe_urnd_key),
1147:     .req_sec_wipe_urnd_keys_i    (req_sec_wipe_urnd_keys),
1148: 
1149:     .escalate_en_i               (core_escalate_en),
1150:     .rma_req_i                   (mubi_rma_req),
1151:     .rma_ack_o                   (mubi_rma_ack),
1152: 
1153:     .software_errs_fatal_i       (software_errs_fatal_q),
1154: 
1155:     .sideload_key_shares_i       (keymgr_key_i.key),
1156:     .sideload_key_shares_valid_i ({2{keymgr_key_i.valid}})
1157:   );
1158: 
1159:   always_ff @(posedge clk_i or negedge rst_n) begin
1160:     if (!rst_n) begin
1161:       locking_q <= 1'b0;
1162:     end else begin
1163:       locking_q <= locking;
1164:     end
1165:   end
1166: 
1167:   // Collect up the error bits that don't come from the core itself and latch them so that they'll
1168:   // be available when an operation finishes.
1169:   assign non_core_err_bits = '{
1170:     lifecycle_escalation: lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[0]),
1171:     illegal_bus_access:   illegal_bus_access_q,
1172:     bad_internal_state:   otbn_scramble_state_error | missed_gnt_error_q,
1173:     bus_intg_violation:   bus_intg_violation
1174:   };
1175: 
1176:   assign non_core_err_bits_d = non_core_err_bits_q | non_core_err_bits;
1177:   always_ff @(posedge clk_i or negedge rst_ni) begin
1178:     if (!rst_ni) begin
1179:       non_core_err_bits_q <= '0;
1180:     end else begin
1181:       non_core_err_bits_q <= non_core_err_bits_d;
1182:     end
1183:   end
1184: 
1185:   // Construct a full set of error bits from the core output
1186:   assign err_bits = '{
1187:     fatal_software:       core_err_bits.fatal_software,
1188:     lifecycle_escalation: non_core_err_bits_d.lifecycle_escalation,
1189:     illegal_bus_access:   non_core_err_bits_d.illegal_bus_access,
1190:     bad_internal_state:   |{core_err_bits.bad_internal_state,
1191:                             non_core_err_bits_d.bad_internal_state},
1192:     bus_intg_violation:   non_core_err_bits_d.bus_intg_violation,
1193:     reg_intg_violation:   core_err_bits.reg_intg_violation,
1194:     dmem_intg_violation:  core_err_bits.dmem_intg_violation,
1195:     imem_intg_violation:  core_err_bits.imem_intg_violation,
1196:     rnd_fips_chk_fail:    core_err_bits.rnd_fips_chk_fail,
1197:     rnd_rep_chk_fail:     core_err_bits.rnd_rep_chk_fail,
1198:     key_invalid:          core_err_bits.key_invalid,
1199:     loop:                 core_err_bits.loop,
1200:     illegal_insn:         core_err_bits.illegal_insn,
1201:     call_stack:           core_err_bits.call_stack,
1202:     bad_insn_addr:        core_err_bits.bad_insn_addr,
1203:     bad_data_addr:        core_err_bits.bad_data_addr
1204:   };
1205: 
1206:   // An error signal going down into the core to show that it should locally escalate. In
1207:   // accordance with the lc_ctrl spec, all values of the lc_escalate_en signal other than the OFF
1208:   // value must be interpreted as ON.
1209:   assign core_escalate_en = mubi4_bool_to_mubi(
1210:       |{non_core_err_bits.illegal_bus_access,
1211:         non_core_err_bits.bad_internal_state,
1212:         non_core_err_bits.bus_intg_violation,
1213:         lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[1])});
1214: 
1215:   // The core can never signal a write to IMEM
1216:   assign imem_write_core = 1'b0;
1217: 
1218: 
1219:   // Asserts ===================================================================
1220:   for (genvar i = 0; i < LoopStackDepth; ++i) begin : gen_loop_stack_cntr_asserts
1221:     `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(
1222:       LoopStackCntAlertCheck_A,
1223:       u_otbn_core.u_otbn_controller.u_otbn_loop_controller.g_loop_counters[i].u_loop_count,
1224:       alert_tx_o[AlertFatal]
1225:     )
1226:   end
1227: 
1228:   // GPR assertions for secure wipe
1229:   // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1230:   // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
1231:   // secure wiping complete.
1232:   // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
1233:   // because a fatal error affecting internal secure wiping could cause an immediate locking
1234:   // behaviour in which it's not guaranteed to see a succesful secure wipe.
1235:   for (genvar i = 2; i < NGpr; ++i) begin : gen_sec_wipe_gpr_asserts
1236:     // Initial secure wipe needs to initialise all registers to nonzero
1237:     `ASSERT(InitSecWipeNonZeroBaseRegs_A,
1238:       $fell(busy_secure_wipe) |->
1239:       u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
1240:         EccZeroWord,
1241:       clk_i,
1242:       !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1243:       u_otbn_core.u_otbn_start_stop_control.state_error_d)
1244:     // After execution, it's expected to see a change resulting with a nonzero register value
1245:     `ASSERT(SecWipeChangedBaseRegs_A,
1246:       $rose(busy_secure_wipe) |-> ((##[0:$]
1247:         u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
1248:           EccZeroWord &&
1249:         $changed(
1250:           u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q))
1251:         within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
1252:       clk_i,
1253:       !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1254:       u_otbn_core.u_otbn_start_stop_control.state_error_d)
1255:   end
1256: 
1257:   // We have several assertions that check that secure wipe worked properly. However, we've also got
1258:   // some tests where we force nets, stopping it from working properly! That's fine, and the tests
1259:   // are checking that some other mechanism catches the problem. However, we don't want the
1260:   // simulation to die with a failed assertion, so we put everything in a named block which we can
1261:   // turn off with $assertoff.
1262:   //
1263:   // The silly-looking name is to avoid a lint warning. Verible (correctly) points out that
1264:   // SystemVerilog doesn't allow bare begin/end blocks at module level. So I cheated and put
1265:   // everything in an if(1) block. But this is treated as a generate block, and our lint rules
1266:   // therefore expect its name to start with a "g_".
1267:   if (1) begin : g_secure_wipe_assertions
1268:     // WDR assertions for secure wipe
1269:     // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1270:     // goes to LOCKED state immediately after this error which means that it's not guaranteed to
1271:     // have secure wiping complete.
1272:     // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
1273:     // because a fatal error affecting internal secure wiping could cause an immediate locking
1274:     // behaviour in which it's not guaranteed to see a succesful secure wipe.
1275:     for (genvar i = 0; i < NWdr; ++i) begin : gen_sec_wipe_wdr_asserts
1276:       // Initial secure wipe needs to initialise all registers to nonzero
1277:       `ASSERT(InitSecWipeNonZeroWideRegs_A,
1278:               $fell(busy_secure_wipe) |->
1279:                 u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
1280:                   EccWideZeroWord,
1281:               clk_i,
1282:               !rst_ni || u_otbn_core.urnd_reseed_err ||
1283:                 u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1284:                 u_otbn_core.u_otbn_start_stop_control.state_error_d)
1285: 
1286:       // After execution, it's expected to see a change resulting with a nonzero register value
1287:       `ASSERT(SecWipeChangedWideRegs_A,
1288:               $rose(busy_secure_wipe) |-> ((##[0:$]
1289:                 u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
1290:                   EccWideZeroWord &&
1291:                 $changed(
1292:                   u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i]))
1293:                 within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
1294:             clk_i, !rst_ni || u_otbn_core.urnd_reseed_err ||
1295:               u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1296:     end
1297:   end
1298: 
1299:   // Secure wipe needs to invalidate call and loop stack, initialize MOD, ACC to nonzero and set
1300:   // FLAGS CSR to zero
1301:   // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
1302:   // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
1303:   // secure wiping complete.
1304:   // 2. mubi_err_d of start_stop_control disables the secure wipe related assertions because a
1305:   // fatal error affecting internal secure wiping could cause an immediate locking behaviour
1306:   // in which it's not guaranteed to see a succesful secure wipe.
1307:   `ASSERT(SecWipeInvalidCallStack_A,
1308:           $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_rf_base.u_call_stack.top_valid_o),
1309:           clk_i,
1310:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1311:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1312:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1313:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1314:   `ASSERT(SecWipeInvalidLoopStack_A,
1315:           $fell(busy_secure_wipe) |->
1316:             (!u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.top_valid_o),
1317:           clk_i,
1318:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1319:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1320:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1321:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1322: 
1323:   `ASSERT(SecWipeNonZeroMod_A,
1324:           $fell(busy_secure_wipe) |-> u_otbn_core.u_otbn_alu_bignum.mod_intg_q != EccWideZeroWord,
1325:           clk_i,
1326:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1327:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1328:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1329:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1330: 
1331:   `ASSERT(SecWipeNonZeroACC_A,
1332:           $fell(busy_secure_wipe) |->
1333:             u_otbn_core.u_otbn_alu_bignum.ispr_acc_intg_i != EccWideZeroWord,
1334:           clk_i,
1335:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1336:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1337:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1338: 
1339:   `ASSERT(SecWipeNonZeroFlags_A,
1340:           $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_alu_bignum.flags_flattened),
1341:           clk_i,
1342:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1343:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
1344:             u_otbn_core.u_otbn_start_stop_control.state_error_d ||
1345:             u_otbn_core.u_otbn_start_stop_control.state_error_d)
1346: 
1347:   // Secure wipe of IMEM and DMEM first happens with a key change from URND (while valid is zero)
1348:   `ASSERT(ImemSecWipeRequiresUrndKey_A,
1349:           $rose(imem_sec_wipe) |=> (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)),
1350:           clk_i,
1351:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1352:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1353:   `ASSERT(DmemSecWipeRequiresUrndKey_A,
1354:           $rose(dmem_sec_wipe) |=> (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)),
1355:           clk_i,
1356:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1357:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1358: 
1359:   // Then it is guaranteed to have a valid key from OTP interface which is different from URND key
1360:   `ASSERT(ImemSecWipeRequiresOtpKey_A,
1361:           $rose(imem_sec_wipe) ##1 (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)) |=>
1362:             ##[0:$] otbn_imem_scramble_valid && $changed(otbn_imem_scramble_key),
1363:           clk_i,
1364:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1365:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1366:   `ASSERT(DmemSecWipeRequiresOtpKey_A,
1367:           $rose(dmem_sec_wipe) ##1 (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)) |=>
1368:             ##[0:$] otbn_dmem_scramble_valid && $changed(otbn_dmem_scramble_key),
1369:           clk_i,
1370:           !rst_ni || u_otbn_core.urnd_reseed_err ||
1371:             u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
1372: 
1373:   // All outputs should be known value after reset
1374:   `ASSERT_KNOWN(TlODValidKnown_A, tl_o.d_valid)
1375:   `ASSERT_KNOWN(TlOAReadyKnown_A, tl_o.a_ready)
1376:   `ASSERT_KNOWN(IdleOKnown_A, idle_o)
1377:   `ASSERT_KNOWN(IntrDoneOKnown_A, intr_done_o)
1378:   `ASSERT_KNOWN(AlertTxOKnown_A, alert_tx_o)
1379:   `ASSERT_KNOWN(EdnRndOKnown_A, edn_rnd_o, clk_edn_i, !rst_edn_ni)
1380:   `ASSERT_KNOWN(EdnUrndOKnown_A, edn_urnd_o, clk_edn_i, !rst_edn_ni)
1381:   `ASSERT_KNOWN(OtbnOtpKeyO_A, otbn_otp_key_o, clk_otp_i, !rst_otp_ni)
1382:   `ASSERT_KNOWN(ErrBitsKnown_A, err_bits)
1383: 
1384:   // Incoming key must be valid (other inputs go via prim modules that handle the X checks).
1385:   `ASSERT_KNOWN(KeyMgrKeyValid_A, keymgr_key_i.valid)
1386: 
1387:   // In locked state, the readable registers INSN_CNT, IMEM, and DMEM are expected to always read 0
1388:   // when accessed from the bus. For INSN_CNT, we use "|=>" so that the assertion lines up with
1389:   // "status.q" (a signal that isn't directly accessible here).
1390:   `ASSERT(LockedInsnCntReadsZero_A, (hw2reg.status.d == StatusLocked) |=> insn_cnt == 'd0)
1391:   `ASSERT(ExecuteOrLockedImemReadsZero_A,
1392:           (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & imem_rvalid_bus
1393:           |-> imem_rdata_bus == 'd0)
1394:   `ASSERT(ExecuteOrLockedDmemReadsZero_A,
1395:           (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & dmem_rvalid_bus
1396:           |-> dmem_rdata_bus == 'd0)
1397: 
1398:   // From the cycle the core is told to start to when it is done, it must always be busy executing,
1399:   // locking, or both -- even if the core is never done.  We use this property to enable blanking
1400:   // while the core is executing or locking, and this assertion ensures that there is no gap
1401:   // between execution and locking.
1402:   `ASSERT(BusyOrLockingFromStartToDone_A,
1403:           $rose(start_q) |-> (busy_execute_d | locking) |-> ##[0:$] $rose(done_core))
1404: 
1405:   // Error handling: if we pass an error signal down to the core then we should also be setting an
1406:   // error flag. Note that this uses err_bits, not err_bits_q, because the latter signal only gets
1407:   // asserted when an operation finishes.
1408:   `ASSERT(ErrBitIfEscalate_A, mubi4_test_true_loose(core_escalate_en) |=> |err_bits)
1409: 
1410:   // Constraint from package, check here as we cannot have `ASSERT_INIT in package
1411:   `ASSERT_INIT(WsrESizeMatchesParameter_A, $bits(wsr_e) == WsrNumWidth)
1412: 
1413:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnStartStopFsmCheck_A,
1414:     u_otbn_core.u_otbn_start_stop_control.u_state_regs, alert_tx_o[AlertFatal])
1415:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnControllerFsmCheck_A,
1416:     u_otbn_core.u_otbn_controller.u_state_regs, alert_tx_o[AlertFatal])
1417:   `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnScrambleCtrlFsmCheck_A,
1418:     u_otbn_scramble_ctrl.u_state_regs, alert_tx_o[AlertFatal])
1419: 
1420:   `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnCallStackWrPtrAlertCheck_A,
1421:     u_otbn_core.u_otbn_rf_base.u_call_stack.u_stack_wr_ptr, alert_tx_o[AlertFatal])
1422:   `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnLoopInfoStackWrPtrAlertCheck_A,
1423:     u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.u_stack_wr_ptr,
1424:     alert_tx_o[AlertFatal])
1425: 
1426:   // Alert assertions for reg_we onehot check
1427:   `ASSERT_PRIM_REG_WE_ONEHOT_ERROR_TRIGGER_ALERT(RegWeOnehotCheck_A,
1428:       u_reg, alert_tx_o[AlertFatal])
1429:   // other onehot checks
1430:   `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBaseOnehotCheck_A,
1431:       u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.u_prim_onehot_check,
1432:       alert_tx_o[AlertFatal])
1433:   `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBignumOnehotCheck_A,
1434:       u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.u_prim_onehot_check,
1435:       alert_tx_o[AlertFatal])
1436: 
1437:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemRspFifo,
1438:                                                u_tlul_adapter_sram_dmem.u_rspfifo,
1439:                                                alert_tx_o[AlertFatal])
1440:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemSramReqFifo,
1441:                                                u_tlul_adapter_sram_dmem.u_sramreqfifo,
1442:                                                alert_tx_o[AlertFatal])
1443:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemReqFifo,
1444:                                                u_tlul_adapter_sram_dmem.u_reqfifo,
1445:                                                alert_tx_o[AlertFatal])
1446: 
1447:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemRspFifo,
1448:                                                u_tlul_adapter_sram_imem.u_rspfifo,
1449:                                                alert_tx_o[AlertFatal])
1450:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemSramReqFifo,
1451:                                                u_tlul_adapter_sram_imem.u_sramreqfifo,
1452:                                                alert_tx_o[AlertFatal])
1453:   `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemReqFifo,
1454:                                                u_tlul_adapter_sram_imem.u_reqfifo,
1455:                                                alert_tx_o[AlertFatal])
1456: endmodule

================================== Ai Message ==================================

Based on the similar_bug_tool results and the file content, I found the following similar bug instances:

1. Line 448: `assign imem_rdata_bus_en_d = 1'b1;`
2. Line 690: `assign dmem_rdata_bus_en_d = 1'b1;`

These lines are part of a security mechanism to blank bus read data interfaces during core operation. However, hardcoding the enable signal to 1'b1 might not be the intended behavior. 

The context suggests these lines are used to prevent leaking memory data through the bus during core operation or when OTBN is locked. The surrounding code includes assertions that check the blanking behavior:

- Line 475-479 has assertions to ensure the bus read data is disabled during core access and enabled when idle
- Line 720-724 has similar assertions for DMEM

While the hardcoded 1'b1 might be intentional, it's worth reviewing with the original designers to confirm this is the desired implementation for preventing data leakage.
================================= Tool Message =================================
Name: run_similar_bug_agent

Based on the similar_bug_tool results and the file content, I found the following similar bug instances:

1. Line 448: `assign imem_rdata_bus_en_d = 1'b1;`
2. Line 690: `assign dmem_rdata_bus_en_d = 1'b1;`

These lines are part of a security mechanism to blank bus read data interfaces during core operation. However, hardcoding the enable signal to 1'b1 might not be the intended behavior. 

The context suggests these lines are used to prevent leaking memory data through the bus during core operation or when OTBN is locked. The surrounding code includes assertions that check the blanking behavior:

- Line 475-479 has assertions to ensure the bus read data is disabled during core access and enabled when idle
- Line 720-724 has similar assertions for DMEM

While the hardcoded 1'b1 might be intentional, it's worth reviewing with the original designers to confirm this is the desired implementation for preventing data leakage.
================================== Ai Message ==================================
Tool Calls:
  run_llm_cwe_checker_agent (call_Sc8d5wA9O9tKHLdeqAHy6txG)
 Call ID: call_Sc8d5wA9O9tKHLdeqAHy6txG
  Args:
    design_filepath: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn.sv
    top_module: otbn
    security_objective: Confidentiality: Ensure IMEM/DMEM contents are not exposed over TL-UL during BUSY/LOCKED; verify blanking logic, write ignore, and ILLEGAL_BUS_ACCESS behavior
================================ Human Message =================================

Are there security concerns related to Confidentiality: Ensure IMEM/DMEM contents are not exposed over TL-UL during BUSY/LOCKED; verify blanking logic, write ignore, and ILLEGAL_BUS_ACCESS behavior in the provided RTL:
    """

    // Copyright lowRISC contributors (OpenTitan project).
// Licensed under the Apache License, Version 2.0, see LICENSE for details.
// SPDX-License-Identifier: Apache-2.0

`include "prim_assert.sv"
`include "prim_fifo_assert.svh"

/**
 * OpenTitan Big Number Accelerator (OTBN)
 */
module otbn
  import prim_alert_pkg::*;
  import otbn_pkg::*;
  import otbn_reg_pkg::*;
#(
  parameter bit                   Stub         = 1'b0,
  parameter regfile_e             RegFile      = RegFileFF,
  parameter logic [NumAlerts-1:0] AlertAsyncOn = {NumAlerts{1'b1}},

  // Default seed for URND PRNG
  parameter urnd_prng_seed_t RndCnstUrndPrngSeed = RndCnstUrndPrngSeedDefault,

  // Disable URND advance when not in use. Useful for SCA only.
  parameter bit SecMuteUrnd = 1'b0,
  // Skip URND re-seed at the start of an operation. Useful for SCA only.
  parameter bit SecSkipUrndReseedAtStart = 1'b0,

  // Default seed and nonce for scrambling
  parameter otp_ctrl_pkg::otbn_key_t   RndCnstOtbnKey   = RndCnstOtbnKeyDefault,
  parameter otp_ctrl_pkg::otbn_nonce_t RndCnstOtbnNonce = RndCnstOtbnNonceDefault
) (
  input clk_i,
  input rst_ni,

  input  tlul_pkg::tl_h2d_t tl_i,
  output tlul_pkg::tl_d2h_t tl_o,

  // Inter-module signals
  output prim_mubi_pkg::mubi4_t idle_o,

  // Interrupts
  output logic intr_done_o,

  // Alerts
  input  prim_alert_pkg::alert_rx_t [NumAlerts-1:0] alert_rx_i,
  output prim_alert_pkg::alert_tx_t [NumAlerts-1:0] alert_tx_o,

  // Lifecycle interfaces
  input  lc_ctrl_pkg::lc_tx_t lc_escalate_en_i,

  input  lc_ctrl_pkg::lc_tx_t lc_rma_req_i,
  output lc_ctrl_pkg::lc_tx_t lc_rma_ack_o,

  // Memory configuration
  input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_imem_i,
  input  prim_ram_1p_pkg::ram_1p_cfg_t     ram_cfg_dmem_i,
  output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_imem_o,
  output prim_ram_1p_pkg::ram_1p_cfg_rsp_t ram_cfg_rsp_dmem_o,

  // EDN clock and interface
  input                     clk_edn_i,
  input                     rst_edn_ni,
  output edn_pkg::edn_req_t edn_rnd_o,
  input  edn_pkg::edn_rsp_t edn_rnd_i,

  output edn_pkg::edn_req_t edn_urnd_o,
  input  edn_pkg::edn_rsp_t edn_urnd_i,

  // Key request to OTP (running on clk_fixed)
  input                                   clk_otp_i,
  input                                   rst_otp_ni,
  output otp_ctrl_pkg::otbn_otp_key_req_t otbn_otp_key_o,
  input  otp_ctrl_pkg::otbn_otp_key_rsp_t otbn_otp_key_i,

  input keymgr_pkg::otbn_key_req_t keymgr_key_i
);

  import prim_mubi_pkg::*;
  import prim_util_pkg::vbits;

  logic rst_n;

  // hold module in reset permanently when stubbing
  if (Stub) begin : gen_stub_otbn
    assign rst_n = 1'b0;
  end else begin : gen_real_otbn
    assign rst_n = rst_ni;
  end

  // The OTBN_*_SIZE parameters are auto-generated by regtool and come from the bus window sizes;
  // they are given in bytes and must be powers of two.
  //
  // DMEM is actually a bit bigger than OTBN_DMEM_SIZE: there are an extra DmemScratchSizeByte bytes
  // that aren't accessible over the bus.
  localparam int ImemSizeByte = int'(otbn_reg_pkg::OTBN_IMEM_SIZE);
  localparam int DmemSizeByte = int'(otbn_reg_pkg::OTBN_DMEM_SIZE + DmemScratchSizeByte);

  localparam int ImemAddrWidth = vbits(ImemSizeByte);
  localparam int DmemAddrWidth = vbits(DmemSizeByte);

  `ASSERT_INIT(ImemSizePowerOfTwo, 2 ** ImemAddrWidth == ImemSizeByte)
  `ASSERT_INIT(DmemSizePowerOfTwo, 2 ** DmemAddrWidth == DmemSizeByte)

  logic start_d, start_q;
  logic busy_execute_d, busy_execute_q;
  logic done, done_core, locking, locking_q;
  logic busy_secure_wipe;
  logic init_sec_wipe_done_d, init_sec_wipe_done_q;
  logic illegal_bus_access_d, illegal_bus_access_q;
  logic missed_gnt_error_d, missed_gnt_error_q;
  logic dmem_sec_wipe;
  logic imem_sec_wipe;
  logic mems_sec_wipe;
  logic req_sec_wipe_urnd_keys;
  logic [127:0] dmem_sec_wipe_urnd_key, imem_sec_wipe_urnd_key;

  logic core_recoverable_err, recoverable_err_d, recoverable_err_q;
  mubi4_t core_escalate_en;

  core_err_bits_t     core_err_bits;
  non_core_err_bits_t non_core_err_bits, non_core_err_bits_d, non_core_err_bits_q;
  err_bits_t          err_bits, err_bits_d, err_bits_q;
  logic               err_bits_en;

  // ERR_BITS register should be cleared due to a write request from the host processor
  // when OTBN is not running.
  logic err_bits_clear;

  logic software_errs_fatal_q, software_errs_fatal_d;

  otbn_reg2hw_t reg2hw;
  otbn_hw2reg_t hw2reg;
  status_e      status_d, status_q;

  // Bus device windows, as specified in otbn.hjson
  typedef enum logic {
    TlWinImem = 1'b0,
    TlWinDmem = 1'b1
  } tl_win_e;

  tlul_pkg::tl_h2d_t tl_win_h2d[2];
  tlul_pkg::tl_d2h_t tl_win_d2h[2];

  // The clock can be gated and some registers can be updated as long as OTBN isn't currently
  // running. Other registers can only be updated when OTBN is in the Idle state (which also implies
  // we are not locked).
  logic is_not_running_d, is_not_running_q;
  logic otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy;

  assign is_not_running_d = ~|{busy_execute_d,
                               otbn_dmem_scramble_key_req_busy,
                               otbn_imem_scramble_key_req_busy,
                               busy_secure_wipe};

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if(!rst_ni) begin
      // OTBN starts busy, performing the initial secure wipe.
      is_not_running_q  <= 1'b0;
    end else begin
      is_not_running_q  <= is_not_running_d;
    end
  end

  // Inter-module signals ======================================================

  // Note: This is not the same thing as STATUS == IDLE. For example, we want to allow clock gating
  // when locked.
  prim_mubi4_sender #(
    .ResetValue(prim_mubi_pkg::MuBi4True)
  ) u_prim_mubi4_sender (
    .clk_i,
    .rst_ni,
    .mubi_i(mubi4_bool_to_mubi(is_not_running_q)),
    .mubi_o(idle_o)
  );

  // Lifecycle ==================================================================

  localparam int unsigned LcEscalateCopies = 2;
  lc_ctrl_pkg::lc_tx_t [LcEscalateCopies-1:0] lc_escalate_en;
  prim_lc_sync #(
    .NumCopies(LcEscalateCopies)
  ) u_lc_escalate_en_sync (
    .clk_i,
    .rst_ni,
    .lc_en_i(lc_escalate_en_i),
    .lc_en_o(lc_escalate_en)
  );

  lc_ctrl_pkg::lc_tx_t lc_rma_req;
  prim_lc_sync #(
    .NumCopies(1)
  ) u_lc_rma_req_sync (
    .clk_i,
    .rst_ni,
    .lc_en_i(lc_rma_req_i),
    .lc_en_o({lc_rma_req})
  );

  // Internally, OTBN uses MUBI types.
  mubi4_t mubi_rma_req, mubi_rma_ack;
  assign mubi_rma_req = lc_ctrl_pkg::lc_to_mubi4(lc_rma_req);

  // When stubbing, forward req to ack.
  if (Stub) begin : gen_stub_rma_ack
    assign lc_rma_ack_o = lc_rma_req;
  end else begin : gen_real_rma_ack
    assign lc_rma_ack_o = lc_ctrl_pkg::mubi4_to_lc(mubi_rma_ack);
  end

  // Interrupts ================================================================

  assign done = is_busy_status(status_q) & ~is_busy_status(status_d) & init_sec_wipe_done_q;

  prim_intr_hw #(
    .Width(1)
  ) u_intr_hw_done (
    .clk_i,
    .rst_ni                (rst_n),
    .event_intr_i          (done),
    .reg2hw_intr_enable_q_i(reg2hw.intr_enable.q),
    .reg2hw_intr_test_q_i  (reg2hw.intr_test.q),
    .reg2hw_intr_test_qe_i (reg2hw.intr_test.qe),
    .reg2hw_intr_state_q_i (reg2hw.intr_state.q),
    .hw2reg_intr_state_de_o(hw2reg.intr_state.de),
    .hw2reg_intr_state_d_o (hw2reg.intr_state.d),
    .intr_o                (intr_done_o)
  );

  // Instruction Memory (IMEM) =================================================

  localparam int ImemSizeWords = ImemSizeByte / 4;
  localparam int ImemIndexWidth = vbits(ImemSizeWords);

  // Access select to IMEM: core (1), or bus (0)
  logic imem_access_core;

  logic imem_req;
  logic imem_gnt;
  logic imem_write;
  logic imem_wr_collision;
  logic imem_wpending;
  logic [ImemIndexWidth-1:0] imem_index;
  logic [38:0] imem_wdata;
  logic [38:0] imem_wmask;
  logic [38:0] imem_rdata;
  logic imem_rvalid;
  logic imem_illegal_bus_access;
  logic imem_missed_gnt;

  logic imem_req_core;
  logic imem_write_core;
  logic [ImemIndexWidth-1:0] imem_index_core;
  logic [38:0] imem_rdata_core;
  logic imem_rvalid_core;

  logic imem_req_bus;
  logic imem_dummy_response_q, imem_dummy_response_d;
  logic imem_write_bus;
  logic [ImemIndexWidth-1:0] imem_index_bus;
  logic [38:0] imem_wdata_bus;
  logic [38:0] imem_wmask_bus;
  logic [38:0] imem_rdata_bus, imem_rdata_bus_raw;
  logic imem_rdata_bus_en_q, imem_rdata_bus_en_d;
  logic [top_pkg::TL_DBW-1:0] imem_byte_mask_bus;
  logic imem_rvalid_bus;
  logic [1:0] imem_rerror_bus;

  logic imem_bus_intg_violation;

  typedef struct packed {
    logic        imem;
    logic [14:0] index;
    logic [31:0] wr_data;
  } mem_crc_data_in_t;

  logic             mem_crc_data_in_valid;
  mem_crc_data_in_t mem_crc_data_in;
  logic             set_crc;
  logic [31:0]      crc_in, crc_out;

  logic [ImemAddrWidth-1:0] imem_addr_core;
  assign imem_index_core = imem_addr_core[ImemAddrWidth-1:2];

  logic [1:0] unused_imem_addr_core_wordbits;
  assign unused_imem_addr_core_wordbits = imem_addr_core[1:0];

  otp_ctrl_pkg::otbn_key_t otbn_imem_scramble_key;
  otbn_imem_nonce_t        otbn_imem_scramble_nonce;
  logic                    otbn_imem_scramble_valid;
  logic                    unused_otbn_imem_scramble_key_seed_valid;

  otp_ctrl_pkg::otbn_key_t otbn_dmem_scramble_key;
  otbn_dmem_nonce_t        otbn_dmem_scramble_nonce;
  logic                    otbn_dmem_scramble_valid;
  logic                    unused_otbn_dmem_scramble_key_seed_valid;


  logic otbn_scramble_state_error;

  // SEC_CM: SCRAMBLE.KEY.SIDELOAD
  otbn_scramble_ctrl #(
    .RndCnstOtbnKey  (RndCnstOtbnKey),
    .RndCnstOtbnNonce(RndCnstOtbnNonce)
  ) u_otbn_scramble_ctrl (
    .clk_i,
    .rst_ni,

    .clk_otp_i,
    .rst_otp_ni,

    .otbn_otp_key_o,
    .otbn_otp_key_i,

    .otbn_dmem_scramble_key_o           (otbn_dmem_scramble_key),
    .otbn_dmem_scramble_nonce_o         (otbn_dmem_scramble_nonce),
    .otbn_dmem_scramble_valid_o         (otbn_dmem_scramble_valid),
    .otbn_dmem_scramble_key_seed_valid_o(unused_otbn_dmem_scramble_key_seed_valid),

    .otbn_imem_scramble_key_o           (otbn_imem_scramble_key),
    .otbn_imem_scramble_nonce_o         (otbn_imem_scramble_nonce),
    .otbn_imem_scramble_valid_o         (otbn_imem_scramble_valid),
    .otbn_imem_scramble_key_seed_valid_o(unused_otbn_imem_scramble_key_seed_valid),

    .otbn_dmem_scramble_sec_wipe_i    (dmem_sec_wipe),
    .otbn_dmem_scramble_sec_wipe_key_i(dmem_sec_wipe_urnd_key),
    .otbn_imem_scramble_sec_wipe_i    (imem_sec_wipe),
    .otbn_imem_scramble_sec_wipe_key_i(imem_sec_wipe_urnd_key),

    .otbn_dmem_scramble_key_req_busy_o(otbn_dmem_scramble_key_req_busy),
    .otbn_imem_scramble_key_req_busy_o(otbn_imem_scramble_key_req_busy),

    .state_error_o(otbn_scramble_state_error)
  );

  // SEC_CM: MEM.SCRAMBLE
  prim_ram_1p_scr #(
    .Width          (39),
    .Depth          (ImemSizeWords),
    .InstDepth      (ImemSizeWords),
    .DataBitsPerMask(39),
    .EnableParity   (0)
  ) u_imem (
    .clk_i,
    .rst_ni(rst_n),

    .key_valid_i(otbn_imem_scramble_valid),
    .key_i      (otbn_imem_scramble_key),
    .nonce_i    (otbn_imem_scramble_nonce),

    .req_i       (imem_req),
    .gnt_o       (imem_gnt),
    .write_i     (imem_write),
    .addr_i      (imem_index),
    .wdata_i     (imem_wdata),
    .wmask_i     (imem_wmask),
    .intg_error_i(locking),

    .rdata_o  (imem_rdata),
    .rvalid_o (imem_rvalid),
    .raddr_o  (),
    .rerror_o (),
    .cfg_i    (ram_cfg_imem_i),
    .cfg_rsp_o(ram_cfg_rsp_imem_o),

    .wr_collision_o   (imem_wr_collision),
    .write_pending_o  (imem_wpending),

    .alert_o ()
  );

  // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
  assign imem_missed_gnt = imem_req & ~imem_gnt;

  // IMEM access from main TL-UL bus
  logic imem_gnt_bus;
  // Always grant to bus accesses, when OTBN is running a dummy response is returned
  assign imem_gnt_bus = imem_req_bus;

  tlul_adapter_sram #(
    .SramAw          (ImemIndexWidth),
    .SramDw          (32),
    .Outstanding     (1),
    .ByteAccess      (0),
    .ErrOnRead       (0),
    .EnableDataIntgPt(1),
    .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
  ) u_tlul_adapter_sram_imem (
    .clk_i,
    .rst_ni                     (rst_n),
    .tl_i                       (tl_win_h2d[TlWinImem]),
    .tl_o                       (tl_win_d2h[TlWinImem]),
    .en_ifetch_i                (MuBi4False),
    .req_o                      (imem_req_bus),
    .req_type_o                 (),
    .gnt_i                      (imem_gnt_bus),
    .we_o                       (imem_write_bus),
    .addr_o                     (imem_index_bus),
    .wdata_o                    (imem_wdata_bus),
    .wmask_o                    (imem_wmask_bus),
    .intg_error_o               (imem_bus_intg_violation),
    .user_rsvd_o                (),
    .rdata_i                    (imem_rdata_bus),
    .rvalid_i                   (imem_rvalid_bus),
    .rerror_i                   (imem_rerror_bus),
    .compound_txn_in_progress_o (),
    .readback_en_i              (prim_mubi_pkg::MuBi4False),
    .readback_error_o           (),
    .wr_collision_i             (imem_wr_collision),
    .write_pending_i            (imem_wpending)
  );


  // Mux core and bus access into IMEM
  assign imem_access_core = busy_execute_q | start_q;

  assign imem_req   = imem_access_core ? imem_req_core        : imem_req_bus;
  assign imem_write = imem_access_core ? imem_write_core      : imem_write_bus;
  assign imem_index = imem_access_core ? imem_index_core      : imem_index_bus;
  assign imem_wdata = imem_access_core ? '0                   : imem_wdata_bus;

  assign imem_illegal_bus_access = imem_req_bus & imem_access_core;

  assign imem_dummy_response_d = imem_illegal_bus_access;
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      imem_dummy_response_q <= 1'b0;
    end else begin
      imem_dummy_response_q <= imem_dummy_response_d;
    end
  end

  // The instruction memory only supports 32b word writes, so we hardcode its
  // wmask here.
  //
  // Since this could cause confusion if the bus tried to do a partial write
  // (which wasn't caught in the TLUL adapter for some reason), we assert that
  // the wmask signal from the bus is indeed '1 when it requests a write. We
  // don't have the corresponding check for writes from the core because the
  // core cannot perform writes (and has no imem_wmask_o port).
  assign imem_wmask = imem_access_core ? '1 : imem_wmask_bus;
  `ASSERT(ImemWmaskBusIsFullWord_A, imem_req_bus && imem_write_bus |-> imem_wmask_bus == '1)

  // SEC_CM: DATA_REG_SW.SCA
  // Blank bus read data interface during core operation to avoid leaking the currently executed
  // instruction from IMEM through the bus unintentionally. Also blank when OTBN is returning
  // a dummy response (responding to an illegal bus access) and when OTBN is locked.
  assign imem_rdata_bus_en_d = 1'b1;

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
        imem_rdata_bus_en_q <= 1'b1;
    end else begin
        imem_rdata_bus_en_q <= imem_rdata_bus_en_d;
    end
  end

  prim_blanker #(.Width(39)) u_imem_rdata_bus_blanker (
    .in_i (imem_rdata),
    .en_i (imem_rdata_bus_en_q),
    .out_o(imem_rdata_bus_raw)
  );

  // When OTBN is locked all imem bus reads should return 0. The blanker produces the 0s, this adds
  // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
  // through. Data bits are always left un-modified. A registered version of `locking` is used for
  // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
  // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
  // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
  // in so it is reasonable to proceed with returning the supplied integrity.
  assign imem_rdata_bus =
    {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : imem_rdata_bus_raw[38:32],
     imem_rdata_bus_raw[31:0]};

  `ASSERT(ImemRDataBusDisabledWhenCoreAccess_A, imem_access_core |-> !imem_rdata_bus_en_q)
  `ASSERT(ImemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> imem_rdata_bus_en_q)
  `ASSERT(ImemRDataBusDisabledWhenLocked_A, locking |=> !imem_rdata_bus_en_q)
  `ASSERT(ImemRDataBusReadAsZeroWhenLocked_A,
    imem_rvalid_bus & locking |-> imem_rdata_bus_raw == '0)

  assign imem_rdata_core = imem_rdata;

  // When an illegal bus access is seen, always return a dummy response the follow cycle.
  assign imem_rvalid_bus = (~imem_access_core & imem_rvalid) | imem_dummy_response_q;
  assign imem_rvalid_core = imem_access_core ? imem_rvalid : 1'b0;

  assign imem_byte_mask_bus = tl_win_h2d[TlWinImem].a_mask;

  // No imem errors reported for bus reads. Integrity is carried through on the bus so integrity
  // checking on TL responses will pick up any errors.
  assign imem_rerror_bus = 2'b00;

  // Data Memory (DMEM) ========================================================

  localparam int DmemSizeWords = DmemSizeByte / (WLEN / 8);
  localparam int DmemIndexWidth = vbits(DmemSizeWords);

  localparam int DmemBusSizeWords = int'(otbn_reg_pkg::OTBN_DMEM_SIZE) / (WLEN / 8);
  localparam int DmemBusIndexWidth = vbits(DmemBusSizeWords);

  // Access select to DMEM: core (1), or bus (0)
  logic dmem_access_core;

  logic dmem_req;
  logic dmem_gnt;
  logic dmem_write;
  logic [DmemIndexWidth-1:0] dmem_index;
  logic [ExtWLEN-1:0] dmem_wdata;
  logic [ExtWLEN-1:0] dmem_wmask;
  logic [ExtWLEN-1:0] dmem_rdata;
  logic dmem_rvalid;
  logic [BaseWordsPerWLEN*2-1:0] dmem_rerror_vec;
  logic dmem_rerror;
  logic dmem_illegal_bus_access;
  logic dmem_missed_gnt;

  logic dmem_req_core;
  logic dmem_write_core;
  logic [DmemIndexWidth-1:0] dmem_index_core;
  logic [ExtWLEN-1:0] dmem_wdata_core;
  logic [ExtWLEN-1:0] dmem_wmask_core;
  logic [BaseWordsPerWLEN-1:0] dmem_rmask_core_q, dmem_rmask_core_d;
  logic [ExtWLEN-1:0] dmem_rdata_core;
  logic dmem_rvalid_core;
  logic dmem_rerror_core;

  logic dmem_req_bus;
  logic dmem_dummy_response_q, dmem_dummy_response_d;
  logic dmem_write_bus;
  logic [DmemBusIndexWidth-1:0] dmem_index_bus;
  logic [ExtWLEN-1:0] dmem_wdata_bus;
  logic [ExtWLEN-1:0] dmem_wmask_bus;
  logic [ExtWLEN-1:0] dmem_rdata_bus, dmem_rdata_bus_raw;
  logic dmem_rdata_bus_en_q, dmem_rdata_bus_en_d;
  logic [DmemAddrWidth-1:0] dmem_addr_bus;
  logic unused_dmem_addr_bus;
  logic [31:0] dmem_wdata_narrow_bus;
  logic [top_pkg::TL_DBW-1:0] dmem_byte_mask_bus;
  logic dmem_rvalid_bus;
  logic dmem_wr_collision;
  logic dmem_wpending;
  logic [1:0] dmem_rerror_bus;

  logic dmem_bus_intg_violation;

  logic [DmemAddrWidth-1:0] dmem_addr_core;
  assign dmem_index_core = dmem_addr_core[DmemAddrWidth-1:DmemAddrWidth-DmemIndexWidth];

  logic unused_dmem_addr_core_wordbits;
  assign unused_dmem_addr_core_wordbits = ^dmem_addr_core[DmemAddrWidth-DmemIndexWidth-1:0];

  // SEC_CM: MEM.SCRAMBLE
  prim_ram_1p_scr #(
    .Width             (ExtWLEN),
    .Depth             (DmemSizeWords),
    .InstDepth         (DmemSizeWords),
    .DataBitsPerMask   (39),
    .EnableParity      (0),
    .ReplicateKeyStream(1)
  ) u_dmem (
    .clk_i,
    .rst_ni(rst_n),

    .key_valid_i(otbn_dmem_scramble_valid),
    .key_i      (otbn_dmem_scramble_key),
    .nonce_i    (otbn_dmem_scramble_nonce),

    .req_i       (dmem_req),
    .gnt_o       (dmem_gnt),
    .write_i     (dmem_write),
    .addr_i      (dmem_index),
    .wdata_i     (dmem_wdata),
    .wmask_i     (dmem_wmask),
    .intg_error_i(locking),

    .rdata_o  (dmem_rdata),
    .rvalid_o (dmem_rvalid),
    .raddr_o  (),
    .rerror_o (),
    .cfg_i    (ram_cfg_dmem_i),
    .cfg_rsp_o(ram_cfg_rsp_dmem_o),

    .wr_collision_o   (dmem_wr_collision),
    .write_pending_o  (dmem_wpending),

    .alert_o ()
  );

  // We should never see a request that doesn't get granted. A fatal error is raised if this occurs.
  assign dmem_missed_gnt = dmem_req & !dmem_gnt;

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      dmem_rmask_core_q <= '0;
    end else begin
      if (dmem_req_core) begin
        dmem_rmask_core_q <= dmem_rmask_core_d;
      end
    end
  end

  // SEC_CM: DATA.MEM.INTEGRITY
  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_intg_check
    logic [1:0] dmem_rerror_raw;

    // Separate check for dmem read data integrity outside of `u_dmem` as `prim_ram_1p_adv` doesn't
    // have functionality for only integrity checking, just fully integrated ECC. Integrity bits are
    // implemented on a 32-bit granule so separate checks are required for each.
    prim_secded_inv_39_32_dec u_dmem_intg_check (
      .data_i    (dmem_rdata[i_word*39+:39]),
      .data_o    (),
      .syndrome_o(),
      .err_o     (dmem_rerror_raw)
    );

    // Only report an error where the word was actually accessed. Otherwise uninitialised memory
    // that OTBN isn't using will cause false errors. dmem_rerror is only reported for reads from
    // OTBN. For Ibex reads integrity checking on TL responses will serve the same purpose.
    assign dmem_rerror_vec[i_word*2 +: 2] = {2{dmem_rmask_core_q[i_word] & dmem_rvalid & dmem_access_core}};
  end

  // dmem_rerror_vec is 2 bits wide and is used to report ECC errors. Bit 1 is set if there's an
  // uncorrectable error and bit 0 is set if there's a correctable error. However, we're treating
  // all errors as fatal, so OR the two signals together.
  assign dmem_rerror = |dmem_rerror_vec;

  // DMEM access from main TL-UL bus
  logic dmem_gnt_bus;
  // Always grant to bus accesses, when OTBN is running a dummy response is returned
  assign dmem_gnt_bus = dmem_req_bus;

  tlul_adapter_sram #(
    .SramAw          (DmemBusIndexWidth),
    .SramDw          (WLEN),
    .Outstanding     (1),
    .ByteAccess      (0),
    .ErrOnRead       (0),
    .EnableDataIntgPt(1),
    .SecFifoPtr      (1)  // SEC_CM: TLUL_FIFO.CTR.REDUN
  ) u_tlul_adapter_sram_dmem (
    .clk_i,
    .rst_ni                     (rst_n),
    .tl_i                       (tl_win_h2d[TlWinDmem]),
    .tl_o                       (tl_win_d2h[TlWinDmem]),
    .en_ifetch_i                (MuBi4False),
    .req_o                      (dmem_req_bus),
    .req_type_o                 (),
    .gnt_i                      (dmem_gnt_bus),
    .we_o                       (dmem_write_bus),
    .addr_o                     (dmem_index_bus),
    .wdata_o                    (dmem_wdata_bus),
    .wmask_o                    (dmem_wmask_bus),
    .intg_error_o               (dmem_bus_intg_violation),
    .user_rsvd_o                (),
    .rdata_i                    (dmem_rdata_bus),
    .rvalid_i                   (dmem_rvalid_bus),
    .rerror_i                   (dmem_rerror_bus),
    .compound_txn_in_progress_o (),
    .readback_en_i              (prim_mubi_pkg::MuBi4False),
    .readback_error_o           (),
    .wr_collision_i             (dmem_wr_collision),
    .write_pending_i            (dmem_wpending)
  );

  // Mux core and bus access into dmem
  assign dmem_access_core = busy_execute_q;

  assign dmem_req = dmem_access_core ? dmem_req_core : dmem_req_bus;
  assign dmem_write = dmem_access_core ? dmem_write_core : dmem_write_bus;
  assign dmem_wmask = dmem_access_core ? dmem_wmask_core : dmem_wmask_bus;
  // SEC_CM: DATA.MEM.SW_NOACCESS
  assign dmem_index = dmem_access_core ? dmem_index_core : dmem_index_bus;
  assign dmem_wdata = dmem_access_core ? dmem_wdata_core : dmem_wdata_bus;

  assign dmem_illegal_bus_access = dmem_req_bus & dmem_access_core;

  assign dmem_dummy_response_d = dmem_illegal_bus_access;
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      dmem_dummy_response_q <= 1'b0;
    end else begin
      dmem_dummy_response_q <= dmem_dummy_response_d;
    end
  end

  // SEC_CM: DATA_REG_SW.SCA
  // Blank bus read data interface during core operation to avoid leaking DMEM data through the bus
  // unintentionally. Also blank when OTBN is returning a dummy response (responding to an illegal
  // bus access) and when OTBN is locked.
  assign dmem_rdata_bus_en_d = 1'b1;

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
        dmem_rdata_bus_en_q <= 1'b1;
    end else begin
        dmem_rdata_bus_en_q <= dmem_rdata_bus_en_d;
    end
  end

  prim_blanker #(.Width(ExtWLEN)) u_dmem_rdata_bus_blanker (
    .in_i (dmem_rdata),
    .en_i (dmem_rdata_bus_en_q),
    .out_o(dmem_rdata_bus_raw)
  );

  // When OTBN is locked all dmem bus reads should return 0. The blanker produces the 0s, this adds
  // the appropriate ECC. When OTBN is not locked the output of the blanker is passed straight
  // through. Data bits are always left un-modified. A registered version of `locking` is used for
  // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
  // timing reasons. When a read comes in when `locking` has just been asserted, `locking_q` will be
  // set the following cycle and the rdata will be forced to 0 with appropriate ECC. When `locking`
  // is asserted the cycle the rdata is being returned no locking was ocurring when the request came
  // in so it is reasonable to proceed with returning the supplied integrity.
  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; ++i_word) begin : g_dmem_rdata_bus
    assign dmem_rdata_bus[i_word*39+:39] =
      {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : dmem_rdata_bus_raw[i_word*39+32+:7],
       dmem_rdata_bus_raw[i_word*39+:32]};
  end

  `ASSERT(DmemRDataBusDisabledWhenCoreAccess_A, dmem_access_core |-> !dmem_rdata_bus_en_q)
  `ASSERT(DmemRDataBusEnabledWhenIdle_A, status_q == StatusIdle |-> dmem_rdata_bus_en_q)
  `ASSERT(DmemRDataBusDisabledWhenLocked_A, locking |=> !dmem_rdata_bus_en_q)
  `ASSERT(DmemRDataBusReadAsZeroWhenLocked_A,
    dmem_rvalid_bus & locking |-> dmem_rdata_bus_raw == '0)

  assign dmem_rdata_core = dmem_rdata;

  // When an illegal bus access is seen, always return a dummy response the follow cycle.
  assign dmem_rvalid_bus  = (~dmem_access_core & dmem_rvalid) | dmem_dummy_response_q;
  assign dmem_rvalid_core = dmem_access_core ? dmem_rvalid : 1'b0;

  // No dmem errors reported for bus reads. Integrity is carried through on the bus so integrity
  // checking on TL responses will pick up any errors.
  assign dmem_rerror_bus  = 2'b00;
  assign dmem_rerror_core = dmem_rerror;

  assign dmem_addr_bus = tl_win_h2d[TlWinDmem].a_address[DmemAddrWidth-1:0];
  assign dmem_wdata_narrow_bus = tl_win_h2d[TlWinDmem].a_data[31:0];
  assign dmem_byte_mask_bus = tl_win_h2d[TlWinDmem].a_mask;

  // Memory Load Integrity =====================================================
  // CRC logic below assumes a incoming data bus width of 32 bits
  `ASSERT_INIT(TLDWIs32Bit_A, top_pkg::TL_DW == 32)

  // Only advance CRC calculation on full 32-bit writes;
  assign mem_crc_data_in_valid   = ~(dmem_access_core | imem_access_core) &
      ((imem_req_bus & (imem_byte_mask_bus == 4'hf)) |
       (dmem_req_bus & (dmem_byte_mask_bus == 4'hf)));

  assign mem_crc_data_in.wr_data = imem_req_bus ? imem_wdata_bus[31:0] :
                                                  dmem_wdata_narrow_bus[31:0];
  assign mem_crc_data_in.index   = imem_req_bus ? {{15 - ImemIndexWidth{1'b0}}, imem_index_bus} :
                                                   {{15 - (DmemAddrWidth - 2){1'b0}},
                                                    dmem_addr_bus[DmemAddrWidth-1:2]};
  assign mem_crc_data_in.imem    = imem_req_bus;

  // Only the bits that factor into the dmem index and dmem word enables are required
  assign unused_dmem_addr_bus = ^{dmem_addr_bus[DmemAddrWidth-1:DmemIndexWidth],
                                  dmem_addr_bus[1:0]};

  // SEC_CM: WRITE.MEM.INTEGRITY
  prim_crc32 #(
    .BytesPerWord(6)
  ) u_mem_load_crc32 (
    .clk_i (clk_i),
    .rst_ni(rst_ni),

    .set_crc_i(set_crc),
    .crc_in_i (crc_in),

    .data_valid_i(mem_crc_data_in_valid),
    .data_i      (mem_crc_data_in),
    .crc_out_o   (crc_out)
  );

  assign set_crc = reg2hw.load_checksum.qe;
  assign crc_in = reg2hw.load_checksum.q;
  assign hw2reg.load_checksum.d = crc_out;

  // Registers =================================================================

  logic reg_bus_intg_violation;

  otbn_reg_top u_reg (
    .clk_i,
    .rst_ni  (rst_n),
    .tl_i,
    .tl_o,
    .tl_win_o(tl_win_h2d),
    .tl_win_i(tl_win_d2h),

    .reg2hw,
    .hw2reg,

    .intg_err_o(reg_bus_intg_violation)
  );

  // SEC_CM: BUS.INTEGRITY
  // SEC_CM: TLUL_FIFO.CTR.REDUN
  logic bus_intg_violation;
  assign bus_intg_violation = (imem_bus_intg_violation | dmem_bus_intg_violation |
                               reg_bus_intg_violation);

  // CMD register
  always_comb begin
    // start is flopped to avoid long timing paths from the TL fabric into OTBN internals.
    start_d       = 1'b0;
    dmem_sec_wipe = 1'b0;
    imem_sec_wipe = 1'b0;

    // Can only start a new command when idle.
    if (status_q == StatusIdle) begin
      if (reg2hw.cmd.qe) begin
        unique case (reg2hw.cmd.q)
          CmdExecute:     start_d       = 1'b1;
          CmdSecWipeDmem: dmem_sec_wipe = 1'b1;
          CmdSecWipeImem: imem_sec_wipe = 1'b1;
          default: ;
        endcase
      end
    end else if (busy_execute_q) begin
      // OTBN can command a secure wipe of IMEM and DMEM. This occurs when OTBN encounters a fatal
      // error.
      if (mems_sec_wipe) begin
        dmem_sec_wipe = 1'b1;
        imem_sec_wipe = 1'b1;
      end
    end
  end

  assign req_sec_wipe_urnd_keys = dmem_sec_wipe | imem_sec_wipe;

  assign illegal_bus_access_d = dmem_illegal_bus_access | imem_illegal_bus_access;

  // It should not be possible to request an imem or dmem access without it being granted. Either
  // a scramble key is present so the request will be granted or the core is busy obtaining a new
  // key, so no request can occur (the core won't generate one whilst awaiting a scrambling key and
  // the bus requests get an immediate dummy response bypassing the dmem or imem). A fatal error is
  // raised if request is seen without a grant.
  assign missed_gnt_error_d = dmem_missed_gnt | imem_missed_gnt;

  // Flop `illegal_bus_access_q` and `missed_gnt_error_q` to break timing paths from the TL
  // interface into the OTBN core.
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      start_q              <= 1'b0;
      illegal_bus_access_q <= 1'b0;
      missed_gnt_error_q   <= 1'b0;
    end else begin
      start_q              <= start_d;
      illegal_bus_access_q <= illegal_bus_access_d;
      missed_gnt_error_q   <= missed_gnt_error_d;
    end
  end

  // STATUS register
  // imem/dmem scramble req can be busy when locked, so use a priority selection so locked status
  // always takes priority.
  //
  // Note that these signals are all "a cycle early". For example, the locking signal gets asserted
  // combinatorially on the cycle that an error is injected. The STATUS register change, done
  // interrupt and any change to the idle signal will be delayed by 2 cycles.
  assign status_d = locking                         ? StatusLocked          :
                    busy_secure_wipe                ? StatusBusySecWipeInt  :
                    busy_execute_d                  ? StatusBusyExecute     :
                    otbn_dmem_scramble_key_req_busy ? StatusBusySecWipeDmem :
                    otbn_imem_scramble_key_req_busy ? StatusBusySecWipeImem :
                                                      StatusIdle;
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      status_q <= StatusBusySecWipeInt;
    end else begin
      status_q <= status_d;
    end
  end

  assign hw2reg.status.d = status_q;
  assign hw2reg.status.de = 1'b1;

  // Only certain combinations of the state variable {locking, busy_execute_d,
  // otbn_dmem_scramble_key_req_busy, otbn_imem_scramble_key_req_busy} are possible.
  //
  // - Once locking is high, we guarantee never to see a new execution or the start of a key
  //   rotation. (Assertion: NoStartWhenLocked_A)

  `ASSERT(NoStartWhenLocked_A,
          locking |=> !($rose(busy_execute_d) ||
                        $rose(otbn_dmem_scramble_key_req_busy) ||
                        $rose(otbn_imem_scramble_key_req_busy)))

  // CTRL register
  assign software_errs_fatal_d =
    reg2hw.ctrl.qe && (status_q == StatusIdle) ? reg2hw.ctrl.q :
                                                 software_errs_fatal_q;

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      software_errs_fatal_q <= 1'b0;
    end else begin
      software_errs_fatal_q <= software_errs_fatal_d;
    end
  end

  assign hw2reg.ctrl.d = software_errs_fatal_q;

  // ERR_BITS register
  // The error bits for an OTBN operation get stored on the cycle that done is
  // asserted. Software is expected to read them out before starting the next operation.

  assign hw2reg.err_bits.bad_data_addr.d = err_bits_q.bad_data_addr;
  assign hw2reg.err_bits.bad_insn_addr.d = err_bits_q.bad_insn_addr;
  assign hw2reg.err_bits.call_stack.d = err_bits_q.call_stack;
  assign hw2reg.err_bits.illegal_insn.d = err_bits_q.illegal_insn;
  assign hw2reg.err_bits.loop.d = err_bits_q.loop;
  assign hw2reg.err_bits.key_invalid.d = err_bits_q.key_invalid;
  assign hw2reg.err_bits.rnd_rep_chk_fail.d = err_bits_q.rnd_rep_chk_fail;
  assign hw2reg.err_bits.rnd_fips_chk_fail.d = err_bits_q.rnd_fips_chk_fail;
  assign hw2reg.err_bits.imem_intg_violation.d = err_bits_q.imem_intg_violation;
  assign hw2reg.err_bits.dmem_intg_violation.d = err_bits_q.dmem_intg_violation;
  assign hw2reg.err_bits.reg_intg_violation.d = err_bits_q.reg_intg_violation;
  assign hw2reg.err_bits.bus_intg_violation.d = err_bits_q.bus_intg_violation;
  assign hw2reg.err_bits.bad_internal_state.d = err_bits_q.bad_internal_state;
  assign hw2reg.err_bits.illegal_bus_access.d = err_bits_q.illegal_bus_access;
  assign hw2reg.err_bits.lifecycle_escalation.d = err_bits_q.lifecycle_escalation;
  assign hw2reg.err_bits.fatal_software.d = err_bits_q.fatal_software;

  assign err_bits_clear = reg2hw.err_bits.bad_data_addr.qe & is_not_running_q;
  assign err_bits_d = err_bits_clear ? '0 : err_bits;
  assign err_bits_en = err_bits_clear | done_core;

  logic unused_reg2hw_err_bits;

  // Majority of reg2hw.err_bits is unused as write values are ignored, all writes clear the
  // register to 0.
  assign unused_reg2hw_err_bits = ^{reg2hw.err_bits.bad_data_addr.q,
                                    reg2hw.err_bits.bad_insn_addr,
                                    reg2hw.err_bits.call_stack,
                                    reg2hw.err_bits.illegal_insn,
                                    reg2hw.err_bits.loop,
                                    reg2hw.err_bits.key_invalid,
                                    reg2hw.err_bits.rnd_rep_chk_fail,
                                    reg2hw.err_bits.rnd_fips_chk_fail,
                                    reg2hw.err_bits.imem_intg_violation,
                                    reg2hw.err_bits.dmem_intg_violation,
                                    reg2hw.err_bits.reg_intg_violation,
                                    reg2hw.err_bits.bus_intg_violation,
                                    reg2hw.err_bits.bad_internal_state,
                                    reg2hw.err_bits.illegal_bus_access,
                                    reg2hw.err_bits.lifecycle_escalation,
                                    reg2hw.err_bits.fatal_software};

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      err_bits_q <= '0;
    end else if (err_bits_en) begin
      err_bits_q <= err_bits_d;
    end
  end

  // Latch the recoverable error signal from the core. This will be generated as a pulse some time
  // during the run (and before secure wipe finishes). Collect up this bit, clearing on the start or
  // end of an operation (start_q / done_core, respectively)
  assign recoverable_err_d = (recoverable_err_q | core_recoverable_err) & ~(start_q | done_core);
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      recoverable_err_q <= '0;
    end else begin
      recoverable_err_q <= recoverable_err_d;
    end
  end

  // FATAL_ALERT_CAUSE register. The .de and .d values are equal for each bit, so that it can only
  // be set, not cleared.
`define DEF_FAC_BIT(NAME)                                         \
  assign hw2reg.fatal_alert_cause.``NAME``.d = 1'b1;              \
  assign hw2reg.fatal_alert_cause.``NAME``.de = err_bits.``NAME;

  `DEF_FAC_BIT(fatal_software)
  `DEF_FAC_BIT(lifecycle_escalation)
  `DEF_FAC_BIT(illegal_bus_access)
  `DEF_FAC_BIT(bad_internal_state)
  `DEF_FAC_BIT(bus_intg_violation)
  `DEF_FAC_BIT(reg_intg_violation)
  `DEF_FAC_BIT(dmem_intg_violation)
  `DEF_FAC_BIT(imem_intg_violation)

`undef DEF_FAC_BIT

  // INSN_CNT register
  logic [31:0] insn_cnt;
  logic        insn_cnt_clear;
  logic        unused_insn_cnt_q;
  assign hw2reg.insn_cnt.d = insn_cnt;
  assign insn_cnt_clear = reg2hw.insn_cnt.qe & is_not_running_q;
  // Ignore all write data to insn_cnt. All writes zero the register.
  assign unused_insn_cnt_q = ^reg2hw.insn_cnt.q;

  // Alerts ====================================================================

  logic [NumAlerts-1:0] alert_test;
  assign alert_test[AlertFatal] = reg2hw.alert_test.fatal.q & reg2hw.alert_test.fatal.qe;
  assign alert_test[AlertRecov] = reg2hw.alert_test.recov.q & reg2hw.alert_test.recov.qe;

  logic [NumAlerts-1:0] alerts;
  assign alerts[AlertFatal] = |{err_bits.fatal_software,
                                err_bits.lifecycle_escalation,
                                err_bits.illegal_bus_access,
                                err_bits.bad_internal_state,
                                err_bits.bus_intg_violation,
                                err_bits.reg_intg_violation,
                                err_bits.dmem_intg_violation,
                                err_bits.imem_intg_violation};

  assign alerts[AlertRecov] = (core_recoverable_err | recoverable_err_q) & done_core;

  for (genvar i = 0; i < NumAlerts; i++) begin : gen_alert_tx
    prim_alert_sender #(
      .AsyncOn(AlertAsyncOn[i]),
      .IsFatal(i == AlertFatal)
    ) u_prim_alert_sender (
      .clk_i,
      .rst_ni       (rst_n),
      .alert_test_i (alert_test[i]),
      .alert_req_i  (alerts[i]),
      .alert_ack_o  (),
      .alert_state_o(),
      .alert_rx_i   (alert_rx_i[i]),
      .alert_tx_o   (alert_tx_o[i])
    );
  end


  // EDN Connections ============================================================
  logic edn_rnd_req, edn_rnd_ack;
  logic [EdnDataWidth-1:0] edn_rnd_data;
  logic edn_rnd_fips, edn_rnd_err;

  logic edn_urnd_req, edn_urnd_ack;
  logic [EdnDataWidth-1:0] edn_urnd_data;

  // These synchronize the data coming from EDN and stack the 32 bit EDN words to achieve an
  // internal entropy width of 256 bit.

  prim_edn_req #(
    .EnRstChks(1'b1),
    .OutWidth(EdnDataWidth),
    // SEC_CM: RND.BUS.CONSISTENCY
    .RepCheck(1'b1)
  ) u_prim_edn_rnd_req (
    .clk_i,
    .rst_ni     ( rst_n        ),
    .req_chk_i  ( 1'b1         ),
    .req_i      ( edn_rnd_req  ),
    .ack_o      ( edn_rnd_ack  ),
    .data_o     ( edn_rnd_data ),
    .fips_o     ( edn_rnd_fips ),
    .err_o      ( edn_rnd_err  ),
    .clk_edn_i,
    .rst_edn_ni,
    .edn_o      ( edn_rnd_o ),
    .edn_i      ( edn_rnd_i )
  );

  prim_edn_req #(
    .EnRstChks(1'b1),
    .OutWidth(EdnDataWidth)
  ) u_prim_edn_urnd_req (
    .clk_i,
    .rst_ni     ( rst_n         ),
    .req_chk_i  ( 1'b1          ),
    .req_i      ( edn_urnd_req  ),
    .ack_o      ( edn_urnd_ack  ),
    .data_o     ( edn_urnd_data ),
    .fips_o     (               ), // unused
    .err_o      (               ), // unused
    .clk_edn_i,
    .rst_edn_ni,
    .edn_o      ( edn_urnd_o    ),
    .edn_i      ( edn_urnd_i    )
  );


  // OTBN Core =================================================================

  always_ff @(posedge clk_i or negedge rst_n) begin
    if (!rst_n) begin
      busy_execute_q       <= 1'b0;
      init_sec_wipe_done_q <= 1'b0;
    end else begin
      busy_execute_q       <= busy_execute_d;
      init_sec_wipe_done_q <= init_sec_wipe_done_d;
    end
  end
  assign busy_execute_d = (busy_execute_q | start_d) & ~done_core;
  assign init_sec_wipe_done_d = init_sec_wipe_done_q | ~busy_secure_wipe;

  otbn_core #(
    .RegFile(RegFile),
    .DmemSizeByte(DmemSizeByte),
    .ImemSizeByte(ImemSizeByte),
    .RndCnstUrndPrngSeed(RndCnstUrndPrngSeed),
    .SecMuteUrnd(SecMuteUrnd),
    .SecSkipUrndReseedAtStart(SecSkipUrndReseedAtStart)
  ) u_otbn_core (
    .clk_i,
    .rst_ni                      (rst_n),

    .start_i                     (start_q),
    .done_o                      (done_core),
    .locking_o                   (locking),
    .secure_wipe_running_o       (busy_secure_wipe),

    .err_bits_o                  (core_err_bits),
    .recoverable_err_o           (core_recoverable_err),

    .imem_req_o                  (imem_req_core),
    .imem_addr_o                 (imem_addr_core),
    .imem_rdata_i                (imem_rdata_core),
    .imem_rvalid_i               (imem_rvalid_core),

    .dmem_req_o                  (dmem_req_core),
    .dmem_write_o                (dmem_write_core),
    .dmem_addr_o                 (dmem_addr_core),
    .dmem_wdata_o                (dmem_wdata_core),
    .dmem_wmask_o                (dmem_wmask_core),
    .dmem_rmask_o                (dmem_rmask_core_d),
    .dmem_rdata_i                (dmem_rdata_core),
    .dmem_rvalid_i               (dmem_rvalid_core),
    .dmem_rerror_i               (dmem_rerror_core),

    .edn_rnd_req_o               (edn_rnd_req),
    .edn_rnd_ack_i               (edn_rnd_ack),
    .edn_rnd_data_i              (edn_rnd_data),
    .edn_rnd_fips_i              (edn_rnd_fips),
    .edn_rnd_err_i               (edn_rnd_err),

    .edn_urnd_req_o              (edn_urnd_req),
    .edn_urnd_ack_i              (edn_urnd_ack),
    .edn_urnd_data_i             (edn_urnd_data),

    .insn_cnt_o                  (insn_cnt),
    .insn_cnt_clear_i            (insn_cnt_clear),

    .mems_sec_wipe_o             (mems_sec_wipe),
    .dmem_sec_wipe_urnd_key_o    (dmem_sec_wipe_urnd_key),
    .imem_sec_wipe_urnd_key_o    (imem_sec_wipe_urnd_key),
    .req_sec_wipe_urnd_keys_i    (req_sec_wipe_urnd_keys),

    .escalate_en_i               (core_escalate_en),
    .rma_req_i                   (mubi_rma_req),
    .rma_ack_o                   (mubi_rma_ack),

    .software_errs_fatal_i       (software_errs_fatal_q),

    .sideload_key_shares_i       (keymgr_key_i.key),
    .sideload_key_shares_valid_i ({2{keymgr_key_i.valid}})
  );

  always_ff @(posedge clk_i or negedge rst_n) begin
    if (!rst_n) begin
      locking_q <= 1'b0;
    end else begin
      locking_q <= locking;
    end
  end

  // Collect up the error bits that don't come from the core itself and latch them so that they'll
  // be available when an operation finishes.
  assign non_core_err_bits = '{
    lifecycle_escalation: lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[0]),
    illegal_bus_access:   illegal_bus_access_q,
    bad_internal_state:   otbn_scramble_state_error | missed_gnt_error_q,
    bus_intg_violation:   bus_intg_violation
  };

  assign non_core_err_bits_d = non_core_err_bits_q | non_core_err_bits;
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      non_core_err_bits_q <= '0;
    end else begin
      non_core_err_bits_q <= non_core_err_bits_d;
    end
  end

  // Construct a full set of error bits from the core output
  assign err_bits = '{
    fatal_software:       core_err_bits.fatal_software,
    lifecycle_escalation: non_core_err_bits_d.lifecycle_escalation,
    illegal_bus_access:   non_core_err_bits_d.illegal_bus_access,
    bad_internal_state:   |{core_err_bits.bad_internal_state,
                            non_core_err_bits_d.bad_internal_state},
    bus_intg_violation:   non_core_err_bits_d.bus_intg_violation,
    reg_intg_violation:   core_err_bits.reg_intg_violation,
    dmem_intg_violation:  core_err_bits.dmem_intg_violation,
    imem_intg_violation:  core_err_bits.imem_intg_violation,
    rnd_fips_chk_fail:    core_err_bits.rnd_fips_chk_fail,
    rnd_rep_chk_fail:     core_err_bits.rnd_rep_chk_fail,
    key_invalid:          core_err_bits.key_invalid,
    loop:                 core_err_bits.loop,
    illegal_insn:         core_err_bits.illegal_insn,
    call_stack:           core_err_bits.call_stack,
    bad_insn_addr:        core_err_bits.bad_insn_addr,
    bad_data_addr:        core_err_bits.bad_data_addr
  };

  // An error signal going down into the core to show that it should locally escalate. In
  // accordance with the lc_ctrl spec, all values of the lc_escalate_en signal other than the OFF
  // value must be interpreted as ON.
  assign core_escalate_en = mubi4_bool_to_mubi(
      |{non_core_err_bits.illegal_bus_access,
        non_core_err_bits.bad_internal_state,
        non_core_err_bits.bus_intg_violation,
        lc_ctrl_pkg::lc_tx_test_true_loose(lc_escalate_en[1])});

  // The core can never signal a write to IMEM
  assign imem_write_core = 1'b0;


  // Asserts ===================================================================
  for (genvar i = 0; i < LoopStackDepth; ++i) begin : gen_loop_stack_cntr_asserts
    `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(
      LoopStackCntAlertCheck_A,
      u_otbn_core.u_otbn_controller.u_otbn_loop_controller.g_loop_counters[i].u_loop_count,
      alert_tx_o[AlertFatal]
    )
  end

  // GPR assertions for secure wipe
  // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
  // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
  // secure wiping complete.
  // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
  // because a fatal error affecting internal secure wiping could cause an immediate locking
  // behaviour in which it's not guaranteed to see a succesful secure wipe.
  for (genvar i = 2; i < NGpr; ++i) begin : gen_sec_wipe_gpr_asserts
    // Initial secure wipe needs to initialise all registers to nonzero
    `ASSERT(InitSecWipeNonZeroBaseRegs_A,
      $fell(busy_secure_wipe) |->
      u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
        EccZeroWord,
      clk_i,
      !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
      u_otbn_core.u_otbn_start_stop_control.state_error_d)
    // After execution, it's expected to see a change resulting with a nonzero register value
    `ASSERT(SecWipeChangedBaseRegs_A,
      $rose(busy_secure_wipe) |-> ((##[0:$]
        u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q !=
          EccZeroWord &&
        $changed(
          u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.g_rf_flops[i].rf_reg_q))
        within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
      clk_i,
      !rst_ni || u_otbn_core.urnd_reseed_err || u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
      u_otbn_core.u_otbn_start_stop_control.state_error_d)
  end

  // We have several assertions that check that secure wipe worked properly. However, we've also got
  // some tests where we force nets, stopping it from working properly! That's fine, and the tests
  // are checking that some other mechanism catches the problem. However, we don't want the
  // simulation to die with a failed assertion, so we put everything in a named block which we can
  // turn off with $assertoff.
  //
  // The silly-looking name is to avoid a lint warning. Verible (correctly) points out that
  // SystemVerilog doesn't allow bare begin/end blocks at module level. So I cheated and put
  // everything in an if(1) block. But this is treated as a generate block, and our lint rules
  // therefore expect its name to start with a "g_".
  if (1) begin : g_secure_wipe_assertions
    // WDR assertions for secure wipe
    // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
    // goes to LOCKED state immediately after this error which means that it's not guaranteed to
    // have secure wiping complete.
    // 2. mubi_err_d of start_stop_control disables the internal secure wipe related assertion
    // because a fatal error affecting internal secure wiping could cause an immediate locking
    // behaviour in which it's not guaranteed to see a succesful secure wipe.
    for (genvar i = 0; i < NWdr; ++i) begin : gen_sec_wipe_wdr_asserts
      // Initial secure wipe needs to initialise all registers to nonzero
      `ASSERT(InitSecWipeNonZeroWideRegs_A,
              $fell(busy_secure_wipe) |->
                u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
                  EccWideZeroWord,
              clk_i,
              !rst_ni || u_otbn_core.urnd_reseed_err ||
                u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
                u_otbn_core.u_otbn_start_stop_control.state_error_d)

      // After execution, it's expected to see a change resulting with a nonzero register value
      `ASSERT(SecWipeChangedWideRegs_A,
              $rose(busy_secure_wipe) |-> ((##[0:$]
                u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i] !=
                  EccWideZeroWord &&
                $changed(
                  u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.rf[i]))
                within ($rose(busy_secure_wipe) ##[0:$] $fell(busy_secure_wipe))),
            clk_i, !rst_ni || u_otbn_core.urnd_reseed_err ||
              u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
    end
  end

  // Secure wipe needs to invalidate call and loop stack, initialize MOD, ACC to nonzero and set
  // FLAGS CSR to zero
  // 1. urnd_reseed_err disables the assertion because secure wipe finishes with failure and OTBN
  // goes to LOCKED state immediately after this error which means that it's not guaranteed to have
  // secure wiping complete.
  // 2. mubi_err_d of start_stop_control disables the secure wipe related assertions because a
  // fatal error affecting internal secure wiping could cause an immediate locking behaviour
  // in which it's not guaranteed to see a succesful secure wipe.
  `ASSERT(SecWipeInvalidCallStack_A,
          $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_rf_base.u_call_stack.top_valid_o),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)
  `ASSERT(SecWipeInvalidLoopStack_A,
          $fell(busy_secure_wipe) |->
            (!u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.top_valid_o),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)

  `ASSERT(SecWipeNonZeroMod_A,
          $fell(busy_secure_wipe) |-> u_otbn_core.u_otbn_alu_bignum.mod_intg_q != EccWideZeroWord,
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)

  `ASSERT(SecWipeNonZeroACC_A,
          $fell(busy_secure_wipe) |->
            u_otbn_core.u_otbn_alu_bignum.ispr_acc_intg_i != EccWideZeroWord,
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)

  `ASSERT(SecWipeNonZeroFlags_A,
          $fell(busy_secure_wipe) |-> (!u_otbn_core.u_otbn_alu_bignum.flags_flattened),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d ||
            u_otbn_core.u_otbn_start_stop_control.state_error_d)

  // Secure wipe of IMEM and DMEM first happens with a key change from URND (while valid is zero)
  `ASSERT(ImemSecWipeRequiresUrndKey_A,
          $rose(imem_sec_wipe) |=> (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
  `ASSERT(DmemSecWipeRequiresUrndKey_A,
          $rose(dmem_sec_wipe) |=> (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d)

  // Then it is guaranteed to have a valid key from OTP interface which is different from URND key
  `ASSERT(ImemSecWipeRequiresOtpKey_A,
          $rose(imem_sec_wipe) ##1 (otbn_imem_scramble_key == $past(imem_sec_wipe_urnd_key)) |=>
            ##[0:$] otbn_imem_scramble_valid && $changed(otbn_imem_scramble_key),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d)
  `ASSERT(DmemSecWipeRequiresOtpKey_A,
          $rose(dmem_sec_wipe) ##1 (otbn_dmem_scramble_key == $past(dmem_sec_wipe_urnd_key)) |=>
            ##[0:$] otbn_dmem_scramble_valid && $changed(otbn_dmem_scramble_key),
          clk_i,
          !rst_ni || u_otbn_core.urnd_reseed_err ||
            u_otbn_core.u_otbn_start_stop_control.mubi_err_d)

  // All outputs should be known value after reset
  `ASSERT_KNOWN(TlODValidKnown_A, tl_o.d_valid)
  `ASSERT_KNOWN(TlOAReadyKnown_A, tl_o.a_ready)
  `ASSERT_KNOWN(IdleOKnown_A, idle_o)
  `ASSERT_KNOWN(IntrDoneOKnown_A, intr_done_o)
  `ASSERT_KNOWN(AlertTxOKnown_A, alert_tx_o)
  `ASSERT_KNOWN(EdnRndOKnown_A, edn_rnd_o, clk_edn_i, !rst_edn_ni)
  `ASSERT_KNOWN(EdnUrndOKnown_A, edn_urnd_o, clk_edn_i, !rst_edn_ni)
  `ASSERT_KNOWN(OtbnOtpKeyO_A, otbn_otp_key_o, clk_otp_i, !rst_otp_ni)
  `ASSERT_KNOWN(ErrBitsKnown_A, err_bits)

  // Incoming key must be valid (other inputs go via prim modules that handle the X checks).
  `ASSERT_KNOWN(KeyMgrKeyValid_A, keymgr_key_i.valid)

  // In locked state, the readable registers INSN_CNT, IMEM, and DMEM are expected to always read 0
  // when accessed from the bus. For INSN_CNT, we use "|=>" so that the assertion lines up with
  // "status.q" (a signal that isn't directly accessible here).
  `ASSERT(LockedInsnCntReadsZero_A, (hw2reg.status.d == StatusLocked) |=> insn_cnt == 'd0)
  `ASSERT(ExecuteOrLockedImemReadsZero_A,
          (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & imem_rvalid_bus
          |-> imem_rdata_bus == 'd0)
  `ASSERT(ExecuteOrLockedDmemReadsZero_A,
          (hw2reg.status.d inside {StatusBusyExecute, StatusLocked}) & dmem_rvalid_bus
          |-> dmem_rdata_bus == 'd0)

  // From the cycle the core is told to start to when it is done, it must always be busy executing,
  // locking, or both -- even if the core is never done.  We use this property to enable blanking
  // while the core is executing or locking, and this assertion ensures that there is no gap
  // between execution and locking.
  `ASSERT(BusyOrLockingFromStartToDone_A,
          $rose(start_q) |-> (busy_execute_d | locking) |-> ##[0:$] $rose(done_core))

  // Error handling: if we pass an error signal down to the core then we should also be setting an
  // error flag. Note that this uses err_bits, not err_bits_q, because the latter signal only gets
  // asserted when an operation finishes.
  `ASSERT(ErrBitIfEscalate_A, mubi4_test_true_loose(core_escalate_en) |=> |err_bits)

  // Constraint from package, check here as we cannot have `ASSERT_INIT in package
  `ASSERT_INIT(WsrESizeMatchesParameter_A, $bits(wsr_e) == WsrNumWidth)

  `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnStartStopFsmCheck_A,
    u_otbn_core.u_otbn_start_stop_control.u_state_regs, alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnControllerFsmCheck_A,
    u_otbn_core.u_otbn_controller.u_state_regs, alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FSM_ERROR_TRIGGER_ALERT(OtbnScrambleCtrlFsmCheck_A,
    u_otbn_scramble_ctrl.u_state_regs, alert_tx_o[AlertFatal])

  `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnCallStackWrPtrAlertCheck_A,
    u_otbn_core.u_otbn_rf_base.u_call_stack.u_stack_wr_ptr, alert_tx_o[AlertFatal])
  `ASSERT_PRIM_COUNT_ERROR_TRIGGER_ALERT(OtbnLoopInfoStackWrPtrAlertCheck_A,
    u_otbn_core.u_otbn_controller.u_otbn_loop_controller.loop_info_stack.u_stack_wr_ptr,
    alert_tx_o[AlertFatal])

  // Alert assertions for reg_we onehot check
  `ASSERT_PRIM_REG_WE_ONEHOT_ERROR_TRIGGER_ALERT(RegWeOnehotCheck_A,
      u_reg, alert_tx_o[AlertFatal])
  // other onehot checks
  `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBaseOnehotCheck_A,
      u_otbn_core.u_otbn_rf_base.gen_rf_base_ff.u_otbn_rf_base_inner.u_prim_onehot_check,
      alert_tx_o[AlertFatal])
  `ASSERT_PRIM_ONEHOT_ERROR_TRIGGER_ALERT(RfBignumOnehotCheck_A,
      u_otbn_core.u_otbn_rf_bignum.gen_rf_bignum_ff.u_otbn_rf_bignum_inner.u_prim_onehot_check,
      alert_tx_o[AlertFatal])

  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemRspFifo,
                                               u_tlul_adapter_sram_dmem.u_rspfifo,
                                               alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemSramReqFifo,
                                               u_tlul_adapter_sram_dmem.u_sramreqfifo,
                                               alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(DmemReqFifo,
                                               u_tlul_adapter_sram_dmem.u_reqfifo,
                                               alert_tx_o[AlertFatal])

  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemRspFifo,
                                               u_tlul_adapter_sram_imem.u_rspfifo,
                                               alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemSramReqFifo,
                                               u_tlul_adapter_sram_imem.u_sramreqfifo,
                                               alert_tx_o[AlertFatal])
  `ASSERT_PRIM_FIFO_SYNC_ERROR_TRIGGERS_ALERT1(ImemReqFifo,
                                               u_tlul_adapter_sram_imem.u_reqfifo,
                                               alert_tx_o[AlertFatal])
endmodule


    """


    Identify the CWE relevant to the security issue for the given RTL.
    Obtain details of the CWE.

    Then determine if there are security issues relevant to the identified CWE in the RTL.
    Refer to the code that corresponds to the issues identified.
    
================================== Ai Message ==================================

[{'text': "I'll analyze the RTL code for security concerns related to confidentiality and memory access control during BUSY/LOCKED states.", 'type': 'text'}, {'id': 'toolu_0119U7sRdBKpBUBKHtLrVbdC', 'input': {'security_issue': 'Confidentiality: Ensure IMEM/DMEM contents are not exposed over TL-UL during BUSY/LOCKED; verify blanking logic, write ignore, and ILLEGAL_BUS_ACCESS behavior'}, 'name': 'llm_cwe_details_retriever_tool', 'type': 'tool_use'}]
Tool Calls:
  llm_cwe_details_retriever_tool (toolu_0119U7sRdBKpBUBKHtLrVbdC)
 Call ID: toolu_0119U7sRdBKpBUBKHtLrVbdC
  Args:
    security_issue: Confidentiality: Ensure IMEM/DMEM contents are not exposed over TL-UL during BUSY/LOCKED; verify blanking logic, write ignore, and ILLEGAL_BUS_ACCESS behavior
================================= Tool Message =================================
Name: llm_cwe_details_retriever_tool

Successfully executed:
```LLM CWE details retriever tool
```
Output:
 CWE-1233: Security-Sensitive Hardware Controls with Missing Lock Bit Protection
The product uses a register lock bit protection mechanism, but it does not ensure that the lock bit prevents modification of system registers or controls that perform changes to important hardware system configuration.
Integrated circuits and hardware intellectual properties (IPs) might provide device configuration controls that need to be programmed after device power reset by a trusted firmware or software module, commonly set by BIOS/bootloader. After reset, there can be an expectation that the controls cannot be used to perform any further modification. This behavior is commonly implemented using a trusted lock bit, which can be set to disable writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration).
Example 1
Consider the example design below for a digital thermal sensor that detects overheating of the silicon and triggers system shutdown. The system critical temperature limit (CRITICAL_TEMP_LIMIT) and thermal sensor calibration (TEMP_SENSOR_CALIB) data have to be programmed by the firmware.
(bad code)
Example Language: Other
Register Field description CRITICAL_TEMP_LIMIT [31:8] Reserved field; Read only; Default 0 [7:0] Critical temp 0-255 Centigrade; Read-write-lock; Default 125 TEMP_SENSOR_CALIB [31:0] Thermal sensor calibration data. A slope value used to map sensor reading to a degree Centigrade. Read-write; Default 25 TEMP_SENSOR_LOCK [31:1] Reserved field; Read only; Default 0 [0] Lock bit, locks CRITICAL_TEMP_LIMIT register; Write-1-once; Default 0 TEMP_HW_SHUTDOWN [31:2] Reserved field; Read only; Default 0 [1] Enable hardware shutdown on a critical temperature detection; Read-write; Default 0 CURRENT_TEMP [31:8] Reserved field; Read only; Default 0 [7:0] Current Temp 0-255 Centigrade; Read-only; Default 0
In this example note that only the CRITICAL_TEMP_LIMIT register is protected by the TEMP_SENSOR_LOCK bit, while the security design intent is to protect any modification of the critical temperature detection and response. The response of the system, if the system heats to a critical temperature, is controlled by TEMP_HW_SHUTDOWN bit [1], which is not lockable. Also, the TEMP_SENSOR_CALIB register is not protected by the lock bit. By modifying the temperature sensor calibration, the conversion of the sensor data to a degree centigrade can be changed, such that the current temperature will never be detected to exceed critical temperature value programmed by the protected lock. Similarly, by modifying the TEMP_HW_SHUTDOWN.Enable bit, the system response detection of the current temperature exceeding critical temperature can be disabled.
(good code)
Example Language: Other
Change TEMP_HW_SHUTDOWN and TEMP_SENSOR_CALIB controls to be locked by TEMP_SENSOR_LOCK. TEMP_SENSOR_CALIB [31:0] Thermal sensor calibration data. A slope value used to map sensor reading to a degree Centigrade. Read-write-Lock; Default 25; Locked by TEMP_SENSOR_LOCK bit[0] TEMP_HW_SHUTDOWN [31:2] Reserved field; Read only; Default 0[1] Enable hardware shutdown on critical temperature detection; Read-write-Lock; Default 0; Locked by TEMP_SENSOR_LOCK bit[0]


================================== Ai Message ==================================

Now let me analyze the RTL code for security issues related to confidentiality and memory access control. Based on the CWE-1233 and the specific security concern about IMEM/DMEM content exposure during BUSY/LOCKED states, I can identify several relevant security mechanisms and potential issues:

## Security Analysis Results

### Identified CWE
**CWE-1233: Security-Sensitive Hardware Controls with Missing Lock Bit Protection** - This CWE is highly relevant as it deals with ensuring that security-sensitive controls (like memory access) are properly protected when the system is in a locked state.

### Security Issues Found in the RTL

#### 1. **Blanking Logic Implementation - SECURE**
The RTL implements proper blanking logic to prevent data leakage:

**IMEM Blanking (Lines 424-442):**
```systemverilog
// SEC_CM: DATA_REG_SW.SCA
// Blank bus read data interface during core operation to avoid leaking the currently executed
// instruction from IMEM through the bus unintentionally. Also blank when OTBN is returning
// a dummy response (responding to an illegal bus access) and when OTBN is locked.
assign imem_rdata_bus_en_d = 1'b1;

prim_blanker #(.Width(39)) u_imem_rdata_bus_blanker (
  .in_i (imem_rdata),
  .en_i (imem_rdata_bus_en_q),
  .out_o(imem_rdata_bus_raw)
);

// When OTBN is locked all imem bus reads should return 0
assign imem_rdata_bus =
  {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : imem_rdata_bus_raw[38:32],
   imem_rdata_bus_raw[31:0]};
```

**DMEM Blanking (Lines 608-630):**
```systemverilog
// SEC_CM: DATA_REG_SW.SCA
// Blank bus read data interface during core operation to avoid leaking DMEM data through the bus
// unintentionally. Also blank when OTBN is returning a dummy response (responding to an illegal
// bus access) and when OTBN is locked.
assign dmem_rdata_bus_en_d = 1'b1;

prim_blanker #(.Width(ExtWLEN)) u_dmem_rdata_bus_blanker (
  .in_i (dmem_rdata),
  .en_i (dmem_rdata_bus_en_q),
  .out_o(dmem_rdata_bus_raw)
);
```

#### 2. **Illegal Bus Access Detection - SECURE**
The RTL properly detects and handles illegal bus accesses:

**IMEM Illegal Access (Lines 380-390):**
```systemverilog
assign imem_illegal_bus_access = imem_req_bus & imem_access_core;

assign imem_dummy_response_d = imem_illegal_bus_access;
always_ff @(posedge clk_i or negedge rst_ni) begin
  if (!rst_ni) begin
    imem_dummy_response_q <= 1'b0;
  end else begin
    imem_dummy_response_q <= imem_dummy_response_d;
  end
end
```

**DMEM Illegal Access (Lines 580-590):**
```systemverilog
assign dmem_illegal_bus_access = dmem_req_bus & dmem_access_core;

assign dmem_dummy_response_d = dmem_illegal_bus_access;
always_ff @(posedge clk_i or negedge rst_ni) begin
  if (!rst_ni) begin
    dmem_dummy_response_q <= 1'b0;
  end else begin
    dmem_dummy_response_q <= dmem_dummy_response_d;
  end
end
```

#### 3. **Write Ignore During BUSY/LOCKED - POTENTIAL ISSUE**
While the RTL has good read protection, there's a potential concern with write handling:

**Issue Location (Lines 365
================================= Tool Message =================================
Name: run_llm_cwe_checker_agent

Now let me analyze the RTL code for security issues related to confidentiality and memory access control. Based on the CWE-1233 and the specific security concern about IMEM/DMEM content exposure during BUSY/LOCKED states, I can identify several relevant security mechanisms and potential issues:

## Security Analysis Results

### Identified CWE
**CWE-1233: Security-Sensitive Hardware Controls with Missing Lock Bit Protection** - This CWE is highly relevant as it deals with ensuring that security-sensitive controls (like memory access) are properly protected when the system is in a locked state.

### Security Issues Found in the RTL

#### 1. **Blanking Logic Implementation - SECURE**
The RTL implements proper blanking logic to prevent data leakage:

**IMEM Blanking (Lines 424-442):**
```systemverilog
// SEC_CM: DATA_REG_SW.SCA
// Blank bus read data interface during core operation to avoid leaking the currently executed
// instruction from IMEM through the bus unintentionally. Also blank when OTBN is returning
// a dummy response (responding to an illegal bus access) and when OTBN is locked.
assign imem_rdata_bus_en_d = 1'b1;

prim_blanker #(.Width(39)) u_imem_rdata_bus_blanker (
  .in_i (imem_rdata),
  .en_i (imem_rdata_bus_en_q),
  .out_o(imem_rdata_bus_raw)
);

// When OTBN is locked all imem bus reads should return 0
assign imem_rdata_bus =
  {locking_q ? prim_secded_pkg::SecdedInv3932ZeroEcc : imem_rdata_bus_raw[38:32],
   imem_rdata_bus_raw[31:0]};
```

**DMEM Blanking (Lines 608-630):**
```systemverilog
// SEC_CM: DATA_REG_SW.SCA
// Blank bus read data interface during core operation to avoid leaking DMEM data through the bus
// unintentionally. Also blank when OTBN is returning a dummy response (responding to an illegal
// bus access) and when OTBN is locked.
assign dmem_rdata_bus_en_d = 1'b1;

prim_blanker #(.Width(ExtWLEN)) u_dmem_rdata_bus_blanker (
  .in_i (dmem_rdata),
  .en_i (dmem_rdata_bus_en_q),
  .out_o(dmem_rdata_bus_raw)
);
```

#### 2. **Illegal Bus Access Detection - SECURE**
The RTL properly detects and handles illegal bus accesses:

**IMEM Illegal Access (Lines 380-390):**
```systemverilog
assign imem_illegal_bus_access = imem_req_bus & imem_access_core;

assign imem_dummy_response_d = imem_illegal_bus_access;
always_ff @(posedge clk_i or negedge rst_ni) begin
  if (!rst_ni) begin
    imem_dummy_response_q <= 1'b0;
  end else begin
    imem_dummy_response_q <= imem_dummy_response_d;
  end
end
```

**DMEM Illegal Access (Lines 580-590):**
```systemverilog
assign dmem_illegal_bus_access = dmem_req_bus & dmem_access_core;

assign dmem_dummy_response_d = dmem_illegal_bus_access;
always_ff @(posedge clk_i or negedge rst_ni) begin
  if (!rst_ni) begin
    dmem_dummy_response_q <= 1'b0;
  end else begin
    dmem_dummy_response_q <= dmem_dummy_response_d;
  end
end
```

#### 3. **Write Ignore During BUSY/LOCKED - POTENTIAL ISSUE**
While the RTL has good read protection, there's a potential concern with write handling:

**Issue Location (Lines 365
================================== Ai Message ==================================
Tool Calls:
  read_file_with_line_numbers (call_qMYcs7HqdYv31ElJRtlEvdZ9)
 Call ID: call_qMYcs7HqdYv31ElJRtlEvdZ9
  Args:
    file_path: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn_instruction_fetch.sv
================================= Tool Message =================================
Name: read_file_with_line_numbers

1: // Copyright lowRISC contributors (OpenTitan project).
2: // Licensed under the Apache License, Version 2.0, see LICENSE for details.
3: // SPDX-License-Identifier: Apache-2.0
4: 
5: `include "prim_assert.sv"
6: 
7: /**
8:  * OTBN Instruction Fetch Unit
9:  *
10:  * Fetch an instruction from the instruction memory.
11:  */
12: module otbn_instruction_fetch
13:   import otbn_pkg::*;
14: #(
15:   parameter int ImemSizeByte = 4096,
16: 
17:   localparam int ImemAddrWidth = prim_util_pkg::vbits(ImemSizeByte)
18: ) (
19:   input logic clk_i,
20:   input logic rst_ni,
21: 
22:   // Instruction memory (IMEM) interface. Read-only.
23:   output logic                     imem_req_o,
24:   output logic [ImemAddrWidth-1:0] imem_addr_o,
25:   input  logic [38:0]              imem_rdata_i,
26:   input  logic                     imem_rvalid_i,
27: 
28:   // Next instruction selection (to instruction fetch)
29:   input logic                     insn_fetch_req_valid_i,
30:   input logic                     insn_fetch_req_valid_raw_i,
31:   input logic [ImemAddrWidth-1:0] insn_fetch_req_addr_i,
32: 
33:   // Decoded instruction
34:   output logic                     insn_fetch_resp_valid_o,
35:   output logic [ImemAddrWidth-1:0] insn_fetch_resp_addr_o,
36:   output logic [31:0]              insn_fetch_resp_data_o,
37:   input  logic                     insn_fetch_resp_clear_i,
38: 
39:   output rf_predec_bignum_t        rf_predec_bignum_o,
40:   output alu_predec_bignum_t       alu_predec_bignum_o,
41:   output ctrl_flow_predec_t        ctrl_flow_predec_o,
42:   output logic [ImemAddrWidth-1:0] ctrl_flow_target_predec_o,
43:   output ispr_predec_bignum_t      ispr_predec_bignum_o,
44:   output mac_predec_bignum_t       mac_predec_bignum_o,
45:   output logic                     lsu_addr_en_predec_o,
46: 
47:   input logic [NWdr-1:0] rf_bignum_rd_a_indirect_onehot_i,
48:   input logic [NWdr-1:0] rf_bignum_rd_b_indirect_onehot_i,
49:   input logic [NWdr-1:0] rf_bignum_wr_indirect_onehot_i,
50:   input logic            rf_bignum_indirect_en_i,
51: 
52:   output logic insn_fetch_err_o,  // ECC error seen in instruction fetch
53:   output logic insn_addr_err_o,
54: 
55:   input logic                     prefetch_en_i,
56:   input logic                     prefetch_loop_active_i,
57:   input logic [31:0]              prefetch_loop_iterations_i,
58:   input logic [ImemAddrWidth:0]   prefetch_loop_end_addr_i,
59:   input logic [ImemAddrWidth-1:0] prefetch_loop_jump_addr_i,
60:   input logic                     prefetch_ignore_errs_i,
61: 
62:   input logic                     sec_wipe_wdr_en_i,
63:   input logic [4:0]               sec_wipe_wdr_addr_i,
64: 
65:   input logic                     zero_flags_i
66: );
67: 
68:   function automatic logic insn_is_branch(logic [31:0] insn_data);
69:     logic [31:7] unused_insn_data;
70: 
71:     unused_insn_data = insn_data[31:7];
72: 
73:     return insn_data[6:0] inside {InsnOpcodeBaseBranch, InsnOpcodeBaseJal, InsnOpcodeBaseJalr};
74:   endfunction
75: 
76:   logic [ImemAddrWidth-1:0] insn_prefetch_addr;
77:   logic [38:0]              insn_fetch_resp_data_intg_q, insn_fetch_resp_data_intg_d;
78:   logic [ImemAddrWidth-1:0] insn_fetch_resp_addr_q;
79:   logic                     insn_fetch_resp_valid_q, insn_fetch_resp_valid_d;
80:   logic [1:0]               insn_fetch_resp_intg_error_vec;
81:   logic                     insn_fetch_en;
82: 
83:   logic                     insn_prefetch;
84:   logic                     insn_prefetch_fail;
85: 
86:   logic                     imem_rvalid_final;
87:   logic                     imem_rvalid_kill_q, imem_rvalid_kill_d;
88: 
89:   rf_predec_bignum_t   rf_predec_bignum_indirect, rf_predec_bignum_sec_wipe;
90:   rf_predec_bignum_t   rf_predec_bignum_q, rf_predec_bignum_d, rf_predec_bignum_insn;
91:   alu_predec_bignum_t  alu_predec_bignum_zero_flags;
92:   alu_predec_bignum_t  alu_predec_bignum_q, alu_predec_bignum_d, alu_predec_bignum_insn;
93:   ispr_predec_bignum_t ispr_predec_bignum_q, ispr_predec_bignum_d;
94:   ispr_predec_bignum_t ispr_predec_bignum;
95:   mac_predec_bignum_t  mac_predec_bignum, mac_predec_bignum_q, mac_predec_bignum_d;
96:   logic                lsu_addr_en_predec_q, lsu_addr_en_predec_d;
97:   logic                lsu_addr_en_predec_insn;
98:   logic                insn_addr_err_unbuf;
99: 
100:   ctrl_flow_predec_t ctrl_flow_predec, ctrl_flow_predec_d, ctrl_flow_predec_q;
101: 
102:   logic [ImemAddrWidth-1:0] ctrl_flow_target_predec, ctrl_flow_target_predec_d;
103:   logic [ImemAddrWidth-1:0] ctrl_flow_target_predec_q;
104: 
105:   logic [NWdr-1:0] rf_bignum_wr_sec_wipe_onehot;
106: 
107:   assign imem_rvalid_final = imem_rvalid_i & ~imem_rvalid_kill_q;
108: 
109:   // The prefetch has failed if a fetch is requested and either no prefetch has done or was done to
110:   // the wrong address. The `insn_fetch_req_valid_raw_i` signal doesn't factor in errors which is
111:   // important to avoid timing issues here as this signal factors into the muxing for the
112:   // imem_addr_o output.
113:   assign insn_prefetch_fail = insn_fetch_req_valid_raw_i &
114:                               (~imem_rvalid_final || (insn_fetch_req_addr_i != insn_prefetch_addr));
115: 
116:   // Fetch response is valid when prefetch has matched what was requested. Otherwise if no fetch is
117:   // requested keep fetch response validity constant unless a clear is commanded.
118:   assign insn_fetch_resp_valid_d =
119:     insn_fetch_req_valid_i ? imem_rvalid_final & (insn_fetch_req_addr_i == insn_prefetch_addr) :
120:                              insn_fetch_resp_valid_q & ~insn_fetch_resp_clear_i;
121: 
122:   always_ff @(posedge clk_i or negedge rst_ni) begin
123:     if (!rst_ni) begin
124:       insn_fetch_resp_valid_q <= 1'b0;
125:     end else begin
126:       insn_fetch_resp_valid_q <= insn_fetch_resp_valid_d;
127:     end
128:   end
129: 
130:   // SEC_CM: DATA_REG_SW.SCA
131:   otbn_predecode #(
132:     .ImemSizeByte(ImemSizeByte)
133:   ) u_otbn_predecode (
134:     .clk_i,
135:     .rst_ni,
136: 
137:     .imem_rdata_i (imem_rdata_i[31:0]),
138:     .imem_raddr_i (insn_prefetch_addr),
139:     .imem_rvalid_i(imem_rvalid_final),
140: 
141:     .rf_predec_bignum_o        (rf_predec_bignum_insn),
142:     .alu_predec_bignum_o       (alu_predec_bignum_insn),
143:     .ctrl_flow_predec_o        (ctrl_flow_predec),
144:     .ctrl_flow_target_predec_o (ctrl_flow_target_predec),
145:     .ispr_predec_bignum_o      (ispr_predec_bignum),
146:     .mac_predec_bignum_o       (mac_predec_bignum),
147:     .lsu_addr_en_predec_o      (lsu_addr_en_predec_insn)
148:   );
149: 
150:   prim_onehot_enc #(
151:     .OneHotWidth(NWdr)
152:   ) rf_we_bignum_sec_wipe_onehot_enc (
153:     .in_i  (sec_wipe_wdr_addr_i),
154:     .en_i  (sec_wipe_wdr_en_i),
155:     .out_o (rf_bignum_wr_sec_wipe_onehot)
156:   );
157: 
158:   // Indirect register addressing
159:   // For instructions using indirect addressing (BN.LID/BN.SID/BN.MOVR) the base register read to
160:   // determine which bignum register is used occurs in the first cycle of the instruction
161:   // execution. The onehot encoded version of the register index is passed back here (via the
162:   // `rf_bignum_*_indirect_onehot_i` signals to set the enables for the following cycle.
163:   assign rf_predec_bignum_indirect = '{rf_ren_a : rf_bignum_rd_a_indirect_onehot_i,
164:                                        rf_ren_b : rf_bignum_rd_b_indirect_onehot_i,
165:                                        rf_we    : rf_bignum_wr_indirect_onehot_i};
166: 
167:   assign rf_predec_bignum_sec_wipe = '{rf_ren_a : '0,
168:                                        rf_ren_b : '0,
169:                                        rf_we    : rf_bignum_wr_sec_wipe_onehot};
170: 
171:   // Register enables for bignum come from precode unless indirect register accesses are used
172:   assign rf_predec_bignum_d = sec_wipe_wdr_en_i       ? rf_predec_bignum_sec_wipe :
173:                               rf_bignum_indirect_en_i ? rf_predec_bignum_indirect :
174:                               insn_fetch_en           ? rf_predec_bignum_insn     :
175:                               insn_fetch_resp_clear_i ? '0                        :
176:                                                         rf_predec_bignum_q;
177: 
178:   assign ispr_predec_bignum_d = insn_fetch_en           ? ispr_predec_bignum :
179:                                 insn_fetch_resp_clear_i ? '0                 :
180:                                                           ispr_predec_bignum_q;
181: 
182:   assign lsu_addr_en_predec_d = insn_fetch_en           ? lsu_addr_en_predec_insn :
183:                                 insn_fetch_resp_clear_i ? 1'b0:
184:                                                           lsu_addr_en_predec_q;
185: 
186:   assign insn_fetch_en = imem_rvalid_final & insn_fetch_req_valid_i;
187: 
188:   assign insn_fetch_resp_data_intg_d = insn_fetch_en ? imem_rdata_i :
189:                                                        insn_fetch_resp_data_intg_q;
190: 
191:   prim_flop #(
192:     .Width(39),
193:     .ResetValue('0)
194:   ) u_insn_fetch_resp_data_intg_flop (
195:     .clk_i,
196:     .rst_ni,
197: 
198:     .d_i(insn_fetch_resp_data_intg_d),
199:     .q_o(insn_fetch_resp_data_intg_q)
200:   );
201: 
202:   always_ff @(posedge clk_i) begin
203:     if (insn_fetch_en) begin
204:       insn_fetch_resp_addr_q      <= insn_prefetch_addr;
205:     end
206:   end
207: 
208:   // Flag zeroing
209:   // For secure wipe and ISPR initialization, flags need to be set to 0. This is achieved
210:   // by setting all selector inputs for the corresponding one-hot mux in the ALU to zero.
211:   always_comb begin
212:     alu_predec_bignum_zero_flags = alu_predec_bignum_insn;
213: 
214:     alu_predec_bignum_zero_flags.flags_keep         = '0;
215:     alu_predec_bignum_zero_flags.flags_adder_update = '0;
216:     alu_predec_bignum_zero_flags.flags_logic_update = '0;
217:     alu_predec_bignum_zero_flags.flags_mac_update   = '0;
218:     alu_predec_bignum_zero_flags.flags_ispr_wr      = '0;
219:   end
220: 
221:   assign alu_predec_bignum_d = zero_flags_i  ? alu_predec_bignum_zero_flags :
222:                                insn_fetch_en ? alu_predec_bignum_insn       :
223:                                                alu_predec_bignum_q;
224: 
225:   assign mac_predec_bignum_d = insn_fetch_en ? mac_predec_bignum : mac_predec_bignum_q;
226: 
227:   assign ctrl_flow_predec_d = insn_fetch_en           ? ctrl_flow_predec   :
228:                               insn_fetch_resp_clear_i ? '0                 :
229:                                                         ctrl_flow_predec_q;
230: 
231:   assign ctrl_flow_target_predec_d = insn_fetch_en ? ctrl_flow_target_predec   :
232:                                                      ctrl_flow_target_predec_q;
233: 
234: 
235:   prim_flop #(
236:     .Width($bits(alu_predec_bignum_t)),
237:     .ResetValue('0)
238:   ) u_alu_predec_bignum_flop(
239:     .clk_i,
240:     .rst_ni,
241: 
242:     .d_i(alu_predec_bignum_d),
243:     .q_o(alu_predec_bignum_q)
244:   );
245: 
246:   prim_flop #(
247:     .Width($bits(mac_predec_bignum_t)),
248:     .ResetValue('0)
249:   ) u_mac_predec_bignum_flop (
250:     .clk_i,
251:     .rst_ni,
252: 
253:     .d_i(mac_predec_bignum_d),
254:     .q_o(mac_predec_bignum_q)
255:   );
256: 
257:   prim_flop #(
258:     .Width($bits(ctrl_flow_predec_t)),
259:     .ResetValue('0)
260:   ) u_ctrl_flow_predec_flop (
261:     .clk_i,
262:     .rst_ni,
263: 
264:     .d_i(ctrl_flow_predec_d),
265:     .q_o(ctrl_flow_predec_q)
266:   );
267: 
268:   prim_flop #(
269:     .Width(ImemAddrWidth),
270:     .ResetValue('0)
271:   ) u_ctrl_flow_target_predec_flop (
272:     .clk_i,
273:     .rst_ni,
274: 
275:     .d_i(ctrl_flow_target_predec_d),
276:     .q_o(ctrl_flow_target_predec_q)
277:   );
278: 
279:   prim_flop #(
280:     .Width($bits(rf_predec_bignum_t)),
281:     .ResetValue('0)
282:   ) u_rf_predec_bignum_flop (
283:     .clk_i,
284:     .rst_ni,
285: 
286:     .d_i(rf_predec_bignum_d),
287:     .q_o(rf_predec_bignum_q)
288:   );
289: 
290:   prim_flop #(
291:     .Width($bits(ispr_predec_bignum_t)),
292:     .ResetValue('0)
293:   ) u_ispr_predec_bignum_flop (
294:     .clk_i,
295:     .rst_ni,
296: 
297:     .d_i(ispr_predec_bignum_d),
298:     .q_o(ispr_predec_bignum_q)
299:   );
300: 
301:   prim_flop #(
302:     .Width(1),
303:     .ResetValue(1'b0)
304:   ) u_lsu_addr_en_predec_flop (
305:     .clk_i,
306:     .rst_ni,
307: 
308:     .d_i(lsu_addr_en_predec_d),
309:     .q_o(lsu_addr_en_predec_q)
310:   );
311: 
312:   always_ff @(posedge clk_i) begin
313:     if (insn_prefetch) begin
314:       insn_prefetch_addr <= imem_addr_o;
315:     end
316:   end
317: 
318:   // Prefetch control
319:   always_comb begin
320:     // By default prefetch the next instruction
321:     imem_addr_o = insn_prefetch_addr + 'd4;
322:     // The kill is flopped and applied to imem_rvalid the following cycle. It's used for branching.
323:     imem_rvalid_kill_d = 1'b0;
324:     // Only prefetch if controller tells us to
325:     insn_prefetch = prefetch_en_i;
326: 
327:     // Use the `insn_fetch_req_valid_raw_i` signal here as it doesn't factor in errors. This is
328:     // important for timing reasons so errors don't factor into the `imem_addr_o` signal.
329:     if (!insn_fetch_req_valid_raw_i) begin
330:       // Keep prefetching the same instruction when a new one isn't being requested. In this
331:       // scenario OTBN is stalled and will eventually want the prefetched instruction.
332:       imem_addr_o = insn_prefetch_addr;
333:     end else if (insn_prefetch_fail) begin
334:       // When prefetching has failed prefetch the requested address
335:       imem_addr_o = insn_fetch_req_addr_i;
336:     end else begin
337:       if ({1'b0, insn_prefetch_addr} == prefetch_loop_end_addr_i &&
338:           prefetch_loop_active_i &&
339:           prefetch_loop_iterations_i > 32'd1) begin
340:         // When in a loop prefetch the loop beginning when execution reaches the end.
341:         imem_addr_o = prefetch_loop_jump_addr_i;
342:       end
343: 
344:       // It is important this if doesn't take priority over others in this block. If it does then
345:       // when `imem_rdata_i` is unknown `imem_addr_o` becomes unknown when running a simulation that
346:       // propagates X through if. In hardware terms this means there isn't a combinational path from
347:       // `imem_rdata_i` and `imem_addr_o`. This may be useful for timing purposes as well.
348:       if (insn_is_branch(imem_rdata_i[31:0])) begin
349:         // For a branch we do not know if it will be taken or untaken. So never prefetch to keep
350:         // timing consistent regardless of taken/not-taken. This also applies to jumps, this avoids
351:         // the need to calculate the jump address here.
352:         //
353:         // For x-prop reasons we do not suppress the imem_req_o here. When OTBN executes an
354:         // instruction that produces a software error it comes to an immediate halt. However only
355:         // the raw fetch request is considered here for timing reasons. So if the instruction
356:         // following the error causing instruction is X in simulation the `insn_is_branch` sees an
357:         // X here which would result in imem_req_o going X (using simulator options that enable
358:         // X prop for if statements). This is turn causes an assertion failure.
359:         //
360:         // The imem_rvalid_kill signal is used to avoid the X prop issue. This suppresses the
361:         // imem_rvalid signal the following cycle. Whilst imem_rvalid_kill itself will go X if
362:         // imem_rdata_i is X, as OTBN has halted following the error this doesn't cause a problem.
363:         imem_rvalid_kill_d = 1'b1;
364:         insn_prefetch      = 1'b0;
365:       end
366:     end
367:   end
368: 
369:   always_ff @(posedge clk_i or negedge rst_ni) begin
370:     if (!rst_ni) begin
371:       imem_rvalid_kill_q <= 1'b0;
372:     end else begin
373:       imem_rvalid_kill_q <= imem_rvalid_kill_d;
374:     end
375:   end
376: 
377:   // SEC_CM: INSTRUCTION.MEM.INTEGRITY
378:   // Check integrity on prefetched instruction
379:   prim_secded_inv_39_32_dec u_insn_intg_check (
380:     .data_i    (insn_fetch_resp_data_intg_q),
381:     .data_o    (),
382:     .syndrome_o(),
383:     .err_o     (insn_fetch_resp_intg_error_vec)
384:   );
385: 
386:   // Read from imem when prefetching is enabled
387:   assign imem_req_o = prefetch_en_i;
388: 
389:   assign insn_fetch_resp_valid_o = insn_fetch_resp_valid_q;
390:   assign insn_fetch_resp_addr_o  = insn_fetch_resp_addr_q;
391:   // Strip integrity bits before passing instruction to decoder
392:   assign insn_fetch_resp_data_o  = insn_fetch_resp_data_intg_q[31:0];
393: 
394:   assign insn_fetch_err_o = |insn_fetch_resp_intg_error_vec & insn_fetch_resp_valid_q;
395: 
396:   // SEC_CM: PC.CTRL_FLOW.REDUN
397:   // Signal an `insn_addr_err` if the instruction the execute stage requests is not the one that was
398:   // prefetched. By design the prefetcher is either correct or doesn't prefetch, so a mismatch
399:   // here indicates a fault.  `insn_fetch_req_valid_raw_i` is used as it doesn't factor in errors,
400:   // which is required here otherwise we get a combinational loop.
401:   assign insn_addr_err_unbuf =
402:     imem_rvalid_final & insn_fetch_req_valid_raw_i & ~prefetch_ignore_errs_i &
403:     (insn_fetch_req_addr_i != insn_prefetch_addr);
404: 
405:   prim_buf #(.Width(1)) u_insn_addr_buf (
406:     .in_i(insn_addr_err_unbuf),
407:     .out_o(insn_addr_err_o)
408:   );
409: 
410:   assign rf_predec_bignum_o        = rf_predec_bignum_q;
411:   assign alu_predec_bignum_o       = alu_predec_bignum_q;
412:   assign ctrl_flow_predec_o        = ctrl_flow_predec_q;
413:   assign ctrl_flow_target_predec_o = ctrl_flow_target_predec_q;
414:   assign ispr_predec_bignum_o      = ispr_predec_bignum_q;
415:   assign mac_predec_bignum_o       = mac_predec_bignum_q;
416:   assign lsu_addr_en_predec_o      = lsu_addr_en_predec_q;
417: 
418:   `ASSERT(FetchEnOnlyIfValidIMem, insn_fetch_en |-> imem_rvalid_i)
419:   `ASSERT(NoFetchEnAndIndirectEn, !(insn_fetch_en && rf_bignum_indirect_en_i))
420: endmodule

================================== Ai Message ==================================
Tool Calls:
  run_anomaly_detector_agent (call_JxIOpAyyrIMcp1vh35zszUCI)
 Call ID: call_JxIOpAyyrIMcp1vh35zszUCI
  Args:
    design_filepath: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn_controller.sv
    top_module: otbn_controller
    security_objective: FSM transitions to Locked on error and secure wipe handshake; stall behavior; predecode redundancy checks
================================ Human Message =================================

Are there security concerns related to FSM transitions to Locked on error and secure wipe handshake; stall behavior; predecode redundancy checks in the provided RTL:
    The design filepath is:

    /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn_controller.sv

    The RTL code is:
    '''verilog
    // Copyright lowRISC contributors (OpenTitan project).
// Licensed under the Apache License, Version 2.0, see LICENSE for details.
// SPDX-License-Identifier: Apache-2.0

`include "prim_assert.sv"

/**
 * OTBN Controller
 */
module otbn_controller
  import otbn_pkg::*;
#(
  // Size of the instruction memory, in bytes
  parameter int ImemSizeByte = 4096,
  // Size of the data memory, in bytes
  parameter int DmemSizeByte = 4096,

  localparam int ImemAddrWidth = prim_util_pkg::vbits(ImemSizeByte),
  localparam int DmemAddrWidth = prim_util_pkg::vbits(DmemSizeByte)
) (
  input logic clk_i,
  input logic rst_ni,

  input  logic start_i,   // start the processing at address zero
  output logic locking_o, // Controller is in or is entering the locked state
  input  logic err_bit_clear_i,

  input prim_mubi_pkg::mubi4_t fatal_escalate_en_i,
  input prim_mubi_pkg::mubi4_t recov_escalate_en_i,
  input prim_mubi_pkg::mubi4_t rma_req_i,
  output controller_err_bits_t err_bits_o,
  output logic                 recoverable_err_o,

  // Next instruction selection (to instruction fetch)
  output logic                     insn_fetch_req_valid_o,
  output logic                     insn_fetch_req_valid_raw_o,
  output logic [ImemAddrWidth-1:0] insn_fetch_req_addr_o,
  output logic                     insn_fetch_resp_clear_o,

  // Fetched/decoded instruction
  input logic                     insn_valid_i,
  input logic                     insn_illegal_i,
  input logic [ImemAddrWidth-1:0] insn_addr_i,

  // Decoded instruction data
  input insn_dec_base_t   insn_dec_base_i,
  input insn_dec_bignum_t insn_dec_bignum_i,
  input insn_dec_shared_t insn_dec_shared_i,

  // Base register file
  output logic [4:0]               rf_base_wr_addr_o,
  output logic                     rf_base_wr_en_o,
  output logic                     rf_base_wr_commit_o,
  output logic [31:0]              rf_base_wr_data_no_intg_o,
  output logic [BaseIntgWidth-1:0] rf_base_wr_data_intg_o,
  output logic                     rf_base_wr_data_intg_sel_o,

  output logic [4:0]               rf_base_rd_addr_a_o,
  output logic                     rf_base_rd_en_a_o,
  input  logic [BaseIntgWidth-1:0] rf_base_rd_data_a_intg_i,
  output logic [4:0]               rf_base_rd_addr_b_o,
  output logic                     rf_base_rd_en_b_o,
  input  logic [BaseIntgWidth-1:0] rf_base_rd_data_b_intg_i,
  output logic                     rf_base_rd_commit_o,

  input logic rf_base_call_stack_sw_err_i,
  input logic rf_base_call_stack_hw_err_i,

  // Bignum register file (WDRs)
  output logic [4:0]         rf_bignum_wr_addr_o,
  output logic [1:0]         rf_bignum_wr_en_o,
  output logic               rf_bignum_wr_commit_o,
  output logic [WLEN-1:0]    rf_bignum_wr_data_no_intg_o,
  output logic [ExtWLEN-1:0] rf_bignum_wr_data_intg_o,
  output logic               rf_bignum_wr_data_intg_sel_o,

  output logic [4:0]         rf_bignum_rd_addr_a_o,
  output logic               rf_bignum_rd_en_a_o,
  input  logic [ExtWLEN-1:0] rf_bignum_rd_data_a_intg_i,

  output logic [4:0]         rf_bignum_rd_addr_b_o,
  output logic               rf_bignum_rd_en_b_o,
  input  logic [ExtWLEN-1:0] rf_bignum_rd_data_b_intg_i,

  input logic rf_bignum_intg_err_i,
  input logic rf_bignum_spurious_we_err_i,

  output logic [NWdr-1:0] rf_bignum_rd_a_indirect_onehot_o,
  output logic [NWdr-1:0] rf_bignum_rd_b_indirect_onehot_o,
  output logic [NWdr-1:0] rf_bignum_wr_indirect_onehot_o,
  output logic            rf_bignum_indirect_en_o,

  // Execution units

  // Base ALU
  output alu_base_operation_t  alu_base_operation_o,
  output alu_base_comparison_t alu_base_comparison_o,
  input  logic [31:0]          alu_base_operation_result_i,
  input  logic                 alu_base_comparison_result_i,

  // Bignum ALU
  output alu_bignum_operation_t alu_bignum_operation_o,
  output logic                  alu_bignum_operation_valid_o,
  output logic                  alu_bignum_operation_commit_o,
  input  logic [WLEN-1:0]       alu_bignum_operation_result_i,
  input  logic                  alu_bignum_selection_flag_i,

  // Bignum MAC
  output mac_bignum_operation_t mac_bignum_operation_o,
  input  logic [WLEN-1:0]       mac_bignum_operation_result_i,
  output logic                  mac_bignum_en_o,
  output logic                  mac_bignum_commit_o,

  // LSU
  output logic                     lsu_load_req_o,
  output logic                     lsu_store_req_o,
  output insn_subset_e             lsu_req_subset_o,
  output logic [DmemAddrWidth-1:0] lsu_addr_o,
  input  logic                     lsu_addr_en_predec_i,

  output logic [BaseIntgWidth-1:0] lsu_base_wdata_o,
  output logic [ExtWLEN-1:0]       lsu_bignum_wdata_o,

  input  logic [BaseIntgWidth-1:0] lsu_base_rdata_i,
  input  logic [ExtWLEN-1:0]       lsu_bignum_rdata_i,

  // Internal Special-Purpose Registers (ISPRs)
  output ispr_e                       ispr_addr_o,
  output logic [31:0]                 ispr_base_wdata_o,
  output logic [BaseWordsPerWLEN-1:0] ispr_base_wr_en_o,
  output logic [ExtWLEN-1:0]          ispr_bignum_wdata_intg_o,
  output logic                        ispr_bignum_wr_en_o,
  output logic [NFlagGroups-1:0]      ispr_flags_wr_o,
  output logic                        ispr_wr_commit_o,
  input  logic [ExtWLEN-1:0]          ispr_rdata_intg_i,
  output logic                        ispr_rd_en_o,

  // RND interface
  output logic rnd_req_o,
  output logic rnd_prefetch_req_o,
  input  logic rnd_valid_i,

  input  logic urnd_reseed_err_i,

  // Secure Wipe
  output logic secure_wipe_req_o,
  input  logic secure_wipe_ack_i,
  input  logic sec_wipe_zero_i,
  input  logic secure_wipe_running_i,
  input  logic sec_wipe_err_i,

  input  logic        state_reset_i,
  output logic [31:0] insn_cnt_o,
  input  logic        insn_cnt_clear_ext_i,
  input  logic        insn_cnt_clear_int_i,
  output logic        mems_sec_wipe_o,

  input  logic        software_errs_fatal_i,

  input logic [1:0] sideload_key_shares_valid_i,

  // Prefetch stage control
  output logic                     prefetch_en_o,
  output logic                     prefetch_loop_active_o,
  output logic [31:0]              prefetch_loop_iterations_o,
  output logic [ImemAddrWidth:0]   prefetch_loop_end_addr_o,
  output logic [ImemAddrWidth-1:0] prefetch_loop_jump_addr_o,
  output logic                     prefetch_ignore_errs_o,

  // Predecoded control
  input  ctrl_flow_predec_t        ctrl_flow_predec_i,
  input  logic [ImemAddrWidth-1:0] ctrl_flow_target_predec_i,
  output logic                     predec_error_o
);
  import prim_mubi_pkg::*;

  otbn_state_e state_q, state_d;


  controller_err_bits_t err_bits_q, err_bits_d;

  // The specific error signals that go into err_bits_d
  logic fatal_software_err, bad_internal_state_err, reg_intg_violation_err, key_invalid_err;
  logic illegal_insn_err, bad_data_addr_err, call_stack_sw_err, bad_insn_addr_err;

  logic err;
  logic internal_err;
  logic recoverable_err;
  logic software_err;
  logic non_insn_addr_software_err;
  logic fatal_err;
  logic internal_fatal_err;
  logic done_complete;
  logic executing;
  logic state_error, state_error_d, state_error_q;
  logic spurious_secure_wipe_ack_q, spurious_secure_wipe_ack_d;
  logic sec_wipe_err_q, sec_wipe_err_d;
  logic mubi_err_q, mubi_err_d;

  logic                     insn_fetch_req_valid_raw;
  logic [ImemAddrWidth-1:0] insn_fetch_req_addr_last;

  logic stall;
  logic ispr_stall;
  logic mem_stall;
  logic rf_indirect_stall;
  logic jump_or_branch;
  logic branch_taken;
  logic insn_executing;
  logic ld_insn_with_addr_from_call_stack, st_insn_with_addr_from_call_stack;
  logic [ImemAddrWidth-1:0] branch_target;
  logic                     branch_target_overflow;
  logic [ImemAddrWidth:0]   next_insn_addr_wide;
  logic [ImemAddrWidth-1:0] next_insn_addr;

  csr_e                                csr_addr;
  logic [$clog2(BaseWordsPerWLEN)-1:0] csr_sub_addr;
  logic [31:0]                         csr_rdata_raw;
  logic [31:0]                         csr_rdata;
  logic [BaseWordsPerWLEN-1:0]         csr_rdata_mux [32];
  logic [31:0]                         csr_wdata_raw;
  logic [31:0]                         csr_wdata;

  wsr_e                                wsr_addr;
  logic [WLEN-1:0]                     wsr_wdata;

  ispr_e                               ispr_addr_base;
  logic [$clog2(BaseWordsPerWLEN)-1:0] ispr_word_addr_base;
  logic [BaseWordsPerWLEN-1:0]         ispr_word_sel_base;

  ispr_e                               ispr_addr_bignum;

  logic                                ispr_wr_insn, ispr_rd_insn;
  logic                                ispr_wr_base_insn;
  logic                                ispr_wr_bignum_insn;
  logic                                ispr_rd_bignum_insn;

  logic                     lsu_load_req_raw;
  logic                     lsu_store_req_raw;
  logic [DmemAddrWidth-1:0] lsu_addr, lsu_addr_blanked, lsu_addr_saved_d, lsu_addr_saved_q;
  logic                     lsu_addr_saved_sel;
  logic                     expected_lsu_addr_en;

  logic                     expected_call_stack_push, expected_call_stack_pop;
  logic                     lsu_predec_error, branch_target_predec_error, ctrl_predec_error;

  logic rnd_req_raw;

  // Register read data with integrity stripped off
  logic [31:0]     rf_base_rd_data_a_no_intg;
  logic [31:0]     rf_base_rd_data_b_no_intg;
  logic [WLEN-1:0] rf_bignum_rd_data_a_no_intg;
  logic [WLEN-1:0] rf_bignum_rd_data_b_no_intg;

  logic [ExtWLEN-1:0] rf_bignum_rd_data_b_intg_blanked;
  logic [ExtWLEN-1:0] selection_result;

  logic [1:0] rf_bignum_wr_en_unbuf;
  logic [4:0] rf_bignum_wr_addr_unbuf;
  logic [4:0] rf_bignum_rd_addr_a_unbuf;
  logic       rf_bignum_rd_en_a_unbuf;
  logic [4:0] rf_bignum_rd_addr_b_unbuf;
  logic       rf_bignum_rd_en_b_unbuf;

  logic rf_bignum_rd_a_indirect_en;
  logic rf_bignum_rd_b_indirect_en;
  logic rf_bignum_wr_indirect_en;

  // Computed increments for indirect register index and memory address in BN.LID/BN.SID/BN.MOVR
  // instructions.
  logic [5:0]  rf_base_rd_data_a_inc;
  logic [5:0]  rf_base_rd_data_b_inc;
  logic [26:0] rf_base_rd_data_a_wlen_word_inc;

  // Read/Write enables for base register file before illegal instruction encoding are factored in
  logic rf_base_rd_en_a_raw, rf_base_rd_en_b_raw, rf_base_wr_en_raw;

  // Output of mux taking the above increments as inputs and choosing one to write back to base
  // register file with appropriate zero extension and padding to give a 32-bit result.
  logic [31:0]              increment_out;

  // Loop control, used to start a new loop
  logic        loop_start_req;
  logic        loop_start_commit;
  logic        loop_reset;
  logic [11:0] loop_bodysize;
  logic [31:0] loop_iterations;

  // Loop generated jumps. The loop controller asks to jump when execution reaches the end of a loop
  // body that hasn't completed all of its iterations.
  logic                     loop_jump;
  logic [ImemAddrWidth-1:0] loop_jump_addr;

  logic [WLEN-1:0] mac_bignum_rf_wr_data;

  logic loop_hw_err, loop_predec_err;
  logic csr_illegal_addr, wsr_illegal_addr, ispr_illegal_addr;
  logic imem_addr_err, loop_sw_err, ispr_err;
  logic dmem_addr_err_check, dmem_addr_err;
  logic dmem_addr_unaligned_base, dmem_addr_unaligned_bignum, dmem_addr_overflow;
  logic illegal_insn_static;
  logic key_invalid;

  logic rf_a_indirect_err, rf_b_indirect_err, rf_d_indirect_err, rf_indirect_err;

  // If we are doing an indirect access to the bignum register file, it's possible that the
  // address that we use for the access is architecturally unknown. This happens if it came from x1
  // and we've underflowed the call stack. When this happens, we want to ignore any read data
  // integrity errors and spurious write enable errors since the access to the bignum register file
  // didn't happen architecturally anyway.
  logic ignore_rf_bignum_intg_errs;
  logic rf_bignum_intg_err;
  logic ignore_rf_bignum_spurious_we_errs;
  logic rf_bignum_spurious_we_err;

  logic ispr_rdata_intg_err;

  logic [31:0] insn_cnt_d, insn_cnt_q;
  logic        insn_cnt_clear;

  logic [4:0] insn_bignum_rd_addr_a_q, insn_bignum_rd_addr_b_q, insn_bignum_wr_addr_q;

  logic       start_secure_wipe;
  logic       secure_wipe_running_q, secure_wipe_running_d;

  assign secure_wipe_running_d = start_secure_wipe | (secure_wipe_running_q & ~secure_wipe_ack_i);

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      secure_wipe_running_q <= 1'b0;
    end else begin
      secure_wipe_running_q <= secure_wipe_running_d;
    end
  end
  assign secure_wipe_req_o = start_secure_wipe | secure_wipe_running_q; 

  // Spot spurious acks on the secure wipe interface. There is a an ack at the end of the initial
  // secure wipe, and as `secure_wipe_running_q` is only high during secure wipes triggered by this
  // controller, we have to ignore acks before the initial secure wipe is done.  Register this
  // signal to break a circular path (a secure wipe can be triggered by a stop, and a spurious
  // secure wipe ack can trigger a stop).
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      spurious_secure_wipe_ack_q <= 1'b0;
    end else begin
      spurious_secure_wipe_ack_q <= spurious_secure_wipe_ack_d;
    end
  end
  assign spurious_secure_wipe_ack_d = spurious_secure_wipe_ack_q |
                                      (secure_wipe_ack_i      &
                                       ~secure_wipe_running_q &
                                       ~secure_wipe_running_i);

  // Detect and latch unexpected secure wipe signals.
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      sec_wipe_err_q <= 1'b0;
    end else begin
      sec_wipe_err_q <= sec_wipe_err_d;
    end
  end
  assign sec_wipe_err_d = sec_wipe_err_q |
                          sec_wipe_err_i |
                          (sec_wipe_zero_i & ~secure_wipe_running_i);

  // Stall a cycle on loads to allow load data writeback to happen the following cycle. Stall not
  // required on stores as there is no response to deal with.
  assign mem_stall = lsu_load_req_raw;

  // Reads to RND must stall until data is available
  assign ispr_stall = rnd_req_raw & ~rnd_valid_i;

  assign rf_indirect_stall = insn_valid_i &
                             (state_q != OtbnStateStall) &
                             (insn_dec_shared_i.subset == InsnSubsetBignum) &
                             (insn_dec_bignum_i.rf_a_indirect |
                              insn_dec_bignum_i.rf_b_indirect |
                              insn_dec_bignum_i.rf_d_indirect);

  assign stall = mem_stall | ispr_stall | rf_indirect_stall;

  // OTBN is done when it was executing something (in state OtbnStateRun or OtbnStateStall)
  // and either it executes an ecall or an error occurs. A pulse on the done signal raises the
  // 'done' interrupt and also tells the top-level to update its ERR_BITS status
  // register. The calculation that ecall triggered done is factored out as `done_complete` to
  // avoid logic loops in the error handling logic.
  assign done_complete = (insn_valid_i & insn_dec_shared_i.ecall_insn);
  assign executing = (state_q == OtbnStateRun) ||
                     (state_q == OtbnStateStall);

  // Set the *locking* output when the next state is the *locked* state and no secure wipe is
  // running or there is a URND reseed error.  `locking_o` is thus set only after the secure wipe
  // has completed or if it cannot complete due to an URND reseed error (in which case
  // `secure_wipe_req_o` and `urnd_reseed_err_i` will remain high).  The condition for secure wipe
  // running involves `secure_wipe_running_i`, which is high for the initial secure wipe, and
  // `secure_wipe_req_o`, which is high for post-execution secure wipes.
  assign locking_o = (state_d == OtbnStateLocked) & (~(secure_wipe_running_i | secure_wipe_req_o) |
                                                     urnd_reseed_err_i | mubi_err_d);

  assign start_secure_wipe = executing & (done_complete | err);

  assign jump_or_branch = (insn_valid_i &
                           (insn_dec_shared_i.branch_insn | insn_dec_shared_i.jump_insn));

  // Branch taken when there is a valid branch instruction and comparison passes or a valid jump
  // instruction (which is always taken)
  assign branch_taken = insn_valid_i &
                        ((insn_dec_shared_i.branch_insn & alu_base_comparison_result_i) |
                         insn_dec_shared_i.jump_insn);
  // Branch target computed by base ALU (PC + imm)
  assign branch_target = alu_base_operation_result_i[ImemAddrWidth-1:0];
  assign branch_target_overflow = |alu_base_operation_result_i[31:ImemAddrWidth];

  assign next_insn_addr_wide = {1'b0, insn_addr_i} + 'd4;
  assign next_insn_addr = next_insn_addr_wide[ImemAddrWidth-1:0];

  // Record address for fetch request so it can be retried when an invalid response is received
  always_ff @(posedge clk_i) begin
    if (insn_fetch_req_valid_raw) begin
      insn_fetch_req_addr_last <= insn_fetch_req_addr_o;
    end
  end

  always_comb begin
    state_d                  = state_q;
    // `insn_fetch_req_valid_raw` is the value `insn_fetch_req_valid_o` before any errors are
    // considered.
    insn_fetch_req_valid_raw = 1'b0;
    insn_fetch_req_addr_o    = '0;
    insn_fetch_resp_clear_o  = 1'b1;
    prefetch_en_o            = 1'b0;

    state_error = 1'b0;

    unique case (state_q)
      OtbnStateHalt: begin
        if (start_i) begin
          state_d = OtbnStateRun;

          insn_fetch_req_addr_o    = '0;
          insn_fetch_req_valid_raw = 1'b1;
          prefetch_en_o            = 1'b1;
        end
      end
      OtbnStateRun: begin
        insn_fetch_req_valid_raw = 1'b1;
        prefetch_en_o            = 1'b1;

        if (!insn_valid_i) begin
          insn_fetch_req_addr_o = insn_fetch_req_addr_last;
        end else if (done_complete) begin
          state_d                  = OtbnStateHalt;
          insn_fetch_req_valid_raw = 1'b0;
          prefetch_en_o            = 1'b0;
        end else begin
          if (stall) begin
            // When stalling don't request a new fetch and don't clear response either to keep
            // current instruction.
            state_d                  = OtbnStateStall;
            insn_fetch_req_valid_raw = 1'b0;
            insn_fetch_resp_clear_o  = 1'b0;
          end else begin
            if (branch_taken) begin
              insn_fetch_req_addr_o = branch_target;
            end else if (loop_jump) begin
              insn_fetch_req_addr_o = loop_jump_addr;
            end else begin
              insn_fetch_req_addr_o = next_insn_addr;
            end
          end
        end
      end
      OtbnStateStall: begin
        prefetch_en_o = 1'b1;
        // When stalling refetch the same instruction to keep decode inputs constant
        if (stall) begin
          state_d                  = OtbnStateStall;
          //insn_fetch_req_addr_o = insn_addr_i;
          insn_fetch_req_valid_raw = 1'b0;
          insn_fetch_resp_clear_o  = 1'b0;
        end else begin
          insn_fetch_req_valid_raw = 1'b1;

          if (loop_jump) begin
            insn_fetch_req_addr_o = loop_jump_addr;
          end else begin
            insn_fetch_req_addr_o = next_insn_addr;
          end

          state_d = OtbnStateRun;
        end
      end
      OtbnStateLocked: begin
        insn_fetch_req_valid_raw = 1'b0;
        state_d                  = OtbnStateLocked;
      end
      default: begin
        // We should never get here. If we do (e.g. via a malicious glitch), error out immediately.
        // SEC_CM: CONTROLLER.FSM.LOCAL_ESC
        state_d = OtbnStateLocked;
        state_error = 1'b1;
      end
    endcase

    // On any error immediately halt, either going to OtbnStateLocked or OtbnStateHalt depending on
    // whether it was a fatal error.
    if (err) begin
      insn_fetch_resp_clear_o = 1'b1;

      if (fatal_err) begin
        // SEC_CM: CONTROLLER.FSM.GLOBAL_ESC
        state_d = OtbnStateLocked;
      end else begin
        state_d = OtbnStateHalt;
      end
    end

    // Regardless of what happens above enforce staying in OtnbStateLocked.
    if (state_q == OtbnStateLocked) begin
      state_d = OtbnStateLocked;
    end
  end

  assign state_error_d = state_error | state_error_q;

  prim_flop #(
    .Width(1),
    .ResetValue('0)
  ) u_state_error_flop (
    .clk_i,
    .rst_ni,

    .d_i(state_error_d),
    .q_o(state_error_q)
  );

  `ASSERT(InsnAlwaysValidInStall, state_q == OtbnStateStall |-> insn_valid_i)

  // Anything that moves us or keeps us in the stall state should cause `stall` to be asserted
  `ASSERT(StallIfNextStateStall, insn_valid_i & (state_d == OtbnStateStall) |-> stall)

  // The raw signal is needed by the instruction fetch stage for generating instruction address
  // errors (where instruction fetch and prefetch disagree on address). `err` will factor this in so
  // using the qualified signal results in a combinational loop.
  assign insn_fetch_req_valid_raw_o = insn_fetch_req_valid_raw;
  assign insn_fetch_req_valid_o     = err ? 1'b0 : insn_fetch_req_valid_raw;

  // Determine if there are any errors related to the Imem fetch address.
  always_comb begin
    imem_addr_err = 1'b0;

    if (insn_fetch_req_valid_raw) begin
      if (|insn_fetch_req_addr_o[1:0]) begin
        // Imem address is unaligned
        imem_addr_err = 1'b1;
      end else if (branch_taken) begin
        imem_addr_err = branch_target_overflow;
      end else begin
        imem_addr_err = next_insn_addr_wide[ImemAddrWidth] & insn_valid_i;
      end
    end
  end

  // Signal error if MuBi input signals take on invalid values as this means something bad is
  // happening. Register the error signal to break circular paths (instruction fetch errors factor
  // into fatal_escalate_en_i, RND errors factor into recov_escalate_en_i).
  assign mubi_err_d = |{mubi4_test_invalid(fatal_escalate_en_i),
                        mubi4_test_invalid(recov_escalate_en_i),
                        mubi_err_q};
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      mubi_err_q <= 1'b0;
    end else begin
      mubi_err_q <= mubi_err_d;
    end
  end

  // Instruction is illegal based on the static properties of the instruction bits (illegal encoding
  // or illegal WSR/CSR referenced).
  assign illegal_insn_static = insn_illegal_i | ispr_err;

  assign fatal_software_err       = software_err & software_errs_fatal_i;
  assign bad_internal_state_err   = |{state_error_d, loop_hw_err, rf_base_call_stack_hw_err_i,
                                      rf_bignum_spurious_we_err, spurious_secure_wipe_ack_q,
                                      sec_wipe_err_q, mubi_err_q};
  assign reg_intg_violation_err   = rf_bignum_intg_err | ispr_rdata_intg_err;
  assign key_invalid_err          = ispr_rd_bignum_insn & insn_valid_i & key_invalid;
  assign illegal_insn_err         = illegal_insn_static | rf_indirect_err;
  assign call_stack_sw_err        = rf_base_call_stack_sw_err_i;

  // Flag a bad data address error if the data memory address is invalid and it does not come from
  // an empty call stack.  The second case cannot be decided as bad data address because the address
  // on top of the empty call stack may or may not be valid.  (Also, in most RTL simulators an empty
  // call stack that has never been pushed contains an unknown value, so this error bit would become
  // unknown.)  Thus, a data memory address coming from an empty call stack raises a call stack
  // error but never a bad data address error.
  assign bad_data_addr_err = dmem_addr_err &
                             ~(call_stack_sw_err &
                               (ld_insn_with_addr_from_call_stack |
                                st_insn_with_addr_from_call_stack));

  // Identify load instructions that take the memory address from the call stack.
  assign ld_insn_with_addr_from_call_stack = insn_valid_i               &
                                             insn_dec_shared_i.ld_insn  &
                                             insn_dec_base_i.rf_ren_a   &
                                             (insn_dec_base_i.a == 5'd1);

  // Identify store instructions that take the memory address from the call stack.
  assign st_insn_with_addr_from_call_stack = insn_valid_i               &
                                             insn_dec_shared_i.st_insn  &
                                             insn_dec_base_i.rf_ren_a   &
                                             (insn_dec_base_i.a == 5'd1);

  // All software errors that aren't bad_insn_addr. Factored into bad_insn_addr so it is only raised
  // if other software errors haven't ocurred. As bad_insn_addr relates to the next instruction
  // begin fetched it cannot occur if the current instruction has seen an error and failed to
  // execute.
  assign non_insn_addr_software_err = |{key_invalid_err,
                                        loop_sw_err,
                                        illegal_insn_err,
                                        call_stack_sw_err,
                                        bad_data_addr_err};

  assign bad_insn_addr_err = imem_addr_err & ~non_insn_addr_software_err;

  assign err_bits_d = '{
    fatal_software:     fatal_software_err,
    bad_internal_state: bad_internal_state_err,
    reg_intg_violation: reg_intg_violation_err,
    key_invalid:        key_invalid_err,
    loop:               loop_sw_err,
    illegal_insn:       illegal_insn_err,
    call_stack:         call_stack_sw_err,
    bad_data_addr:      bad_data_addr_err,
    bad_insn_addr:      bad_insn_addr_err
  };

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      err_bits_q <= '0;
    end else begin
      if (err_bit_clear_i && !locking_o) begin
        err_bits_q <= '0;
      end else begin
        err_bits_q <= err_bits_q | err_bits_d;
      end
    end
  end
  assign err_bits_o = err_bits_q;

  assign software_err = non_insn_addr_software_err | bad_insn_addr_err;

  assign recoverable_err = mubi4_test_true_loose(recov_escalate_en_i);

  assign internal_fatal_err = |{fatal_software_err,
                                bad_internal_state_err,
                                reg_intg_violation_err};

  // In case of an RMA request, just lock up the controller. This triggers the rotation of the
  // scrambling keys. The start/stop controller takes care of initiating the internal secure wipe
  // and eventually acknowledging the RMA request.
  assign fatal_err = |{internal_fatal_err,
                       mubi4_test_true_loose(fatal_escalate_en_i),
                       mubi4_test_true_strict(rma_req_i)};

  assign recoverable_err_o = recoverable_err | (software_err & ~software_errs_fatal_i);
  assign mems_sec_wipe_o   = (state_d == OtbnStateLocked) & (state_q != OtbnStateLocked);

  assign internal_err = software_err | internal_fatal_err;
  assign err          = software_err | recoverable_err | fatal_err;

  assign prefetch_ignore_errs_o = internal_err;

  // Instructions must not execute if there is an error
  assign insn_executing = insn_valid_i & ~err;

  `ASSERT(ErrBitSetOnErr,
      err & (mubi4_test_false_strict(fatal_escalate_en_i) &
             mubi4_test_false_strict(recov_escalate_en_i) &
             mubi4_test_false_loose(rma_req_i)) |=>
          err_bits_o)
  `ASSERT(ErrSetOnFatalErr, fatal_err |-> err)
  `ASSERT(SoftwareErrIfNonInsnAddrSoftwareErr, non_insn_addr_software_err |-> software_err)

  `ASSERT(ControllerStateValid,
          state_q inside {OtbnStateHalt, OtbnStateRun, OtbnStateStall, OtbnStateLocked})
  // Branch only takes effect in OtbnStateRun so must not go into stall state for branch
  // instructions.
  `ASSERT(NoStallOnBranch,
      insn_valid_i & insn_dec_shared_i.branch_insn |-> state_q != OtbnStateStall)

  // SEC_CM: CONTROLLER.FSM.SPARSE
  `PRIM_FLOP_SPARSE_FSM(u_state_regs, state_d, state_q, otbn_state_e, OtbnStateHalt)

  // SEC_CM: CTRL_FLOW.COUNT
  // Two explicit clear controls, one comes from external to otbn_core and the other is generated
  // internally (by otbn_start_stop_control).
  assign insn_cnt_clear =
    (state_q == OtbnStateLocked) | insn_cnt_clear_ext_i | insn_cnt_clear_int_i;

  always_comb begin
    if (insn_cnt_clear) begin
      insn_cnt_d = 32'd0;
    end else if (insn_executing & ~stall & (insn_cnt_q != 32'hffffffff)) begin
      insn_cnt_d = insn_cnt_q + 32'd1;
    end else begin
      insn_cnt_d = insn_cnt_q;
    end
  end

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      insn_cnt_q <= 32'd0;
    end else begin
      insn_cnt_q <= insn_cnt_d;
    end
  end

  assign insn_cnt_o = insn_cnt_q;

  assign loop_reset = state_reset_i | sec_wipe_zero_i;

  otbn_loop_controller #(
    .ImemAddrWidth(ImemAddrWidth)
  ) u_otbn_loop_controller (
    .clk_i,
    .rst_ni,

    .state_reset_i(loop_reset),

    .insn_valid_i,
    .insn_addr_i,
    .next_insn_addr_i(next_insn_addr),

    .loop_start_req_i       (loop_start_req),
    .loop_start_commit_i    (loop_start_commit),
    .loop_bodysize_i        (loop_bodysize),
    .loop_iterations_i      (loop_iterations),
    .loop_end_addr_predec_i (ctrl_flow_target_predec_i),

    .loop_jump_o     (loop_jump),
    .loop_jump_addr_o(loop_jump_addr),

    .sw_err_o     (loop_sw_err),
    .hw_err_o     (loop_hw_err),
    .predec_err_o (loop_predec_err),

    .jump_or_branch_i(jump_or_branch),
    .otbn_stall_i    (stall),

    .prefetch_loop_active_o,
    .prefetch_loop_iterations_o,
    .prefetch_loop_end_addr_o,
    .prefetch_loop_jump_addr_o
  );

  // loop_start_req indicates the instruction wishes to start a loop, loop_start_commit confirms it
  // should occur.
  assign loop_start_req    = insn_valid_i & insn_dec_shared_i.loop_insn;
  assign loop_start_commit = insn_executing;
  assign loop_bodysize     = insn_dec_base_i.loop_bodysize;
  assign loop_iterations   = insn_dec_base_i.loop_immediate ? insn_dec_base_i.i :
                                                              rf_base_rd_data_a_no_intg;

  // Compute increments which can be optionally applied to indirect register accesses and memory
  // addresses in BN.LID/BN.SID/BN.MOVR instructions.
  assign rf_base_rd_data_a_inc           = rf_base_rd_data_a_no_intg[4:0] + 1'b1;
  assign rf_base_rd_data_b_inc           = rf_base_rd_data_b_no_intg[4:0] + 1'b1;
  // We can avoid a full 32-bit adder here because the offset is 32-bit aligned, so we know the
  // load/store address will only be valid if rf_base_rd_data_a_no_intg[4:0] is zero.
  assign rf_base_rd_data_a_wlen_word_inc = rf_base_rd_data_a_no_intg[31:5] + 27'h1;

  // Choose increment to write back to base register file, only one increment can be written as
  // there is only one write port. Note that where an instruction is incrementing the indirect
  // reference to its destination register (insn_dec_bignum_i.d_inc) that reference is read on the
  // B read port so the B increment is written back.
  always_comb begin
    unique case (1'b1)
      insn_dec_bignum_i.a_inc: begin
        increment_out = {26'b0, rf_base_rd_data_a_inc};
      end
      insn_dec_bignum_i.b_inc: begin
        increment_out = {26'b0, rf_base_rd_data_b_inc};
      end
      insn_dec_bignum_i.d_inc: begin
        increment_out = {26'b0, rf_base_rd_data_b_inc};
      end
      insn_dec_bignum_i.a_wlen_word_inc: begin
        increment_out = {rf_base_rd_data_a_wlen_word_inc, 5'b0};
      end
      default: begin
        // Whenever increment_out is written back to the register file, exactly one of the
        // increment selector signals is high. To prevent the automatic inference of latches in
        // case nothing is written back (rf_wdata_sel != RfWdSelIncr) and to save logic, we choose
        // a valid output as default.
        increment_out = {26'b0, rf_base_rd_data_a_inc};
      end
    endcase
  end

  // Base RF read/write address, enable and commit control
  always_comb begin
    rf_base_rd_addr_a_o = insn_dec_base_i.a;
    rf_base_rd_addr_b_o = insn_dec_base_i.b;
    rf_base_wr_addr_o   = insn_dec_base_i.d;

    // Only commit read or write if the instruction is executing (in particular a read commit pops
    // the call stack so must not occur where a valid instruction sees an error and doesn't
    // execute).
    rf_base_rd_commit_o = insn_executing;
    rf_base_wr_commit_o = insn_executing;

    rf_base_rd_en_a_raw = 1'b0;
    rf_base_rd_en_b_raw = 1'b0;
    rf_base_wr_en_raw   = 1'b0;

    if (insn_valid_i) begin
      if (insn_dec_shared_i.st_insn) begin
        // For stores, both base reads happen in the first cycle of the store instruction. For base
        // stores this is the same cycle as the request. For bignum stores this is the cycle before
        // the request (as the indirect register read to get the store data occurs the following
        // cycle).
        rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a &
          (rf_indirect_stall | (insn_dec_shared_i.subset == InsnSubsetBase));
        rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b &
          (rf_indirect_stall | (insn_dec_shared_i.subset == InsnSubsetBase));

        // Bignum stores can update the base register file where an increment is used.
        rf_base_wr_en_raw   = (insn_dec_shared_i.subset == InsnSubsetBignum) &
                              insn_dec_base_i.rf_we                          &
                              rf_indirect_stall;
      end else if (insn_dec_shared_i.ld_insn) begin
        // For loads, both base reads happen in the same cycle as the request. The address is
        // required for the request and the indirect destination register (only used for Bignum
        // loads) is flopped in ld_insn_bignum_wr_addr_q to correctly deal with the case where it's
        // updated by an increment.
        rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & lsu_load_req_raw;
        rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & lsu_load_req_raw;

        if (insn_dec_shared_i.subset == InsnSubsetBignum) begin
          // Bignum loads can update the base register file where an increment is used. This must
          // always happen in the same cycle as the request as this is where both registers are
          // read.
          rf_base_wr_en_raw = insn_dec_base_i.rf_we & lsu_load_req_raw & rf_indirect_stall;
        end else begin
          // For Base loads write the base register file when the instruction is unstalled (meaning
          // the load data is available).
          rf_base_wr_en_raw = insn_dec_base_i.rf_we & ~stall;
        end
      end else if (insn_dec_bignum_i.rf_wdata_sel == RfWdSelMovSel) begin
        // For MOVR base register reads occur in the first cycle of the instruction. The indirect
        // register read for the bignum data occurs in the following cycle.
        rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & rf_indirect_stall;
        rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & rf_indirect_stall;
        rf_base_wr_en_raw   = insn_dec_base_i.rf_we    & rf_indirect_stall;
      end else begin
        // For all other instructions the read and write happen when the instruction is unstalled.
        rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & ~stall;
        rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & ~stall;
        rf_base_wr_en_raw   = insn_dec_base_i.rf_we    & ~stall;
      end
    end

    if (insn_dec_shared_i.subset == InsnSubsetBignum) begin
      unique case (1'b1)
        insn_dec_bignum_i.a_inc,
        insn_dec_bignum_i.a_wlen_word_inc: begin
          rf_base_wr_addr_o = insn_dec_base_i.a;
        end

        insn_dec_bignum_i.b_inc,
        insn_dec_bignum_i.d_inc: begin
          rf_base_wr_addr_o = insn_dec_base_i.b;
        end
        default: ;
      endcase
    end

    rf_base_rd_en_a_o = rf_base_rd_en_a_raw & ~illegal_insn_static;
    rf_base_rd_en_b_o = rf_base_rd_en_b_raw & ~illegal_insn_static;
    rf_base_wr_en_o   = rf_base_wr_en_raw   & ~illegal_insn_static;
  end

  // Base ALU Operand A MUX
  always_comb begin
    unique case (insn_dec_base_i.op_a_sel)
      OpASelRegister: alu_base_operation_o.operand_a = rf_base_rd_data_a_no_intg;
      OpASelZero:     alu_base_operation_o.operand_a = '0;
      OpASelCurrPc:   alu_base_operation_o.operand_a = {{(32 - ImemAddrWidth){1'b0}}, insn_addr_i};
      default:        alu_base_operation_o.operand_a = rf_base_rd_data_a_no_intg;
    endcase
  end

  // Base ALU Operand B MUX
  always_comb begin
    unique case (insn_dec_base_i.op_b_sel)
      OpBSelRegister:  alu_base_operation_o.operand_b = rf_base_rd_data_b_no_intg;
      OpBSelImmediate: alu_base_operation_o.operand_b = insn_dec_base_i.i;
      default:         alu_base_operation_o.operand_b = rf_base_rd_data_b_no_intg;
    endcase
  end

  assign alu_base_operation_o.op = insn_dec_base_i.alu_op;

  assign alu_base_comparison_o.operand_a = rf_base_rd_data_a_no_intg;
  assign alu_base_comparison_o.operand_b = rf_base_rd_data_b_no_intg;
  assign alu_base_comparison_o.op = insn_dec_base_i.comparison_op;

  assign rf_base_rd_data_a_no_intg = rf_base_rd_data_a_intg_i[31:0];
  assign rf_base_rd_data_b_no_intg = rf_base_rd_data_b_intg_i[31:0];

  logic unused_rf_base_rd_a_intg_bits;

  // TODO(#18266): Implement GPR to ISPR end to end integrity path (ISPR writes from GPR take data
  // from base RF port A)
  assign unused_rf_base_rd_a_intg_bits = |rf_base_rd_data_a_intg_i[38:32];

  // Base register file write MUX. Depending on the data source, integrity bits do or don't have to
  // be appended:
  // - Data sources that require appending integrity bits go into `rf_base_wr_data_no_intg_o` and
  //   `rf_base_wr_data_intg_sel_o` is low.
  // - Data sources that already come with integrity bits go into `rf_base_wr_data_intg_o` and
  //   `rf_base_wr_data_intg_sel_o` is high.
  always_comb begin
    // Default values
    rf_base_wr_data_no_intg_o  = alu_base_operation_result_i;
    rf_base_wr_data_intg_o     = '0;
    rf_base_wr_data_intg_sel_o = 1'b0;

    unique case (insn_dec_base_i.rf_wdata_sel)
      RfWdSelEx: begin
        rf_base_wr_data_no_intg_o  = alu_base_operation_result_i;
      end
      RfWdSelNextPc: begin
        rf_base_wr_data_no_intg_o  = {{(32-(ImemAddrWidth+1)){1'b0}}, next_insn_addr_wide};
      end
      RfWdSelIspr: begin
        rf_base_wr_data_no_intg_o  = csr_rdata;
      end
      RfWdSelIncr: begin
        rf_base_wr_data_no_intg_o  = increment_out;
      end
      RfWdSelLsu: begin
        rf_base_wr_data_intg_sel_o = 1'b1;
        rf_base_wr_data_intg_o     = lsu_base_rdata_i;
      end
      default: ;
    endcase
  end

  for (genvar i = 0; i < BaseWordsPerWLEN; ++i) begin : g_rf_bignum_rd_data
    assign rf_bignum_rd_data_a_no_intg[i*32+:32] = rf_bignum_rd_data_a_intg_i[i*39+:32];
    assign rf_bignum_rd_data_b_no_intg[i*32+:32] = rf_bignum_rd_data_b_intg_i[i*39+:32];
  end

  // Bignum RF control signals from the controller aren't actually used, instead the predecoded
  // one-hot versions are. The predecoded versions get checked against the signals produced here.
  // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
  // always be identical).
  assign rf_bignum_rd_addr_a_unbuf = insn_dec_bignum_i.rf_a_indirect ? insn_bignum_rd_addr_a_q :
                                                                       insn_dec_bignum_i.a;

  prim_buf #(
    .Width(WdrAw)
  ) u_rf_bignum_rd_addr_a_buf (
    .in_i (rf_bignum_rd_addr_a_unbuf),
    .out_o(rf_bignum_rd_addr_a_o)
  );

  assign rf_bignum_rd_en_a_unbuf = insn_dec_bignum_i.rf_ren_a & insn_valid_i & ~stall;

  prim_buf #(
    .Width(1)
  ) u_rf_bignum_rd_en_a_buf (
    .in_i (rf_bignum_rd_en_a_unbuf),
    .out_o(rf_bignum_rd_en_a_o)
  );

  assign rf_bignum_rd_addr_b_unbuf = insn_dec_bignum_i.rf_b_indirect ? insn_bignum_rd_addr_b_q :
                                                                       insn_dec_bignum_i.b;

  prim_buf #(
    .Width(WdrAw)
  ) u_rf_bignum_rd_addr_b_buf (
    .in_i (rf_bignum_rd_addr_b_unbuf),
    .out_o(rf_bignum_rd_addr_b_o)
  );

  assign rf_bignum_rd_en_b_unbuf = insn_dec_bignum_i.rf_ren_b & insn_valid_i & ~stall;

  prim_buf #(
    .Width(1)
  ) u_rf_bignum_rd_en_b_buf (
    .in_i (rf_bignum_rd_en_b_unbuf),
    .out_o(rf_bignum_rd_en_b_o)
  );

  assign alu_bignum_operation_o.operand_a = rf_bignum_rd_data_a_no_intg;

  // Base ALU Operand B MUX
  always_comb begin
    unique case (insn_dec_bignum_i.alu_op_b_sel)
      OpBSelRegister:  alu_bignum_operation_o.operand_b = rf_bignum_rd_data_b_no_intg;
      OpBSelImmediate: alu_bignum_operation_o.operand_b = insn_dec_bignum_i.i;
      default:         alu_bignum_operation_o.operand_b = rf_bignum_rd_data_b_no_intg;
    endcase
  end

  assign alu_bignum_operation_o.op          = insn_dec_bignum_i.alu_op;
  assign alu_bignum_operation_o.shift_right = insn_dec_bignum_i.alu_shift_right;
  assign alu_bignum_operation_o.shift_amt   = insn_dec_bignum_i.alu_shift_amt;
  assign alu_bignum_operation_o.flag_group  = insn_dec_bignum_i.alu_flag_group;
  assign alu_bignum_operation_o.sel_flag    = insn_dec_bignum_i.alu_sel_flag;
  assign alu_bignum_operation_o.alu_flag_en = insn_dec_bignum_i.alu_flag_en & insn_valid_i;
  assign alu_bignum_operation_o.mac_flag_en = insn_dec_bignum_i.mac_flag_en & insn_valid_i;

  assign alu_bignum_operation_valid_o  = insn_valid_i;
  assign alu_bignum_operation_commit_o = insn_executing;

  assign mac_bignum_operation_o.operand_a         = rf_bignum_rd_data_a_no_intg;
  assign mac_bignum_operation_o.operand_b         = rf_bignum_rd_data_b_no_intg;
  assign mac_bignum_operation_o.operand_a_qw_sel  = insn_dec_bignum_i.mac_op_a_qw_sel;
  assign mac_bignum_operation_o.operand_b_qw_sel  = insn_dec_bignum_i.mac_op_b_qw_sel;
  assign mac_bignum_operation_o.wr_hw_sel_upper   = insn_dec_bignum_i.mac_wr_hw_sel_upper;
  assign mac_bignum_operation_o.pre_acc_shift_imm = insn_dec_bignum_i.mac_pre_acc_shift;
  assign mac_bignum_operation_o.zero_acc          = insn_dec_bignum_i.mac_zero_acc;
  assign mac_bignum_operation_o.shift_acc         = insn_dec_bignum_i.mac_shift_out;

  assign mac_bignum_en_o     = insn_valid_i & insn_dec_bignum_i.mac_en;
  assign mac_bignum_commit_o = insn_executing;

  // Move / Conditional Select. Only select B register data when a selection instruction is being
  // executed and the selection flag isn't set. To avoid undesirable SCA leakage between the two
  // registers for non-selection instructions, the B register is blanked except for selection
  // instructions.
  // Note that blanking both registers is not feasible nor absolutely required because:
  // - The flag group selection and flag selection are known in the predecoder stage but the actual
  //   flag isn't.
  // - Selecting the flag in the predocder stage using combinatorial inputs may lead to SCA leakage
  //   between the still combinatorial flag groups and flags within a group which might be
  //   undesirable as well.
  // - When executing a selection instruction, programmers can expected that there will be some SCA
  //   leakage between the two options. But it may be much lesse expected for such leakage to occur
  //   for other instructions.
  `ASSERT(SelFlagValid, insn_valid_i & insn_dec_bignum_i.sel_insn |->
    insn_dec_bignum_i.alu_sel_flag inside {FlagC, FlagL, FlagM, FlagZ})

  // SEC_CM: DATA_REG_SW.SCA
  prim_blanker #(.Width(ExtWLEN)) u_rf_bignum_rd_data_b_intg_blanker (
    .in_i (rf_bignum_rd_data_b_intg_i),
    .en_i (ctrl_flow_predec_i.sel_insn),
    .out_o(rf_bignum_rd_data_b_intg_blanked)
  );

  `ASSERT(BlankingBignumRdDataBSel,
    ~(insn_valid_i & insn_dec_bignum_i.sel_insn) |-> rf_bignum_rd_data_b_intg_blanked == '0,
    clk_i, !rst_ni || ctrl_predec_error || !insn_executing)

  assign selection_result =
    ~ctrl_flow_predec_i.sel_insn | alu_bignum_selection_flag_i ? rf_bignum_rd_data_a_intg_i :
                                                                 rf_bignum_rd_data_b_intg_blanked;

  // Bignum Register file write control

  always_comb begin
    // By default write nothing
    rf_bignum_wr_en_unbuf = 2'b00;

    // Only write if valid instruction wants a bignum rf write and it isn't stalled. If instruction
    // doesn't execute (e.g. due to an error) the write won't commit.
    if (insn_valid_i && insn_dec_bignum_i.rf_we && !rf_indirect_stall) begin
      if (insn_dec_bignum_i.mac_en && insn_dec_bignum_i.mac_shift_out) begin
        // Special handling for BN.MULQACC.SO, only enable upper or lower half depending on
        // mac_wr_hw_sel_upper.
        rf_bignum_wr_en_unbuf = insn_dec_bignum_i.mac_wr_hw_sel_upper ? 2'b10 : 2'b01;
      end else begin
        // For everything else write both halves immediately.
        rf_bignum_wr_en_unbuf = 2'b11;
      end
    end
  end

  // Bignum RF control signals from the controller aren't actually used, instead the predecoded
  // one-hot versions are. The predecoded versions get checked against the signals produced here.
  // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
  // always be identical).
  prim_buf #(
    .Width(2)
  ) u_bignum_wr_en_buf (
    .in_i (rf_bignum_wr_en_unbuf),
    .out_o(rf_bignum_wr_en_o)
  );


  assign rf_bignum_wr_commit_o = |rf_bignum_wr_en_o & insn_executing & !stall;

  assign rf_bignum_indirect_en_o    = insn_executing & rf_indirect_stall;
  assign rf_bignum_rd_a_indirect_en = insn_executing & insn_dec_bignum_i.rf_a_indirect;
  assign rf_bignum_rd_b_indirect_en = insn_executing & insn_dec_bignum_i.rf_b_indirect;
  assign rf_bignum_wr_indirect_en   = insn_executing & insn_dec_bignum_i.rf_d_indirect;

  prim_onehot_enc #(
    .OneHotWidth(NWdr)
  ) rf_bignum_rd_a_idirect_onehot__enc (
    .in_i  (rf_base_rd_data_a_no_intg[4:0]),
    .en_i  (rf_bignum_rd_a_indirect_en),
    .out_o (rf_bignum_rd_a_indirect_onehot_o)
  );

  prim_onehot_enc #(
    .OneHotWidth(NWdr)
  ) rf_bignum_rd_b_indirect_onehot_enc (
    .in_i  (rf_base_rd_data_b_no_intg[4:0]),
    .en_i  (rf_bignum_rd_b_indirect_en),
    .out_o (rf_bignum_rd_b_indirect_onehot_o)
  );

  prim_onehot_enc #(
    .OneHotWidth(NWdr)
  ) rf_bignum_wr_indirect_onehot_enc (
    .in_i  (rf_base_rd_data_b_no_intg[4:0]),
    .en_i  (rf_bignum_wr_indirect_en),
    .out_o (rf_bignum_wr_indirect_onehot_o)
  );

  // For BN.LID sample the indirect destination register index in first cycle as an increment might
  // change it for the second cycle where the load data is written to the bignum register file.
  always_ff @(posedge clk_i) begin
    if (insn_dec_bignum_i.rf_d_indirect) begin
      insn_bignum_wr_addr_q <= rf_base_rd_data_b_no_intg[4:0];
    end

    if (insn_dec_bignum_i.rf_a_indirect) begin
      insn_bignum_rd_addr_a_q <= rf_base_rd_data_a_no_intg[4:0];
    end

    if (insn_dec_bignum_i.rf_b_indirect) begin
      insn_bignum_rd_addr_b_q <= rf_base_rd_data_b_no_intg[4:0];
    end
  end

  // Bignum RF control signals from the controller aren't actually used, instead the predecoded
  // one-hot versions are. The predecoded versions get checked against the signals produced here.
  // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
  // always be identical).
  assign rf_bignum_wr_addr_unbuf = insn_dec_bignum_i.rf_d_indirect ? insn_bignum_wr_addr_q :
                                                                     insn_dec_bignum_i.d;

  prim_buf #(
    .Width(WdrAw)
  ) u_rf_bignum_wr_addr_buf (
    .in_i (rf_bignum_wr_addr_unbuf),
    .out_o(rf_bignum_wr_addr_o)
  );

  // For the shift-out variant of BN.MULQACC the bottom half of the MAC result is written to one
  // half of a desintation register specified by the instruction (mac_wr_hw_sel_upper). The bottom
  // half of the MAC result must be placed in the appropriate half of the write data (the RF only
  // accepts write data for the top half in the top half of the write data input). Otherwise
  // (shift-out to bottom half and all other BN.MULQACC instructions) simply pass the MAC result
  // through unchanged as write data.
  assign mac_bignum_rf_wr_data[WLEN-1:WLEN/2] =
      insn_dec_bignum_i.mac_wr_hw_sel_upper &&
      insn_dec_bignum_i.mac_shift_out          ? mac_bignum_operation_result_i[WLEN/2-1:0] :
                                                 mac_bignum_operation_result_i[WLEN-1:WLEN/2];

  assign mac_bignum_rf_wr_data[WLEN/2-1:0] = mac_bignum_operation_result_i[WLEN/2-1:0];

  // Bignum register file write MUX. Depending on the data source, integrity bits do or don't have
  // to be appended; see comments on the "Base register file write MUX" for details.
  always_comb begin
    // Default values
    rf_bignum_wr_data_intg_sel_o = 1'b0;
    rf_bignum_wr_data_intg_o     = '0;
    rf_bignum_wr_data_no_intg_o  = alu_bignum_operation_result_i;

    unique case (insn_dec_bignum_i.rf_wdata_sel)
      RfWdSelEx: begin
        rf_bignum_wr_data_no_intg_o  = alu_bignum_operation_result_i;
      end
      RfWdSelMac: begin
        rf_bignum_wr_data_no_intg_o  = mac_bignum_rf_wr_data;
      end
      RfWdSelIspr: begin
        rf_bignum_wr_data_intg_sel_o = 1'b1;
        rf_bignum_wr_data_intg_o     = ispr_rdata_intg_i;
      end
      RfWdSelMovSel: begin
        rf_bignum_wr_data_intg_sel_o = 1'b1;
        rf_bignum_wr_data_intg_o     = selection_result;
      end
      RfWdSelLsu: begin
        rf_bignum_wr_data_intg_sel_o = 1'b1;
        //SEC_CM: BUS.INTEGRITY
        rf_bignum_wr_data_intg_o     = lsu_bignum_rdata_i;
      end
      default: ;
    endcase
  end

  assign rf_a_indirect_err = insn_dec_bignum_i.rf_a_indirect    &
                             (|rf_base_rd_data_a_no_intg[31:5]) &
                             ~rf_base_call_stack_sw_err_i       &
                             rf_base_rd_en_a_o;

  assign rf_b_indirect_err = insn_dec_bignum_i.rf_b_indirect    &
                             (|rf_base_rd_data_b_no_intg[31:5]) &
                             ~rf_base_call_stack_sw_err_i       &
                             rf_base_rd_en_b_o;

  assign rf_d_indirect_err = insn_dec_bignum_i.rf_d_indirect    &
                             (|rf_base_rd_data_b_no_intg[31:5]) &
                             ~rf_base_call_stack_sw_err_i       &
                             rf_base_rd_en_b_o;

  assign rf_indirect_err =
      insn_valid_i & (rf_a_indirect_err | rf_b_indirect_err | rf_d_indirect_err);


  // If the source registers are indirectly indexed and there is a stack error, the source
  // register indices were illegal due to a stack pop error. In this case, ignore bignum RF read
  // integrity errors.
  assign ignore_rf_bignum_intg_errs = (insn_dec_bignum_i.rf_a_indirect |
                                       insn_dec_bignum_i.rf_b_indirect) &
                                      rf_base_call_stack_sw_err_i;

  assign rf_bignum_intg_err = rf_bignum_intg_err_i & ~ignore_rf_bignum_intg_errs;

  // If the destination register is indirectly indexed and there is a stack error, the destination
  // register index was illegal due to a stack pop error. In this case, ignore bignum RF
  // write-enable errors.
  assign ignore_rf_bignum_spurious_we_errs = insn_dec_bignum_i.rf_d_indirect &
                                             rf_base_call_stack_sw_err_i;

  assign rf_bignum_spurious_we_err = rf_bignum_spurious_we_err_i &
                                     ~ignore_rf_bignum_spurious_we_errs;

  // CSR/WSR/ISPR handling
  // ISPRs (Internal Special Purpose Registers) are the internal registers. CSRs and WSRs are the
  // ISA visible versions of those registers in the base and bignum ISAs respectively.

  assign csr_addr     = csr_e'(insn_dec_base_i.i[11:0]);
  assign csr_sub_addr = insn_dec_base_i.i[$clog2(BaseWordsPerWLEN)-1:0];

  always_comb begin
    ispr_addr_base      = IsprMod;
    ispr_word_addr_base = '0;
    csr_illegal_addr    = 1'b0;

    unique case (csr_addr)
      CsrFlags, CsrFg0, CsrFg1: begin
        ispr_addr_base      = IsprFlags;
        ispr_word_addr_base = '0;
      end
      CsrMod0, CsrMod1, CsrMod2, CsrMod3, CsrMod4, CsrMod5, CsrMod6, CsrMod7: begin
        ispr_addr_base      = IsprMod;
        ispr_word_addr_base = csr_sub_addr;
      end
      CsrRndPrefetch: begin
        // Reading from RND_PREFETCH results in 0, there is no ISPR to read so no address is set.
        // The csr_rdata mux logic takes care of producing the 0.
      end
      CsrRnd: begin
        ispr_addr_base      = IsprRnd;
        ispr_word_addr_base = '0;
      end
      CsrUrnd: begin
        ispr_addr_base      = IsprUrnd;
        ispr_word_addr_base = '0;
      end
      default: csr_illegal_addr = 1'b1;
    endcase
  end

  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_word_sel_base
    assign ispr_word_sel_base[i_word] = ispr_word_addr_base == i_word;
  end

  // Decode wide ISPR read data.
  logic [WLEN-1:0]                ispr_rdata;
  logic [2*BaseWordsPerWLEN-1:0]  ispr_rdata_intg_err_wide;
  logic [BaseWordsPerWLEN-1:0]    ispr_rdata_intg_err_narrow;
  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_rdata_dec
    prim_secded_inv_39_32_dec i_secded_dec (
      .data_i     (ispr_rdata_intg_i[i_word*39+:39]),
      .data_o     (/* unused because we abort on any integrity error */),
      .syndrome_o (/* unused */),
      .err_o      (ispr_rdata_intg_err_wide[i_word*2+:2])
    );
    assign ispr_rdata[i_word*32+:32] = ispr_rdata_intg_i[i_word*39+:32];
    assign ispr_rdata_intg_err_narrow[i_word] = |(ispr_rdata_intg_err_wide[i_word*2+:2]);
  end

  // Propagate integrity error only if wide ISPR is used.

  // Handle ISPR integrity error detection. We've got a bitmask of ISPR words that failed their
  // integrity check (ispr_rdata_intg_err_narrow), but a nonzero entry may not be a problem if we
  // don't actually use the data.
  //
  // The situations when the data is actually used are:
  //
  //   (1) This is a bignum instruction that writes back to the bignum register file by reading an
  //       ISPR. In this case, we actually pass the data through with integrity bits, but it
  //       shouldn't hurt to add fault detection at this point.
  //
  //   (2) This instruction consumes the data by selecting a word from an ISPR and then writing it
  //       back. This happens for things like CSRRS instructions, where the data flows to the base
  //       register file through rf_base_wr_data_no_intg_o and back to the ISPR through
  //       ispr_base_wdata_o. The word used is given by the onehot ispr_word_sel_base mask.
  //
  // In both cases, there's a special case for the RND_PREFETCH register, which doesn't actually
  // have any backing data. It reads as zero with invalid integrity bits which we want to ignore.

  // Are we reading all the ISPR data? (case (1) above)
  logic all_ispr_words_used;
  assign all_ispr_words_used = (insn_dec_bignum_i.rf_wdata_sel == RfWdSelIspr);

  // Are we reading just one word of the ISPR data? (case (2) above).
  logic one_ispr_word_used;
  assign one_ispr_word_used = ispr_rd_insn & (insn_dec_shared_i.subset == InsnSubsetBase);

  // A bit-mask giving which ISPR words are being read
  logic [BaseWordsPerWLEN-1:0] ispr_read_mask;
  assign ispr_read_mask = all_ispr_words_used ? '1 :
                          one_ispr_word_used  ? ispr_word_sel_base : '0;

  // Use ispr_read_mask to qualify the error bit-mask that came out of the integrity decoder.
  logic [BaseWordsPerWLEN-1:0] ispr_rdata_used_intg_err;
  assign ispr_rdata_used_intg_err = ispr_read_mask & ispr_rdata_intg_err_narrow;

  // We only architecturally read the ISPR when there's a non-stalled instruction. This is also the
  // place where we factor in the special RND_PREFETCH behaviour. We also need to squash any
  // integrity errors if we're reading a sideload key which isn't currently valid (this will
  // generate a key_invalid error, but we shouldn't have any behaviour that depends on what happens
  // to be on the pins)
  logic non_prefetch_insn_running;
  assign non_prefetch_insn_running = (insn_valid_i & ~stall &
                                      (csr_addr != CsrRndPrefetch) & ~key_invalid);

  assign ispr_rdata_intg_err = non_prefetch_insn_running & |(ispr_rdata_used_intg_err);

  `ASSERT_KNOWN(IsprRdataIntgErrKnown_A, ispr_rdata_intg_err)

  for (genvar i_bit = 0; i_bit < 32; i_bit++) begin : g_csr_rdata_mux
    for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_csr_rdata_mux_inner
      assign csr_rdata_mux[i_bit][i_word] =
          ispr_rdata[i_word*32 + i_bit] & ispr_word_sel_base[i_word];
    end

    assign csr_rdata_raw[i_bit] = |csr_rdata_mux[i_bit];
  end

  // Specialised read data handling for CSR reads where raw read data needs modification.
  always_comb begin
    csr_rdata = csr_rdata_raw;

    unique case (csr_addr)
      // For FG0/FG1 select out appropriate bits from FLAGS ISPR and pad the rest with zeros.
      CsrFg0:         csr_rdata = {28'b0, csr_rdata_raw[3:0]};
      CsrFg1:         csr_rdata = {28'b0, csr_rdata_raw[7:4]};
      CsrRndPrefetch: csr_rdata = '0;
      default: ;
    endcase
  end

  assign csr_wdata_raw = insn_dec_shared_i.ispr_rs_insn ? csr_rdata | rf_base_rd_data_a_no_intg :
                                                          rf_base_rd_data_a_no_intg;

  // Specialised write data handling for CSR writes where raw write data needs modification.
  always_comb begin
    csr_wdata = csr_wdata_raw;

    unique case (csr_addr)
      // For FG0/FG1 only modify relevant part of FLAGS ISPR.
      CsrFg0: csr_wdata = {24'b0, csr_rdata_raw[7:4], csr_wdata_raw[3:0]};
      CsrFg1: csr_wdata = {24'b0, csr_wdata_raw[3:0], csr_rdata_raw[3:0]};
      default: ;
    endcase
  end

  // ISPR RS (read and set) must not be combined with ISPR RD or WR (read or write). ISPR RD and
  // WR (read and write) is allowed.
  `ASSERT(NoIsprRorWAndRs, insn_valid_i |-> ~(insn_dec_shared_i.ispr_rs_insn   &
                                              (insn_dec_shared_i.ispr_rd_insn |
                                               insn_dec_shared_i.ispr_wr_insn)))


  assign wsr_addr = wsr_e'(insn_dec_bignum_i.i[WsrNumWidth-1:0]);

  always_comb begin
    ispr_addr_bignum = IsprMod;
    wsr_illegal_addr = 1'b0;
    key_invalid      = 1'b0;

    unique case (wsr_addr)
      WsrMod:  ispr_addr_bignum = IsprMod;
      WsrRnd:  ispr_addr_bignum = IsprRnd;
      WsrUrnd: ispr_addr_bignum = IsprUrnd;
      WsrAcc:  ispr_addr_bignum = IsprAcc;
      WsrKeyS0L: begin
        ispr_addr_bignum = IsprKeyS0L;
        key_invalid = ~sideload_key_shares_valid_i[0];
      end
      WsrKeyS0H: begin
        ispr_addr_bignum = IsprKeyS0H;
        key_invalid = ~sideload_key_shares_valid_i[0];
      end
      WsrKeyS1L: begin
        ispr_addr_bignum = IsprKeyS1L;
        key_invalid = ~sideload_key_shares_valid_i[1];
      end
      WsrKeyS1H: begin
        ispr_addr_bignum = IsprKeyS1H;
        key_invalid = ~sideload_key_shares_valid_i[1];
      end
      default: wsr_illegal_addr = 1'b1;
    endcase
  end

  assign wsr_wdata = insn_dec_shared_i.ispr_rs_insn ? ispr_rdata | rf_bignum_rd_data_a_no_intg :
                                                      rf_bignum_rd_data_a_no_intg;

  assign ispr_illegal_addr = insn_dec_shared_i.subset == InsnSubsetBase ? csr_illegal_addr :
                                                                          wsr_illegal_addr;

  assign ispr_err = ispr_illegal_addr & insn_valid_i & (insn_dec_shared_i.ispr_rd_insn |
                                                        insn_dec_shared_i.ispr_wr_insn |
                                                        insn_dec_shared_i.ispr_rs_insn);

  assign ispr_wr_insn = insn_dec_shared_i.ispr_wr_insn | insn_dec_shared_i.ispr_rs_insn;
  assign ispr_rd_insn = insn_dec_shared_i.ispr_rd_insn | insn_dec_shared_i.ispr_rs_insn;

  assign ispr_flags_wr_o = insn_dec_shared_i.ispr_flags_wr;

  // Write to RND_PREFETCH must not produce ISR write
  assign ispr_wr_base_insn =
    ispr_wr_insn & (insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr != CsrRndPrefetch);

  assign ispr_wr_bignum_insn = ispr_wr_insn & (insn_dec_shared_i.subset == InsnSubsetBignum);
  assign ispr_rd_bignum_insn = ispr_rd_insn & (insn_dec_shared_i.subset == InsnSubsetBignum);

  assign ispr_addr_o         = insn_dec_shared_i.subset == InsnSubsetBase ? ispr_addr_base :
                                                                            ispr_addr_bignum;
  assign ispr_base_wdata_o   = csr_wdata;
  assign ispr_base_wr_en_o   = {BaseWordsPerWLEN{ispr_wr_base_insn & insn_valid_i}} &
                               ispr_word_sel_base;

  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_bignum_wdata_enc
    prim_secded_inv_39_32_enc i_secded_enc (
      .data_i(wsr_wdata[i_word*32+:32]),
      .data_o(ispr_bignum_wdata_intg_o[i_word*39+:39])
    );
  end
  assign ispr_bignum_wr_en_o = ispr_wr_bignum_insn & insn_valid_i;

  assign ispr_wr_commit_o = ispr_wr_insn & insn_executing; 
  
  assign ispr_rd_en_o     = ispr_rd_insn & insn_valid_i &
    ~((insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr == CsrRndPrefetch));

  // For BN.SID the LSU address is computed in the first cycle by the base ALU. The store request
  // itself occurs in the second cycle when the store data is available (from the indirect register
  // read). The calculated address is saved in a flop here so it's available for use in the second
  // cycle.
  assign lsu_addr_saved_d = alu_base_operation_result_i[DmemAddrWidth-1:0];
  always_ff @(posedge clk_i) begin
    lsu_addr_saved_q <= lsu_addr_saved_d;
  end

  //assign expected_lsu_addr_en_predec = insn_valid & insn_dec_shared_i.ld_insn

  // lsu_load_req_raw/lsu_store_req_raw indicate an instruction wishes to perform a store or a load.
  // lsu_load_req_o/lsu_store_req_o factor in whether an instruction is actually executing (it may
  // be suppressed due an error) and command the load or store to happen when asserted.
  assign lsu_load_req_raw = insn_valid_i & insn_dec_shared_i.ld_insn & (state_q == OtbnStateRun);
  assign lsu_load_req_o   = insn_executing & lsu_load_req_raw;

  assign lsu_store_req_raw = insn_valid_i & insn_dec_shared_i.st_insn & ~rf_indirect_stall;
  assign lsu_store_req_o   = insn_executing & lsu_store_req_raw;

  assign lsu_req_subset_o = insn_dec_shared_i.subset;

  // To simplify blanking logic all two cycle memory operations (BN.LID, BN.SID, LW) present the
  // calculated address in their first cycle and the saved address in the second cycle. This results
  // in lsu_addr_o remaining stable for the entire instruction. Only SW is a single cycle
  // instruction so it only presents the calculated address. The stability property is checked by an
  // assertion.
  assign lsu_addr_saved_sel =
    insn_valid_i & ((insn_dec_shared_i.subset == InsnSubsetBignum) ||
                    insn_dec_shared_i.ld_insn                         ? ~stall : 1'b0);

  assign lsu_addr = lsu_addr_saved_sel ? lsu_addr_saved_q                                :
                                         alu_base_operation_result_i[DmemAddrWidth-1:0];

  // SEC_CM: CTRL.REDUN
  assign expected_lsu_addr_en =
    insn_valid_i & (insn_dec_shared_i.ld_insn | insn_dec_shared_i.st_insn);

  assign lsu_predec_error = expected_lsu_addr_en != lsu_addr_en_predec_i;

  assign expected_call_stack_push =
    insn_valid_i & insn_dec_base_i.rf_we & rf_base_wr_addr_o == 5'd1;

  assign expected_call_stack_pop = insn_valid_i &
                                   ((insn_dec_base_i.rf_ren_a & rf_base_rd_addr_a_o == 5'd1) |
                                    (insn_dec_base_i.rf_ren_b & rf_base_rd_addr_b_o == 5'd1));

  // Check branch target against the precalculated target from pre-decode. Pre-decode cannot
  // calculate the jump target of a JALR as it requires a register read so this is excluded from the
  // check (by looking at the ALU op a selection).
  assign branch_target_predec_error =
    insn_dec_shared_i.branch_insn                                            &
    insn_dec_shared_i.jump_insn & insn_dec_base_i.op_a_sel != OpASelRegister &
    (ctrl_flow_target_predec_i != branch_target);

  assign ctrl_predec_error =
    |{ctrl_flow_predec_i.jump_insn       != (insn_dec_shared_i.jump_insn   & insn_valid_i),
      ctrl_flow_predec_i.loop_insn       != (insn_dec_shared_i.loop_insn   & insn_valid_i),
      ctrl_flow_predec_i.branch_insn     != (insn_dec_shared_i.branch_insn & insn_valid_i),
      ctrl_flow_predec_i.sel_insn        != (insn_dec_bignum_i.sel_insn    & insn_valid_i),
      ctrl_flow_predec_i.call_stack_push != expected_call_stack_push,
      ctrl_flow_predec_i.call_stack_pop  != expected_call_stack_pop,
      branch_target_predec_error,
      loop_predec_err};

  assign predec_error_o = lsu_predec_error | ctrl_predec_error;

  // SEC_CM: DATA_REG_SW.SCA
  prim_blanker #(.Width(DmemAddrWidth)) u_lsu_addr_blanker (
    .in_i (lsu_addr),
    .en_i (lsu_addr_en_predec_i),
    .out_o(lsu_addr_blanked)
  );

  // Check stability property described above (see the lsu_addr_saved_sel signal) holds.
  `ASSERT(LsuAddrBlankedStable_A, insn_valid_i & stall & ~err |=> $stable(lsu_addr_blanked))

  assign lsu_addr_o = lsu_addr_blanked; 

  assign lsu_base_wdata_o   = rf_base_rd_data_b_intg_i;
  assign lsu_bignum_wdata_o = rf_bignum_rd_data_b_intg_i;

  assign dmem_addr_unaligned_bignum =
      (lsu_req_subset_o == InsnSubsetBignum) & (|lsu_addr_o[$clog2(WLEN/8)-1:0]);
  assign dmem_addr_unaligned_base   =
      (lsu_req_subset_o == InsnSubsetBase)   & (|lsu_addr_o[1:0]);
  assign dmem_addr_overflow         = |alu_base_operation_result_i[31:DmemAddrWidth];

  // A dmem address is checked the cycle it is available. For bignum stores this is the first cycle
  // where the base register file read occurs, with the store request occurring the following cycle.
  // For all other loads and stores the dmem address is available the same cycle as the request.
  assign dmem_addr_err_check =
    (lsu_req_subset_o == InsnSubsetBignum) &
    insn_dec_shared_i.st_insn               ? rf_indirect_stall :
                                              lsu_load_req_raw | lsu_store_req_raw;

  assign dmem_addr_err =
      insn_valid_i & dmem_addr_err_check & (dmem_addr_overflow         |
                                            dmem_addr_unaligned_bignum |
                                            dmem_addr_unaligned_base);

  assign rnd_req_raw = insn_valid_i & ispr_rd_insn & (ispr_addr_o == IsprRnd);
  // Don't factor rnd_rep/fips_err_i into rnd_req_o. This would lead to a combo loop.
  assign rnd_req_o = rnd_req_raw & insn_valid_i & ~(software_err | fatal_err);

  assign rnd_prefetch_req_o = insn_executing & ispr_wr_insn &
      (insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr == CsrRndPrefetch);
endmodule

    '''

    Use the anomaly detector tool to identify lines in the design RTL that are anomalous.
    Then determine whether the identified anomalous line(s) represent a security issue or not.

    
================================== Ai Message ==================================
Tool Calls:
  anomaly_detector_tool (call_B6uhFZNcallc1Hw45FvGAIyG)
 Call ID: call_B6uhFZNcallc1Hw45FvGAIyG
  Args:
    design_filepath: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn_controller.sv
================================= Tool Message =================================
Name: anomaly_detector_tool

Successfully executed:
```LLM Anomaly Detector tool
```
Output:
Here are clusters of similar verilog constructs in the RTL file:



Cluster 0:
assign secure_wipe_running_d = start_secure_wipe | (secure_wipe_running_q & ~secure_wipe_ack_i);
assign secure_wipe_req_o = start_secure_wipe | secure_wipe_running_q;
assign spurious_secure_wipe_ack_d = spurious_secure_wipe_ack_q |
assign sec_wipe_err_d = sec_wipe_err_q |
assign locking_o = (state_d == OtbnStateLocked) & (~(secure_wipe_running_i | secure_wipe_req_o) |
assign start_secure_wipe = executing & (done_complete | err);
assign mems_sec_wipe_o   = (state_d == OtbnStateLocked) & (state_q != OtbnStateLocked);


Cluster 1:
assign mem_stall = lsu_load_req_raw;
assign ispr_stall = rnd_req_raw & ~rnd_valid_i;
assign rf_indirect_stall = insn_valid_i &
assign stall = mem_stall | ispr_stall | rf_indirect_stall;
assign jump_or_branch = (insn_valid_i &
assign branch_taken = insn_valid_i &
assign next_insn_addr_wide = {1'b0, insn_addr_i} + 'd4;
assign next_insn_addr = next_insn_addr_wide[ImemAddrWidth-1:0];
assign insn_fetch_req_valid_raw_o = insn_fetch_req_valid_raw;
assign insn_fetch_req_valid_o     = err ? 1'b0 : insn_fetch_req_valid_raw;
assign illegal_insn_static = insn_illegal_i | ispr_err;
assign reg_intg_violation_err   = rf_bignum_intg_err | ispr_rdata_intg_err;
assign illegal_insn_err         = illegal_insn_static | rf_indirect_err;
assign ld_insn_with_addr_from_call_stack = insn_valid_i               &
assign st_insn_with_addr_from_call_stack = insn_valid_i               &
assign insn_executing = insn_valid_i & ~err;
assign insn_cnt_clear =
assign insn_cnt_o = insn_cnt_q;
assign loop_start_req    = insn_valid_i & insn_dec_shared_i.loop_insn;
assign loop_start_commit = insn_executing;
assign loop_bodysize     = insn_dec_base_i.loop_bodysize;
assign loop_iterations   = insn_dec_base_i.loop_immediate ? insn_dec_base_i.i :
assign rf_base_rd_data_a_inc           = rf_base_rd_data_a_no_intg[4:0] + 1'b1;
assign rf_base_rd_data_b_inc           = rf_base_rd_data_b_no_intg[4:0] + 1'b1;
assign rf_base_rd_data_a_wlen_word_inc = rf_base_rd_data_a_no_intg[31:5] + 27'h1;
assign alu_base_operation_o.op = insn_dec_base_i.alu_op;
assign alu_base_comparison_o.operand_a = rf_base_rd_data_a_no_intg;
assign alu_base_comparison_o.operand_b = rf_base_rd_data_b_no_intg;
assign alu_base_comparison_o.op = insn_dec_base_i.comparison_op;
assign rf_base_rd_data_a_no_intg = rf_base_rd_data_a_intg_i[31:0];
assign rf_base_rd_data_b_no_intg = rf_base_rd_data_b_intg_i[31:0];
assign unused_rf_base_rd_a_intg_bits = |rf_base_rd_data_a_intg_i[38:32];
assign rf_bignum_rd_data_a_no_intg[i*32+:32] = rf_bignum_rd_data_a_intg_i[i*39+:32];
assign rf_bignum_rd_data_b_no_intg[i*32+:32] = rf_bignum_rd_data_b_intg_i[i*39+:32];
assign rf_bignum_rd_addr_a_unbuf = insn_dec_bignum_i.rf_a_indirect ? insn_bignum_rd_addr_a_q :
assign rf_bignum_rd_en_a_unbuf = insn_dec_bignum_i.rf_ren_a & insn_valid_i & ~stall;
assign rf_bignum_rd_addr_b_unbuf = insn_dec_bignum_i.rf_b_indirect ? insn_bignum_rd_addr_b_q :
assign rf_bignum_rd_en_b_unbuf = insn_dec_bignum_i.rf_ren_b & insn_valid_i & ~stall;
assign alu_bignum_operation_o.operand_a = rf_bignum_rd_data_a_no_intg;
assign alu_bignum_operation_o.op          = insn_dec_bignum_i.alu_op;
assign alu_bignum_operation_o.shift_right = insn_dec_bignum_i.alu_shift_right;
assign alu_bignum_operation_o.shift_amt   = insn_dec_bignum_i.alu_shift_amt;
assign alu_bignum_operation_o.flag_group  = insn_dec_bignum_i.alu_flag_group;
assign alu_bignum_operation_o.sel_flag    = insn_dec_bignum_i.alu_sel_flag;
assign alu_bignum_operation_o.alu_flag_en = insn_dec_bignum_i.alu_flag_en & insn_valid_i;
assign alu_bignum_operation_o.mac_flag_en = insn_dec_bignum_i.mac_flag_en & insn_valid_i;
assign alu_bignum_operation_valid_o  = insn_valid_i;
assign alu_bignum_operation_commit_o = insn_executing;
assign mac_bignum_operation_o.operand_a         = rf_bignum_rd_data_a_no_intg;
assign mac_bignum_operation_o.operand_b         = rf_bignum_rd_data_b_no_intg;
assign mac_bignum_operation_o.operand_a_qw_sel  = insn_dec_bignum_i.mac_op_a_qw_sel;
assign mac_bignum_operation_o.operand_b_qw_sel  = insn_dec_bignum_i.mac_op_b_qw_sel;
assign mac_bignum_operation_o.wr_hw_sel_upper   = insn_dec_bignum_i.mac_wr_hw_sel_upper;
assign mac_bignum_operation_o.pre_acc_shift_imm = insn_dec_bignum_i.mac_pre_acc_shift;
assign mac_bignum_operation_o.zero_acc          = insn_dec_bignum_i.mac_zero_acc;
assign mac_bignum_operation_o.shift_acc         = insn_dec_bignum_i.mac_shift_out;
assign mac_bignum_en_o     = insn_valid_i & insn_dec_bignum_i.mac_en;
assign mac_bignum_commit_o = insn_executing;
assign rf_bignum_wr_commit_o = |rf_bignum_wr_en_o & insn_executing & !stall;
assign rf_bignum_indirect_en_o    = insn_executing & rf_indirect_stall;
assign rf_bignum_rd_a_indirect_en = insn_executing & insn_dec_bignum_i.rf_a_indirect;
assign rf_bignum_rd_b_indirect_en = insn_executing & insn_dec_bignum_i.rf_b_indirect;
assign rf_bignum_wr_indirect_en   = insn_executing & insn_dec_bignum_i.rf_d_indirect;
assign rf_bignum_wr_addr_unbuf = insn_dec_bignum_i.rf_d_indirect ? insn_bignum_wr_addr_q :
assign mac_bignum_rf_wr_data[WLEN-1:WLEN/2] =
assign mac_bignum_rf_wr_data[WLEN/2-1:0] = mac_bignum_operation_result_i[WLEN/2-1:0];
assign rf_a_indirect_err = insn_dec_bignum_i.rf_a_indirect    &
assign rf_b_indirect_err = insn_dec_bignum_i.rf_b_indirect    &
assign rf_d_indirect_err = insn_dec_bignum_i.rf_d_indirect    &
assign rf_indirect_err =
assign ignore_rf_bignum_intg_errs = (insn_dec_bignum_i.rf_a_indirect |
assign rf_bignum_intg_err = rf_bignum_intg_err_i & ~ignore_rf_bignum_intg_errs;
assign ignore_rf_bignum_spurious_we_errs = insn_dec_bignum_i.rf_d_indirect &
assign rf_bignum_spurious_we_err = rf_bignum_spurious_we_err_i &
assign csr_addr     = csr_e'(insn_dec_base_i.i[11:0]);
assign csr_sub_addr = insn_dec_base_i.i[$clog2(BaseWordsPerWLEN)-1:0];
assign ispr_word_sel_base[i_word] = ispr_word_addr_base == i_word;
assign ispr_rdata[i_word*32+:32] = ispr_rdata_intg_i[i_word*39+:32];
assign ispr_rdata_intg_err_narrow[i_word] = |(ispr_rdata_intg_err_wide[i_word*2+:2]);
assign all_ispr_words_used = (insn_dec_bignum_i.rf_wdata_sel == RfWdSelIspr);
assign one_ispr_word_used = ispr_rd_insn & (insn_dec_shared_i.subset == InsnSubsetBase);
assign ispr_read_mask = all_ispr_words_used ? '1 :
assign ispr_rdata_used_intg_err = ispr_read_mask & ispr_rdata_intg_err_narrow;
assign non_prefetch_insn_running = (insn_valid_i & ~stall &
assign ispr_rdata_intg_err = non_prefetch_insn_running & |(ispr_rdata_used_intg_err);
assign csr_rdata_mux[i_bit][i_word] =
assign csr_rdata_raw[i_bit] = |csr_rdata_mux[i_bit];
assign csr_wdata_raw = insn_dec_shared_i.ispr_rs_insn ? csr_rdata | rf_base_rd_data_a_no_intg :
assign wsr_addr = wsr_e'(insn_dec_bignum_i.i[WsrNumWidth-1:0]);
assign wsr_wdata = insn_dec_shared_i.ispr_rs_insn ? ispr_rdata | rf_bignum_rd_data_a_no_intg :
assign ispr_illegal_addr = insn_dec_shared_i.subset == InsnSubsetBase ? csr_illegal_addr :
assign ispr_err = ispr_illegal_addr & insn_valid_i & (insn_dec_shared_i.ispr_rd_insn |
assign ispr_wr_insn = insn_dec_shared_i.ispr_wr_insn | insn_dec_shared_i.ispr_rs_insn;
assign ispr_rd_insn = insn_dec_shared_i.ispr_rd_insn | insn_dec_shared_i.ispr_rs_insn;
assign ispr_flags_wr_o = insn_dec_shared_i.ispr_flags_wr;
assign ispr_wr_base_insn =
assign ispr_wr_bignum_insn = ispr_wr_insn & (insn_dec_shared_i.subset == InsnSubsetBignum);
assign ispr_rd_bignum_insn = ispr_rd_insn & (insn_dec_shared_i.subset == InsnSubsetBignum);
assign ispr_addr_o         = insn_dec_shared_i.subset == InsnSubsetBase ? ispr_addr_base :
assign ispr_base_wdata_o   = csr_wdata;
assign ispr_base_wr_en_o   = {BaseWordsPerWLEN{ispr_wr_base_insn & insn_valid_i}} &
assign ispr_bignum_wr_en_o = ispr_wr_bignum_insn & insn_valid_i;
assign ispr_wr_commit_o = ispr_wr_insn & insn_executing;
assign ispr_rd_en_o     = ispr_rd_insn & insn_valid_i &
assign lsu_load_req_raw = insn_valid_i & insn_dec_shared_i.ld_insn & (state_q == OtbnStateRun);
assign lsu_load_req_o   = insn_executing & lsu_load_req_raw;
assign lsu_store_req_raw = insn_valid_i & insn_dec_shared_i.st_insn & ~rf_indirect_stall;
assign lsu_store_req_o   = insn_executing & lsu_store_req_raw;
assign lsu_req_subset_o = insn_dec_shared_i.subset;
assign expected_call_stack_push =
assign expected_call_stack_pop = insn_valid_i &
assign lsu_base_wdata_o   = rf_base_rd_data_b_intg_i;
assign lsu_bignum_wdata_o = rf_bignum_rd_data_b_intg_i;
assign rnd_req_raw = insn_valid_i & ispr_rd_insn & (ispr_addr_o == IsprRnd);
assign rnd_req_o = rnd_req_raw & insn_valid_i & ~(software_err | fatal_err);
assign rnd_prefetch_req_o = insn_executing & ispr_wr_insn &


Cluster 2:
assign branch_target = alu_base_operation_result_i[ImemAddrWidth-1:0];
assign branch_target_overflow = |alu_base_operation_result_i[31:ImemAddrWidth];
assign bad_data_addr_err = dmem_addr_err &
assign lsu_addr_saved_d = alu_base_operation_result_i[DmemAddrWidth-1:0];
assign lsu_addr_saved_sel =
assign lsu_addr = lsu_addr_saved_sel ? lsu_addr_saved_q                                :
assign expected_lsu_addr_en =
assign lsu_predec_error = expected_lsu_addr_en != lsu_addr_en_predec_i;
assign ctrl_predec_error =
assign predec_error_o = lsu_predec_error | ctrl_predec_error;
assign lsu_addr_o = lsu_addr_blanked;
assign dmem_addr_unaligned_bignum =
assign dmem_addr_unaligned_base   =
assign dmem_addr_overflow         = |alu_base_operation_result_i[31:DmemAddrWidth];
assign dmem_addr_err_check =
assign dmem_addr_err =


Cluster 3:
assign fatal_software_err       = software_err & software_errs_fatal_i;
assign key_invalid_err          = ispr_rd_bignum_insn & insn_valid_i & key_invalid;
assign non_insn_addr_software_err = |{key_invalid_err,
assign bad_insn_addr_err = imem_addr_err & ~non_insn_addr_software_err;
assign software_err = non_insn_addr_software_err | bad_insn_addr_err;
assign internal_fatal_err = |{fatal_software_err,
assign fatal_err = |{internal_fatal_err,
assign recoverable_err_o = recoverable_err | (software_err & ~software_errs_fatal_i);
assign internal_err = software_err | internal_fatal_err;
assign err          = software_err | recoverable_err | fatal_err;


Cluster 4:
assign err_bits_d = '{
assign err_bits_o = err_bits_q;

================================== Ai Message ==================================

I ran the anomaly detector over the provided otbn_controller.sv and reviewed the clustered results. Below I list the anomalous lines/expressions the tool found that are relevant to your three concern areas (FSM -> Locked on error & secure-wipe handshake; stall behaviour; predecode redundancy checks), explain why they look anomalous, evaluate whether they are security issues, and give recommended fixes or mitigations.

Summary of the most important anomalies (ranked by severity)
- High: branch_target_predec_error boolean logic looks wrong (disables the branch-target predecode check).
- Medium: interplay of state -> Locked, secure-wipe handshake, and locking_o gating (possible window where err bits / state visibility can be cleared/modified while wipe in progress).
- Low/Medium: stall logic appears consistent overall but has subtle interactions (mem_stall/ispr_stall/rf_indirect_stall) that need care; predecode redundancy checks are mostly present but one check (branch target) is effectively disabled by a likely typo.

1) branch_target_predec_error (High severity)
- Code (anomalous expression):
  assign branch_target_predec_error =
    insn_dec_shared_i.branch_insn                                            &
    insn_dec_shared_i.jump_insn & insn_dec_base_i.op_a_sel != OpASelRegister &
    (ctrl_flow_target_predec_i != branch_target);
- Why anomalous:
  The second line has both insn_dec_shared_i.branch_insn AND insn_dec_shared_i.jump_insn. Branch and jump are distinct instruction classes  requiring both to be true at once is almost always false. The intended condition is almost certainly to check when the instruction is a branch or a jump (and where the predecoder can predict the target), or to exclude JALR (which needs register read). As written, this effectively disables the branch-target predecode check because the conjunction of branch_insn and jump_insn will rarely (never) be true.
- Security impact:
  High. This check is intended to detect mismatches between a predecoded target and the actual computed branch target (control-flow integrity). With the check effectively disabled, mismatches could go undetected, meaning an attacker who can manipulate the computed branch target (e.g., via faults, microarchitectural bug, or corrupted immediate/register) could cause incorrect control flow without being flagged by this predecode check. This reduces detection coverage for control-flow errors/attacks.
- Recommended fix:
  Correct the boolean expression. Likely intended forms:
    - If you want to check both branch and jump instructions (except JALR): use (insn_dec_shared_i.branch_insn | insn_dec_shared_i.jump_insn) & (insn_dec_base_i.op_a_sel != OpASelRegister) & ...
    - If only branch instructions are relevant: use insn_dec_shared_i.branch_insn & (insn_dec_base_i.op_a_sel != OpASelRegister) & ...
  Add a unit test or simulation test that validates that a mismatch between ctrl_flow_target_predec_i and branch_target raises branch_target_predec_error for both branches and jumps where applicable.

2) Predecode redundancy checks generally present, but the effective disabling above breaks them (Medium)
- Code locations:
  - expected_lsu_addr_en and lsu_predec_error:
    assign expected_lsu_addr_en =
      insn_valid_i & (insn_dec_shared_i.ld_insn | insn_dec_shared_i.st_insn);
    assign lsu_predec_error = expected_lsu_addr_en != lsu_addr_en_predec_i;
  - ctrl_predec_error (many comparisons of ctrl_flow_predec_i fields vs decoded signals)
- Why anomalous/what to watch:
  The expected_lsu_addr_en check compares a dynamically computed expected signal to the predecoders lsu_addr_en_predec_i  that is fine and is the intended redundancy check. The logic around branch target check (see above) is the actual anomalous disabling. Also ensure the timing semantics of insn_valid_i, stall, and when the predecode outputs are valid are consistent  otherwise spurious mismatches could occur or real mismatches could be missed.
- Security impact:
  Medium/low by itself: the existence of these redundancy checks is good. But because the branch target check is broken, one of the important control-flow redundancy checks is not effective. Also be cautious about differences in when predecode signals and actual signals are evaluated (timing could cause false positives or missed errors).
- Recommendation:
  Fix branch_target_predec_error. Add timing-aware checks and test vectors that exercise corner cases (stall cycles, two-cycle load/store patterns) to ensure expected_lsu_addr_en matches the predecoder during the right cycle(s). Add unit tests which intentionally flip the predecode signals to ensure lsu_predec_error and ctrl_predec_error assert as expected.

3) FSM transitions to Locked and secure-wipe handshake (Medium severity, design-intent dependent)
- Code (clustered anomalies that are relevant):
  assign secure_wipe_running_d = start_secure_wipe | (secure_wipe_running_q & ~secure_wipe_ack_i);
  assign secure_wipe_req_o = start_secure_wipe | secure_wipe_running_q;
  assign spurious_secure_wipe_ack_d = spurious_secure_wipe_ack_q |
                                      (secure_wipe_ack_i      &
                                       ~secure_wipe_running_q &
                                       ~secure_wipe_running_i);
  assign sec_wipe_err_d = sec_wipe_err_q |
                          sec_wipe_err_i |
                          (sec_wipe_zero_i & ~secure_wipe_running_i);
  assign locking_o = (state_d == OtbnStateLocked) & (~(secure_wipe_running_i | secure_wipe_req_o) |
                                                     urnd_reseed_err_i | mubi_err_d);
  assign start_secure_wipe = executing & (done_complete | err);
  assign mems_sec_wipe_o   = (state_d == OtbnStateLocked) & (state_q != OtbnStateLocked);
- Why anomalous / what to watch:
  The controller sets state_d = OtbnStateLocked immediately on a fatal error (and in the default/error FSM path), but the external locking_o signal is gated so that it does not assert until secure-wipe has completed (unless URND reseed error or mubi error forces it). That gating is intentional (comment explains it) so the top-level can perform a secure-wipe before the locking signal observes Locked. This creates a period where:
    - state_d == Locked (internal next-state), but locking_o is false because secure wipe is running or requested.
    - err_bits can be cleared while locking_o is false if err_bit_clear_i is asserted  the clear logic explicitly allows clearing when !locking_o.
  That behavior is visible in the RTL and seems intentional, but it is worth calling out as a risk surface.
- Security impact:
  Medium. If an attacker or privileged software can assert err_bit_clear_i during the secure-wipe window (before locking_o asserts), they could clear error bits that would otherwise be recorded, potentially hiding evidence of a fatal/internal error. Whether that is a real vulnerability depends on system-level constraints:
    - Who can drive err_bit_clear_i? If only a trusted host or an on-chip manager can, the risk is low.
    - If an attacker can cause or force a secure-wipe handshake and concurrently assert err_bit_clear_i (or the design mistakenly allows software write during the wipe), then logs/err bits might be cleared prematurely.
- Recommendations:
  - Confirm the threat model and who can assert err_bit_clear_i; if err bit clearing comes from untrusted software, you should not allow clearing while the controller is in transitional state associated with a fatal error.
  - Consider tightening the clear condition to require state_q != OtbnStateLocked && state_d != OtbnStateLocked && !secure_wipe_req_o (i.e., disallow clearing once the FSM has moved to Locked even if locking_o not yet asserted), or add an explicit "fatal error latched" bit that prevents clearing if a fatal/internal fault triggered the lock.
  - Add an assertion that err_bits cannot be cleared in cycles after the FSM has been forced to Locked by a fatal internal error.

4) Stall logic: mem_stall / ispr_stall / rf_indirect_stall interplay (Low/Medium)
- Code snippets:
  assign mem_stall = lsu_load_req_raw;
  assign ispr_stall = rnd_req_raw & ~rnd_valid_i;
  assign rf_indirect_stall = insn_valid_i &
                             (state_q != OtbnStateStall) &
                             (insn_dec_shared_i.subset == InsnSubsetBignum) &
                             (insn_dec_bignum_i.rf_a_indirect |
                              insn_dec_bignum_i.rf_b_indirect |
                              insn_dec_bignum_i.rf_d_indirect);
  assign stall = mem_stall | ispr_stall | rf_indirect_stall;
- Why anomalous / what to watch:
  The stall sources are logical and expected. The tool flagged these because stall is central to instruction fetching and many signals are gated by stall. Nothing obviously wrong in the expressions themselves. However be aware of:
    - The timing assumptions (e.g., mem_stall is derived from lsu_load_req_raw which depends on state_q == Run). The assertions in the file (StallIfNextStateStall, NoStallOnBranch) are present to catch invalid interactions, but ensure they are proven/tested.
    - The RF indirect stall uses (state_q != OtbnStateStall)  odd but probably to avoid retriggering when already stalled. Verify this does not create an edge case where an indirect-indexed instruction can slip through unstalled.
- Security impact:
  Low/Medium. If stall gating is incorrect it could cause incorrect fetches/decodes under certain conditions, but no obvious direct security exploit. Still: ensure assertions cover timing cases and add directed tests for combinations (load + prefetch, indirect RF + branch, etc.).

5) Predecoder redundancy coverage OK except for disabled branch-target check (ties back to #1)
- The file contains a number of predecode vs decoded signal checks (lsu_predec_error, ctrl_predec_error, predec_error_o). The anomaly detector grouped these but the substantive problem is the disabled branch target check above which disables an important part of ctrl_predec_error.
- Recommendation: fix the branch_target_predec_error expression, and add directed tests that flip predecoder outputs (including target) and verify predec_error_o asserts.

Other minor anomalies / notes
- Spurious secure-wipe ack detection and sec_wipe_err detection are present and registered to avoid combinational loops. That logic looks intentional and correct; just ensure tests cover spurious ack and sec_wipe_zero semantics.
- There are many integrity-related masks and ignores (e.g., ignore_rf_bignum_intg_errs when call-stack underflow); these are fine but require good test coverage to ensure no unintended masking occurs.

Conclusion / action items
1. Fix branch_target_predec_error immediately  this is a correctness/security bug that disables branch-target predecode checking (HIGH).
   - Suggested change (example): replace the conjunction with an OR or the correct condition:
       assign branch_target_predec_error =
         (insn_dec_shared_i.branch_insn | insn_dec_shared_i.jump_insn) &
         (insn_dec_base_i.op_a_sel != OpASelRegister) &
         (ctrl_flow_target_predec_i != branch_target);
   - Add unit tests that force mismatched ctrl_flow_target_predec_i vs branch_target and verify the error fires.
2. Review the err_bits clearing gating vs locking_o / secure-wipe handshake and either:
   - tighten the clear condition so err bits cannot be cleared once the FSM has been forced to Locked by a fatal error, OR
   - document and enforce that only trusted agents can assert err_bit_clear_i and that clearing during secure-wipe is acceptable in your design threat model.
3. Add directed tests (and formal checks if possible) to exercise stall sources + predecode timing, and to ensure ctrl_predec_error/lsu_predec_error assert properly at the correct cycle boundaries.
4. Add a simulation test that injects spurious secure_wipe_ack_i and sec_wipe_zero_i to validate sec_wipe_err handling (already present but worth coverage).

If you want, I can:
- produce a patch suggestion that fixes the branch_target_predec_error line,
- generate a small set of directed unit tests (SystemVerilog test sequences) to validate the predecode checks and the locking/err-bit-clear behavior,
- or run further static checks to find other likely-typo patterns in boolean expressions. Which of these would you like next?
================================= Tool Message =================================
Name: run_anomaly_detector_agent

I ran the anomaly detector over the provided otbn_controller.sv and reviewed the clustered results. Below I list the anomalous lines/expressions the tool found that are relevant to your three concern areas (FSM -> Locked on error & secure-wipe handshake; stall behaviour; predecode redundancy checks), explain why they look anomalous, evaluate whether they are security issues, and give recommended fixes or mitigations.

Summary of the most important anomalies (ranked by severity)
- High: branch_target_predec_error boolean logic looks wrong (disables the branch-target predecode check).
- Medium: interplay of state -> Locked, secure-wipe handshake, and locking_o gating (possible window where err bits / state visibility can be cleared/modified while wipe in progress).
- Low/Medium: stall logic appears consistent overall but has subtle interactions (mem_stall/ispr_stall/rf_indirect_stall) that need care; predecode redundancy checks are mostly present but one check (branch target) is effectively disabled by a likely typo.

1) branch_target_predec_error (High severity)
- Code (anomalous expression):
  assign branch_target_predec_error =
    insn_dec_shared_i.branch_insn                                            &
    insn_dec_shared_i.jump_insn & insn_dec_base_i.op_a_sel != OpASelRegister &
    (ctrl_flow_target_predec_i != branch_target);
- Why anomalous:
  The second line has both insn_dec_shared_i.branch_insn AND insn_dec_shared_i.jump_insn. Branch and jump are distinct instruction classes  requiring both to be true at once is almost always false. The intended condition is almost certainly to check when the instruction is a branch or a jump (and where the predecoder can predict the target), or to exclude JALR (which needs register read). As written, this effectively disables the branch-target predecode check because the conjunction of branch_insn and jump_insn will rarely (never) be true.
- Security impact:
  High. This check is intended to detect mismatches between a predecoded target and the actual computed branch target (control-flow integrity). With the check effectively disabled, mismatches could go undetected, meaning an attacker who can manipulate the computed branch target (e.g., via faults, microarchitectural bug, or corrupted immediate/register) could cause incorrect control flow without being flagged by this predecode check. This reduces detection coverage for control-flow errors/attacks.
- Recommended fix:
  Correct the boolean expression. Likely intended forms:
    - If you want to check both branch and jump instructions (except JALR): use (insn_dec_shared_i.branch_insn | insn_dec_shared_i.jump_insn) & (insn_dec_base_i.op_a_sel != OpASelRegister) & ...
    - If only branch instructions are relevant: use insn_dec_shared_i.branch_insn & (insn_dec_base_i.op_a_sel != OpASelRegister) & ...
  Add a unit test or simulation test that validates that a mismatch between ctrl_flow_target_predec_i and branch_target raises branch_target_predec_error for both branches and jumps where applicable.

2) Predecode redundancy checks generally present, but the effective disabling above breaks them (Medium)
- Code locations:
  - expected_lsu_addr_en and lsu_predec_error:
    assign expected_lsu_addr_en =
      insn_valid_i & (insn_dec_shared_i.ld_insn | insn_dec_shared_i.st_insn);
    assign lsu_predec_error = expected_lsu_addr_en != lsu_addr_en_predec_i;
  - ctrl_predec_error (many comparisons of ctrl_flow_predec_i fields vs decoded signals)
- Why anomalous/what to watch:
  The expected_lsu_addr_en check compares a dynamically computed expected signal to the predecoders lsu_addr_en_predec_i  that is fine and is the intended redundancy check. The logic around branch target check (see above) is the actual anomalous disabling. Also ensure the timing semantics of insn_valid_i, stall, and when the predecode outputs are valid are consistent  otherwise spurious mismatches could occur or real mismatches could be missed.
- Security impact:
  Medium/low by itself: the existence of these redundancy checks is good. But because the branch target check is broken, one of the important control-flow redundancy checks is not effective. Also be cautious about differences in when predecode signals and actual signals are evaluated (timing could cause false positives or missed errors).
- Recommendation:
  Fix branch_target_predec_error. Add timing-aware checks and test vectors that exercise corner cases (stall cycles, two-cycle load/store patterns) to ensure expected_lsu_addr_en matches the predecoder during the right cycle(s). Add unit tests which intentionally flip the predecode signals to ensure lsu_predec_error and ctrl_predec_error assert as expected.

3) FSM transitions to Locked and secure-wipe handshake (Medium severity, design-intent dependent)
- Code (clustered anomalies that are relevant):
  assign secure_wipe_running_d = start_secure_wipe | (secure_wipe_running_q & ~secure_wipe_ack_i);
  assign secure_wipe_req_o = start_secure_wipe | secure_wipe_running_q;
  assign spurious_secure_wipe_ack_d = spurious_secure_wipe_ack_q |
                                      (secure_wipe_ack_i      &
                                       ~secure_wipe_running_q &
                                       ~secure_wipe_running_i);
  assign sec_wipe_err_d = sec_wipe_err_q |
                          sec_wipe_err_i |
                          (sec_wipe_zero_i & ~secure_wipe_running_i);
  assign locking_o = (state_d == OtbnStateLocked) & (~(secure_wipe_running_i | secure_wipe_req_o) |
                                                     urnd_reseed_err_i | mubi_err_d);
  assign start_secure_wipe = executing & (done_complete | err);
  assign mems_sec_wipe_o   = (state_d == OtbnStateLocked) & (state_q != OtbnStateLocked);
- Why anomalous / what to watch:
  The controller sets state_d = OtbnStateLocked immediately on a fatal error (and in the default/error FSM path), but the external locking_o signal is gated so that it does not assert until secure-wipe has completed (unless URND reseed error or mubi error forces it). That gating is intentional (comment explains it) so the top-level can perform a secure-wipe before the locking signal observes Locked. This creates a period where:
    - state_d == Locked (internal next-state), but locking_o is false because secure wipe is running or requested.
    - err_bits can be cleared while locking_o is false if err_bit_clear_i is asserted  the clear logic explicitly allows clearing when !locking_o.
  That behavior is visible in the RTL and seems intentional, but it is worth calling out as a risk surface.
- Security impact:
  Medium. If an attacker or privileged software can assert err_bit_clear_i during the secure-wipe window (before locking_o asserts), they could clear error bits that would otherwise be recorded, potentially hiding evidence of a fatal/internal error. Whether that is a real vulnerability depends on system-level constraints:
    - Who can drive err_bit_clear_i? If only a trusted host or an on-chip manager can, the risk is low.
    - If an attacker can cause or force a secure-wipe handshake and concurrently assert err_bit_clear_i (or the design mistakenly allows software write during the wipe), then logs/err bits might be cleared prematurely.
- Recommendations:
  - Confirm the threat model and who can assert err_bit_clear_i; if err bit clearing comes from untrusted software, you should not allow clearing while the controller is in transitional state associated with a fatal error.
  - Consider tightening the clear condition to require state_q != OtbnStateLocked && state_d != OtbnStateLocked && !secure_wipe_req_o (i.e., disallow clearing once the FSM has moved to Locked even if locking_o not yet asserted), or add an explicit "fatal error latched" bit that prevents clearing if a fatal/internal fault triggered the lock.
  - Add an assertion that err_bits cannot be cleared in cycles after the FSM has been forced to Locked by a fatal internal error.

4) Stall logic: mem_stall / ispr_stall / rf_indirect_stall interplay (Low/Medium)
- Code snippets:
  assign mem_stall = lsu_load_req_raw;
  assign ispr_stall = rnd_req_raw & ~rnd_valid_i;
  assign rf_indirect_stall = insn_valid_i &
                             (state_q != OtbnStateStall) &
                             (insn_dec_shared_i.subset == InsnSubsetBignum) &
                             (insn_dec_bignum_i.rf_a_indirect |
                              insn_dec_bignum_i.rf_b_indirect |
                              insn_dec_bignum_i.rf_d_indirect);
  assign stall = mem_stall | ispr_stall | rf_indirect_stall;
- Why anomalous / what to watch:
  The stall sources are logical and expected. The tool flagged these because stall is central to instruction fetching and many signals are gated by stall. Nothing obviously wrong in the expressions themselves. However be aware of:
    - The timing assumptions (e.g., mem_stall is derived from lsu_load_req_raw which depends on state_q == Run). The assertions in the file (StallIfNextStateStall, NoStallOnBranch) are present to catch invalid interactions, but ensure they are proven/tested.
    - The RF indirect stall uses (state_q != OtbnStateStall)  odd but probably to avoid retriggering when already stalled. Verify this does not create an edge case where an indirect-indexed instruction can slip through unstalled.
- Security impact:
  Low/Medium. If stall gating is incorrect it could cause incorrect fetches/decodes under certain conditions, but no obvious direct security exploit. Still: ensure assertions cover timing cases and add directed tests for combinations (load + prefetch, indirect RF + branch, etc.).

5) Predecoder redundancy coverage OK except for disabled branch-target check (ties back to #1)
- The file contains a number of predecode vs decoded signal checks (lsu_predec_error, ctrl_predec_error, predec_error_o). The anomaly detector grouped these but the substantive problem is the disabled branch target check above which disables an important part of ctrl_predec_error.
- Recommendation: fix the branch_target_predec_error expression, and add directed tests that flip predecoder outputs (including target) and verify predec_error_o asserts.

Other minor anomalies / notes
- Spurious secure-wipe ack detection and sec_wipe_err detection are present and registered to avoid combinational loops. That logic looks intentional and correct; just ensure tests cover spurious ack and sec_wipe_zero semantics.
- There are many integrity-related masks and ignores (e.g., ignore_rf_bignum_intg_errs when call-stack underflow); these are fine but require good test coverage to ensure no unintended masking occurs.

Conclusion / action items
1. Fix branch_target_predec_error immediately  this is a correctness/security bug that disables branch-target predecode checking (HIGH).
   - Suggested change (example): replace the conjunction with an OR or the correct condition:
       assign branch_target_predec_error =
         (insn_dec_shared_i.branch_insn | insn_dec_shared_i.jump_insn) &
         (insn_dec_base_i.op_a_sel != OpASelRegister) &
         (ctrl_flow_target_predec_i != branch_target);
   - Add unit tests that force mismatched ctrl_flow_target_predec_i vs branch_target and verify the error fires.
2. Review the err_bits clearing gating vs locking_o / secure-wipe handshake and either:
   - tighten the clear condition so err bits cannot be cleared once the FSM has been forced to Locked by a fatal error, OR
   - document and enforce that only trusted agents can assert err_bit_clear_i and that clearing during secure-wipe is acceptable in your design threat model.
3. Add directed tests (and formal checks if possible) to exercise stall sources + predecode timing, and to ensure ctrl_predec_error/lsu_predec_error assert properly at the correct cycle boundaries.
4. Add a simulation test that injects spurious secure_wipe_ack_i and sec_wipe_zero_i to validate sec_wipe_err handling (already present but worth coverage).

If you want, I can:
- produce a patch suggestion that fixes the branch_target_predec_error line,
- generate a small set of directed unit tests (SystemVerilog test sequences) to validate the predecode checks and the locking/err-bit-clear behavior,
- or run further static checks to find other likely-typo patterns in boolean expressions. Which of these would you like next?
================================== Ai Message ==================================
Tool Calls:
  run_llm_cwe_checker_agent (call_r5osaLCygS7puUjRQMp3eFft)
 Call ID: call_r5osaLCygS7puUjRQMp3eFft
  Args:
    design_filepath: /home/eden/Desktop/Code/HACK@CHES/p2/opentitan/hw/ip/otbn/rtl/otbn_controller.sv
    top_module: otbn_controller
    security_objective: Control-flow integrity: validate predecode redundancy checks and branch target check; CWE mapping
================================ Human Message =================================

Are there security concerns related to Control-flow integrity: validate predecode redundancy checks and branch target check; CWE mapping in the provided RTL:
    """

    // Copyright lowRISC contributors (OpenTitan project).
// Licensed under the Apache License, Version 2.0, see LICENSE for details.
// SPDX-License-Identifier: Apache-2.0

`include "prim_assert.sv"

/**
 * OTBN Controller
 */
module otbn_controller
  import otbn_pkg::*;
#(
  // Size of the instruction memory, in bytes
  parameter int ImemSizeByte = 4096,
  // Size of the data memory, in bytes
  parameter int DmemSizeByte = 4096,

  localparam int ImemAddrWidth = prim_util_pkg::vbits(ImemSizeByte),
  localparam int DmemAddrWidth = prim_util_pkg::vbits(DmemSizeByte)
) (
  input logic clk_i,
  input logic rst_ni,

  input  logic start_i,   // start the processing at address zero
  output logic locking_o, // Controller is in or is entering the locked state
  input  logic err_bit_clear_i,

  input prim_mubi_pkg::mubi4_t fatal_escalate_en_i,
  input prim_mubi_pkg::mubi4_t recov_escalate_en_i,
  input prim_mubi_pkg::mubi4_t rma_req_i,
  output controller_err_bits_t err_bits_o,
  output logic                 recoverable_err_o,

  // Next instruction selection (to instruction fetch)
  output logic                     insn_fetch_req_valid_o,
  output logic                     insn_fetch_req_valid_raw_o,
  output logic [ImemAddrWidth-1:0] insn_fetch_req_addr_o,
  output logic                     insn_fetch_resp_clear_o,

  // Fetched/decoded instruction
  input logic                     insn_valid_i,
  input logic                     insn_illegal_i,
  input logic [ImemAddrWidth-1:0] insn_addr_i,

  // Decoded instruction data
  input insn_dec_base_t   insn_dec_base_i,
  input insn_dec_bignum_t insn_dec_bignum_i,
  input insn_dec_shared_t insn_dec_shared_i,

  // Base register file
  output logic [4:0]               rf_base_wr_addr_o,
  output logic                     rf_base_wr_en_o,
  output logic                     rf_base_wr_commit_o,
  output logic [31:0]              rf_base_wr_data_no_intg_o,
  output logic [BaseIntgWidth-1:0] rf_base_wr_data_intg_o,
  output logic                     rf_base_wr_data_intg_sel_o,

  output logic [4:0]               rf_base_rd_addr_a_o,
  output logic                     rf_base_rd_en_a_o,
  input  logic [BaseIntgWidth-1:0] rf_base_rd_data_a_intg_i,
  output logic [4:0]               rf_base_rd_addr_b_o,
  output logic                     rf_base_rd_en_b_o,
  input  logic [BaseIntgWidth-1:0] rf_base_rd_data_b_intg_i,
  output logic                     rf_base_rd_commit_o,

  input logic rf_base_call_stack_sw_err_i,
  input logic rf_base_call_stack_hw_err_i,

  // Bignum register file (WDRs)
  output logic [4:0]         rf_bignum_wr_addr_o,
  output logic [1:0]         rf_bignum_wr_en_o,
  output logic               rf_bignum_wr_commit_o,
  output logic [WLEN-1:0]    rf_bignum_wr_data_no_intg_o,
  output logic [ExtWLEN-1:0] rf_bignum_wr_data_intg_o,
  output logic               rf_bignum_wr_data_intg_sel_o,

  output logic [4:0]         rf_bignum_rd_addr_a_o,
  output logic               rf_bignum_rd_en_a_o,
  input  logic [ExtWLEN-1:0] rf_bignum_rd_data_a_intg_i,

  output logic [4:0]         rf_bignum_rd_addr_b_o,
  output logic               rf_bignum_rd_en_b_o,
  input  logic [ExtWLEN-1:0] rf_bignum_rd_data_b_intg_i,

  input logic rf_bignum_intg_err_i,
  input logic rf_bignum_spurious_we_err_i,

  output logic [NWdr-1:0] rf_bignum_rd_a_indirect_onehot_o,
  output logic [NWdr-1:0] rf_bignum_rd_b_indirect_onehot_o,
  output logic [NWdr-1:0] rf_bignum_wr_indirect_onehot_o,
  output logic            rf_bignum_indirect_en_o,

  // Execution units

  // Base ALU
  output alu_base_operation_t  alu_base_operation_o,
  output alu_base_comparison_t alu_base_comparison_o,
  input  logic [31:0]          alu_base_operation_result_i,
  input  logic                 alu_base_comparison_result_i,

  // Bignum ALU
  output alu_bignum_operation_t alu_bignum_operation_o,
  output logic                  alu_bignum_operation_valid_o,
  output logic                  alu_bignum_operation_commit_o,
  input  logic [WLEN-1:0]       alu_bignum_operation_result_i,
  input  logic                  alu_bignum_selection_flag_i,

  // Bignum MAC
  output mac_bignum_operation_t mac_bignum_operation_o,
  input  logic [WLEN-1:0]       mac_bignum_operation_result_i,
  output logic                  mac_bignum_en_o,
  output logic                  mac_bignum_commit_o,

  // LSU
  output logic                     lsu_load_req_o,
  output logic                     lsu_store_req_o,
  output insn_subset_e             lsu_req_subset_o,
  output logic [DmemAddrWidth-1:0] lsu_addr_o,
  input  logic                     lsu_addr_en_predec_i,

  output logic [BaseIntgWidth-1:0] lsu_base_wdata_o,
  output logic [ExtWLEN-1:0]       lsu_bignum_wdata_o,

  input  logic [BaseIntgWidth-1:0] lsu_base_rdata_i,
  input  logic [ExtWLEN-1:0]       lsu_bignum_rdata_i,

  // Internal Special-Purpose Registers (ISPRs)
  output ispr_e                       ispr_addr_o,
  output logic [31:0]                 ispr_base_wdata_o,
  output logic [BaseWordsPerWLEN-1:0] ispr_base_wr_en_o,
  output logic [ExtWLEN-1:0]          ispr_bignum_wdata_intg_o,
  output logic                        ispr_bignum_wr_en_o,
  output logic [NFlagGroups-1:0]      ispr_flags_wr_o,
  output logic                        ispr_wr_commit_o,
  input  logic [ExtWLEN-1:0]          ispr_rdata_intg_i,
  output logic                        ispr_rd_en_o,

  // RND interface
  output logic rnd_req_o,
  output logic rnd_prefetch_req_o,
  input  logic rnd_valid_i,

  input  logic urnd_reseed_err_i,

  // Secure Wipe
  output logic secure_wipe_req_o,
  input  logic secure_wipe_ack_i,
  input  logic sec_wipe_zero_i,
  input  logic secure_wipe_running_i,
  input  logic sec_wipe_err_i,

  input  logic        state_reset_i,
  output logic [31:0] insn_cnt_o,
  input  logic        insn_cnt_clear_ext_i,
  input  logic        insn_cnt_clear_int_i,
  output logic        mems_sec_wipe_o,

  input  logic        software_errs_fatal_i,

  input logic [1:0] sideload_key_shares_valid_i,

  // Prefetch stage control
  output logic                     prefetch_en_o,
  output logic                     prefetch_loop_active_o,
  output logic [31:0]              prefetch_loop_iterations_o,
  output logic [ImemAddrWidth:0]   prefetch_loop_end_addr_o,
  output logic [ImemAddrWidth-1:0] prefetch_loop_jump_addr_o,
  output logic                     prefetch_ignore_errs_o,

  // Predecoded control
  input  ctrl_flow_predec_t        ctrl_flow_predec_i,
  input  logic [ImemAddrWidth-1:0] ctrl_flow_target_predec_i,
  output logic                     predec_error_o
);
  import prim_mubi_pkg::*;

  otbn_state_e state_q, state_d;


  controller_err_bits_t err_bits_q, err_bits_d;

  // The specific error signals that go into err_bits_d
  logic fatal_software_err, bad_internal_state_err, reg_intg_violation_err, key_invalid_err;
  logic illegal_insn_err, bad_data_addr_err, call_stack_sw_err, bad_insn_addr_err;

  logic err;
  logic internal_err;
  logic recoverable_err;
  logic software_err;
  logic non_insn_addr_software_err;
  logic fatal_err;
  logic internal_fatal_err;
  logic done_complete;
  logic executing;
  logic state_error, state_error_d, state_error_q;
  logic spurious_secure_wipe_ack_q, spurious_secure_wipe_ack_d;
  logic sec_wipe_err_q, sec_wipe_err_d;
  logic mubi_err_q, mubi_err_d;

  logic                     insn_fetch_req_valid_raw;
  logic [ImemAddrWidth-1:0] insn_fetch_req_addr_last;

  logic stall;
  logic ispr_stall;
  logic mem_stall;
  logic rf_indirect_stall;
  logic jump_or_branch;
  logic branch_taken;
  logic insn_executing;
  logic ld_insn_with_addr_from_call_stack, st_insn_with_addr_from_call_stack;
  logic [ImemAddrWidth-1:0] branch_target;
  logic                     branch_target_overflow;
  logic [ImemAddrWidth:0]   next_insn_addr_wide;
  logic [ImemAddrWidth-1:0] next_insn_addr;

  csr_e                                csr_addr;
  logic [$clog2(BaseWordsPerWLEN)-1:0] csr_sub_addr;
  logic [31:0]                         csr_rdata_raw;
  logic [31:0]                         csr_rdata;
  logic [BaseWordsPerWLEN-1:0]         csr_rdata_mux [32];
  logic [31:0]                         csr_wdata_raw;
  logic [31:0]                         csr_wdata;

  wsr_e                                wsr_addr;
  logic [WLEN-1:0]                     wsr_wdata;

  ispr_e                               ispr_addr_base;
  logic [$clog2(BaseWordsPerWLEN)-1:0] ispr_word_addr_base;
  logic [BaseWordsPerWLEN-1:0]         ispr_word_sel_base;

  ispr_e                               ispr_addr_bignum;

  logic                                ispr_wr_insn, ispr_rd_insn;
  logic                                ispr_wr_base_insn;
  logic                                ispr_wr_bignum_insn;
  logic                                ispr_rd_bignum_insn;

  logic                     lsu_load_req_raw;
  logic                     lsu_store_req_raw;
  logic [DmemAddrWidth-1:0] lsu_addr, lsu_addr_blanked, lsu_addr_saved_d, lsu_addr_saved_q;
  logic                     lsu_addr_saved_sel;
  logic                     expected_lsu_addr_en;

  logic                     expected_call_stack_push, expected_call_stack_pop;
  logic                     lsu_predec_error, branch_target_predec_error, ctrl_predec_error;

  logic rnd_req_raw;

  // Register read data with integrity stripped off
  logic [31:0]     rf_base_rd_data_a_no_intg;
  logic [31:0]     rf_base_rd_data_b_no_intg;
  logic [WLEN-1:0] rf_bignum_rd_data_a_no_intg;
  logic [WLEN-1:0] rf_bignum_rd_data_b_no_intg;

  logic [ExtWLEN-1:0] rf_bignum_rd_data_b_intg_blanked;
  logic [ExtWLEN-1:0] selection_result;

  logic [1:0] rf_bignum_wr_en_unbuf;
  logic [4:0] rf_bignum_wr_addr_unbuf;
  logic [4:0] rf_bignum_rd_addr_a_unbuf;
  logic       rf_bignum_rd_en_a_unbuf;
  logic [4:0] rf_bignum_rd_addr_b_unbuf;
  logic       rf_bignum_rd_en_b_unbuf;

  logic rf_bignum_rd_a_indirect_en;
  logic rf_bignum_rd_b_indirect_en;
  logic rf_bignum_wr_indirect_en;

  // Computed increments for indirect register index and memory address in BN.LID/BN.SID/BN.MOVR
  // instructions.
  logic [5:0]  rf_base_rd_data_a_inc;
  logic [5:0]  rf_base_rd_data_b_inc;
  logic [26:0] rf_base_rd_data_a_wlen_word_inc;

  // Read/Write enables for base register file before illegal instruction encoding are factored in
  logic rf_base_rd_en_a_raw, rf_base_rd_en_b_raw, rf_base_wr_en_raw;

  // Output of mux taking the above increments as inputs and choosing one to write back to base
  // register file with appropriate zero extension and padding to give a 32-bit result.
  logic [31:0]              increment_out;

  // Loop control, used to start a new loop
  logic        loop_start_req;
  logic        loop_start_commit;
  logic        loop_reset;
  logic [11:0] loop_bodysize;
  logic [31:0] loop_iterations;

  // Loop generated jumps. The loop controller asks to jump when execution reaches the end of a loop
  // body that hasn't completed all of its iterations.
  logic                     loop_jump;
  logic [ImemAddrWidth-1:0] loop_jump_addr;

  logic [WLEN-1:0] mac_bignum_rf_wr_data;

  logic loop_hw_err, loop_predec_err;
  logic csr_illegal_addr, wsr_illegal_addr, ispr_illegal_addr;
  logic imem_addr_err, loop_sw_err, ispr_err;
  logic dmem_addr_err_check, dmem_addr_err;
  logic dmem_addr_unaligned_base, dmem_addr_unaligned_bignum, dmem_addr_overflow;
  logic illegal_insn_static;
  logic key_invalid;

  logic rf_a_indirect_err, rf_b_indirect_err, rf_d_indirect_err, rf_indirect_err;

  // If we are doing an indirect access to the bignum register file, it's possible that the
  // address that we use for the access is architecturally unknown. This happens if it came from x1
  // and we've underflowed the call stack. When this happens, we want to ignore any read data
  // integrity errors and spurious write enable errors since the access to the bignum register file
  // didn't happen architecturally anyway.
  logic ignore_rf_bignum_intg_errs;
  logic rf_bignum_intg_err;
  logic ignore_rf_bignum_spurious_we_errs;
  logic rf_bignum_spurious_we_err;

  logic ispr_rdata_intg_err;

  logic [31:0] insn_cnt_d, insn_cnt_q;
  logic        insn_cnt_clear;

  logic [4:0] insn_bignum_rd_addr_a_q, insn_bignum_rd_addr_b_q, insn_bignum_wr_addr_q;

  logic       start_secure_wipe;
  logic       secure_wipe_running_q, secure_wipe_running_d;

  assign secure_wipe_running_d = start_secure_wipe | (secure_wipe_running_q & ~secure_wipe_ack_i);

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      secure_wipe_running_q <= 1'b0;
    end else begin
      secure_wipe_running_q <= secure_wipe_running_d;
    end
  end
  assign secure_wipe_req_o = start_secure_wipe | secure_wipe_running_q; 

  // Spot spurious acks on the secure wipe interface. There is a an ack at the end of the initial
  // secure wipe, and as `secure_wipe_running_q` is only high during secure wipes triggered by this
  // controller, we have to ignore acks before the initial secure wipe is done.  Register this
  // signal to break a circular path (a secure wipe can be triggered by a stop, and a spurious
  // secure wipe ack can trigger a stop).
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      spurious_secure_wipe_ack_q <= 1'b0;
    end else begin
      spurious_secure_wipe_ack_q <= spurious_secure_wipe_ack_d;
    end
  end
  assign spurious_secure_wipe_ack_d = spurious_secure_wipe_ack_q |
                                      (secure_wipe_ack_i      &
                                       ~secure_wipe_running_q &
                                       ~secure_wipe_running_i);

  // Detect and latch unexpected secure wipe signals.
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      sec_wipe_err_q <= 1'b0;
    end else begin
      sec_wipe_err_q <= sec_wipe_err_d;
    end
  end
  assign sec_wipe_err_d = sec_wipe_err_q |
                          sec_wipe_err_i |
                          (sec_wipe_zero_i & ~secure_wipe_running_i);

  // Stall a cycle on loads to allow load data writeback to happen the following cycle. Stall not
  // required on stores as there is no response to deal with.
  assign mem_stall = lsu_load_req_raw;

  // Reads to RND must stall until data is available
  assign ispr_stall = rnd_req_raw & ~rnd_valid_i;

  assign rf_indirect_stall = insn_valid_i &
                             (state_q != OtbnStateStall) &
                             (insn_dec_shared_i.subset == InsnSubsetBignum) &
                             (insn_dec_bignum_i.rf_a_indirect |
                              insn_dec_bignum_i.rf_b_indirect |
                              insn_dec_bignum_i.rf_d_indirect);

  assign stall = mem_stall | ispr_stall | rf_indirect_stall;

  // OTBN is done when it was executing something (in state OtbnStateRun or OtbnStateStall)
  // and either it executes an ecall or an error occurs. A pulse on the done signal raises the
  // 'done' interrupt and also tells the top-level to update its ERR_BITS status
  // register. The calculation that ecall triggered done is factored out as `done_complete` to
  // avoid logic loops in the error handling logic.
  assign done_complete = (insn_valid_i & insn_dec_shared_i.ecall_insn);
  assign executing = (state_q == OtbnStateRun) ||
                     (state_q == OtbnStateStall);

  // Set the *locking* output when the next state is the *locked* state and no secure wipe is
  // running or there is a URND reseed error.  `locking_o` is thus set only after the secure wipe
  // has completed or if it cannot complete due to an URND reseed error (in which case
  // `secure_wipe_req_o` and `urnd_reseed_err_i` will remain high).  The condition for secure wipe
  // running involves `secure_wipe_running_i`, which is high for the initial secure wipe, and
  // `secure_wipe_req_o`, which is high for post-execution secure wipes.
  assign locking_o = (state_d == OtbnStateLocked) & (~(secure_wipe_running_i | secure_wipe_req_o) |
                                                     urnd_reseed_err_i | mubi_err_d);

  assign start_secure_wipe = executing & (done_complete | err);

  assign jump_or_branch = (insn_valid_i &
                           (insn_dec_shared_i.branch_insn | insn_dec_shared_i.jump_insn));

  // Branch taken when there is a valid branch instruction and comparison passes or a valid jump
  // instruction (which is always taken)
  assign branch_taken = insn_valid_i &
                        ((insn_dec_shared_i.branch_insn & alu_base_comparison_result_i) |
                         insn_dec_shared_i.jump_insn);
  // Branch target computed by base ALU (PC + imm)
  assign branch_target = alu_base_operation_result_i[ImemAddrWidth-1:0];
  assign branch_target_overflow = |alu_base_operation_result_i[31:ImemAddrWidth];

  assign next_insn_addr_wide = {1'b0, insn_addr_i} + 'd4;
  assign next_insn_addr = next_insn_addr_wide[ImemAddrWidth-1:0];

  // Record address for fetch request so it can be retried when an invalid response is received
  always_ff @(posedge clk_i) begin
    if (insn_fetch_req_valid_raw) begin
      insn_fetch_req_addr_last <= insn_fetch_req_addr_o;
    end
  end

  always_comb begin
    state_d                  = state_q;
    // `insn_fetch_req_valid_raw` is the value `insn_fetch_req_valid_o` before any errors are
    // considered.
    insn_fetch_req_valid_raw = 1'b0;
    insn_fetch_req_addr_o    = '0;
    insn_fetch_resp_clear_o  = 1'b1;
    prefetch_en_o            = 1'b0;

    state_error = 1'b0;

    unique case (state_q)
      OtbnStateHalt: begin
        if (start_i) begin
          state_d = OtbnStateRun;

          insn_fetch_req_addr_o    = '0;
          insn_fetch_req_valid_raw = 1'b1;
          prefetch_en_o            = 1'b1;
        end
      end
      OtbnStateRun: begin
        insn_fetch_req_valid_raw = 1'b1;
        prefetch_en_o            = 1'b1;

        if (!insn_valid_i) begin
          insn_fetch_req_addr_o = insn_fetch_req_addr_last;
        end else if (done_complete) begin
          state_d                  = OtbnStateHalt;
          insn_fetch_req_valid_raw = 1'b0;
          prefetch_en_o            = 1'b0;
        end else begin
          if (stall) begin
            // When stalling don't request a new fetch and don't clear response either to keep
            // current instruction.
            state_d                  = OtbnStateStall;
            insn_fetch_req_valid_raw = 1'b0;
            insn_fetch_resp_clear_o  = 1'b0;
          end else begin
            if (branch_taken) begin
              insn_fetch_req_addr_o = branch_target;
            end else if (loop_jump) begin
              insn_fetch_req_addr_o = loop_jump_addr;
            end else begin
              insn_fetch_req_addr_o = next_insn_addr;
            end
          end
        end
      end
      OtbnStateStall: begin
        prefetch_en_o = 1'b1;
        // When stalling refetch the same instruction to keep decode inputs constant
        if (stall) begin
          state_d                  = OtbnStateStall;
          //insn_fetch_req_addr_o = insn_addr_i;
          insn_fetch_req_valid_raw = 1'b0;
          insn_fetch_resp_clear_o  = 1'b0;
        end else begin
          insn_fetch_req_valid_raw = 1'b1;

          if (loop_jump) begin
            insn_fetch_req_addr_o = loop_jump_addr;
          end else begin
            insn_fetch_req_addr_o = next_insn_addr;
          end

          state_d = OtbnStateRun;
        end
      end
      OtbnStateLocked: begin
        insn_fetch_req_valid_raw = 1'b0;
        state_d                  = OtbnStateLocked;
      end
      default: begin
        // We should never get here. If we do (e.g. via a malicious glitch), error out immediately.
        // SEC_CM: CONTROLLER.FSM.LOCAL_ESC
        state_d = OtbnStateLocked;
        state_error = 1'b1;
      end
    endcase

    // On any error immediately halt, either going to OtbnStateLocked or OtbnStateHalt depending on
    // whether it was a fatal error.
    if (err) begin
      insn_fetch_resp_clear_o = 1'b1;

      if (fatal_err) begin
        // SEC_CM: CONTROLLER.FSM.GLOBAL_ESC
        state_d = OtbnStateLocked;
      end else begin
        state_d = OtbnStateHalt;
      end
    end

    // Regardless of what happens above enforce staying in OtnbStateLocked.
    if (state_q == OtbnStateLocked) begin
      state_d = OtbnStateLocked;
    end
  end

  assign state_error_d = state_error | state_error_q;

  prim_flop #(
    .Width(1),
    .ResetValue('0)
  ) u_state_error_flop (
    .clk_i,
    .rst_ni,

    .d_i(state_error_d),
    .q_o(state_error_q)
  );

  `ASSERT(InsnAlwaysValidInStall, state_q == OtbnStateStall |-> insn_valid_i)

  // Anything that moves us or keeps us in the stall state should cause `stall` to be asserted
  `ASSERT(StallIfNextStateStall, insn_valid_i & (state_d == OtbnStateStall) |-> stall)

  // The raw signal is needed by the instruction fetch stage for generating instruction address
  // errors (where instruction fetch and prefetch disagree on address). `err` will factor this in so
  // using the qualified signal results in a combinational loop.
  assign insn_fetch_req_valid_raw_o = insn_fetch_req_valid_raw;
  assign insn_fetch_req_valid_o     = err ? 1'b0 : insn_fetch_req_valid_raw;

  // Determine if there are any errors related to the Imem fetch address.
  always_comb begin
    imem_addr_err = 1'b0;

    if (insn_fetch_req_valid_raw) begin
      if (|insn_fetch_req_addr_o[1:0]) begin
        // Imem address is unaligned
        imem_addr_err = 1'b1;
      end else if (branch_taken) begin
        imem_addr_err = branch_target_overflow;
      end else begin
        imem_addr_err = next_insn_addr_wide[ImemAddrWidth] & insn_valid_i;
      end
    end
  end

  // Signal error if MuBi input signals take on invalid values as this means something bad is
  // happening. Register the error signal to break circular paths (instruction fetch errors factor
  // into fatal_escalate_en_i, RND errors factor into recov_escalate_en_i).
  assign mubi_err_d = |{mubi4_test_invalid(fatal_escalate_en_i),
                        mubi4_test_invalid(recov_escalate_en_i),
                        mubi_err_q};
  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      mubi_err_q <= 1'b0;
    end else begin
      mubi_err_q <= mubi_err_d;
    end
  end

  // Instruction is illegal based on the static properties of the instruction bits (illegal encoding
  // or illegal WSR/CSR referenced).
  assign illegal_insn_static = insn_illegal_i | ispr_err;

  assign fatal_software_err       = software_err & software_errs_fatal_i;
  assign bad_internal_state_err   = |{state_error_d, loop_hw_err, rf_base_call_stack_hw_err_i,
                                      rf_bignum_spurious_we_err, spurious_secure_wipe_ack_q,
                                      sec_wipe_err_q, mubi_err_q};
  assign reg_intg_violation_err   = rf_bignum_intg_err | ispr_rdata_intg_err;
  assign key_invalid_err          = ispr_rd_bignum_insn & insn_valid_i & key_invalid;
  assign illegal_insn_err         = illegal_insn_static | rf_indirect_err;
  assign call_stack_sw_err        = rf_base_call_stack_sw_err_i;

  // Flag a bad data address error if the data memory address is invalid and it does not come from
  // an empty call stack.  The second case cannot be decided as bad data address because the address
  // on top of the empty call stack may or may not be valid.  (Also, in most RTL simulators an empty
  // call stack that has never been pushed contains an unknown value, so this error bit would become
  // unknown.)  Thus, a data memory address coming from an empty call stack raises a call stack
  // error but never a bad data address error.
  assign bad_data_addr_err = dmem_addr_err &
                             ~(call_stack_sw_err &
                               (ld_insn_with_addr_from_call_stack |
                                st_insn_with_addr_from_call_stack));

  // Identify load instructions that take the memory address from the call stack.
  assign ld_insn_with_addr_from_call_stack = insn_valid_i               &
                                             insn_dec_shared_i.ld_insn  &
                                             insn_dec_base_i.rf_ren_a   &
                                             (insn_dec_base_i.a == 5'd1);

  // Identify store instructions that take the memory address from the call stack.
  assign st_insn_with_addr_from_call_stack = insn_valid_i               &
                                             insn_dec_shared_i.st_insn  &
                                             insn_dec_base_i.rf_ren_a   &
                                             (insn_dec_base_i.a == 5'd1);

  // All software errors that aren't bad_insn_addr. Factored into bad_insn_addr so it is only raised
  // if other software errors haven't ocurred. As bad_insn_addr relates to the next instruction
  // begin fetched it cannot occur if the current instruction has seen an error and failed to
  // execute.
  assign non_insn_addr_software_err = |{key_invalid_err,
                                        loop_sw_err,
                                        illegal_insn_err,
                                        call_stack_sw_err,
                                        bad_data_addr_err};

  assign bad_insn_addr_err = imem_addr_err & ~non_insn_addr_software_err;

  assign err_bits_d = '{
    fatal_software:     fatal_software_err,
    bad_internal_state: bad_internal_state_err,
    reg_intg_violation: reg_intg_violation_err,
    key_invalid:        key_invalid_err,
    loop:               loop_sw_err,
    illegal_insn:       illegal_insn_err,
    call_stack:         call_stack_sw_err,
    bad_data_addr:      bad_data_addr_err,
    bad_insn_addr:      bad_insn_addr_err
  };

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      err_bits_q <= '0;
    end else begin
      if (err_bit_clear_i && !locking_o) begin
        err_bits_q <= '0;
      end else begin
        err_bits_q <= err_bits_q | err_bits_d;
      end
    end
  end
  assign err_bits_o = err_bits_q;

  assign software_err = non_insn_addr_software_err | bad_insn_addr_err;

  assign recoverable_err = mubi4_test_true_loose(recov_escalate_en_i);

  assign internal_fatal_err = |{fatal_software_err,
                                bad_internal_state_err,
                                reg_intg_violation_err};

  // In case of an RMA request, just lock up the controller. This triggers the rotation of the
  // scrambling keys. The start/stop controller takes care of initiating the internal secure wipe
  // and eventually acknowledging the RMA request.
  assign fatal_err = |{internal_fatal_err,
                       mubi4_test_true_loose(fatal_escalate_en_i),
                       mubi4_test_true_strict(rma_req_i)};

  assign recoverable_err_o = recoverable_err | (software_err & ~software_errs_fatal_i);
  assign mems_sec_wipe_o   = (state_d == OtbnStateLocked) & (state_q != OtbnStateLocked);

  assign internal_err = software_err | internal_fatal_err;
  assign err          = software_err | recoverable_err | fatal_err;

  assign prefetch_ignore_errs_o = internal_err;

  // Instructions must not execute if there is an error
  assign insn_executing = insn_valid_i & ~err;

  `ASSERT(ErrBitSetOnErr,
      err & (mubi4_test_false_strict(fatal_escalate_en_i) &
             mubi4_test_false_strict(recov_escalate_en_i) &
             mubi4_test_false_loose(rma_req_i)) |=>
          err_bits_o)
  `ASSERT(ErrSetOnFatalErr, fatal_err |-> err)
  `ASSERT(SoftwareErrIfNonInsnAddrSoftwareErr, non_insn_addr_software_err |-> software_err)

  `ASSERT(ControllerStateValid,
          state_q inside {OtbnStateHalt, OtbnStateRun, OtbnStateStall, OtbnStateLocked})
  // Branch only takes effect in OtbnStateRun so must not go into stall state for branch
  // instructions.
  `ASSERT(NoStallOnBranch,
      insn_valid_i & insn_dec_shared_i.branch_insn |-> state_q != OtbnStateStall)

  // SEC_CM: CONTROLLER.FSM.SPARSE
  `PRIM_FLOP_SPARSE_FSM(u_state_regs, state_d, state_q, otbn_state_e, OtbnStateHalt)

  // SEC_CM: CTRL_FLOW.COUNT
  // Two explicit clear controls, one comes from external to otbn_core and the other is generated
  // internally (by otbn_start_stop_control).
  assign insn_cnt_clear =
    (state_q == OtbnStateLocked) | insn_cnt_clear_ext_i | insn_cnt_clear_int_i;

  always_comb begin
    if (insn_cnt_clear) begin
      insn_cnt_d = 32'd0;
    end else if (insn_executing & ~stall & (insn_cnt_q != 32'hffffffff)) begin
      insn_cnt_d = insn_cnt_q + 32'd1;
    end else begin
      insn_cnt_d = insn_cnt_q;
    end
  end

  always_ff @(posedge clk_i or negedge rst_ni) begin
    if (!rst_ni) begin
      insn_cnt_q <= 32'd0;
    end else begin
      insn_cnt_q <= insn_cnt_d;
    end
  end

  assign insn_cnt_o = insn_cnt_q;

  assign loop_reset = state_reset_i | sec_wipe_zero_i;

  otbn_loop_controller #(
    .ImemAddrWidth(ImemAddrWidth)
  ) u_otbn_loop_controller (
    .clk_i,
    .rst_ni,

    .state_reset_i(loop_reset),

    .insn_valid_i,
    .insn_addr_i,
    .next_insn_addr_i(next_insn_addr),

    .loop_start_req_i       (loop_start_req),
    .loop_start_commit_i    (loop_start_commit),
    .loop_bodysize_i        (loop_bodysize),
    .loop_iterations_i      (loop_iterations),
    .loop_end_addr_predec_i (ctrl_flow_target_predec_i),

    .loop_jump_o     (loop_jump),
    .loop_jump_addr_o(loop_jump_addr),

    .sw_err_o     (loop_sw_err),
    .hw_err_o     (loop_hw_err),
    .predec_err_o (loop_predec_err),

    .jump_or_branch_i(jump_or_branch),
    .otbn_stall_i    (stall),

    .prefetch_loop_active_o,
    .prefetch_loop_iterations_o,
    .prefetch_loop_end_addr_o,
    .prefetch_loop_jump_addr_o
  );

  // loop_start_req indicates the instruction wishes to start a loop, loop_start_commit confirms it
  // should occur.
  assign loop_start_req    = insn_valid_i & insn_dec_shared_i.loop_insn;
  assign loop_start_commit = insn_executing;
  assign loop_bodysize     = insn_dec_base_i.loop_bodysize;
  assign loop_iterations   = insn_dec_base_i.loop_immediate ? insn_dec_base_i.i :
                                                              rf_base_rd_data_a_no_intg;

  // Compute increments which can be optionally applied to indirect register accesses and memory
  // addresses in BN.LID/BN.SID/BN.MOVR instructions.
  assign rf_base_rd_data_a_inc           = rf_base_rd_data_a_no_intg[4:0] + 1'b1;
  assign rf_base_rd_data_b_inc           = rf_base_rd_data_b_no_intg[4:0] + 1'b1;
  // We can avoid a full 32-bit adder here because the offset is 32-bit aligned, so we know the
  // load/store address will only be valid if rf_base_rd_data_a_no_intg[4:0] is zero.
  assign rf_base_rd_data_a_wlen_word_inc = rf_base_rd_data_a_no_intg[31:5] + 27'h1;

  // Choose increment to write back to base register file, only one increment can be written as
  // there is only one write port. Note that where an instruction is incrementing the indirect
  // reference to its destination register (insn_dec_bignum_i.d_inc) that reference is read on the
  // B read port so the B increment is written back.
  always_comb begin
    unique case (1'b1)
      insn_dec_bignum_i.a_inc: begin
        increment_out = {26'b0, rf_base_rd_data_a_inc};
      end
      insn_dec_bignum_i.b_inc: begin
        increment_out = {26'b0, rf_base_rd_data_b_inc};
      end
      insn_dec_bignum_i.d_inc: begin
        increment_out = {26'b0, rf_base_rd_data_b_inc};
      end
      insn_dec_bignum_i.a_wlen_word_inc: begin
        increment_out = {rf_base_rd_data_a_wlen_word_inc, 5'b0};
      end
      default: begin
        // Whenever increment_out is written back to the register file, exactly one of the
        // increment selector signals is high. To prevent the automatic inference of latches in
        // case nothing is written back (rf_wdata_sel != RfWdSelIncr) and to save logic, we choose
        // a valid output as default.
        increment_out = {26'b0, rf_base_rd_data_a_inc};
      end
    endcase
  end

  // Base RF read/write address, enable and commit control
  always_comb begin
    rf_base_rd_addr_a_o = insn_dec_base_i.a;
    rf_base_rd_addr_b_o = insn_dec_base_i.b;
    rf_base_wr_addr_o   = insn_dec_base_i.d;

    // Only commit read or write if the instruction is executing (in particular a read commit pops
    // the call stack so must not occur where a valid instruction sees an error and doesn't
    // execute).
    rf_base_rd_commit_o = insn_executing;
    rf_base_wr_commit_o = insn_executing;

    rf_base_rd_en_a_raw = 1'b0;
    rf_base_rd_en_b_raw = 1'b0;
    rf_base_wr_en_raw   = 1'b0;

    if (insn_valid_i) begin
      if (insn_dec_shared_i.st_insn) begin
        // For stores, both base reads happen in the first cycle of the store instruction. For base
        // stores this is the same cycle as the request. For bignum stores this is the cycle before
        // the request (as the indirect register read to get the store data occurs the following
        // cycle).
        rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a &
          (rf_indirect_stall | (insn_dec_shared_i.subset == InsnSubsetBase));
        rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b &
          (rf_indirect_stall | (insn_dec_shared_i.subset == InsnSubsetBase));

        // Bignum stores can update the base register file where an increment is used.
        rf_base_wr_en_raw   = (insn_dec_shared_i.subset == InsnSubsetBignum) &
                              insn_dec_base_i.rf_we                          &
                              rf_indirect_stall;
      end else if (insn_dec_shared_i.ld_insn) begin
        // For loads, both base reads happen in the same cycle as the request. The address is
        // required for the request and the indirect destination register (only used for Bignum
        // loads) is flopped in ld_insn_bignum_wr_addr_q to correctly deal with the case where it's
        // updated by an increment.
        rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & lsu_load_req_raw;
        rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & lsu_load_req_raw;

        if (insn_dec_shared_i.subset == InsnSubsetBignum) begin
          // Bignum loads can update the base register file where an increment is used. This must
          // always happen in the same cycle as the request as this is where both registers are
          // read.
          rf_base_wr_en_raw = insn_dec_base_i.rf_we & lsu_load_req_raw & rf_indirect_stall;
        end else begin
          // For Base loads write the base register file when the instruction is unstalled (meaning
          // the load data is available).
          rf_base_wr_en_raw = insn_dec_base_i.rf_we & ~stall;
        end
      end else if (insn_dec_bignum_i.rf_wdata_sel == RfWdSelMovSel) begin
        // For MOVR base register reads occur in the first cycle of the instruction. The indirect
        // register read for the bignum data occurs in the following cycle.
        rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & rf_indirect_stall;
        rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & rf_indirect_stall;
        rf_base_wr_en_raw   = insn_dec_base_i.rf_we    & rf_indirect_stall;
      end else begin
        // For all other instructions the read and write happen when the instruction is unstalled.
        rf_base_rd_en_a_raw = insn_dec_base_i.rf_ren_a & ~stall;
        rf_base_rd_en_b_raw = insn_dec_base_i.rf_ren_b & ~stall;
        rf_base_wr_en_raw   = insn_dec_base_i.rf_we    & ~stall;
      end
    end

    if (insn_dec_shared_i.subset == InsnSubsetBignum) begin
      unique case (1'b1)
        insn_dec_bignum_i.a_inc,
        insn_dec_bignum_i.a_wlen_word_inc: begin
          rf_base_wr_addr_o = insn_dec_base_i.a;
        end

        insn_dec_bignum_i.b_inc,
        insn_dec_bignum_i.d_inc: begin
          rf_base_wr_addr_o = insn_dec_base_i.b;
        end
        default: ;
      endcase
    end

    rf_base_rd_en_a_o = rf_base_rd_en_a_raw & ~illegal_insn_static;
    rf_base_rd_en_b_o = rf_base_rd_en_b_raw & ~illegal_insn_static;
    rf_base_wr_en_o   = rf_base_wr_en_raw   & ~illegal_insn_static;
  end

  // Base ALU Operand A MUX
  always_comb begin
    unique case (insn_dec_base_i.op_a_sel)
      OpASelRegister: alu_base_operation_o.operand_a = rf_base_rd_data_a_no_intg;
      OpASelZero:     alu_base_operation_o.operand_a = '0;
      OpASelCurrPc:   alu_base_operation_o.operand_a = {{(32 - ImemAddrWidth){1'b0}}, insn_addr_i};
      default:        alu_base_operation_o.operand_a = rf_base_rd_data_a_no_intg;
    endcase
  end

  // Base ALU Operand B MUX
  always_comb begin
    unique case (insn_dec_base_i.op_b_sel)
      OpBSelRegister:  alu_base_operation_o.operand_b = rf_base_rd_data_b_no_intg;
      OpBSelImmediate: alu_base_operation_o.operand_b = insn_dec_base_i.i;
      default:         alu_base_operation_o.operand_b = rf_base_rd_data_b_no_intg;
    endcase
  end

  assign alu_base_operation_o.op = insn_dec_base_i.alu_op;

  assign alu_base_comparison_o.operand_a = rf_base_rd_data_a_no_intg;
  assign alu_base_comparison_o.operand_b = rf_base_rd_data_b_no_intg;
  assign alu_base_comparison_o.op = insn_dec_base_i.comparison_op;

  assign rf_base_rd_data_a_no_intg = rf_base_rd_data_a_intg_i[31:0];
  assign rf_base_rd_data_b_no_intg = rf_base_rd_data_b_intg_i[31:0];

  logic unused_rf_base_rd_a_intg_bits;

  // TODO(#18266): Implement GPR to ISPR end to end integrity path (ISPR writes from GPR take data
  // from base RF port A)
  assign unused_rf_base_rd_a_intg_bits = |rf_base_rd_data_a_intg_i[38:32];

  // Base register file write MUX. Depending on the data source, integrity bits do or don't have to
  // be appended:
  // - Data sources that require appending integrity bits go into `rf_base_wr_data_no_intg_o` and
  //   `rf_base_wr_data_intg_sel_o` is low.
  // - Data sources that already come with integrity bits go into `rf_base_wr_data_intg_o` and
  //   `rf_base_wr_data_intg_sel_o` is high.
  always_comb begin
    // Default values
    rf_base_wr_data_no_intg_o  = alu_base_operation_result_i;
    rf_base_wr_data_intg_o     = '0;
    rf_base_wr_data_intg_sel_o = 1'b0;

    unique case (insn_dec_base_i.rf_wdata_sel)
      RfWdSelEx: begin
        rf_base_wr_data_no_intg_o  = alu_base_operation_result_i;
      end
      RfWdSelNextPc: begin
        rf_base_wr_data_no_intg_o  = {{(32-(ImemAddrWidth+1)){1'b0}}, next_insn_addr_wide};
      end
      RfWdSelIspr: begin
        rf_base_wr_data_no_intg_o  = csr_rdata;
      end
      RfWdSelIncr: begin
        rf_base_wr_data_no_intg_o  = increment_out;
      end
      RfWdSelLsu: begin
        rf_base_wr_data_intg_sel_o = 1'b1;
        rf_base_wr_data_intg_o     = lsu_base_rdata_i;
      end
      default: ;
    endcase
  end

  for (genvar i = 0; i < BaseWordsPerWLEN; ++i) begin : g_rf_bignum_rd_data
    assign rf_bignum_rd_data_a_no_intg[i*32+:32] = rf_bignum_rd_data_a_intg_i[i*39+:32];
    assign rf_bignum_rd_data_b_no_intg[i*32+:32] = rf_bignum_rd_data_b_intg_i[i*39+:32];
  end

  // Bignum RF control signals from the controller aren't actually used, instead the predecoded
  // one-hot versions are. The predecoded versions get checked against the signals produced here.
  // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
  // always be identical).
  assign rf_bignum_rd_addr_a_unbuf = insn_dec_bignum_i.rf_a_indirect ? insn_bignum_rd_addr_a_q :
                                                                       insn_dec_bignum_i.a;

  prim_buf #(
    .Width(WdrAw)
  ) u_rf_bignum_rd_addr_a_buf (
    .in_i (rf_bignum_rd_addr_a_unbuf),
    .out_o(rf_bignum_rd_addr_a_o)
  );

  assign rf_bignum_rd_en_a_unbuf = insn_dec_bignum_i.rf_ren_a & insn_valid_i & ~stall;

  prim_buf #(
    .Width(1)
  ) u_rf_bignum_rd_en_a_buf (
    .in_i (rf_bignum_rd_en_a_unbuf),
    .out_o(rf_bignum_rd_en_a_o)
  );

  assign rf_bignum_rd_addr_b_unbuf = insn_dec_bignum_i.rf_b_indirect ? insn_bignum_rd_addr_b_q :
                                                                       insn_dec_bignum_i.b;

  prim_buf #(
    .Width(WdrAw)
  ) u_rf_bignum_rd_addr_b_buf (
    .in_i (rf_bignum_rd_addr_b_unbuf),
    .out_o(rf_bignum_rd_addr_b_o)
  );

  assign rf_bignum_rd_en_b_unbuf = insn_dec_bignum_i.rf_ren_b & insn_valid_i & ~stall;

  prim_buf #(
    .Width(1)
  ) u_rf_bignum_rd_en_b_buf (
    .in_i (rf_bignum_rd_en_b_unbuf),
    .out_o(rf_bignum_rd_en_b_o)
  );

  assign alu_bignum_operation_o.operand_a = rf_bignum_rd_data_a_no_intg;

  // Base ALU Operand B MUX
  always_comb begin
    unique case (insn_dec_bignum_i.alu_op_b_sel)
      OpBSelRegister:  alu_bignum_operation_o.operand_b = rf_bignum_rd_data_b_no_intg;
      OpBSelImmediate: alu_bignum_operation_o.operand_b = insn_dec_bignum_i.i;
      default:         alu_bignum_operation_o.operand_b = rf_bignum_rd_data_b_no_intg;
    endcase
  end

  assign alu_bignum_operation_o.op          = insn_dec_bignum_i.alu_op;
  assign alu_bignum_operation_o.shift_right = insn_dec_bignum_i.alu_shift_right;
  assign alu_bignum_operation_o.shift_amt   = insn_dec_bignum_i.alu_shift_amt;
  assign alu_bignum_operation_o.flag_group  = insn_dec_bignum_i.alu_flag_group;
  assign alu_bignum_operation_o.sel_flag    = insn_dec_bignum_i.alu_sel_flag;
  assign alu_bignum_operation_o.alu_flag_en = insn_dec_bignum_i.alu_flag_en & insn_valid_i;
  assign alu_bignum_operation_o.mac_flag_en = insn_dec_bignum_i.mac_flag_en & insn_valid_i;

  assign alu_bignum_operation_valid_o  = insn_valid_i;
  assign alu_bignum_operation_commit_o = insn_executing;

  assign mac_bignum_operation_o.operand_a         = rf_bignum_rd_data_a_no_intg;
  assign mac_bignum_operation_o.operand_b         = rf_bignum_rd_data_b_no_intg;
  assign mac_bignum_operation_o.operand_a_qw_sel  = insn_dec_bignum_i.mac_op_a_qw_sel;
  assign mac_bignum_operation_o.operand_b_qw_sel  = insn_dec_bignum_i.mac_op_b_qw_sel;
  assign mac_bignum_operation_o.wr_hw_sel_upper   = insn_dec_bignum_i.mac_wr_hw_sel_upper;
  assign mac_bignum_operation_o.pre_acc_shift_imm = insn_dec_bignum_i.mac_pre_acc_shift;
  assign mac_bignum_operation_o.zero_acc          = insn_dec_bignum_i.mac_zero_acc;
  assign mac_bignum_operation_o.shift_acc         = insn_dec_bignum_i.mac_shift_out;

  assign mac_bignum_en_o     = insn_valid_i & insn_dec_bignum_i.mac_en;
  assign mac_bignum_commit_o = insn_executing;

  // Move / Conditional Select. Only select B register data when a selection instruction is being
  // executed and the selection flag isn't set. To avoid undesirable SCA leakage between the two
  // registers for non-selection instructions, the B register is blanked except for selection
  // instructions.
  // Note that blanking both registers is not feasible nor absolutely required because:
  // - The flag group selection and flag selection are known in the predecoder stage but the actual
  //   flag isn't.
  // - Selecting the flag in the predocder stage using combinatorial inputs may lead to SCA leakage
  //   between the still combinatorial flag groups and flags within a group which might be
  //   undesirable as well.
  // - When executing a selection instruction, programmers can expected that there will be some SCA
  //   leakage between the two options. But it may be much lesse expected for such leakage to occur
  //   for other instructions.
  `ASSERT(SelFlagValid, insn_valid_i & insn_dec_bignum_i.sel_insn |->
    insn_dec_bignum_i.alu_sel_flag inside {FlagC, FlagL, FlagM, FlagZ})

  // SEC_CM: DATA_REG_SW.SCA
  prim_blanker #(.Width(ExtWLEN)) u_rf_bignum_rd_data_b_intg_blanker (
    .in_i (rf_bignum_rd_data_b_intg_i),
    .en_i (ctrl_flow_predec_i.sel_insn),
    .out_o(rf_bignum_rd_data_b_intg_blanked)
  );

  `ASSERT(BlankingBignumRdDataBSel,
    ~(insn_valid_i & insn_dec_bignum_i.sel_insn) |-> rf_bignum_rd_data_b_intg_blanked == '0,
    clk_i, !rst_ni || ctrl_predec_error || !insn_executing)

  assign selection_result =
    ~ctrl_flow_predec_i.sel_insn | alu_bignum_selection_flag_i ? rf_bignum_rd_data_a_intg_i :
                                                                 rf_bignum_rd_data_b_intg_blanked;

  // Bignum Register file write control

  always_comb begin
    // By default write nothing
    rf_bignum_wr_en_unbuf = 2'b00;

    // Only write if valid instruction wants a bignum rf write and it isn't stalled. If instruction
    // doesn't execute (e.g. due to an error) the write won't commit.
    if (insn_valid_i && insn_dec_bignum_i.rf_we && !rf_indirect_stall) begin
      if (insn_dec_bignum_i.mac_en && insn_dec_bignum_i.mac_shift_out) begin
        // Special handling for BN.MULQACC.SO, only enable upper or lower half depending on
        // mac_wr_hw_sel_upper.
        rf_bignum_wr_en_unbuf = insn_dec_bignum_i.mac_wr_hw_sel_upper ? 2'b10 : 2'b01;
      end else begin
        // For everything else write both halves immediately.
        rf_bignum_wr_en_unbuf = 2'b11;
      end
    end
  end

  // Bignum RF control signals from the controller aren't actually used, instead the predecoded
  // one-hot versions are. The predecoded versions get checked against the signals produced here.
  // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
  // always be identical).
  prim_buf #(
    .Width(2)
  ) u_bignum_wr_en_buf (
    .in_i (rf_bignum_wr_en_unbuf),
    .out_o(rf_bignum_wr_en_o)
  );


  assign rf_bignum_wr_commit_o = |rf_bignum_wr_en_o & insn_executing & !stall;

  assign rf_bignum_indirect_en_o    = insn_executing & rf_indirect_stall;
  assign rf_bignum_rd_a_indirect_en = insn_executing & insn_dec_bignum_i.rf_a_indirect;
  assign rf_bignum_rd_b_indirect_en = insn_executing & insn_dec_bignum_i.rf_b_indirect;
  assign rf_bignum_wr_indirect_en   = insn_executing & insn_dec_bignum_i.rf_d_indirect;

  prim_onehot_enc #(
    .OneHotWidth(NWdr)
  ) rf_bignum_rd_a_idirect_onehot__enc (
    .in_i  (rf_base_rd_data_a_no_intg[4:0]),
    .en_i  (rf_bignum_rd_a_indirect_en),
    .out_o (rf_bignum_rd_a_indirect_onehot_o)
  );

  prim_onehot_enc #(
    .OneHotWidth(NWdr)
  ) rf_bignum_rd_b_indirect_onehot_enc (
    .in_i  (rf_base_rd_data_b_no_intg[4:0]),
    .en_i  (rf_bignum_rd_b_indirect_en),
    .out_o (rf_bignum_rd_b_indirect_onehot_o)
  );

  prim_onehot_enc #(
    .OneHotWidth(NWdr)
  ) rf_bignum_wr_indirect_onehot_enc (
    .in_i  (rf_base_rd_data_b_no_intg[4:0]),
    .en_i  (rf_bignum_wr_indirect_en),
    .out_o (rf_bignum_wr_indirect_onehot_o)
  );

  // For BN.LID sample the indirect destination register index in first cycle as an increment might
  // change it for the second cycle where the load data is written to the bignum register file.
  always_ff @(posedge clk_i) begin
    if (insn_dec_bignum_i.rf_d_indirect) begin
      insn_bignum_wr_addr_q <= rf_base_rd_data_b_no_intg[4:0];
    end

    if (insn_dec_bignum_i.rf_a_indirect) begin
      insn_bignum_rd_addr_a_q <= rf_base_rd_data_a_no_intg[4:0];
    end

    if (insn_dec_bignum_i.rf_b_indirect) begin
      insn_bignum_rd_addr_b_q <= rf_base_rd_data_b_no_intg[4:0];
    end
  end

  // Bignum RF control signals from the controller aren't actually used, instead the predecoded
  // one-hot versions are. The predecoded versions get checked against the signals produced here.
  // Buffer them to ensure they don't get optimised away (with a functionaly correct OTBN they will
  // always be identical).
  assign rf_bignum_wr_addr_unbuf = insn_dec_bignum_i.rf_d_indirect ? insn_bignum_wr_addr_q :
                                                                     insn_dec_bignum_i.d;

  prim_buf #(
    .Width(WdrAw)
  ) u_rf_bignum_wr_addr_buf (
    .in_i (rf_bignum_wr_addr_unbuf),
    .out_o(rf_bignum_wr_addr_o)
  );

  // For the shift-out variant of BN.MULQACC the bottom half of the MAC result is written to one
  // half of a desintation register specified by the instruction (mac_wr_hw_sel_upper). The bottom
  // half of the MAC result must be placed in the appropriate half of the write data (the RF only
  // accepts write data for the top half in the top half of the write data input). Otherwise
  // (shift-out to bottom half and all other BN.MULQACC instructions) simply pass the MAC result
  // through unchanged as write data.
  assign mac_bignum_rf_wr_data[WLEN-1:WLEN/2] =
      insn_dec_bignum_i.mac_wr_hw_sel_upper &&
      insn_dec_bignum_i.mac_shift_out          ? mac_bignum_operation_result_i[WLEN/2-1:0] :
                                                 mac_bignum_operation_result_i[WLEN-1:WLEN/2];

  assign mac_bignum_rf_wr_data[WLEN/2-1:0] = mac_bignum_operation_result_i[WLEN/2-1:0];

  // Bignum register file write MUX. Depending on the data source, integrity bits do or don't have
  // to be appended; see comments on the "Base register file write MUX" for details.
  always_comb begin
    // Default values
    rf_bignum_wr_data_intg_sel_o = 1'b0;
    rf_bignum_wr_data_intg_o     = '0;
    rf_bignum_wr_data_no_intg_o  = alu_bignum_operation_result_i;

    unique case (insn_dec_bignum_i.rf_wdata_sel)
      RfWdSelEx: begin
        rf_bignum_wr_data_no_intg_o  = alu_bignum_operation_result_i;
      end
      RfWdSelMac: begin
        rf_bignum_wr_data_no_intg_o  = mac_bignum_rf_wr_data;
      end
      RfWdSelIspr: begin
        rf_bignum_wr_data_intg_sel_o = 1'b1;
        rf_bignum_wr_data_intg_o     = ispr_rdata_intg_i;
      end
      RfWdSelMovSel: begin
        rf_bignum_wr_data_intg_sel_o = 1'b1;
        rf_bignum_wr_data_intg_o     = selection_result;
      end
      RfWdSelLsu: begin
        rf_bignum_wr_data_intg_sel_o = 1'b1;
        //SEC_CM: BUS.INTEGRITY
        rf_bignum_wr_data_intg_o     = lsu_bignum_rdata_i;
      end
      default: ;
    endcase
  end

  assign rf_a_indirect_err = insn_dec_bignum_i.rf_a_indirect    &
                             (|rf_base_rd_data_a_no_intg[31:5]) &
                             ~rf_base_call_stack_sw_err_i       &
                             rf_base_rd_en_a_o;

  assign rf_b_indirect_err = insn_dec_bignum_i.rf_b_indirect    &
                             (|rf_base_rd_data_b_no_intg[31:5]) &
                             ~rf_base_call_stack_sw_err_i       &
                             rf_base_rd_en_b_o;

  assign rf_d_indirect_err = insn_dec_bignum_i.rf_d_indirect    &
                             (|rf_base_rd_data_b_no_intg[31:5]) &
                             ~rf_base_call_stack_sw_err_i       &
                             rf_base_rd_en_b_o;

  assign rf_indirect_err =
      insn_valid_i & (rf_a_indirect_err | rf_b_indirect_err | rf_d_indirect_err);


  // If the source registers are indirectly indexed and there is a stack error, the source
  // register indices were illegal due to a stack pop error. In this case, ignore bignum RF read
  // integrity errors.
  assign ignore_rf_bignum_intg_errs = (insn_dec_bignum_i.rf_a_indirect |
                                       insn_dec_bignum_i.rf_b_indirect) &
                                      rf_base_call_stack_sw_err_i;

  assign rf_bignum_intg_err = rf_bignum_intg_err_i & ~ignore_rf_bignum_intg_errs;

  // If the destination register is indirectly indexed and there is a stack error, the destination
  // register index was illegal due to a stack pop error. In this case, ignore bignum RF
  // write-enable errors.
  assign ignore_rf_bignum_spurious_we_errs = insn_dec_bignum_i.rf_d_indirect &
                                             rf_base_call_stack_sw_err_i;

  assign rf_bignum_spurious_we_err = rf_bignum_spurious_we_err_i &
                                     ~ignore_rf_bignum_spurious_we_errs;

  // CSR/WSR/ISPR handling
  // ISPRs (Internal Special Purpose Registers) are the internal registers. CSRs and WSRs are the
  // ISA visible versions of those registers in the base and bignum ISAs respectively.

  assign csr_addr     = csr_e'(insn_dec_base_i.i[11:0]);
  assign csr_sub_addr = insn_dec_base_i.i[$clog2(BaseWordsPerWLEN)-1:0];

  always_comb begin
    ispr_addr_base      = IsprMod;
    ispr_word_addr_base = '0;
    csr_illegal_addr    = 1'b0;

    unique case (csr_addr)
      CsrFlags, CsrFg0, CsrFg1: begin
        ispr_addr_base      = IsprFlags;
        ispr_word_addr_base = '0;
      end
      CsrMod0, CsrMod1, CsrMod2, CsrMod3, CsrMod4, CsrMod5, CsrMod6, CsrMod7: begin
        ispr_addr_base      = IsprMod;
        ispr_word_addr_base = csr_sub_addr;
      end
      CsrRndPrefetch: begin
        // Reading from RND_PREFETCH results in 0, there is no ISPR to read so no address is set.
        // The csr_rdata mux logic takes care of producing the 0.
      end
      CsrRnd: begin
        ispr_addr_base      = IsprRnd;
        ispr_word_addr_base = '0;
      end
      CsrUrnd: begin
        ispr_addr_base      = IsprUrnd;
        ispr_word_addr_base = '0;
      end
      default: csr_illegal_addr = 1'b1;
    endcase
  end

  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_word_sel_base
    assign ispr_word_sel_base[i_word] = ispr_word_addr_base == i_word;
  end

  // Decode wide ISPR read data.
  logic [WLEN-1:0]                ispr_rdata;
  logic [2*BaseWordsPerWLEN-1:0]  ispr_rdata_intg_err_wide;
  logic [BaseWordsPerWLEN-1:0]    ispr_rdata_intg_err_narrow;
  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_rdata_dec
    prim_secded_inv_39_32_dec i_secded_dec (
      .data_i     (ispr_rdata_intg_i[i_word*39+:39]),
      .data_o     (/* unused because we abort on any integrity error */),
      .syndrome_o (/* unused */),
      .err_o      (ispr_rdata_intg_err_wide[i_word*2+:2])
    );
    assign ispr_rdata[i_word*32+:32] = ispr_rdata_intg_i[i_word*39+:32];
    assign ispr_rdata_intg_err_narrow[i_word] = |(ispr_rdata_intg_err_wide[i_word*2+:2]);
  end

  // Propagate integrity error only if wide ISPR is used.

  // Handle ISPR integrity error detection. We've got a bitmask of ISPR words that failed their
  // integrity check (ispr_rdata_intg_err_narrow), but a nonzero entry may not be a problem if we
  // don't actually use the data.
  //
  // The situations when the data is actually used are:
  //
  //   (1) This is a bignum instruction that writes back to the bignum register file by reading an
  //       ISPR. In this case, we actually pass the data through with integrity bits, but it
  //       shouldn't hurt to add fault detection at this point.
  //
  //   (2) This instruction consumes the data by selecting a word from an ISPR and then writing it
  //       back. This happens for things like CSRRS instructions, where the data flows to the base
  //       register file through rf_base_wr_data_no_intg_o and back to the ISPR through
  //       ispr_base_wdata_o. The word used is given by the onehot ispr_word_sel_base mask.
  //
  // In both cases, there's a special case for the RND_PREFETCH register, which doesn't actually
  // have any backing data. It reads as zero with invalid integrity bits which we want to ignore.

  // Are we reading all the ISPR data? (case (1) above)
  logic all_ispr_words_used;
  assign all_ispr_words_used = (insn_dec_bignum_i.rf_wdata_sel == RfWdSelIspr);

  // Are we reading just one word of the ISPR data? (case (2) above).
  logic one_ispr_word_used;
  assign one_ispr_word_used = ispr_rd_insn & (insn_dec_shared_i.subset == InsnSubsetBase);

  // A bit-mask giving which ISPR words are being read
  logic [BaseWordsPerWLEN-1:0] ispr_read_mask;
  assign ispr_read_mask = all_ispr_words_used ? '1 :
                          one_ispr_word_used  ? ispr_word_sel_base : '0;

  // Use ispr_read_mask to qualify the error bit-mask that came out of the integrity decoder.
  logic [BaseWordsPerWLEN-1:0] ispr_rdata_used_intg_err;
  assign ispr_rdata_used_intg_err = ispr_read_mask & ispr_rdata_intg_err_narrow;

  // We only architecturally read the ISPR when there's a non-stalled instruction. This is also the
  // place where we factor in the special RND_PREFETCH behaviour. We also need to squash any
  // integrity errors if we're reading a sideload key which isn't currently valid (this will
  // generate a key_invalid error, but we shouldn't have any behaviour that depends on what happens
  // to be on the pins)
  logic non_prefetch_insn_running;
  assign non_prefetch_insn_running = (insn_valid_i & ~stall &
                                      (csr_addr != CsrRndPrefetch) & ~key_invalid);

  assign ispr_rdata_intg_err = non_prefetch_insn_running & |(ispr_rdata_used_intg_err);

  `ASSERT_KNOWN(IsprRdataIntgErrKnown_A, ispr_rdata_intg_err)

  for (genvar i_bit = 0; i_bit < 32; i_bit++) begin : g_csr_rdata_mux
    for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_csr_rdata_mux_inner
      assign csr_rdata_mux[i_bit][i_word] =
          ispr_rdata[i_word*32 + i_bit] & ispr_word_sel_base[i_word];
    end

    assign csr_rdata_raw[i_bit] = |csr_rdata_mux[i_bit];
  end

  // Specialised read data handling for CSR reads where raw read data needs modification.
  always_comb begin
    csr_rdata = csr_rdata_raw;

    unique case (csr_addr)
      // For FG0/FG1 select out appropriate bits from FLAGS ISPR and pad the rest with zeros.
      CsrFg0:         csr_rdata = {28'b0, csr_rdata_raw[3:0]};
      CsrFg1:         csr_rdata = {28'b0, csr_rdata_raw[7:4]};
      CsrRndPrefetch: csr_rdata = '0;
      default: ;
    endcase
  end

  assign csr_wdata_raw = insn_dec_shared_i.ispr_rs_insn ? csr_rdata | rf_base_rd_data_a_no_intg :
                                                          rf_base_rd_data_a_no_intg;

  // Specialised write data handling for CSR writes where raw write data needs modification.
  always_comb begin
    csr_wdata = csr_wdata_raw;

    unique case (csr_addr)
      // For FG0/FG1 only modify relevant part of FLAGS ISPR.
      CsrFg0: csr_wdata = {24'b0, csr_rdata_raw[7:4], csr_wdata_raw[3:0]};
      CsrFg1: csr_wdata = {24'b0, csr_wdata_raw[3:0], csr_rdata_raw[3:0]};
      default: ;
    endcase
  end

  // ISPR RS (read and set) must not be combined with ISPR RD or WR (read or write). ISPR RD and
  // WR (read and write) is allowed.
  `ASSERT(NoIsprRorWAndRs, insn_valid_i |-> ~(insn_dec_shared_i.ispr_rs_insn   &
                                              (insn_dec_shared_i.ispr_rd_insn |
                                               insn_dec_shared_i.ispr_wr_insn)))


  assign wsr_addr = wsr_e'(insn_dec_bignum_i.i[WsrNumWidth-1:0]);

  always_comb begin
    ispr_addr_bignum = IsprMod;
    wsr_illegal_addr = 1'b0;
    key_invalid      = 1'b0;

    unique case (wsr_addr)
      WsrMod:  ispr_addr_bignum = IsprMod;
      WsrRnd:  ispr_addr_bignum = IsprRnd;
      WsrUrnd: ispr_addr_bignum = IsprUrnd;
      WsrAcc:  ispr_addr_bignum = IsprAcc;
      WsrKeyS0L: begin
        ispr_addr_bignum = IsprKeyS0L;
        key_invalid = ~sideload_key_shares_valid_i[0];
      end
      WsrKeyS0H: begin
        ispr_addr_bignum = IsprKeyS0H;
        key_invalid = ~sideload_key_shares_valid_i[0];
      end
      WsrKeyS1L: begin
        ispr_addr_bignum = IsprKeyS1L;
        key_invalid = ~sideload_key_shares_valid_i[1];
      end
      WsrKeyS1H: begin
        ispr_addr_bignum = IsprKeyS1H;
        key_invalid = ~sideload_key_shares_valid_i[1];
      end
      default: wsr_illegal_addr = 1'b1;
    endcase
  end

  assign wsr_wdata = insn_dec_shared_i.ispr_rs_insn ? ispr_rdata | rf_bignum_rd_data_a_no_intg :
                                                      rf_bignum_rd_data_a_no_intg;

  assign ispr_illegal_addr = insn_dec_shared_i.subset == InsnSubsetBase ? csr_illegal_addr :
                                                                          wsr_illegal_addr;

  assign ispr_err = ispr_illegal_addr & insn_valid_i & (insn_dec_shared_i.ispr_rd_insn |
                                                        insn_dec_shared_i.ispr_wr_insn |
                                                        insn_dec_shared_i.ispr_rs_insn);

  assign ispr_wr_insn = insn_dec_shared_i.ispr_wr_insn | insn_dec_shared_i.ispr_rs_insn;
  assign ispr_rd_insn = insn_dec_shared_i.ispr_rd_insn | insn_dec_shared_i.ispr_rs_insn;

  assign ispr_flags_wr_o = insn_dec_shared_i.ispr_flags_wr;

  // Write to RND_PREFETCH must not produce ISR write
  assign ispr_wr_base_insn =
    ispr_wr_insn & (insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr != CsrRndPrefetch);

  assign ispr_wr_bignum_insn = ispr_wr_insn & (insn_dec_shared_i.subset == InsnSubsetBignum);
  assign ispr_rd_bignum_insn = ispr_rd_insn & (insn_dec_shared_i.subset == InsnSubsetBignum);

  assign ispr_addr_o         = insn_dec_shared_i.subset == InsnSubsetBase ? ispr_addr_base :
                                                                            ispr_addr_bignum;
  assign ispr_base_wdata_o   = csr_wdata;
  assign ispr_base_wr_en_o   = {BaseWordsPerWLEN{ispr_wr_base_insn & insn_valid_i}} &
                               ispr_word_sel_base;

  for (genvar i_word = 0; i_word < BaseWordsPerWLEN; i_word++) begin : g_ispr_bignum_wdata_enc
    prim_secded_inv_39_32_enc i_secded_enc (
      .data_i(wsr_wdata[i_word*32+:32]),
      .data_o(ispr_bignum_wdata_intg_o[i_word*39+:39])
    );
  end
  assign ispr_bignum_wr_en_o = ispr_wr_bignum_insn & insn_valid_i;

  assign ispr_wr_commit_o = ispr_wr_insn & insn_executing; 
  
  assign ispr_rd_en_o     = ispr_rd_insn & insn_valid_i &
    ~((insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr == CsrRndPrefetch));

  // For BN.SID the LSU address is computed in the first cycle by the base ALU. The store request
  // itself occurs in the second cycle when the store data is available (from the indirect register
  // read). The calculated address is saved in a flop here so it's available for use in the second
  // cycle.
  assign lsu_addr_saved_d = alu_base_operation_result_i[DmemAddrWidth-1:0];
  always_ff @(posedge clk_i) begin
    lsu_addr_saved_q <= lsu_addr_saved_d;
  end

  //assign expected_lsu_addr_en_predec = insn_valid & insn_dec_shared_i.ld_insn

  // lsu_load_req_raw/lsu_store_req_raw indicate an instruction wishes to perform a store or a load.
  // lsu_load_req_o/lsu_store_req_o factor in whether an instruction is actually executing (it may
  // be suppressed due an error) and command the load or store to happen when asserted.
  assign lsu_load_req_raw = insn_valid_i & insn_dec_shared_i.ld_insn & (state_q == OtbnStateRun);
  assign lsu_load_req_o   = insn_executing & lsu_load_req_raw;

  assign lsu_store_req_raw = insn_valid_i & insn_dec_shared_i.st_insn & ~rf_indirect_stall;
  assign lsu_store_req_o   = insn_executing & lsu_store_req_raw;

  assign lsu_req_subset_o = insn_dec_shared_i.subset;

  // To simplify blanking logic all two cycle memory operations (BN.LID, BN.SID, LW) present the
  // calculated address in their first cycle and the saved address in the second cycle. This results
  // in lsu_addr_o remaining stable for the entire instruction. Only SW is a single cycle
  // instruction so it only presents the calculated address. The stability property is checked by an
  // assertion.
  assign lsu_addr_saved_sel =
    insn_valid_i & ((insn_dec_shared_i.subset == InsnSubsetBignum) ||
                    insn_dec_shared_i.ld_insn                         ? ~stall : 1'b0);

  assign lsu_addr = lsu_addr_saved_sel ? lsu_addr_saved_q                                :
                                         alu_base_operation_result_i[DmemAddrWidth-1:0];

  // SEC_CM: CTRL.REDUN
  assign expected_lsu_addr_en =
    insn_valid_i & (insn_dec_shared_i.ld_insn | insn_dec_shared_i.st_insn);

  assign lsu_predec_error = expected_lsu_addr_en != lsu_addr_en_predec_i;

  assign expected_call_stack_push =
    insn_valid_i & insn_dec_base_i.rf_we & rf_base_wr_addr_o == 5'd1;

  assign expected_call_stack_pop = insn_valid_i &
                                   ((insn_dec_base_i.rf_ren_a & rf_base_rd_addr_a_o == 5'd1) |
                                    (insn_dec_base_i.rf_ren_b & rf_base_rd_addr_b_o == 5'd1));

  // Check branch target against the precalculated target from pre-decode. Pre-decode cannot
  // calculate the jump target of a JALR as it requires a register read so this is excluded from the
  // check (by looking at the ALU op a selection).
  assign branch_target_predec_error =
    insn_dec_shared_i.branch_insn                                            &
    insn_dec_shared_i.jump_insn & insn_dec_base_i.op_a_sel != OpASelRegister &
    (ctrl_flow_target_predec_i != branch_target);

  assign ctrl_predec_error =
    |{ctrl_flow_predec_i.jump_insn       != (insn_dec_shared_i.jump_insn   & insn_valid_i),
      ctrl_flow_predec_i.loop_insn       != (insn_dec_shared_i.loop_insn   & insn_valid_i),
      ctrl_flow_predec_i.branch_insn     != (insn_dec_shared_i.branch_insn & insn_valid_i),
      ctrl_flow_predec_i.sel_insn        != (insn_dec_bignum_i.sel_insn    & insn_valid_i),
      ctrl_flow_predec_i.call_stack_push != expected_call_stack_push,
      ctrl_flow_predec_i.call_stack_pop  != expected_call_stack_pop,
      branch_target_predec_error,
      loop_predec_err};

  assign predec_error_o = lsu_predec_error | ctrl_predec_error;

  // SEC_CM: DATA_REG_SW.SCA
  prim_blanker #(.Width(DmemAddrWidth)) u_lsu_addr_blanker (
    .in_i (lsu_addr),
    .en_i (lsu_addr_en_predec_i),
    .out_o(lsu_addr_blanked)
  );

  // Check stability property described above (see the lsu_addr_saved_sel signal) holds.
  `ASSERT(LsuAddrBlankedStable_A, insn_valid_i & stall & ~err |=> $stable(lsu_addr_blanked))

  assign lsu_addr_o = lsu_addr_blanked; 

  assign lsu_base_wdata_o   = rf_base_rd_data_b_intg_i;
  assign lsu_bignum_wdata_o = rf_bignum_rd_data_b_intg_i;

  assign dmem_addr_unaligned_bignum =
      (lsu_req_subset_o == InsnSubsetBignum) & (|lsu_addr_o[$clog2(WLEN/8)-1:0]);
  assign dmem_addr_unaligned_base   =
      (lsu_req_subset_o == InsnSubsetBase)   & (|lsu_addr_o[1:0]);
  assign dmem_addr_overflow         = |alu_base_operation_result_i[31:DmemAddrWidth];

  // A dmem address is checked the cycle it is available. For bignum stores this is the first cycle
  // where the base register file read occurs, with the store request occurring the following cycle.
  // For all other loads and stores the dmem address is available the same cycle as the request.
  assign dmem_addr_err_check =
    (lsu_req_subset_o == InsnSubsetBignum) &
    insn_dec_shared_i.st_insn               ? rf_indirect_stall :
                                              lsu_load_req_raw | lsu_store_req_raw;

  assign dmem_addr_err =
      insn_valid_i & dmem_addr_err_check & (dmem_addr_overflow         |
                                            dmem_addr_unaligned_bignum |
                                            dmem_addr_unaligned_base);

  assign rnd_req_raw = insn_valid_i & ispr_rd_insn & (ispr_addr_o == IsprRnd);
  // Don't factor rnd_rep/fips_err_i into rnd_req_o. This would lead to a combo loop.
  assign rnd_req_o = rnd_req_raw & insn_valid_i & ~(software_err | fatal_err);

  assign rnd_prefetch_req_o = insn_executing & ispr_wr_insn &
      (insn_dec_shared_i.subset == InsnSubsetBase) & (csr_addr == CsrRndPrefetch);
endmodule


    """


    Identify the CWE relevant to the security issue for the given RTL.
    Obtain details of the CWE.

    Then determine if there are security issues relevant to the identified CWE in the RTL.
    Refer to the code that corresponds to the issues identified.
    
================================== Ai Message ==================================

[{'text': "I'll analyze the RTL code for security concerns related to control-flow integrity, specifically focusing on predecode redundancy checks and branch target validation.", 'type': 'text'}, {'id': 'toolu_013XaNFA6gn1ecuQnbbBt8Lz', 'input': {'security_issue': 'Control-flow integrity validate predecode redundancy checks and branch target check'}, 'name': 'llm_cwe_details_retriever_tool', 'type': 'tool_use'}]
Tool Calls:
  llm_cwe_details_retriever_tool (toolu_013XaNFA6gn1ecuQnbbBt8Lz)
 Call ID: toolu_013XaNFA6gn1ecuQnbbBt8Lz
  Args:
    security_issue: Control-flow integrity validate predecode redundancy checks and branch target check
================================= Tool Message =================================
Name: llm_cwe_details_retriever_tool

Successfully executed:
```LLM CWE details retriever tool
```
Output:
 CWE-1264: Hardware Logic with Insecure De-Synchronization between Control and Data Channels
The hardware logic for error handling and security checks can incorrectly forward data before the security check is complete.
Many high-performance on-chip bus protocols and processor data-paths employ separate channels for control and data to increase parallelism and maximize throughput. Bugs in the hardware logic that handle errors and security checks can make it possible for data to be forwarded before the completion of the security checks. If the data can propagate to a location in the hardware observable to an attacker, loss of data confidentiality can occur. 'Meltdown' is a concrete example of how de-synchronization between data and permissions checking logic can violate confidentiality requirements. Data loaded from a page marked as privileged was returned to the cpu regardless of current privilege level for performance reasons. The assumption was that the cpu could later remove all traces of this data during the handling of the illegal memory access exception, but this assumption was proven false as traces of the secret data were not removed from the microarchitectural state.
Example 1
There are several standard on-chip bus protocols used in modern SoCs to allow communication between components. There are a wide variety of commercially available hardware IP implementing the interconnect logic for these protocols. A bus connects components which initiate/request communications such as processors and DMA controllers (bus masters) with peripherals which respond to requests. In a typical system, the privilege level or security designation of the bus master along with the intended functionality of each peripheral determine the security policy specifying which specific bus masters can access specific peripherals. This security policy (commonly referred to as a bus firewall) can be enforced using separate IP/logic from the actual interconnect responsible for the data routing.
(bad code)
Example Language: Other
The firewall and data routing logic becomes de-synchronized due to a hardware logic bug allowing components that should not be allowed to communicate to share data. For example, consider an SoC with two processors. One is being used as a root of trust and can access a cryptographic key storage peripheral. The other processor (application cpu) may run potentially untrusted code and should not access the key store. If the application cpu can issue a read request to the key store which is not blocked due to de-synchronization of data routing and the bus firewall, disclosure of cryptographic keys is possible.
(good code)
Example Language: Other
All data is correctly buffered inside the interconnect until the firewall has determined that the endpoint is allowed to receive the data.


================================== Ai Message ==================================

Now let me analyze the RTL code for control-flow integrity issues related to CWE-1264 and similar security concerns:

## Security Analysis: Control-Flow Integrity Issues

Based on the CWE-1264 analysis and examination of the RTL code, I've identified several security concerns related to control-flow integrity, predecode redundancy checks, and branch target validation:

### 1. **Predecode Redundancy Check Vulnerabilities (Lines 1045-1065)**

```systemverilog
// SEC_CM: CTRL.REDUN
assign expected_lsu_addr_en =
  insn_valid_i & (insn_dec_shared_i.ld_insn | insn_dec_shared_i.st_insn);

assign lsu_predec_error = expected_lsu_addr_en != lsu_addr_en_predec_i;

assign expected_call_stack_push =
  insn_valid_i & insn_dec_base_i.rf_we & rf_base_wr_addr_o == 5'd1;

assign expected_call_stack_pop = insn_valid_i &
                                 ((insn_dec_base_i.rf_ren_a & rf_base_rd_addr_a_o == 5'd1) |
                                  (insn_dec_base_i.rf_ren_b & rf_base_rd_addr_b_o == 5'd1));
```

**Security Issue**: The predecode redundancy checks may allow de-synchronization between control and data paths. If `lsu_predec_error` is detected but not properly handled before data forwarding, it could lead to unauthorized memory accesses.

### 2. **Branch Target Validation Bypass (Lines 1067-1072)**

```systemverilog
// Check branch target against the precalculated target from pre-decode
assign branch_target_predec_error =
  insn_dec_shared_i.branch_insn                                            &
  insn_dec_shared_i.jump_insn & insn_dec_base_i.op_a_sel != OpASelRegister &
  (ctrl_flow_target_predec_i != branch_target);
```

**Security Issue**: The branch target check excludes JALR instructions (`op_a_sel != OpASelRegister`), creating a potential control-flow integrity bypass. Attackers could potentially use JALR to jump to unauthorized code locations without proper validation.

### 3. **Control-Flow Predecode Error Handling (Lines 1074-1082)**

```systemverilog
assign ctrl_predec_error =
  |{ctrl_flow_predec_i.jump_insn       != (insn_dec_shared_i.jump_insn   & insn_valid_i),
    ctrl_flow_predec_i.loop_insn       != (insn_dec_shared_i.loop_insn   & insn_valid_i),
    ctrl_flow_predec_i.branch_insn     != (insn_dec_shared_i.branch_insn & insn_valid_i),
    ctrl_flow_predec_i.sel_insn        != (insn_dec_bignum_i.sel_insn    & insn_valid_i),
    ctrl_flow_predec_i.call_stack_push != expected_call_stack_push,
    ctrl_flow_predec_i.call_stack_pop  != expected_call_stack_pop,
    branch_target_predec_error,
    loop_predec_err};
```

**Security Issue**: While comprehensive, this error detection may not immediately halt execution, potentially allowing malicious instructions to proceed before the error is processed.

### 4. **Data Blanking Logic Vulnerability (Lines 1084-1090)**

```systemverilog
// SEC_CM: DATA_REG_SW.SCA
prim_blanker #(.Width(DmemAddrWidth)) u_lsu_addr_blanker (
  .in_i (lsu_addr),
  .en_i (lsu_addr_en_predec_i),
  .out_o(lsu_addr_blanked)
);
```

**Security Issue**: The address blanking
================================= Tool Message =================================
Name: run_llm_cwe_checker_agent

Now let me analyze the RTL code for control-flow integrity issues related to CWE-1264 and similar security concerns:

## Security Analysis: Control-Flow Integrity Issues

Based on the CWE-1264 analysis and examination of the RTL code, I've identified several security concerns related to control-flow integrity, predecode redundancy checks, and branch target validation:

### 1. **Predecode Redundancy Check Vulnerabilities (Lines 1045-1065)**

```systemverilog
// SEC_CM: CTRL.REDUN
assign expected_lsu_addr_en =
  insn_valid_i & (insn_dec_shared_i.ld_insn | insn_dec_shared_i.st_insn);

assign lsu_predec_error = expected_lsu_addr_en != lsu_addr_en_predec_i;

assign expected_call_stack_push =
  insn_valid_i & insn_dec_base_i.rf_we & rf_base_wr_addr_o == 5'd1;

assign expected_call_stack_pop = insn_valid_i &
                                 ((insn_dec_base_i.rf_ren_a & rf_base_rd_addr_a_o == 5'd1) |
                                  (insn_dec_base_i.rf_ren_b & rf_base_rd_addr_b_o == 5'd1));
```

**Security Issue**: The predecode redundancy checks may allow de-synchronization between control and data paths. If `lsu_predec_error` is detected but not properly handled before data forwarding, it could lead to unauthorized memory accesses.

### 2. **Branch Target Validation Bypass (Lines 1067-1072)**

```systemverilog
// Check branch target against the precalculated target from pre-decode
assign branch_target_predec_error =
  insn_dec_shared_i.branch_insn                                            &
  insn_dec_shared_i.jump_insn & insn_dec_base_i.op_a_sel != OpASelRegister &
  (ctrl_flow_target_predec_i != branch_target);
```

**Security Issue**: The branch target check excludes JALR instructions (`op_a_sel != OpASelRegister`), creating a potential control-flow integrity bypass. Attackers could potentially use JALR to jump to unauthorized code locations without proper validation.

### 3. **Control-Flow Predecode Error Handling (Lines 1074-1082)**

```systemverilog
assign ctrl_predec_error =
  |{ctrl_flow_predec_i.jump_insn       != (insn_dec_shared_i.jump_insn   & insn_valid_i),
    ctrl_flow_predec_i.loop_insn       != (insn_dec_shared_i.loop_insn   & insn_valid_i),
    ctrl_flow_predec_i.branch_insn     != (insn_dec_shared_i.branch_insn & insn_valid_i),
    ctrl_flow_predec_i.sel_insn        != (insn_dec_bignum_i.sel_insn    & insn_valid_i),
    ctrl_flow_predec_i.call_stack_push != expected_call_stack_push,
    ctrl_flow_predec_i.call_stack_pop  != expected_call_stack_pop,
    branch_target_predec_error,
    loop_predec_err};
```

**Security Issue**: While comprehensive, this error detection may not immediately halt execution, potentially allowing malicious instructions to proceed before the error is processed.

### 4. **Data Blanking Logic Vulnerability (Lines 1084-1090)**

```systemverilog
// SEC_CM: DATA_REG_SW.SCA
prim_blanker #(.Width(DmemAddrWidth)) u_lsu_addr_blanker (
  .in_i (lsu_addr),
  .en_i (lsu_addr_en_predec_i),
  .out_o(lsu_addr_blanked)
);
```

**Security Issue**: The address blanking
================================== Ai Message ==================================

Summary of security properties and register interface policies for OTBN (from documentation)

Core security/operational properties
- Operational states: init (busy performing internal secure wipe), idle, busy (execute or secure wipe operations), locked (fatal error or RMA). STATUS reflects these.
- Bus memory access control:
  - IMEM/DMEM accessible via register windows only when OTBN is idle; byte writes not supported.
  - If busy or locked, reads return 0 and writes are ignored.
  - If busy, any access additionally triggers a fatal ILLEGAL_BUS_ACCESS error.
- Data protection:
  - SECDED integrity (39,32 Hsiao) on all 32-bit transfers internally; ECC checked on reads.
  - IMEM/DMEM are scrambled at rest with OTP-provided ephemeral keys; keys can be rotated by secure wipes.
  - Instruction prefetch integrity-checked; no speculation.
- Randomness:
  - RND from EDN (32-bit transactions, 8 per 256-bit word), with repetition check and FIPS flags.
  - URND local PRNG reseeded at start; advances every cycle; all-zero state is fatal.
- Errors and alerts:
  - ERR_BITS captures errors at end of operation (or none for non-running detection); some recoverable, others fatal.
  - Fatal alerts are continuous and require reset to clear; FATAL_ALERT_CAUSE latches fatal reasons until reset.
- Secure wipe:
  - DMEM/IMEM secure wipe: replace scramble key with URND then request new keys from OTP.
  - Internal secure wipe: two-step URND overwrite (pre/post reseed) of registers and internal state; triggered at reset and on operation end, and during fatal handling.

Register interface policies (registers.md)
- CMD (wo): Start EXECUTE / SEC_WIPE_DMEM / SEC_WIPE_IMEM. Writes ignored if not idle (enforced by top-level logic).
- CTRL.software_errs_fatal (rw): Controls whether software errors are treated as fatal; writes ignored if not idle (enforced by top-level logic).
- STATUS (ro): Exposes current state.
- ERR_BITS (rw): Host can clear to zero when OTBN is not running; writes while running are ignored.
- FATAL_ALERT_CAUSE (ro): Sticky until reset.
- INSN_CNT (rw to clear): Counts executed instructions; can be cleared when not running.
- LOAD_CHECKSUM (rw): 32-bit CRC accumulator over bus writes to IMEM/DMEM.
- IMEM/DMEM windows (rw): Only usable while idle; if accessed while busy/locked: reads return 0, writes ignored; if busy, also raises ILLEGAL_BUS_ACCESS. Byte writes not supported.

Security analysis and identified RTL issues

Issue 1
- File: hw/ip/otbn/rtl/otbn.sv
- Line numbers: 448, 690
- Description: Bus read-data blanking enable is hardwired to 1 for IMEM and DMEM.
  - imem: assign imem_rdata_bus_en_d = 1'b1;
  - dmem: assign dmem_rdata_bus_en_d = 1'b1;
  The comments and assertions require that the bus read data interface be blanked (return zeros) while the core is executing, when returning dummy responses to illegal bus accesses, and when OTBN is locked. With the enable stuck at 1, the prim_blanker passes IMEM/DMEM data through during these states, contradicting design intent and causing leakage. Multiple assertions nearby assume dynamic gating (e.g., ImemRDataBusDisabledWhenCoreAccess_A, DmemRDataBusDisabledWhenLocked_A), which would fail if assertions were exercised. Security impact: Host can observe IMEM/DMEM contents during EXECUTE or LOCKED states or during dummy responses.
- Security aspect affected: Confidentiality and access control of IMEM/DMEM over TL-UL during BUSY/LOCKED; Data-observable side-channel mitigation (blanking).
  - Relevant CWEs: CWE-200 (Information Exposure), CWE-284 (Improper Access Control), CWE-693 (Protection Mechanism Failure), CWE-668 (Exposure of Resource to Wrong Sphere).
- Tools used: Anomaly Detector (flagged unconditional constants as outliers), Similar Bug Agent (found both IMEM and DMEM instances), CWE Agent (context: confidentiality checks around bus blanking and memory access control).
- Recommended fix: Drive the blanker enables from state, not a constant. For example:
  - assign imem_rdata_bus_en_d = ~(imem_access_core | imem_dummy_response_d | locking);
  - assign dmem_rdata_bus_en_d = ~(dmem_access_core | dmem_dummy_response_d | locking);
  This matches the comments and nearby assertions. Ensure timing aligns with the registered use of locking_q in the data path and assertions.

Issue 2
- File: hw/ip/otbn/rtl/otbn_controller.sv
- Line numbers: 10671072
- Description: Branch target predecode redundancy check is effectively disabled by a logic error.
  - Current code:
    assign branch_target_predec_error =
      insn_dec_shared_i.branch_insn                                            &
      insn_dec_shared_i.jump_insn & insn_dec_base_i.op_a_sel != OpASelRegister &
      (ctrl_flow_target_predec_i != branch_target);
  The conjunction requires both branch_insn and jump_insn simultaneously, which cannot occur for a single instruction class; due to operator precedence, jump_insn & (op_a_sel != OpASelRegister) is further and-ed with branch_insn. This makes the check nearly always false, disabling a key control-flow integrity redundancy check that should compare the calculated target and the predecoded target (except for JALR cases). Security impact: Mismatched branch/jump targets may not be detected, reducing control-flow error detection coverage.
- Security aspect affected: Control-flow integrity and predecode redundancy; fault detection coverage.
  - Relevant CWEs: CWE-693 (Protection Mechanism Failure), CWE-1319 (Incorrect Calculation), CWE-1245 (Improper FSM behavior), CWE-1264 (per CWE agent mapping: control-flow integrity in hardware).
- Tools used: Anomaly Detector (flagged expression as anomalous), CWE Agent (control-flow integrity mapping and review).
- Recommended fix: Correct boolean condition to cover branches/jumps (excluding JALR as intended). For example:
  - assign branch_target_predec_error =
      (insn_dec_shared_i.branch_insn | insn_dec_shared_i.jump_insn) &
      (insn_dec_base_i.op_a_sel != OpASelRegister) &
      (ctrl_flow_target_predec_i != branch_target);
  Add directed tests ensuring mismatches trigger ctrl_predec_error for applicable instructions.

Issue 3 (design hardening/consistency, low severity)
- File: hw/ip/otbn/rtl/otbn.sv
- Line numbers: 892932 (ERR_BITS handling), 856876 (STATUS), 396436 (CTRL handling)
- Description: ERR_BITS clearing is allowed whenever is_not_running_q is true (not busy in execute or key-request or secure wipe). During a fatal path, the controller sets state_d = Locked, initiates secure wipes, and delays the external locking_o signal until wipe completes; there is a window where is_not_running_q may be true while the design is transitioning to Locked or performing wipes. This may allow host-triggered clearing of ERR_BITS before locking_o becomes true, potentially erasing evidence of a fatal/internal error in ERR_BITS. FATAL_ALERT_CAUSE remains sticky until reset, limiting impact.
- Security aspect affected: Error reporting integrity; auditability.
  - Relevant CWEs: CWE-693 (Protection Mechanism Failure), CWE-778 (Insufficient Logging).
- Tools used: Manual code review informed by Anomaly Detector focus on FSM and wipe handshake; documentation cross-check.
- Recommendation: Consider tightening the clear condition so ERR_BITS cannot be cleared once a fatal condition forces the FSM to Locked (e.g., disallow clear when state_d == StatusLocked or while secure wipes are in progress), or document why current behavior is acceptable within the threat model. Note that FATAL_ALERT_CAUSE is RO and sticky, so primary fatal cause remains preserved.

Additional notes
- Register interface policies (writes ignored when not idle) for CMD and CTRL are enforced at the functional layer in otbn.sv (e.g., only act on reg2hw.cmd.qe when status_q == StatusIdle; the CTRL register value latched only when idle). The reg_top itself does not block writes, which aligns with the documented behavior.
- IMEM/DMEM bus adapters always grant requests and generate dummy responses while core is accessing memories; with proper blanking enable logic (Issue 1), reads during BUSY/LOCKED will return zeros and not leak data; illegal accesses correctly set the illegal_bus_access path. The unconditional enables must be fixed to make these guarantees effective.

What to do next (prioritized)
1) Fix Issue 1 immediately (IMEM/DMEM blanking enables). This is a direct confidentiality risk and contradicts the documented security mechanism and assertions.
2) Fix Issue 2 to restore the branch/jump target redundancy check; add directed tests.
3) Evaluate ERR_BITS clear gating (Issue 3) against system threat model; optionally harden.

Tools used summary
- Documentation review: theory_of_operation.md, registers.md
- Code review: otbn.sv, otbn_controller.sv, otbn_core.sv, otbn_instruction_fetch.sv, otbn_reg_top.sv
- Anomaly Detector Agent: to spot anomalous constants and suspicious control expressions.
- CWE Checker Agent: to map and assess confidentiality and control-flow integrity aspects (CWE-200/CWE-284/CWE-693 for blanking; CWE-1264/CWE-693 for control flow).
- Similar Bug Agent: to locate duplicate instances of the IMEM/DMEM blanking enable constant in otbn.sv.

END


Token Usage Summary:
===================
Total API Calls: 20
Total Input Tokens: 877,655
Total Output Tokens: 30,003
Total Tokens: 907,658
Average Input Tokens/Call: 43882.8
Average Output Tokens/Call: 1500.2
Average Total Tokens/Call: 45382.9


Detailed Call History:
==================================================
Call 1: gpt-5-2025-08-07 - Input: 1065, Output: 174, Total: 1239
Call 2: gpt-5-2025-08-07 - Input: 1197, Output: 41, Total: 1238
Call 3: gpt-5-2025-08-07 - Input: 1353, Output: 46, Total: 1399
Call 4: gpt-5-2025-08-07 - Input: 8627, Output: 44, Total: 8671
Call 5: gpt-5-2025-08-07 - Input: 13568, Output: 48, Total: 13616
Call 6: gpt-5-2025-08-07 - Input: 13835, Output: 52, Total: 13887
Call 7: gpt-5-2025-08-07 - Input: 27082, Output: 312, Total: 27394
Call 8: gpt-5-2025-08-07 - Input: 47629, Output: 2745, Total: 50374
Call 9: gpt-5-2025-08-07 - Input: 61335, Output: 51, Total: 61386
Call 10: gpt-5-2025-08-07 - Input: 83937, Output: 861, Total: 84798
Call 11: gpt-5-mini-2025-08-07 - Input: 17204, Output: 55, Total: 17259
Call 12: gpt-5-mini-2025-08-07 - Input: 19180, Output: 2861, Total: 22041
Call 13: gpt-5-2025-08-07 - Input: 85418, Output: 1993, Total: 87411
Call 14: gpt-5-2025-08-07 - Input: 85706, Output: 1836, Total: 87542
Call 15: gpt-5-2025-08-07 - Input: 86627, Output: 3450, Total: 90077
Call 16: gpt-5-2025-08-07 - Input: 92194, Output: 5143, Total: 97337
Call 17: gpt-5-mini-2025-08-07 - Input: 18870, Output: 120, Total: 18990
Call 18: gpt-5-mini-2025-08-07 - Input: 22084, Output: 5222, Total: 27306
Call 19: gpt-5-2025-08-07 - Input: 94942, Output: 81, Total: 95023
Call 20: gpt-5-2025-08-07 - Input: 95802, Output: 4868, Total: 100670
    
